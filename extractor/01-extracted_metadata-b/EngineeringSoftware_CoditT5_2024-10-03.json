{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 18:40:46"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/EngineeringSoftware/CoditT5",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "EngineeringSoftware",
                "type": "Organization"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2022-08-22T17:02:57Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-09-23T15:14:24Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/mit",
                "type": "License",
                "name": "MIT License",
                "url": "https://api.github.com/licenses/mit",
                "spdx_id": "MIT"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "MIT License\n\nCopyright (c) 2022 EngineeringSoftware\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/LICENSE"
        }
    ],
    "description": [
        {
            "result": {
                "value": "CoditT5: Pretraining for Source Code and Natural Language Editing",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "This repo contains the code and artifacts for reproducing the experiments in [CoditT5: Pretraining for Source Code and Natural Language Editing](https://arxiv.org/abs/2208.05446).\nIn this work, we introduce CoditT5 for software **edit** tasks. CoditT5 is a large Language Model pretrained with a novel objective to explicitly model edits. CoditT5 sets the state-of-the-art for downstream tasks including comment updating, bug fixing and automated code review.\n\nThe code includes:\n\n- scripts for synthesizing pretraining data for CoditT5\n- scripts for processing data for downstream tasks\n- scripts for training and evaluating CoditT5 on three downstream tasks\n- scripts for combining CoditT5 and CodeT5 through reranking\n\nThe artifacts include:\n\n- dataset used for pretraining CoditT5\n- datasets for downstream tasks\n- checkpoint for the pretrained CoditT5\n- checkpoints for the CoditT5 models fine-tuned for downstream tasks\n",
                "type": "Text_excerpt",
                "original_header": "Introduction",
                "parent_header": [
                    "CoditT5: Pretraining for Source Code and Natural Language Editing"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "\n1. [How to Use][sec-howto]\n2. [Dependency][sec-dependency]\n3. [Data Downloads][sec-downloads]\n4. [Code for Pretraining][sec-pretrain]\n5. [Code for Processing Fine-tuning Data][sec-process]\n6. [Code for Training and Evaluating Models][sec-traineval]\n7. [Code for Combining CodeT5 and CoditT5][sec-rerank]\n \n",
                "original_header": "Table of Contents"
            },
            "confidence": 0.9612237532571567,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "- `source_pl_file`: the path of data file where each line is a programming language function;\n- `tokenized_pl_file`: the path of tokenized version of `source_pl_file`;\n- `corrupt_pl_file`: corrupted version of `tokenized_pl_file` which is the input of pretrained model.\n- `source_nl_file`: the path of data file where each line is a natural language sequence;\n- `tokenized_nl_file`: the path of tokenized version of `source_nl_file`;\n- `corrupt_nl_file`: corrupted version of `tokenized_nl_file` which is the input of pretrained model.\n```\ncd python/\n./run.sh corrupt_pretrain_data\n```\n \n",
                "original_header": "Synthesize Pretraining Data"
            },
            "confidence": 0.9100040991661014,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "[sec-process]: #code-for-processing-fine-tuning-data \n- CoditT5's input data file name ends with `.buggy`; CoditT5's target output (edit plan + generation) file name ends with `.fixed`; target generation file name ends with `.seq`.\n- CoditT5's input is in the form of `source_sequence </s> context_sequence`; and CoditT5's output is in the form of `edit_plan <s> target_sequence`\n- Raw data files are stored in `raw_data/` (we provide some examples for demo), processed data files are generated to `data/CoditT5/${dataset}`\n- Note that for the comment-update dataset, the processed `edit_plan` is the edits applied to the comment w/o parameter (@return, @param)\n \n",
                "original_header": "Code for Processing Fine-tuning Data"
            },
            "confidence": 0.9582037913354512,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "[sec-rerank]: #code-for-combining-codet5-and-coditt5 \n",
                "original_header": "Code for Combining CodeT5 and CoditT5"
            },
            "confidence": 0.9040352604417008,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "CoditT5",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "EngineeringSoftware/CoditT5",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/EngineeringSoftware/CoditT5/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/EngineeringSoftware/CoditT5/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 29,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "machine-learning, pretrained-language-model, software-engineering",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 3,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/EngineeringSoftware/CoditT5/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 370046
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 10216
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "has_script_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/python/prepare_conda_env.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/python/run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/python/cdt/eval/CodeBLEU/parser/build.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "[sec-howto]: #how-to-use\n\n```python\nfrom transformers import T5ForConditionalGeneration, AutoTokenizer\n\ncheckpoint = \"JiyangZhang/CoditT5\"\n\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = T5ForConditionalGeneration.from_pretrained(checkpoint)\n\ncode_input = \"\"\"class HelloWorld { public static void main(String[] args) { System.out.println(\"Hello, World!\")\"\"\"\n\ninput_ids = tokenizer(code_input, return_tensors=\"pt\").input_ids\ngenerated_ids = model.generate(input_ids, max_length=200)\nprint(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n# output: <INSERT>; } } ;<INSERT_END> class HelloWorld { public static void main(String[] args) { System.out.println(\"Hello, World!\") ; } } ;\n```\n",
                "type": "Text_excerpt",
                "original_header": "How to Use",
                "parent_header": [
                    "CoditT5: Pretraining for Source Code and Natural Language Editing"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        }
    ],
    "requirements": [
        {
            "result": {
                "value": "[sec-dependency]: #dependency\n\nOur code require the following hardware and software environments.\n\n- Operating system: Linux (tested on Ubuntu 20.04)\n- Minimum disk space: 4 GB\n- Python: 3.8\n- Anaconda/Miniconda: appropriate versions for Python 3.8 or higher\n\nAdditional requirements for training and evaluating ML models:\n\n- GPU: NVIDIA GTX 1080 Ti or better (with >= 11GB memory)\n- CUDA: 10.2 or 11.3\n- Disk space: 2 GB per trained model\n\n[Anaconda](https://www.anaconda.com/products/individual#Downloads) or [Miniconda](https://docs.conda.io/en/latest/miniconda.html) is required for installing the other Python library dependencies. Once Anaconda/Miniconda is installed, you can use the following command to setup a virtual environment, named `cdt`, with the Python library dependencies installed:\n\n```\ncd python/\n./prepare_conda_env.sh\n```\n\nAnd then use `conda activate cdt` to activate the created virtual environment.\n",
                "type": "Text_excerpt",
                "original_header": "Dependency",
                "parent_header": [
                    "CoditT5: Pretraining for Source Code and Natural Language Editing"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        }
    ],
    "download": [
        {
            "result": {
                "value": "[sec-downloads]: #data-downloads\n\nAll our data is hosted on UTBox via [a zip file](https://utexas.box.com/s/9rkqnlp6wjhwyfmxce97pgb4ersfc1f9).\n\nData should be downloaded to this directory with the same directory structure (e.g., `data/` from the shared folder should be downloaded as `data/` under current directory).\n",
                "type": "Text_excerpt",
                "original_header": "Data Downloads",
                "parent_header": [
                    "CoditT5: Pretraining for Source Code and Natural Language Editing"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        }
    ],
    "installation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Requires the pretrain dataset at `data/CoditT5/pretrain/`\n```\ncd python/\n./run.sh pretrain_CoditT5\n```\n \n",
                "original_header": "Pretrain CoditT5"
            },
            "confidence": 0.995645850558155,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "We provide the sample script to process the downstream datasets for CoditT5. Requires the raw data files at `raw_data/`.\n```\ncd python/\n./run.sh process_coditT5_dataset --dataset ${dataset}\n\n# Example: ./run.sh process_coditT5_dataset --dataset comment-update\n```\n \n",
                "original_header": "Code for Processing Fine-tuning Data"
            },
            "confidence": 0.9999946804638516,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "```\ncd python/\n# Rerank CodeT5's outputs with CoditT5\n./run.sh CodeT5_rerank ${dataset}\n# Rerank CoditT5's outputs with CodeT5\n./run.sh CodeT5_rerank ${dataset}\n\n# Example: ./run.sh CoditT5_rerank comment-update\n``` \n",
                "original_header": "Rerank Models' outputs"
            },
            "confidence": 0.9999892885860772,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        }
    ],
    "invocation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "We provide the sample script to process the downstream datasets for CoditT5. Requires the raw data files at `raw_data/`.\n```\ncd python/\n./run.sh process_coditT5_dataset --dataset ${dataset}\n\n# Example: ./run.sh process_coditT5_dataset --dataset comment-update\n```\n \n",
                "original_header": "Code for Processing Fine-tuning Data"
            },
            "confidence": 0.95244128160778,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Requires the dataset at `data/${model}/${dataset}/`, where `${model}` is the name of the model (CodeT5, CoditT5); `${dataset}` is the name of the dataset.\n```\ncd python/\n./run.sh ${model}_train ${dataset}\n\n# Example: ./run.sh CoditT5_train comment-update\n```\n \n",
                "original_header": "Train ML models"
            },
            "confidence": 0.9164964464062724,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Requires the dataset at `data/${model}/${dataset}/`, the trained model at `models/${model}/${dataset}/model/`.\n```\ncd python/\n./run.sh ${model}_generate ${dataset}\n\n# Example: ./run.sh CoditT5_generate comment-update\n```\n \n",
                "original_header": "Evaluate ML models"
            },
            "confidence": 0.938549044336453,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Requires the model's reranking results file\n`results/reranks/test-${dataset}-${model}-top-20-rerank-${reranker}-results.json`.\n```\n./run.sh eval_rerank_${model}_${reranker} ${dataset}\n\n# Example: compute metrics for top 1 CoditT5 prediction reranked by CodeT5\n./run.sh eval_rerank_CoditT5_CodeT5 comment-update\n```\n \n",
                "original_header": "Rerank Models' outputs"
            },
            "confidence": 0.9454855684111076,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "@inproceedings{ZhangETAL22CoditT5,\n    year = {2022},\n    booktitle = {International Conference on Automated Software Engineering},\n    title = {Codit{T}5: Pretraining for Source Code and Natural Language Editing},\n    author = {Zhang, Jiyang and Panthaplackel, Sheena and Nie, Pengyu and Li, Junyi Jessy and Gligoric, Milos},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "title": "Codit{T}5: Pretraining for Source Code and Natural Language Editing",
                "author": "Zhang, Jiyang and Panthaplackel, Sheena and Nie, Pengyu and Li, Junyi Jessy and Gligoric, Milos"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "CoditT5: Pretraining for Source Code and Natural Language Editing"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2208.05446"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/CoditT5/main/README.md"
        }
    ]
}
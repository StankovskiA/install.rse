{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 20:56:19"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/gmy2013/LLM_Comment_Generation",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "gmy2013",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2023-06-08T14:49:12Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-09-27T12:27:16Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "description": [
        {
            "result": {
                "value": "Source Code for Paper \"Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning\"",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Code comment generation aims at generating natural language descriptions for a code snippet to facilitate developers' program comprehension activities.\nDespite being studied for a long time, a bottleneck for existing approaches is that given a code snippet, they can only generate one comment while developers usually need to know information from diverse perspectives such as what is the functionality of this code snippet and how to use it.\nTo tackle this limitation, this study empirically investigates the feasibility of utilizing large language models (LLMs) to generate comments that can fulfill developers' diverse intents.\nOur intuition is based on the facts that (1) the code and its pairwise comment are used during the pre-training process of LLMs to build the semantic connection between the natural language and programming language, and (2) comments in the real-world projects, which are collected for the pre-training, usually contain different developers' intents.\nWe thus postulate that the LLMs can already understand the code from different perspectives after the pre-training.\nIndeed, experiments on two large-scale datasets demonstrate the rationale of our insights: by adopting the in-context learning paradigm and giving adequate prompts to the LLM (\\eg providing it with ten or more examples), the LLM can significantly outperform a state-of-the-art supervised learning approach on generating comments with multiple intents.\nResults also show that customized strategies for constructing the prompts and post-processing strategies for reranking the results can both boost the LLM's performances, which shed light on future research directions for using LLMs to achieve comment generation. \n",
                "original_header": "Abstract"
            },
            "confidence": 0.9924180885891709,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/gmy2013/LLM_Comment_Generation/main/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "LLM_Comment_Generation",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "gmy2013/LLM_Comment_Generation",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/gmy2013/LLM_Comment_Generation/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/gmy2013/LLM_Comment_Generation/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 12,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 2,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/gmy2013/LLM_Comment_Generation/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 30056
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/gmy2013/LLM_Comment_Generation/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "OS: Ubuntu 18.04.  \nHardwares: Hygon C86 7385 32-core CPU 2.50GHz machine.  \nThe dataset we used are funcom.test, funcom.train, tlcodesum.test and tlcodesum.train.  \nThe comment categories are \"what\", \"why\", \"how-to-use\", \"how-it-is-done\", \"property\".  \nExample:\n```json\n{\n\"id\": \"53306\",\n\"raw_code\": \"public static int unionSize(long[] x,long[] y){\\n final int lx=x.length, ly=y.length;\\n final int min=(lx < ly) ? lx : ly;\\n int i=0, res=0;\\n for (; i < min; i++) {\\n res+=Long.bitCount(x[i] | y[i]);\\n }\\n for (; i < lx; i++) {\\n res+=Long.bitCount(x[i]);\\n }\\n for (; i < ly; i++) {\\n res+=Long.bitCount(y[i]);\\n }\\n return res;\\n}\",\n\"comment\": \"compute the union size of two bitsets .\",\n\"label\": \"what\"\n}\n```",
                "type": "Text_excerpt",
                "original_header": "Get Started",
                "parent_header": [
                    "Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning (ICSE 2024)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/gmy2013/LLM_Comment_Generation/main/README.md"
        },
        {
            "result": {
                "value": "First, preprocess the dataset to get the similarity scores for each code in the test set.\n```\npython preprocess.py\n```\nThen, you will get the \"sim_token.txt\" and \"sim_semantic.txt\", representing the similarities based on token and semantic respectively.\n",
                "type": "Text_excerpt",
                "original_header": "1. Pre-process",
                "parent_header": [
                    "Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning (ICSE 2024)",
                    "Get Started"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/gmy2013/LLM_Comment_Generation/main/README.md"
        },
        {
            "result": {
                "value": "You can generate the comment for different intents following the corresponding prompt using \"random\", \"retrieve\", \"rerank\" settings.\nThe default number of demonstrations is set to 10 in our code. \nFor the retrieve and rerank settings, you can choose ['false', 'semantic', 'token'].\nFor example, to run the random setting:\n```\npython test_codex.py --random\n```\nTo run the semantic-based retrieve setting:\n```\npython test_codex.py --rerank false --retrieve semantic\n```\nTo run the token-based rerank setting:\n```\npython test_codex.py --rerank token --retrieve false\n```\nTo run the token-based rerank and semantic-based retrieve setting:\n```\npython test_codex.py --rerank token --retrieve semantic\n```\n",
                "type": "Text_excerpt",
                "original_header": "2. Generate the Comments using Codex",
                "parent_header": [
                    "Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning (ICSE 2024)",
                    "Get Started"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/gmy2013/LLM_Comment_Generation/main/README.md"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "```\n@article{geng2023empirical,\n  title={An Empirical Study on Using Large Language Models for Multi-Intent Comment Generation},\n  author={Geng, Mingyang and Wang, Shangwen and Dong, Dezun and Wang, Haotian and Li, Ge and Jin, Zhi and Mao, Xiaoguang and Liao, Xiangke},\n  journal={arXiv preprint arXiv:2304.11384},\n  year={2023}\n}\n```\n\n\n\n\n",
                "type": "Text_excerpt",
                "original_header": "Citation",
                "parent_header": [
                    "Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning (ICSE 2024)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/gmy2013/LLM_Comment_Generation/main/README.md"
        },
        {
            "result": {
                "value": "@article{geng2023empirical,\n    year = {2023},\n    journal = {arXiv preprint arXiv:2304.11384},\n    author = {Geng, Mingyang and Wang, Shangwen and Dong, Dezun and Wang, Haotian and Li, Ge and Jin, Zhi and Mao, Xiaoguang and Liao, Xiangke},\n    title = {An Empirical Study on Using Large Language Models for Multi-Intent Comment Generation},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "title": "An Empirical Study on Using Large Language Models for Multi-Intent Comment Generation",
                "author": "Geng, Mingyang and Wang, Shangwen and Dong, Dezun and Wang, Haotian and Li, Ge and Jin, Zhi and Mao, Xiaoguang and Liao, Xiangke"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/gmy2013/LLM_Comment_Generation/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning (ICSE 2024)"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/gmy2013/LLM_Comment_Generation/main/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/pdf/2304.11384.pdf"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/gmy2013/LLM_Comment_Generation/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2304.11384"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/gmy2013/LLM_Comment_Generation/main/README.md"
        }
    ]
}
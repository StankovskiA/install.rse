{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 18:37:09"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/neulab/incremental_tree_edit",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "neulab",
                "type": "Organization"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2021-01-22T21:40:38Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-02-15T04:49:45Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/mit",
                "type": "License",
                "name": "MIT License",
                "url": "https://api.github.com/licenses/mit",
                "spdx_id": "MIT"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "MIT License\n\nCopyright (c) 2021 NeuLab\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/LICENSE"
        }
    ],
    "description": [
        {
            "result": {
                "value": "Code for \"Learning Structural Edits via Incremental Tree Transformations\" (ICLR'21)",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Code for [\"Learning Structural Edits via Incremental Tree Transformations\" (ICLR'21)](https://openreview.net/pdf?id=v9hAX77--cZ) \n",
                "original_header": "Learning Structural Edits via Incremental Tree Transformations"
            },
            "confidence": 0.9260000331103733,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "If you use our code and data, please cite our paper: \n"
            },
            "confidence": 0.9511684505857537,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "incremental_tree_edit",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "neulab/incremental_tree_edit",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/neulab/incremental_tree_edit/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/neulab/incremental_tree_edit/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 40,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 4,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/neulab/incremental_tree_edit/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 681127
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 2785
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "has_script_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/scripts/githubedits/train.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/scripts/githubedits/test.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "installation": [
        {
            "result": {
                "value": "We recommend using `conda` to manage the environment:\n```\nconda env create -n \"structural_edits\" -f structural_edits.yml\nconda activate structural_edits\n```\n\nInstall the punkt tokenizer:\n```\npython\n>>> import nltk\n>>> nltk.download('punkt')\n>>> <ctrl-D>\n```\n",
                "type": "Text_excerpt",
                "original_header": "1. Prepare Environment",
                "parent_header": [
                    "Learning Structural Edits via Incremental Tree Transformations"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Please extract the datasets and vocabulary files by:\n```\ncd source_data\ntar -xzvf githubedits.tar.gz\n``` \n",
                "original_header": "2. Data"
            },
            "confidence": 0.9998330703624331,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "See training and test scripts in `scripts/githubedits/`. Please configure the `PYTHONPATH` environment variable in line 6.\n  \n",
                "original_header": "3. Experiments"
            },
            "confidence": 0.9985053246401927,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "To further train the model with PostRefine imitation learning, \nplease replace `FOLDER_OF_SUPERVISED_PRETRAINED_MODEL` with your model dir in `source_data/githubedits/configs/graph2iteredit.seq_edit_encoder.20p.postrefine.imitation.json`.\nUncomment only line 27-31 in `scripts/githubedits/train.sh` and run:\n```\nbash scripts/githubedits/train.sh source_data/githubedits/configs/graph2iteredit.seq_edit_encoder.20p.postrefine.imitation.json\n```\nNote that `--small_memory` cannot be used in this setting.\n \n",
                "original_header": "3.1.2 Imitation Learning"
            },
            "confidence": 0.9305972989480313,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        }
    ],
    "faq": [
        {
            "result": {
                "value": " \nIn principle, our framework can work with various programming languages. \nTo this end, several changes are needed:\n1. Implementing a language-specific `ASDLGrammar` class for the new language. \n    - This class could inherit the [`asdl.asdl.ASDLGrammar`](asdl/asdl.py) class.\n    - Basic functions should include \n        - Defining the `primitive` and `composite` types, \n        - Implementing the class constructor (e.g., converting from the `.xml` or `.txt` syntax descriptions),\n        - Converting the source AST data into an `asdl.asdl_ast.AbstractSyntaxTree` object.\n    - Example: see the [`asdl.lang.csharp.CSharpASDLGrammar`](asdl/lang/csharp/csharp_grammar.py) class.\n    - **Sanity check**: It is very helpful to implement a `demo_edits.py` file like [this one for csharp](asdl/lang/csharp/demo_edits.py) and \n        make sure you have checked out the generated ASTs and target edit sequences.\n    - **Useful resource**: The [TranX](https://github.com/pcyin/tranx) library contains ASDLGrammar classes for some other languages.\n        _Note that we have revised the `asdl.asdl.ASDLGrammar` class so directly using the TranX implementation may not work._\n        However, this resource is still a good starting point; you may consider modify it based on the sanity check outputs.\n        \n2. Implementing a language-specific `TransitionSystem` class.\n    - The target edit sequences (of the training data) are calculated by `trees.substitution_system.SubstitutionSystem`,\n        which depends on a `asdl.transition_system.TransitionSystem` object (or its inheritor) (see [reference](trees/substitution_system.py#L16)). \n    - In our current implementation of CSharp, we have reused the `CSharpTransitionSystem` class implemented in the [Graph2Tree library](https://github.com/microsoft/iclr2019-learning-to-represent-edits).\n        However, only the `get_primitive_field_actions` function of the `TransitionSystem` class is actually used by the `SubstitutionSystem` ([example](trees/substitution_system.py#L131)). \n        Therefore, for simplicity, one can only implement only this function. \n        Basically, this `get_primitive_field_actions` function defines how the leaf string should be generated \n        (e.g., multiple `GenTokenAction` actions should be taken for generating a multi-word leaf string), which we will discuss next.\n\n3. Customizing the leaf string generation.\n    - Following the last item, one may also need to customize the `GenTokenAction` action especially about whether and how the [stop signal](asdl/transition_system.py#L29) will be used.\n        For CSharp, we do not use detect any stop signal as in our datasets the leaf string is typically one single-word token.\n        However, it will be needed when the leaf string contains multiple words.\n    - Accordingly, one may customize the [`Add`](/trees/edits.py#L61) edit action and the [`SubstitutionSystem`](trees/substitution_system.py#L170) \n        regarding how the leaf string should be added to the current tree.\n        \n",
                "type": "Text_excerpt",
                "original_header": "4.1 Applications to Other Languages",
                "parent_header": [
                    "Learning Structural Edits via Incremental Tree Transformations",
                    "4. FAQ"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        },
        {
            "result": {
                "value": "**The issue:**\nBy default, the data preprocessing step will \n(1) run a dynamic programming algorithm to calculate the shortest edit sequence `(a_1, a_2, ..., a_T)`\n    as the target edit sequence for each code pair `(C-, C+)`, and \n(2) save every intermediate tree graph `(g_1, g_2, ..., g_T)`, where `g_{t+1}` is the transformation result of \n    applying edit action `a_t` to tree `g_t` at time step `t`, as the input to the tree encoder (see [3.1.2 in our paper](https://openreview.net/pdf?id=v9hAX77--cZ)).\nTherefore, a completely preprocessed training set has a very large size and will take up a lot of CPU memory\nevery time you load the data for model training.\n\n**The solution:**\nA simple solution is to avoid saving any intermediate tree graph, \ni.e., we will only save the shortest edit sequence results from (1) \nwhile leaving the generation of intermediate tree graphs in (2) to during the model training.\nThis can be done by set `--small_memory` in the [train.sh](scripts/githubedits/train.sh) script. \n_Currently this option can only be used for regular supervised learning; for imitation learning, this has to be off._\n\nNote that there will be a trade-off between the CPU memory and the GPU utility/training speed, \nsince the generation of the intermediate tree graphs is done at the CPU level.\n",
                "type": "Text_excerpt",
                "original_header": "4.2 Out of Memory Issue",
                "parent_header": [
                    "Learning Structural Edits via Incremental Tree Transformations",
                    "4. FAQ"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        }
    ],
    "invocation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "To test a trained model, first uncomment only the desired setting in `scripts/githubedits/test.sh` and replace `work_dir` with your model directory, \nand then run:\n```\nbash scripts/githubedits/test.sh\n```\nPlease check out the `TODO`'s in [`scripts/githubedits/test.sh`](scripts/githubedits/test.sh).\n \n",
                "original_header": "3.2 Test"
            },
            "confidence": 0.9264212238073419,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "@inproceedings{yao2021learning,\n    url = {https://openreview.net/forum?id=v9hAX77--cZ},\n    year = {2021},\n    booktitle = {International Conference on Learning Representations},\n    author = {Ziyu Yao and Frank F. Xu and Pengcheng Yin and Huan Sun and Graham Neubig},\n    title = {Learning Structural Edits via Incremental Tree Transformations},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "title": "Learning Structural Edits via Incremental Tree Transformations",
                "author": "Ziyu Yao and Frank F. Xu and Pengcheng Yin and Huan Sun and Graham Neubig",
                "url": "https://openreview.net/forum?id=v9hAX77--cZ"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        },
        {
            "result": {
                "value": "@inproceedings{yin18emnlpdemo,\n    year = {2018},\n    booktitle = {Conference on Empirical Methods in Natural Language Processing (EMNLP) Demo Track},\n    author = {Pengcheng Yin and Graham Neubig},\n    title = {{TRANX}: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "title": "{TRANX}: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation",
                "author": "Pengcheng Yin and Graham Neubig"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        },
        {
            "result": {
                "value": "@inproceedings{yin2018learning,\n    url = {https://openreview.net/forum?id=BJl6AjC5F7},\n    year = {2019},\n    booktitle = {International Conference on Learning Representations},\n    author = {Pengcheng Yin and Graham Neubig and Miltiadis Allamanis and Marc Brockschmidt and Alexander L. Gaunt},\n    title = {Learning to Represent Edits},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "title": "Learning to Represent Edits",
                "author": "Pengcheng Yin and Graham Neubig and Miltiadis Allamanis and Marc Brockschmidt and Alexander L. Gaunt",
                "url": "https://openreview.net/forum?id=BJl6AjC5F7"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Learning Structural Edits via Incremental Tree Transformations"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/incremental_tree_edit/master/README.md"
        }
    ]
}
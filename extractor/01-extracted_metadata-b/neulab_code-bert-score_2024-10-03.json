{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 18:53:30"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/neulab/code-bert-score",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "neulab",
                "type": "Organization"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2022-09-18T16:40:46Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-10-01T14:58:23Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/mit",
                "type": "License",
                "name": "MIT License",
                "url": "https://api.github.com/licenses/mit",
                "spdx_id": "MIT"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "MIT License\n\nCopyright (c) 2023 Shuyan Zhou, Uri Alon, Sumit Agarwal, and Graham Neubig.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/LICENSE"
        }
    ],
    "description": [
        {
            "result": {
                "value": "CodeBERTScore: an automatic metric for code generation, based on BERTScore",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "This is the official implementation of the paper: \nCodeBERTScore is an Automatic Evaluation Metric for Code, based on [BERTScore](https://arxiv.org/abs/1904.09675).\nThis repository is based on the code of [BERTScore](https://github.com/Tiiiger/bert_score), and we are grateful to the authors for releasing their code. \n",
                "original_header": "CodeBERTScore"
            },
            "confidence": 0.9820455538197457,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "* Tuning the layer that the similarity is computed from is also helpful, using `num_layers=N` where `N` is between 5-10:  \n",
                "original_header": "Additional Features"
            },
            "confidence": 0.914833895420723,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "We find that CodeBERTScore is more correlated with human preference compared to a variety of common metrics. See more details in the [paper](https://arxiv.org/pdf/2302.05527.pdf).\n \n",
                "original_header": "Human Evaluation"
            },
            "confidence": 0.9810495968692158,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "We find that CodeBERTScore is more correlated with functional correctness compared to a variety of common metrics. See more details in the [paper](https://arxiv.org/pdf/2302.05527.pdf).\n \n",
                "original_header": "Functional Correctness"
            },
            "confidence": 0.9702580886019301,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "code-bert-score",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "neulab/code-bert-score",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/neulab/code-bert-score/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/neulab/code-bert-score/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 158,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "bert, bertscore, code, code-bert-score, code-bertscore, codebert, codebertscore, score",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 16,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/neulab/code-bert-score/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Jupyter Notebook",
                "name": "Jupyter Notebook",
                "type": "Programming_language",
                "size": 382467
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 133230
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 1415
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "releases": [
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/neulab/code-bert-score/releases/107553995",
                "tag": "v0.4.1",
                "name": "0.4.1",
                "author": {
                    "name": "urialon",
                    "type": "User"
                },
                "description": "Adding a default baseline of 0.5",
                "tarball_url": "https://api.github.com/repos/neulab/code-bert-score/tarball/v0.4.1",
                "zipball_url": "https://api.github.com/repos/neulab/code-bert-score/zipball/v0.4.1",
                "html_url": "https://github.com/neulab/code-bert-score/releases/tag/v0.4.1",
                "url": "https://api.github.com/repos/neulab/code-bert-score/releases/107553995",
                "release_id": 107553995,
                "date_created": "2023-06-06T17:59:56Z",
                "date_published": "2023-06-06T18:00:45Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/neulab/code-bert-score/releases/101274017",
                "tag": "v0.4.0",
                "name": "Initial release of CodeBERTScore",
                "author": {
                    "name": "urialon",
                    "type": "User"
                },
                "tarball_url": "https://api.github.com/repos/neulab/code-bert-score/tarball/v0.4.0",
                "zipball_url": "https://api.github.com/repos/neulab/code-bert-score/zipball/v0.4.0",
                "html_url": "https://github.com/neulab/code-bert-score/releases/tag/v0.4.0",
                "url": "https://api.github.com/repos/neulab/code-bert-score/releases/101274017",
                "release_id": 101274017,
                "date_created": "2023-04-28T12:47:10Z",
                "date_published": "2023-04-28T12:47:50Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "@article{zhou2023codebertscore,\n  url = {https://arxiv.org/abs/2302.05527},\n  author = {Zhou, Shuyan and Alon, Uri and Agarwal, Sumit and Neubig, Graham},\n  title = {CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code},  \n  publisher = {arXiv},\n  year = {2023},\n}\n",
                "type": "File_dump",
                "format": "cff"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/citation.cff"
        },
        {
            "result": {
                "value": "```\n@article{zhou2023codebertscore,\n  url = {https://arxiv.org/abs/2302.05527},\n  author = {Zhou, Shuyan and Alon, Uri and Agarwal, Sumit and Neubig, Graham},\n  title = {CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code},  \n  publisher = {arXiv},\n  year = {2023},\n}\n```\n",
                "type": "Text_excerpt",
                "original_header": "Citation",
                "parent_header": [
                    "CodeBERTScore"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "value": "@article{zhou2023codebertscore,\n    year = {2023},\n    publisher = {arXiv},\n    title = {CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code},\n    author = {Zhou, Shuyan and Alon, Uri and Agarwal, Sumit and Neubig, Graham},\n    url = {https://arxiv.org/abs/2302.05527},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "title": "CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code",
                "author": "Zhou, Shuyan and Alon, Uri and Agarwal, Sumit and Neubig, Graham",
                "url": "https://arxiv.org/abs/2302.05527"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "has_script_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/neulab/code-bert-score/main/tune_layers/download_data.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/neulab/code-bert-score/main/tune_layers/tune.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/neulab/code-bert-score/main/evaluation/run_score.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "executable_example": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/neulab/code-bert-score/main/example/Demo.ipynb",
                "type": "Url",
                "format": "jupyter_notebook"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/example/Demo.ipynb"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "![](./images/example.png \"Example\")\n\nFigure (a) shows a reference code snippet in Java. Figures (b) and (c) show two generated predictions. Among these two candidates and given the reference, BLEU prefers (scores higher) the code in (b), which is not functionally equivalent to the reference, while CodeBERTScore prefers the code in (c), which is functionaly equivalent to the reference.\n",
                "type": "Text_excerpt",
                "original_header": "Example:",
                "parent_header": [
                    "CodeBERTScore"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "value": "```\nimport code_bert_score\npred_results = code_bert_score.score(cands=predictions, refs=refs, lang='python')\n```\nWhere `pred_results` is a 4-tuple of `(precision, recall, F1, F3)`, where each is a 1-D tensor of scores for each prediction-reference pair. `F3` is similar to the well-known `F1` score, that considers recall 3 times as important as precision. See the [definition on Wikipedia](https://en.wikipedia.org/wiki/F-score#F%CE%B2_score).\n\nSee our [example.py](./example.py) script. Additional details are shown in the original BERTScore [demo notebook](./example/Demo.ipynb).\n",
                "type": "Text_excerpt",
                "original_header": "Usage",
                "parent_header": [
                    "CodeBERTScore"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        }
    ],
    "installation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "_**April 2023**_ - CodeBERTScore is now available on [pypi](https://pypi.org/project/code-bert-score/), which means that you can simply `pip install code-bert-score`! \n",
                "original_header": "CodeBERTScore"
            },
            "confidence": 0.999993498426168,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        }
    ],
    "invocation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "The appropriate model will be loaded automatically when passing the `lang` argument to the `score(..)` function, for example: `lang='python'`. \nFor other uses, these models can be loaded using (for example):\n```python\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"neulab/codebert-python\")\nmodel = AutoModelForMaskedLM.from_pretrained(\"neulab/codebert-python\")\n```\n \n",
                "original_header": "Huggingface \ud83e\udd17 Models"
            },
            "confidence": 0.9159011800140597,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "CodeBERTScore"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        }
    ],
    "images": [
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/neulab/code-bert-score/main/./images/example.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/neulab/code-bert-score/main/./images/flow.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/neulab/code-bert-score/main/./images/layer.jpg"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/neulab/code-bert-score/main/./images/human.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/neulab/code-bert-score/main/./images/functional.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/1904.09675"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2302.05527"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/pdf/2302.05527.pdf"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/neulab/code-bert-score/main/README.md"
        }
    ]
}
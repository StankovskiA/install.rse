{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 19:10:10"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/github/CodeSearchNet",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "github",
                "type": "Organization"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2019-02-28T17:22:54Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-10-01T13:11:38Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/mit",
                "type": "License",
                "name": "MIT License",
                "url": "https://api.github.com/licenses/mit",
                "spdx_id": "MIT"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "MIT License\n\nCopyright (c) 2019 GitHub\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/LICENSE"
        },
        {
            "result": {
                "value": "The licenses for source code used as data for this project are provided with the [data download](#downloading-data-from-s3) for each language in `_licenses.pkl` [files](resources/README.md#directory-structure).\n\nThis code and documentation for this project are released under the [MIT License](LICENSE).\n",
                "type": "Text_excerpt",
                "original_header": "Licenses",
                "parent_header": [
                    "References"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ],
    "description": [
        {
            "result": {
                "value": "Datasets, tools, and benchmarks for representation learning of code.",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "  [CodeSearchNet][paper] is a collection of datasets and benchmarks that explore the problem of code retrieval using natural language.  This research is a continuation of some ideas presented in this [blog post](https://githubengineering.com/towards-natural-language-semantic-code-search/) and is a joint collaboration between GitHub and the [Deep Program Understanding](https://www.microsoft.com/en-us/research/project/program/) group at [Microsoft Research - Cambridge](https://www.microsoft.com/en-us/research/lab/microsoft-research-cambridge/).  We aim to provide a platform for community research on semantic code search via the following: \n\n  1. Instructions for obtaining large corpora of relevant data\n  2. Open source code for a range of baseline models, along with pre-trained weights\n  3. Baseline evaluation metrics and utilities\n  4. Mechanisms to track progress on a [shared community benchmark](https://app.wandb.ai/github/CodeSearchNet/benchmark) hosted by [Weights & Biases](https://www.wandb.com/)\n\nWe hope that CodeSearchNet is a step towards engaging with the broader machine learning and NLP community regarding the relationship between source code and natural language. We describe a specific task here, but we expect and welcome other uses of our dataset.\n\nMore context regarding the motivation for this problem is in this [technical report][paper]. Please, cite the dataset and the challenge as\n```\n@article{husain2019codesearchnet,\n  title={{CodeSearchNet} challenge: Evaluating the state of semantic code search},\n  author={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\n  journal={arXiv preprint arXiv:1909.09436},\n  year={2019}\n}\n```\n",
                "type": "Text_excerpt",
                "original_header": "Project Overview",
                "parent_header": [
                    "Introduction"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "value": "  The primary dataset consists of 2 million (`comment`, `code`) pairs from open source libraries.  Concretely, a `comment` is a top-level function or method comment (e.g. [docstrings](https://en.wikipedia.org/wiki/Docstring) in Python), and `code` is an entire function or method. Currently, the dataset contains Python, Javascript, Ruby, Go, Java, and PHP code.  Throughout this repo, we refer to the terms docstring and query interchangeably.  We partition the data into train, validation, and test splits such that code from the same repository can only exist in one partition. Currently this is the only dataset on which we train our model. Summary statistics about this dataset can be found in [this notebook](notebooks/ExploreData.ipynb)\n\n  For more information about how to obtain the data, see [this section](#data-details).\n",
                "type": "Text_excerpt",
                "original_header": "Data",
                "parent_header": [
                    "Introduction"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "value": "  The metric we use for evaluation is [Normalized Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain#Normalized_DCG).  Please reference [this paper][paper] for further details regarding model evaluation. The evaluation script can be found [here](/src/relevanceeval.py).\n",
                "type": "Text_excerpt",
                "original_header": "Evaluation",
                "parent_header": [
                    "Introduction"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "value": "  We manually annotated retrieval results for the six languages from 99 general [queries](resources/queries.csv). This dataset is used as groundtruth data for evaluation _only_. Please refer to [this paper][paper] for further details on the annotation process. These annotations were used to compute the scores in the leaderboard. Now that the competition has been concluded, you can find the annotations, along with the annotator comments [here](/resources/annotationStore.csv).\n\n",
                "type": "Text_excerpt",
                "original_header": "Annotations",
                "parent_header": [
                    "Introduction",
                    "Evaluation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "> # The CodeSearchNet challenge has been concluded\n> We would like to thank all participants for their submissions\n> and we hope that this challenge provided insights to practitioners and researchers about the challenges in semantic code search and motivated new research. We would like to encourage everyone to continue using the dataset and the human evaluations, which we now provide publicly. Please, see below for details, specifically the [Evaluation](https://github.com/github/CodeSearchNet#evaluation) section.\n>\n> No new submissions to the challenge will be accepted. \n**Table of Contents** \n",
                "original_header": "The CodeSearchNet challenge has been concluded"
            },
            "confidence": 0.9623587309787651,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "- **repo:** the owner/repo\n- **path:** the full path to the original file\n- **func_name:** the function or method name\n- **original_string:** the raw string before tokenization or parsing\n- **language:** the programming language\n- **code:** the part of the `original_string` that is code\n- **code_tokens:** tokenized version of `code`\n- **docstring:** the top-level comment or docstring, if it exists in the original string\n- **docstring_tokens:** tokenized version of `docstring`\n- **sha:** this field is not being used [TODO: add note on where this comes from?]\n- **partition:** a flag indicating what partition this datum belongs to of {train, valid, test, etc.} This is not used by the model.  Instead we rely on directory structure to denote the partition of the data.\n- **url:** the url for the code snippet including the line numbers \n",
                "original_header": "Schema &amp; Format"
            },
            "confidence": 0.9454123707852822,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "CodeSearchNet",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "github/CodeSearchNet",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/github/CodeSearchNet/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/github/CodeSearchNet/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 2192,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "bert, cnn, data, data-science, datasets, deep-learning, machine-learning, machine-learning-on-source-code, ml, natural-language-processing, neural-networks, nlp, nlp-machine-learning, open-data, programming-language-theory, python, representation-learning, rnn, self-attention, tensorflow",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 386,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/github/CodeSearchNet/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Jupyter Notebook",
                "name": "Jupyter Notebook",
                "type": "Programming_language",
                "size": 368173
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 291937
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Dockerfile",
                "name": "Dockerfile",
                "type": "Programming_language",
                "size": 4008
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 1535
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "code_of_conduct": [
        {
            "result": {
                "value": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at opensource@github.com. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/CODE_OF_CONDUCT.md"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "contributing_guidelines": [
        {
            "result": {
                "value": "## Contributing\n\n[fork]: https://help.github.com/articles/fork-a-repo/\n[pr]: https://help.github.com/articles/creating-a-pull-request/\n[style]: https://www.python.org/dev/peps/pep-0008/\n[code-of-conduct]: CODE_OF_CONDUCT.md\n[azurepipelines]: azure-pipelines.yml\n[benchmark]: BENCHMARK.md\n\nHi there! We're thrilled that you'd like to contribute to this project. Your help is essential for keeping it great.\n\nContributions to this project are [released](https://help.github.com/articles/github-terms-of-service/#6-contributions-under-repository-license) to the public under the [project's open source license](LICENSE).\n\nPlease note that this project is released with a [Contributor Code of Conduct][code-of-conduct]. By participating in this project you agree to abide by its terms.\n\n## Scope\n\nWe want to use this repository to distribute the best data pre-processing and loading pipeline for the CodeSearchNet dataset.\nAs we anticipate other data scientists and researchers to design many custom architectures and use frameworks other than Tensorflow, we do not want to update the models in this repository beyond the simple baselines we originally released.\nTherefore, we are accepting pull requests for the following items:\n\n- Improvements of the data pre-processing pipeline (e.g. better cleaning heuristics, new supported languages, etc.)\n- Documentation updates that help others use the dataset\n- Documentation updates with links to your project(s) where improvements to the baseline have been made\n- Bug fixes for bugs in the baseline models (i.e., not better hyperparameter settings)\n\nPlease open an issue if you are unsure regarding the best course of action.  \n\n## Submitting a pull request\n\n0. [Fork][fork] and clone the repository\n0. Configure and install the dependencies: `script/bootstrap`\n0. Make sure the tests pass on your machine: see [azure-pipelines.yml][azurepipelines] to see tests we are currently running.\n0. Create a new branch: `git checkout -b my-branch-name`\n0. Make your change, add tests, and make sure the tests still pass.\n0. Push to your fork and [submit a pull request][pr]\n0. Pat your self on the back and wait for your pull request to be reviewed and merged.\n\nHere are a few things you can do that will increase the likelihood of your pull request being accepted:\n\n- Follow the [style guide][style].\n- Write tests.\n- Keep your change as focused as possible. If there are multiple changes you would like to make that are not dependent upon each other, consider submitting them as separate pull requests.\n- Write a [good commit message](http://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html).\n\n## Resources\n\n- [How to Contribute to Open Source](https://opensource.guide/how-to-contribute/)\n- [Using Pull Requests](https://help.github.com/articles/about-pull-requests/)\n- [GitHub Help](https://help.github.com)\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/CONTRIBUTING.md"
        },
        {
            "result": {
                "value": "  We anticipate that the community will design custom architectures and use frameworks other than Tensorflow.  Furthermore, we anticipate that additional datasets will be useful.  It is not our intention to integrate these models, approaches, and datasets into this repository as a superset of all available ideas.  Rather, we intend to maintain the baseline models and links to the data in this repository as a central place of reference.  We are accepting PRs that update the documentation, link to your project(s) with improved benchmarks, fix bugs, or make minor improvements to the code.  Here are [more specific guidelines for contributing to this repository](CONTRIBUTING.md); note particularly our [Code of Conduct](CODE_OF_CONDUCT.md).  Please open an issue if you are unsure of the best course of action.  \n",
                "type": "Text_excerpt",
                "original_header": "How to Contribute",
                "parent_header": [
                    "References"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ],
    "has_build_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/github/CodeSearchNet/master/function_parser/Dockerfile",
                "type": "Url",
                "format": "dockerfile"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/function_parser/Dockerfile"
        }
    ],
    "executable_example": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/github/CodeSearchNet/master/function_parser/function_parser/demo.ipynb",
                "type": "Url",
                "format": "jupyter_notebook"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/function_parser/function_parser/demo.ipynb"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/github/CodeSearchNet/master/notebooks/ExploreData.ipynb",
                "type": "Url",
                "format": "jupyter_notebook"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/notebooks/ExploreData.ipynb"
        }
    ],
    "documentation": [
        {
            "result": {
                "value": "https://github.com/github/CodeSearchNet/tree/master/src/docs",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "type": [
        {
            "result": {
                "value": "commandline-application",
                "type": "String"
            },
            "confidence": 0.82,
            "technique": "software_type_heuristics"
        }
    ],
    "installation": [
        {
            "result": {
                "value": "  You should only have to perform the setup steps once to download the data and prepare the environment.\n\n  1. Due to the complexity of installing all dependencies, we prepared Docker containers to run this code. You can find instructions on how to install Docker in the [official docs](https://docs.docker.com/get-started/).  Additionally, you must install [Nvidia-Docker](https://github.com/NVIDIA/nvidia-docker) to satisfy GPU-compute related dependencies.  For those who are new to Docker, this [blog post](https://towardsdatascience.com/how-docker-can-help-you-become-a-more-effective-data-scientist-7fc048ef91d5) provides a gentle introduction focused on data science.\n\n  2. After installing Docker, you need to download the pre-processed datasets, which are hosted on S3.  You can do this by running `script/setup`.\n      ```\n      script/setup\n      ```\n      This will build Docker containers and download the datasets.  By default, the data is downloaded into the `resources/data/` folder inside this repository, with the directory structure described [here](resources/README.md).\n\n  **The datasets you will download (most of them compressed) have a combined size of only ~ 3.5 GB.**\n  \n  3.  To start the Docker container, run `script/console`:\n      ```\n      script/console\n      ```\n      This will land you inside the Docker container, starting in the `/src` directory. You can detach from/attach to this container to pause/continue your work.\n \n  For more about the data, see [Data Details](#data-details) below, as well as [this notebook](notebooks/ExploreData.ipynb).\n\n",
                "type": "Text_excerpt",
                "original_header": "Setup",
                "parent_header": [
                    "Introduction"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "value": " To initialize W&B:\n\n   1. Navigate to the `/src` directory in this repository.\n\n   2. If it's your first time using W&B on a machine, you will need to log in:\n\n      ```\n      $ wandb login\n      ```\n\n   3. You will be asked for your API key, which appears on your [W&B profile settings page](https://app.wandb.ai/settings).\n",
                "type": "Text_excerpt",
                "original_header": "W&amp;B Setup",
                "parent_header": [
                    "References"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "**If this is your first time reading this, we recommend skipping this section and reading the following sections.** The below commands assume you have [Docker](https://docs.docker.com/get-started/) and [Nvidia-Docker](https://github.com/NVIDIA/nvidia-docker), as well as a GPU that supports [CUDA 9.0](https://developer.nvidia.com/cuda-90-download-archive) or greater. Note: you should only have to run `script/setup` once to download the data. \n  ```bash\n  # clone this repository\n  git clone https://github.com/github/CodeSearchNet.git\n  cd CodeSearchNet/\n  # download data (~3.5GB) from S3; build and run the Docker container\n  script/setup\n  # this will drop you into the shell inside a Docker container\n  script/console\n  # optional: log in to W&B to see your training metrics,\n  # track your experiments, and submit your models to the benchmark\n  wandb login\n\n  # verify your setup by training a tiny model\n  python train.py --testrun\n  # see other command line options, try a full training run with default values,\n  # and explore other model variants by extending this baseline script\n  python train.py --help\n  python train.py\n\n  # generate predictions for model evaluation\n  python predict.py -r github/CodeSearchNet/0123456 # this is the org/project_name/run_id\n  ``` \nFinally, you can submit your run to the [community benchmark](https://app.wandb.ai/github/CodeSearchNet/benchmark) by following these [instructions](BENCHMARK.md).\n \n",
                "original_header": "Quickstart"
            },
            "confidence": 0.9955060884899142,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "If you have run the [setup steps](#setup) above you will already have the data, and nothing more needs to be done. The data will be available in the `/resources/data` folder of this repository, with [this directory structure](/resources/README.md).\n \n",
                "original_header": "Data Acquisition"
            },
            "confidence": 0.9718270981060628,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Code, comments, and docstrings are extracted in a language-specific manner, removing artifacts of that language.\n```{json}\n{\n  'code': 'def get_vid_from_url(url):\\n'\n          '        \"\"\"Extracts video ID from URL.\\n'\n          '        \"\"\"\\n'\n          \"        return match1(url, r'youtu\\\\.be/([^?/]+)') or \\\\\\n\"\n          \"          match1(url, r'youtube\\\\.com/embed/([^/?]+)') or \\\\\\n\"\n          \"          match1(url, r'youtube\\\\.com/v/([^/?]+)') or \\\\\\n\"\n          \"          match1(url, r'youtube\\\\.com/watch/([^/?]+)') or \\\\\\n\"\n          \"          parse_query_param(url, 'v') or \\\\\\n\"\n          \"          parse_query_param(parse_query_param(url, 'u'), 'v')\",\n  'code_tokens': ['def',\n                  'get_vid_from_url',\n                  '(',\n                  'url',\n                  ')',\n                  ':',\n                  'return',\n                  'match1',\n                  '(',\n                  'url',\n                  ',',\n                  \"r'youtu\\\\.be/([^?/]+)'\",\n                  ')',\n                  'or',\n                  'match1',\n                  '(',\n                  'url',\n                  ',',\n                  \"r'youtube\\\\.com/embed/([^/?]+)'\",\n                  ')',\n                  'or',\n                  'match1',\n                  '(',\n                  'url',\n                  ',',\n                  \"r'youtube\\\\.com/v/([^/?]+)'\",\n                  ')',\n                  'or',\n                  'match1',\n                  '(',\n                  'url',\n                  ',',\n                  \"r'youtube\\\\.com/watch/([^/?]+)'\",\n                  ')',\n                  'or',\n                  'parse_query_param',\n                  '(',\n                  'url',\n                  ',',\n                  \"'v'\",\n                  ')',\n                  'or',\n                  'parse_query_param',\n                  '(',\n                  'parse_query_param',\n                  '(',\n                  'url',\n                  ',',\n                  \"'u'\",\n                  ')',\n                  ',',\n                  \"'v'\",\n                  ')'],\n  'docstring': 'Extracts video ID from URL.',\n  'docstring_tokens': ['Extracts', 'video', 'ID', 'from', 'URL', '.'],\n  'func_name': 'YouTube.get_vid_from_url',\n  'language': 'python',\n  'original_string': 'def get_vid_from_url(url):\\n'\n                      '        \"\"\"Extracts video ID from URL.\\n'\n                      '        \"\"\"\\n'\n                      \"        return match1(url, r'youtu\\\\.be/([^?/]+)') or \\\\\\n\"\n                      \"          match1(url, r'youtube\\\\.com/embed/([^/?]+)') or \"\n                      '\\\\\\n'\n                      \"          match1(url, r'youtube\\\\.com/v/([^/?]+)') or \\\\\\n\"\n                      \"          match1(url, r'youtube\\\\.com/watch/([^/?]+)') or \"\n                      '\\\\\\n'\n                      \"          parse_query_param(url, 'v') or \\\\\\n\"\n                      \"          parse_query_param(parse_query_param(url, 'u'), \"\n                      \"'v')\",\n  'partition': 'test',\n  'path': 'src/you_get/extractors/youtube.py',\n  'repo': 'soimort/you-get',\n  'sha': 'b746ac01c9f39de94cac2d56f665285b0523b974',\n  'url': 'https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/youtube.py#L135-L143'\n}\n```\n \n",
                "original_header": "Schema &amp; Format"
            },
            "confidence": 0.9980679884638683,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ],
    "download": [
        {
            "result": {
                "value": "The shell script `/script/setup` will automatically download these files into the `/resources/data` directory.  Here are the links to the relevant files for visibility:\n\nThe s3 links follow this pattern:\n\n> https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/{python,java,go,php,javascript,ruby}.zip\n\nFor example, the link for the `java` is:\n\n> https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/java.zip\n\nThe size of the dataset is approximately 20 GB.  The various files and the directory structure are explained [here](resources/README.md).\n",
                "type": "Text_excerpt",
                "original_header": "Downloading Data from S3",
                "parent_header": [
                    "Data Details"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ],
    "run": [
        {
            "result": {
                "value": "We encourage you to reproduce and extend these models, though most variants take several hours to train (and some take more than 24 hours on an [AWS P3-V100](https://aws.amazon.com/ec2/instance-types/p3/) instance).\n",
                "type": "Text_excerpt",
                "original_header": "Running Our Baseline Model"
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "value": "  Our baseline models ingest a parallel corpus of (`comments`, `code`) and learn to retrieve a code snippet given a natural language query.  Specifically, `comments` are top-level function and method comments (e.g. docstrings in Python), and `code` is an entire function or method. Throughout this repo, we refer to the terms docstring and query interchangeably.\n\n  The query has a single encoder, whereas each programming language has its own encoder. The available encoders are Neural-Bag-Of-Words, RNN, 1D-CNN, Self-Attention (BERT), and a 1D-CNN+Self-Attention Hybrid.\n\n  The diagram below illustrates the general architecture of our baseline models:\n\n  ![alt text](images/architecture.png \"Architecture\")\n",
                "type": "Text_excerpt",
                "original_header": "Model Architecture",
                "parent_header": [
                    "Running Our Baseline Model"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "value": "This step assumes that you have a suitable Nvidia-GPU with [Cuda v9.0](https://developer.nvidia.com/cuda-90-download-archive) installed.  We used [AWS P3-V100](https://aws.amazon.com/ec2/instance-types/p3/) instances (a `p3.2xlarge` is sufficient).\n\n  1. Start the model run environment by running `script/console`:\n      ```\n      script/console\n      ```\n      This will drop you into the shell of a Docker container with all necessary dependencies installed, including the code in this repository, along with data that you downloaded earlier.  By default, you will be placed in the `src/` folder of this GitHub repository.  From here you can execute commands to run the model.\n\n  2. Set up [W&B](https://docs.wandb.com/docs/started.html) (free for open source projects) [per the instructions below](#wb-setup) if you would like to share your results on the community benchmark.  This is optional but highly recommended.\n\n  3. The entry point to this model is `src/train.py`.  You can see various options by executing the following command:\n      ```\n      python train.py --help\n      ```\n      To test if everything is working on a small dataset, you can run the following command:\n      ```\n      python train.py --testrun\n      ```\n\n  4. Now you are prepared for a full training run.  Example commands to kick off training runs:\n  * Training a neural-bag-of-words model on all languages\n      ```\n      python train.py --model neuralbow\n      ```\n\n    The above command will assume default values for the location(s) of the training data and a destination where you would like to save the output model.  The default location for training data is specified in `/src/data_dirs_{train,valid,test}.txt`.  These files each contain a list of paths where data for the corresponding partition exists. If more than one path specified (separated by a newline), the data from all the paths will be concatenated together.  For example, this is the content of `src/data_dirs_train.txt`:\n\n    ```\n    $ cat data_dirs_train.txt\n    ../resources/data/python/final/jsonl/train\n    ../resources/data/javascript/final/jsonl/train\n    ../resources/data/java/final/jsonl/train\n    ../resources/data/php/final/jsonl/train\n    ../resources/data/ruby/final/jsonl/train\n    ../resources/data/go/final/jsonl/train\n    ```\n\n    By default, models are saved in the `resources/saved_models` folder of this repository.\n\n  * Training a 1D-CNN model on Python data only:\n    ```\n    python train.py --model 1dcnn /trained_models ../resources/data/python/final/jsonl/train ../resources/data/python/final/jsonl/valid ../resources/data/python/final/jsonl/test\n    ```\n\n    The above command overrides the default locations for saving the model to `trained_models` and also overrides the source of the train, validation, and test sets.\n\nAdditional notes:\n* Options for `--model` are currently listed in `src/model_restore_helper.get_model_class_from_name`.\n\n* Hyperparameters are specific to the respective model/encoder classes. A simple trick to discover them is to kick off a run without specifying hyperparameter choices, as that will print a list of all used hyperparameters with their default values (in JSON format).\n",
                "type": "Text_excerpt",
                "original_header": "Training",
                "parent_header": [
                    "Running Our Baseline Model"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "  We are using a community benchmark for this project to encourage collaboration and improve reproducibility.  It is hosted by [Weights & Biases](https://www.wandb.com/) (W&B), which is free for open source projects.  Our entries in the benchmark link to detailed logs of our training and evaluation metrics, as well as model artifacts, and we encourage other participants to provide as much detail as possible.\n\n  We invite the community to submit their runs to this benchmark to facilitate transparency by following [these instructions](BENCHMARK.md).\n",
                "type": "Text_excerpt",
                "original_header": "Benchmark",
                "parent_header": [
                    "References"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "value": "- [Submitting to the benchmark](BENCHMARK.md)\n- [Data structure](/resources/README.md)\n",
                "type": "Text_excerpt",
                "original_header": "Other READMEs",
                "parent_header": [
                    "References"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "value": "@article{husain2019codesearchnet,\n    year = {2019},\n    journal = {arXiv preprint arXiv:1909.09436},\n    author = {Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\n    title = {{CodeSearchNet} challenge: Evaluating the state of semantic code search},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "title": "{CodeSearchNet} challenge: Evaluating the state of semantic code search",
                "author": "Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ],
    "invocation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "  ```bash\n  # clone this repository\n  git clone https://github.com/github/CodeSearchNet.git\n  cd CodeSearchNet/\n  # download data (~3.5GB) from S3; build and run the Docker container\n  script/setup\n  # this will drop you into the shell inside a Docker container\n  script/console\n  # optional: log in to W&B to see your training metrics,\n  # track your experiments, and submit your models to the benchmark\n  wandb login\n\n  # verify your setup by training a tiny model\n  python train.py --testrun\n  # see other command line options, try a full training run with default values,\n  # and explore other model variants by extending this baseline script\n  python train.py --help\n  python train.py\n\n  # generate predictions for model evaluation\n  python predict.py -r github/CodeSearchNet/0123456 # this is the org/project_name/run_id\n  ``` \n",
                "original_header": "Quickstart"
            },
            "confidence": 0.916800313676993,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "The CodeSearchNet challenge has been concluded"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ],
    "images": [
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/github/CodeSearchNet/master/images/architecture.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/1909.09436\n\n> # The CodeSearchNet challenge has been concluded\n> We would like to thank all participants for their submissions\n> and we hope that this challenge provided insights to practitioners and researchers about the challenges in semantic code search and motivated new research. We would like to encourage everyone to continue using the dataset and the human evaluations, which we now provide publicly. Please, see below for details, specifically the [Evaluation](https://github.com/github/CodeSearchNet#evaluation"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/1909.09436"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/github/CodeSearchNet/master/README.md"
        }
    ]
}
{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 19:05:01"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/FlowSs/PMT",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "FlowSs",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2022-07-29T13:59:24Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-01-17T18:48:19Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "name": [
        {
            "result": {
                "value": "PMT",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "FlowSs/PMT",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/FlowSs/PMT/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/FlowSs/PMT/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 3,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 1,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/FlowSs/PMT/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 430016
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "requirements": [
        {
            "result": {
                "value": "\r\nThe framework uses *Python 3.8* and we recommend creating a `conda` environment\r\nto manage the different packages.\r\n\r\nThe base requirements are the same as DeepCrime provided *requirements38.txt*.\r\n\r\n```\r\nnumpy~=1.18.5 \r\ntensorflow~=2.3.0 \r\ntensorflow-gpu~=2.3.0 \r\nKeras~=2.4.3 \r\nmatplotlib~=3.3.0 \r\nprogressbar~=2.5 \r\nscikit-learn~=0.23.1 \r\ntermcolor~=1.1.0 \r\nh5py~=2.10.0 \r\npandas~=1.1.0 \r\nstatsmodels~=0.11.1 \r\nopencv-python~=4.3.0.36 \r\nnetworkx~=2.5.1 \r\npatsy~=0.5.1 \r\nscipy~=1.4.1 \r\n```\r\n\r\nWe extend those requirements with some additional packages needed in our scripts:\r\n```\r\ntqdm~=4.64.0\r\ncolorama~=0.4.4 \r\ntqdm-multiprocess~=0.0.11\r\n```\r\n\r\nAll package required are present in the `requirements.txt` file.\r\n\r",
                "type": "Text_excerpt",
                "original_header": "Requirements",
                "parent_header": [
                    "Replication package for \"A Probabilistic Framework for Mutation Testing in Deep Neural Networks\" paper"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        }
    ],
    "run": [
        {
            "result": {
                "value": "\r\n*Execution time:* ~1 min/mutation\r\n\r\n*Files/Directory concerned*: <br>\r\n\r\n* `raw_data/`\r\n* `utils.py`\r\n* `comp_deepcrime.py`\r\n\r\nIf `--dc` is used, the scripts uses data in `raw_data/deepcrime_comp/` to yield the `p-value` and `cohen's d`, as well as the decision (Killed or not) for the test when comparing healthy instances against mutated instances. The instances used in that vae are the ones provided in DeepCrime's replication package. Results are already presented in `raw_data/deepcrime_comp/` in the `[model]_results_kill_DC.txt`.\r\n\r\nIf `--dc` is NOT used, the script will use DeepCrime's mutation test over multiple experiences using our instances, returning the average number of times the mutation test passed for each magntiude following the protocol we detailled in the Motivating Example of Section 4 in our paper.\r\n\r\n`--same` needs to be used for *model* level mutation so the healthy instances are compared to their mutated counter-part.\r\n\r\nfiles. \r\n\r\nUsage is:\r\n```bash\r\npython comp_deepcrime.py --model [model] --mut [mutation] [--dc] [--same]\r\n```\r\n\r\nFor instance, using only their instances and their single test:\r\n```bash\r\npython comp_deepcrime.py --model 'mnist' --mut 'delete_training_data' --dc\r\n```\r\n\r\n```\r\nExp: delete_training_data_3.1\r\np-value 0.907, effect_size 0.03689417305183907\r\n*********************\r\nExp: delete_training_data_9.29\r\np-value 0.048, effect_size 0.6241987215473714\r\nKilled\r\n*********************\r\nExp: delete_training_data_12.38\r\np-value 0.387, effect_size 0.2735018636400621\r\n*********************\r\nExp: delete_training_data_18.57\r\np-value 0.001, effect_size 1.0074392666953291\r\nKilled\r\n*********************\r\nExp: delete_training_data_30.93\r\np-value 0.0, effect_size 1.6320878597970647\r\nKilled\r\n*********************\r\n```\r\n\r\nFor instance, using multiple iterations of the test over our instances:\r\n```bash\r\npython comp_deepcrime.py --model 'mnist' --mut 'delete_training_data'\r\n```\r\n\r\n```\r\nAverage number of mutation test passed for healthy instances vs healthy instances: 0.06 (0.051)\r\nAverage number of mutation test passed for healthy instances vs mutated instances (delete_training_data_3.1): 0.13 (0.093)\r\nAverage number of mutation test passed for healthy instances vs mutated instances (delete_training_data_9.29): 0.45 (0.120)\r\nAverage number of mutation test passed for healthy instances vs mutated instances (delete_training_data_12.38): 0.47 (0.143)\r\nAverage number of mutation test passed for healthy instances vs mutated instances (delete_training_data_18.57): 0.85 (0.091)\r\nAverage number of mutation test passed for healthy instances vs mutated instances (delete_training_data_30.93): 1.00 (0.001)\r\n```\r",
                "type": "Text_excerpt",
                "original_header": "Running mutation testing on DeepCrime models",
                "parent_header": [
                    "Replication package for \"A Probabilistic Framework for Mutation Testing in Deep Neural Networks\" paper"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        }
    ],
    "faq": [
        {
            "result": {
                "value": "\r\n*Execution time:* ~ 20 min for `exp.py` and ~ 10 sec for `mce_estim.py`\r\n\r\n*Files/Directory concerned*: <br>\r\n\r\n* `raw_data/`\r\n* `utils.py`\r\n* `exp.py`\r\n* `rep_mce/`\r\n* `mce_estim.py`\r\n\r\nTo calculate the Monte-Carlo error (MCE) as we detailed in Section 5.4,\r\nafter calculating/putting accuracy files in the correct directory in `raw_data/`,\r\none needs to first execute `exp.py` to generate monte-carlo simulation data.\r\n\r\nUsage is:\r\n```bash\r\npython exp.py --model [model] --mut [mutation] [--param [parameter] ] [--proc n] [--same]\r\n```\r\n\r\nThe `model` and `mut` parameters are the same as before. `param` controls the\r\nmutation magnitude/parameter. By default (if flag is not used), uses `original` models.\r\n`proc` parameter control the number of core to use (for parallalelisation).\r\nBy default, only one is used.\r\n\r\n`--same` needs to be used for *model* level mutation so the healthy instances are compared to their mutated counter-part.\r\n\r\nFor instance:\r\n```bash\r\npython exp.py --model 'mnist' --mut 'change_label' --param 3.12 --proc 8\r\n```\r\n\r\nThis will generate a file such as `mnist_change_label_3.12_200_pop_size.npy`\r\nin `rep_mce/mnist/` using 8 cores for instance.\r\n\r\nThen use `mce_estim.py` to calculate the jackknife estimates as described in Section 4.5.\r\n\r\nUsage is:\r\n```bash\r\npython mce_estim.py --model [model] --mut [mutation] [--param [parameter] ]\r\n```\r\n\r\nFor instance:\r\n```bash\r\npython mce_estim.py --model 'mnist' --mut 'change_label' --param 3.12\r\n```\r\n\r\nWhich will returns:\r\n\r\n```\r\nModel mnist, Mutation change_label (Param 3.12)\r\nMean: Avg 0.3688340049807526, 95% Confidence Interval (0.3657941422169647, 0.37187386774454045)\r\nVariance: Avg 0.017087663244883932, 95% Confidence Interval: (0.01661289712701975, 0.017562429362748114)\r\n```\r\n\r",
                "type": "Text_excerpt",
                "original_header": "Calculating the Monte Carlo error over the instances (Bagged posterior stability)"
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "\r\n*Execution time:* ~ 20 min for `exp.py` and ~ 10 sec for `mce_estim.py`\r\n\r\n*Files/Directory concerned*: <br>\r\n\r\n* `raw_data/`\r\n* `utils.py`\r\n* `exp.py`\r\n* `rep_mce/`\r\n* `mce_estim.py`\r\n\r\nTo calculate the Monte-Carlo error (MCE) as we detailed in Section 5.4,\r\nafter calculating/putting accuracy files in the correct directory in `raw_data/`,\r\none needs to first execute `exp.py` to generate monte-carlo simulation data.\r\n\r\nUsage is:\r\n```bash\r\npython exp.py --model [model] --mut [mutation] [--param [parameter] ] [--proc n] [--same]\r\n```\r\n\r\nThe `model` and `mut` parameters are the same as before. `param` controls the\r\nmutation magnitude/parameter. By default (if flag is not used), uses `original` models.\r\n`proc` parameter control the number of core to use (for parallalelisation).\r\nBy default, only one is used.\r\n\r\n`--same` needs to be used for *model* level mutation so the healthy instances are compared to their mutated counter-part.\r\n\r\nFor instance:\r\n```bash\r\npython exp.py --model 'mnist' --mut 'change_label' --param 3.12 --proc 8\r\n```\r\n\r\nThis will generate a file such as `mnist_change_label_3.12_200_pop_size.npy`\r\nin `rep_mce/mnist/` using 8 cores for instance.\r\n\r\nThen use `mce_estim.py` to calculate the jackknife estimates as described in Section 4.5.\r\n\r\nUsage is:\r\n```bash\r\npython mce_estim.py --model [model] --mut [mutation] [--param [parameter] ]\r\n```\r\n\r\nFor instance:\r\n```bash\r\npython mce_estim.py --model 'mnist' --mut 'change_label' --param 3.12\r\n```\r\n\r\nWhich will returns:\r\n\r\n```\r\nModel mnist, Mutation change_label (Param 3.12)\r\nMean: Avg 0.3688340049807526, 95% Confidence Interval (0.3657941422169647, 0.37187386774454045)\r\nVariance: Avg 0.017087663244883932, 95% Confidence Interval: (0.01661289712701975, 0.017562429362748114)\r\n```\r\n\r",
                "type": "Text_excerpt",
                "original_header": "Calculating the Monte Carlo error over the instances (Bagged posterior stability)"
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        }
    ],
    "contributing_guidelines": [
        {
            "result": {
                "value": "\r\n*Execution time:* ~2 hours with 30 cores for `run_mp.py` (see note below to improve speed)\r\nand ~ 5 min with 8 cores for `pop_var.py` (instant if data have already been calculated and\r\nwe just want to plot/print results).\r\n\r\n*Files/Directory concerned*: <br>\r\n\r\n* `raw_data/`\r\n* `utils.py`\r\n* `pop_var.py`\r\n* `rep_practicality/`\r\n* `run_mp.py`\r\n* `plot_results/`\r\n\r\nTo calculate the Sampling Effect after calculating/putting accuracy files in the correct directory in `raw_data/`,\r\none needs to first execute `run_mp.py` to generate monte-carlo simulations for different population size.\r\n\r\nUsage is:\r\n```bash\r\npython run_mp.py --model [model] --mut [mutation] [--size [size] ] [--param [parameter] ] [--proc n] [--same]\r\n```\r\n\r\nThe `model` and `mut` parameters are the same as before. `param` controls the\r\nmutation magnitude/parameter. By default (if flag is not used), uses `original` models.\r\n`size` controls the sample size (default 100). `proc` parameter control the number of core to use (for parallalelisation).\r\nBy default, only one is used.\r\n\r\n`--same` needs to be used for *model* level mutation so the healthy instances are compared to their mutated counter-part.\r\n\r\nFor instance:\r\n```bash\r\npython run_mp.py --model 'mnist' --mut 'change_label' --size 25 --param 3.12 --proc 8\r\n```\r\n\r\nThis will generate a file such as `mnist_change_label_3.12_30_rep_25_size_pop.npy`\r\nin `rep_practicality/mnist/` using 8 cores for instance.\r\n\r\n*Note:* this part can actual be long (around ~2 hours with 30 cores) with\r\nbase parameters. You can reduce the value of `exp_n` (number of monte carlo simulation)\r\nto reduce the computation time without affecting much the results. One may also reduce the value of \r\n`B` (number of bootstrap) to further decrease it but at the possible cost of increased error.\r\n\r\nThen use `pop_var.py` to calculate confidence interval over the jackknife estimates \r\nsimilarly to Figure 4/5. \r\n\r\n\r\nUsage is:\r\n```bash\r\npython pop_var.py --model [model] --mut [mutation] [--param [parameter] ] [--pop_size [size] ] [--proc n]\r\n```\r\n\r\nAll parameters are as before except `--pop_size` instead of `--size`. If the flag\r\nis not provided, the program will generate the figure similarly to Figure 4/5, except that it will\r\nreturn all estimates for one mutation/parameter instead of one estimate for\r\nmutliple models/parameters (see [here](#generating-the-figure-from-the-paper) to replicate figure).\r\n\r\nFor instance:\r\n```bash\r\npython pop_var.py --model 'mnist' --mut 'change_label' --param 3.12 --proc 8\r\n```\r\n\r\nWhich will return a figure in `plot_results/mnist/std/`. To only output the results for a given population size.\r\n\r\nFor instance:\r\n```bash\r\npython pop_var.py --model 'mnist' --mut 'change_label' --param 3.12 --proc 8 --pop_size 25\r\n```\r\n\r\n```\r\n*** Results ***\r\nPop size 25\r\n\r\nAverage and Std of each estimate:\r\nMean: 0.27597470147127784, Confidence Interval: (0.023650261256531954, 0.9899319769698173)\r\nVariance: 0.0052768355722456525, Confidence Interval: (0.00015252938705970809, 0.0844377655575625)\r\n\r\nAverage and Std of each estimate lower bound:\r\nMean: 0.2508633503241399, Confidence Interval: (0.022862401295896513, 0.9898047342083249)\r\nVariance: 0.004110943537826673, Confidence Interval: (0.00014684731827894768, 0.07961359227438368)\r\n\r\nAverage and Std of each estimate upper bound:\r\nMean: 0.30108605261841576, Confidence Interval: (0.024484684235331938, 0.9900592197313096)\r\nVariance: 0.005828029840162291, Confidence Interval: (0.0001582114558404685, 0.08926193884074131)\r\n```\r\n\r",
                "type": "Text_excerpt",
                "original_header": "Calculating the sampling effect for a given population size"
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        },
        {
            "result": {
                "value": "\r\nIn all case, the figures are already present in their respective directory,\r\nhowever here are how to re-generate them:\r\n\r\n*Motivating example*\r\n\r\nRun the following script\r\n```bash\r\npython comp_deepcrime.py --model mnist --mut delete_training_data\r\n```\r\n\r\n*Figure 3*\r\n\r\nRun the following script\r\n```bash\r\npython plot_posterior.py --model 'mnist' --mut 'delete_training_data'\r\npython plot_posterior.py --model 'mnist' --mut 'change_activation_function'\r\npython plot_posterior.py --model 'movie_recomm' --mut 'delete_training_data'\r\npython plot_posterior.py --model 'movie_recomm' --mut 'unbalance_train_data'\r\npython plot_posterior.py --model 'lenet' --mut 'delete_training_data'\r\npython plot_posterior.py --model 'lenet' --mut 'change_label'\r\n```\r\n\r\nData need to be present in `raw_data/{model}/` (see [here](#generating-the-accuracy-data)). Figure will be\r\nsaved to `plot_results/{model}/`. \r\n\r\n*Figure 4*\r\n\r\nRun the following script\r\n```bash\r\npython pop_var.py --model 'mnist' --mut 'delete_training_data' --param 3.1\r\npython pop_var.py --model 'mnist' --mut 'delete_training_data' --param 9.29\r\npython pop_var.py --model 'mnist' --mut 'delete_training_data' --param 30.93\r\n```\r\n\r\nData need to be present in `raw_data/{model}/` (see [here](#generating-the-accuracy-data)). Figure will be\r\nsaved to `plot_results/{model}/data_plot/`.\r\n\r\n*Figure 5*\r\n\r\nRun the following script\r\n```bash\r\npython pop_var.py --model 'mnist' --mut 'change_label' --param 3.12\r\npython pop_var.py --model 'movie_recomm' --mut 'change_label' --param 3.12\r\npython pop_var.py --model 'lenet' --mut 'change_label' --param 3.12\r\n```\r\n\r\nData need to be present in `raw_data/{model}/` (see [here](#generating-the-accuracy-data)). Figure will be\r\nsaved to `plot_results/{model}/data_plot/`.\r\n\r",
                "type": "Text_excerpt",
                "original_header": "Generating the figure from the paper",
                "parent_header": [
                    "Calculating the sampling effect for a given population size"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        },
        {
            "result": {
                "value": "\r\nIf the code is intended to be more of a replication package than a general\r\nframework, it is pretty easy to change it to have it work with any model/mutation/dataset.\r\n\r\nTo do so, the only requirements are:\r\n\r\n* Having trained the instances (sound and mutated) one wish to apply the framework on.\r\n* Having generated the accuracy files similarly to [here](#generating-the-accuracy-data). Please make sure the structure\r\nis the same as other files in `raw_data/`. Note that the files `generate_acc_files*.py` works only for the models we studied. Yet they\r\ncan serve as a template for custom models. The files then need to be put in `raw_data/[model]/`.\r\n\r\nOnce this is done, you need to edit `settings.py` and add to `main_dict`\r\nyou model as well as the mutation label/parameter similarly to studied models/mutations.\r\n\r\nAfter that, you can plot the posterior for analysis such as [Calculating posterior distributions and plotting them](#calculating-posterior-distributions-and-plotting-them)\r\nor calculate the similarity ratio similarly to [Calculating Ratio](#calculating-ratio), in order to decide which mutation is killed.\r\nWith a sufficient number of training instances, it is not even needed to calculate Monte-Carlo error or Sample size effect as we showed in the paper,\r\nso the more time-consuming operations are removed.\r\n\r\n\r\n\r\n",
                "type": "Text_excerpt",
                "original_header": "Making it works with your models/mutations/datasets",
                "parent_header": [
                    "Calculating the sampling effect for a given population size"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        }
    ],
    "description": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "\r\nThis replication package contains all the scripts/data necessary to plot \r\nfigures from our paper and redo experiments of our paper \"A Probabilistic Framework for Mutation Testing in Deep Neural\r\nNetworks?\" published in the journal of Information and Software Technology.\r\n\r\n**A preprint version is available on [arxiv](https://arxiv.org/abs/2208.06018), while the published version is available on the [publisher website](https://doi.org/10.1016/j.infsof.2022.107129)**\r\n\r\nWe also provide a quick way to adapt the framework for custom models/datasets/mutations.\r\n\r\nNote that the package was designed to be functional and facilitate replication of the experiment,\r\nas such it's not as optimized speed wise as it could be.\r\n\r \n",
                "original_header": "Replication package for \"A Probabilistic Framework for Mutation Testing in Deep Neural Networks\" paper"
            },
            "confidence": 0.9936119533916022,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        }
    ],
    "invocation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "\r\n. <br>\r\n\u251c\u2500\u2500 Datasets/ # directory for datasets<br>\r\n\u251c\u2500\u2500 README.md <br>\r\n\u251c\u2500\u2500 comp_deepcrime.py # Comparison script with deepcrime<br>\r\n\u251c\u2500\u2500 exp.py # Monte-Carlo simulation generation<br>\r\n\u251c\u2500\u2500 generate_acc_files.py # Generating accuracy file for MNIST<br>\r\n\u251c\u2500\u2500 generate_acc_files_lenet.py # Generating accuracy file for UnityEyes<br>\r\n\u251c\u2500\u2500 generate_acc_files_movie.py # Generating accuracy file for MovieRecomm<br>\r\n\u251c\u2500\u2500 mce_estim.py # Calculate MCE<br>\r\n\u251c\u2500\u2500 mutated_models # Files for training models <br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lenet <br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 mnist <br>\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 movie <br>\r\n\u251c\u2500\u2500 mutations.py # DeepCrime file, necessary for training mutated models<br>\r\n\u251c\u2500\u2500 operators/ # DeepCrime files, necessary for training mutated models <br>\r\n\u251c\u2500\u2500 plot_param.py # Calculating estimates<br>\r\n\u251c\u2500\u2500 plot_posterior.py # Plotting figure such as Figure 3<br>\r\n\u251c\u2500\u2500 plot_results # Directory with all figures<br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lenet <br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 mnist <br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 movie_recomm <br>\r\n\u251c\u2500\u2500 pop_var.py # To generate figure similar to Figure 4/5<br>\r\n\u251c\u2500\u2500 raw_data # Raw data (accuracy files)<br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deepcrime_comp <br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lenet <br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 mnist <br>\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 movie_recomm <br>\r\n\u251c\u2500\u2500 rep_mce # Data of Monte-Carlo simulations (200 instances)<br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lenet <br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 mnist <br>\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 movie_recomm <br>\r\n\u251c\u2500\u2500 rep_practicality # Data of 30 repetitions of Monte-Carlo simulation for different population size<br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lenet <br>\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 mnist <br>\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 movie_recomm <br>\r\n\u251c\u2500\u2500 requirements.txt <br>\r\n\u251c\u2500\u2500 run_mp.py # Getting 30 repetitions of the Monte-Carlo simulation of different population size<br>\r\n\u251c\u2500\u2500 settings.py # Settings file<br>\r\n\u251c\u2500\u2500 trained_models/ # Directory to put our trained models<br>\r\n\u251c\u2500\u2500 trained_models_dc/ # Directory to put DeepCrime directory<br>\r\n\u251c\u2500\u2500 utils/ # DeepCrime files, necessary for training mutated models <br>\r\n\u2514\u2500\u2500 utils.py # utils file (plot functions as well as math related functions)<br>\r\n\r \n",
                "original_header": "Architecture"
            },
            "confidence": 0.9288341663351902,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": ""
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2208.06018"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/FlowSs/PMT/master/README.html"
        }
    ]
}
{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 20:14:46"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/av9ash/DuplicateBugDetection",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "av9ash",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2023-04-08T06:04:03Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-08-02T22:46:16Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "name": [
        {
            "result": {
                "value": "DuplicateBugDetection",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "av9ash/DuplicateBugDetection",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/av9ash/DuplicateBugDetection/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/av9ash/DuplicateBugDetection/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 5,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 1,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/av9ash/DuplicateBugDetection/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 57655
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/av9ash/DuplicateBugDetection/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "```\n@INPROCEEDINGS{10512000,\n  author={Patil, Avinash and Han, Kihwan and Jadon, Aryan},\n  booktitle={2024 11th International Conference on Signal Processing and Integrated Networks (SPIN)}, \n  title={A Comparative Analysis of Text Embedding Models for Bug Report Semantic Similarity}, \n  year={2024},\n  volume={},\n  number={},\n  pages={262-267},\n  keywords={Training;Analytical models;Limiting;Databases;Computer bugs;Semantics;Software systems;ADA;BERT;Bug Reports;Defect Reports;Duplicate Detection;Embeddings;FastText;Gensim;GPT3;GPT3.5;Information Retrieval;Large Language Models;LLM;Natural Language Processing;Sentence Textual Similarity;Similarity Search},\n  doi={10.1109/SPIN60856.2024.10512000}}\n```\n",
                "type": "Text_excerpt",
                "original_header": "If you use any of this code please Cite Our Paper",
                "parent_header": [
                    "Duplicate-Bug-Detection",
                    "About Project"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/av9ash/DuplicateBugDetection/main/README.md"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "```\n@INPROCEEDINGS{10512000,\n  author={Patil, Avinash and Han, Kihwan and Jadon, Aryan},\n  booktitle={2024 11th International Conference on Signal Processing and Integrated Networks (SPIN)}, \n  title={A Comparative Analysis of Text Embedding Models for Bug Report Semantic Similarity}, \n  year={2024},\n  volume={},\n  number={},\n  pages={262-267},\n  keywords={Training;Analytical models;Limiting;Databases;Computer bugs;Semantics;Software systems;ADA;BERT;Bug Reports;Defect Reports;Duplicate Detection;Embeddings;FastText;Gensim;GPT3;GPT3.5;Information Retrieval;Large Language Models;LLM;Natural Language Processing;Sentence Textual Similarity;Similarity Search},\n  doi={10.1109/SPIN60856.2024.10512000}}\n```\n",
                "type": "Text_excerpt",
                "original_header": "If you use any of this code please Cite Our Paper",
                "parent_header": [
                    "Duplicate-Bug-Detection",
                    "About Project"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/av9ash/DuplicateBugDetection/main/README.md"
        },
        {
            "result": {
                "value": "@inproceedings{10512000,\n    doi = {10.1109/SPIN60856.2024.10512000},\n    keywords = {Training;Analytical models;Limiting;Databases;Computer bugs;Semantics;Software systems;ADA;BERT;Bug Reports;Defect Reports;Duplicate Detection;Embeddings;FastText;Gensim;GPT3;GPT3.5;Information Retrieval;Large Language Models;LLM;Natural Language Processing;Sentence Textual Similarity;Similarity Search},\n    pages = {262-267},\n    number = {},\n    volume = {},\n    year = {2024},\n    title = {A Comparative Analysis of Text Embedding Models for Bug Report Semantic Similarity},\n    booktitle = {2024 11th International Conference on Signal Processing and Integrated Networks (SPIN)},\n    author = {Patil, Avinash and Han, Kihwan and Jadon, Aryan},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "doi": "10.1109/SPIN60856.2024.10512000",
                "title": "A Comparative Analysis of Text Embedding Models for Bug Report Semantic Similarity",
                "author": "Patil, Avinash and Han, Kihwan and Jadon, Aryan"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/av9ash/DuplicateBugDetection/main/README.md"
        }
    ],
    "requirements": [
        {
            "result": {
                "value": "- Make sure you have Python and pip installed.\n  \nSteps:\n\n1. **Clone the repository (if you haven't already)**:\n   ```bash\n   git clone https://github.com/av9ash/DuplicateBugDetection.git\n   cd DuplicateBugDetection\n   ```\n\n2. **(Optional but recommended) Set up a virtual environment**:\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # On Windows, use `venv\\Scripts\\activate`\n   ```\n\n3. **Install the required packages**:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\nAfter following these steps, all necessary libraries should be installed, and you're ready to execute the project.\n\n",
                "type": "Text_excerpt",
                "original_header": "Pre-requisites:",
                "parent_header": [
                    "Duplicate-Bug-Detection",
                    "Installation Instructions"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/av9ash/DuplicateBugDetection/main/README.md"
        }
    ],
    "run": [
        {
            "result": {
                "value": "1. This is the first script you'll need to run. Its main purpose is to create a mapping of bugs, \nwhich can be utilized in subsequent scripts.\n    ```bash\n    python create_bugs_map.py\n    ```\n   \n2. After generating the bugs map, the next step is to split the data into training and testing datasets.\n    ```bash\n    python create_train_test.py\n    ```\n   \n3. Once you have the training and testing data ready, this is the final script you will run which might contain the main \n   algorithm or process of the project.\n    ```bash\n   python main_file.py\n   ```\n",
                "type": "Text_excerpt",
                "original_header": "Steps to Execute the Project",
                "parent_header": [
                    "Duplicate-Bug-Detection",
                    "Installation Instructions"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/av9ash/DuplicateBugDetection/main/README.md"
        }
    ],
    "description": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "```\nThis repository contains the implementation of our paper \"A Comparative Study of Text Embedding Models for Semantic Text Similarity in Bug Reports\".\nDuplicate bug report detection in tracking systems saves debugging efforts. Traditional solutions lack clear ranking, \ndeterring their use. Our paper introduces an NLP-based method using bug report attributes, leveraging a neural \nnetwork for retrieval.\n```\n \n",
                "original_header": "About Project"
            },
            "confidence": 0.9452622316804554,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/av9ash/DuplicateBugDetection/main/README.md"
        }
    ],
    "identifier": [
        {
            "result": {
                "type": "Url",
                "value": "https://zenodo.org/badge/latestdoi/678604821"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/av9ash/DuplicateBugDetection/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Duplicate-Bug-Detection"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/av9ash/DuplicateBugDetection/main/README.md"
        }
    ]
}
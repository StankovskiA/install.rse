{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 19:07:59"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/amazon-science/recode",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "amazon-science",
                "type": "Organization"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2022-12-19T22:14:07Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-09-07T08:09:32Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/apache-2.0",
                "type": "License",
                "name": "Apache License 2.0",
                "url": "https://api.github.com/licenses/apache-2.0",
                "spdx_id": "Apache-2.0"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2022 ReCode Benchmark\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/LICENSE"
        },
        {
            "result": {
                "value": "The ReCode benchmark is under Apache-2.0 license.\n\n",
                "type": "Text_excerpt",
                "original_header": "License",
                "parent_header": [
                    "ReCode: Robustness Evaluation of Code Generation Models"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        }
    ],
    "description": [
        {
            "result": {
                "value": "Releasing code for \"ReCode: Robustness Evaluation of Code Generation Models\"",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "This is the repo for ReCode ([arXiv](https://arxiv.org/abs/2212.10264)), providing a comprehensive evaluation for the practical robustness of code generation models like CodeGEN, Incoder, GPT-J. In specific, this benchmark provides over 30 different general perturbations on docstrings, function names, and codes. The perturbations are carefully selected and implemented such that the perturbed datasets are naturally and semantically close to the original non-perturbed datasets. All the perturbations are well implemented with automatic generation, providing easy usage and customization. With these perturbations available in our benchmark, the user can get to know a comprehensive analysis of model robustness performance. \nOur benchmark is general with regard to datasets and models. Given the perturbed datasets, the users can evaluate any of public/customized code generation models with the default inference provided by our benchmark. We also allow users to provide their own datasets and models to evaluate robustness in our benchmark by configuring `config.json` and inference script `evaluate-public-models/run_eval_models.sh`. \nAfter the model evaluation is done on perturbed datasets, we provide overall robustness analysis for the evaluated models such that the users can easily compare across different models and get aware of the possible practical robustness problems. \nLastly, we release a standard version of the perturbed datasets `dataset-release/perturbed-finalized` for HumanEval and MBPP in this benchmark for general robustness evaluation and compare across different models proposed in future works.\n \n",
                "original_header": "ReCode: Robustness Evaluation of Code Generation Models"
            },
            "confidence": 0.9440377897510424,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "recode",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "amazon-science/recode",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/amazon-science/recode/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/amazon-science/recode/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 46,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "code-generation, large-language-models, nlp, robustness",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 6,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/amazon-science/recode/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 627972
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 2483
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "code_of_conduct": [
        {
            "result": {
                "value": "## Code of Conduct\nThis project has adopted the [Amazon Open Source Code of Conduct](https://aws.github.io/code-of-conduct).\nFor more information see the [Code of Conduct FAQ](https://aws.github.io/code-of-conduct-faq) or contact\nopensource-codeofconduct@amazon.com with any additional questions or comments.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/CODE_OF_CONDUCT.md"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "contributing_guidelines": [
        {
            "result": {
                "value": "# Contributing Guidelines\n\nThank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional\ndocumentation, we greatly value feedback and contributions from our community.\n\nPlease read through this document before submitting any issues or pull requests to ensure we have all the necessary\ninformation to effectively respond to your bug report or contribution.\n\n\n## Reporting Bugs/Feature Requests\n\nWe welcome you to use the GitHub issue tracker to report bugs or suggest features.\n\nWhen filing an issue, please check existing open, or recently closed, issues to make sure somebody else hasn't already\nreported the issue. Please try to include as much information as you can. Details like these are incredibly useful:\n\n* A reproducible test case or series of steps\n* The version of our code being used\n* Any modifications you've made relevant to the bug\n* Anything unusual about your environment or deployment\n\n\n## Contributing via Pull Requests\nContributions via pull requests are much appreciated. Before sending us a pull request, please ensure that:\n\n1. You are working against the latest source on the *main* branch.\n2. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already.\n3. You open an issue to discuss any significant work - we would hate for your time to be wasted.\n\nTo send us a pull request, please:\n\n1. Fork the repository.\n2. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change.\n3. Ensure local tests pass.\n4. Commit to your fork using clear commit messages.\n5. Send us a pull request, answering any default questions in the pull request interface.\n6. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.\n\nGitHub provides additional document on [forking a repository](https://help.github.com/articles/fork-a-repo/) and\n[creating a pull request](https://help.github.com/articles/creating-a-pull-request/).\n\n\n## Finding contributions to work on\nLooking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels (enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.\n\n\n## Code of Conduct\nThis project has adopted the [Amazon Open Source Code of Conduct](https://aws.github.io/code-of-conduct).\nFor more information see the [Code of Conduct FAQ](https://aws.github.io/code-of-conduct-faq) or contact\nopensource-codeofconduct@amazon.com with any additional questions or comments.\n\n\n## Security issue notifications\nIf you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our [vulnerability reporting page](http://aws.amazon.com/security/vulnerability-reporting/). Please do **not** create a public github issue.\n\n\n## Licensing\n\nSee the [LICENSE](LICENSE) file for our project's licensing. We will ask you to confirm the licensing of your contribution.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/CONTRIBUTING.md"
        }
    ],
    "has_script_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/amazon-science/recode/main/evaluate-public-models/run_eval_models.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "installation": [
        {
            "result": {
                "value": "We are using python 3.8, cuda 11.6. Anaconda would be recommended. Please run the following commands for installation.\n```\nconda deactivate; conda env remove --name ReCode\nconda create --name ReCode python=3.8\nconda activate ReCode\n```\n\nInstalling huggingface for model inference\n```\npip install transformers==4.21.1\npip install -U torch==1.11.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n```\n\nInstalling humaneval. Need to enable humaneval by uncommenting out execution line `exec(check_program, exec_globals)` in `execution.py`.\n```\ncd evaluate-public-models\ngit clone https://github.com/openai/human-eval\npip install -e human-eval\ncd ..\n```\n\nInstalling nlaugmenter for perturbations\n```\ncd nlaugmenter\npip install -r requirements.txt\npip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\ncd ..\n```\n\nInstalling treesitter for perturbations. Note that we customized our code syntax perturbatons based on [natgen](https://github.com/saikat107/NatGen). \n```\ncd natgen/treesitter\ngit clone https://github.com/tree-sitter/tree-sitter-python # clone the py-tree-sitter\npython build.py # build my-languages.so file\ncd ../transformations\nln -s ../treesitter/build/my-languages.so ./\npip install sympy\ncd ../..\n```\n",
                "type": "Text_excerpt",
                "original_header": "Installation",
                "parent_header": [
                    "ReCode: Robustness Evaluation of Code Generation Models"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        }
    ],
    "run": [
        {
            "result": {
                "value": "We provide general APIs for running our benchmark in `run_robust.py`. We have four main types of perturbations (1) nlaugmenter on docstrings (nlaugmenter) (2) function rename (func_name) (3) code syntax (natgen) (4) code format (format). Multiple variances are defined and implemented for each type of perturbation. One can find detailed config in `config.json`. \n\nOverall we have multiple steps for benchmark as described in detail in the following sections: (1) [perturb] creating perturbed datasets, (2) [exec] run the models on nominal/perturbed datasets, and (3) [report_coarse] collect and summarize running results according to our proposed robustness metrics.\n",
                "type": "Text_excerpt",
                "original_header": "Running our ReCode benchmark",
                "parent_header": [
                    "ReCode: Robustness Evaluation of Code Generation Models"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        },
        {
            "result": {
                "value": "[perturb] option is used to create perturbed datasets. One can run the following commands to perturb based on one's own nominal datasets (path config in `config.json`). \n\nNote that we also released our perturbed data used for evaluation in paper as a general robustness benchmark (`dataset-release/perturbed_finalized`). To directly evaluate on our created benchmark datasets, please change `output_adv_path` in `config.json` to that path and skip all the following commands for perturbing in this [perturb] section!\n\n\n```\npython run_robust.py create_partial natgen # preparing partial code for code perturbations\npython run_robust.py perturb nlaugmenter # perturb with nlaugmenter transformations on docstrings\npython run_robust.py perturb func_name # perturb with function rename\npython run_robust.py perturb natgen # perturb with code syntax transformations\npython run_robust.py perturb code # perturb with code format transformations\n```\n\nOne can specify augmentation method for each type of perturbations with --aug_method, index can be found in `config.json`. --datasets allow to specify perturbed datasets.\n```\npython run_robust.py perturb func_name --aug_method 0 --datasets humaneval mbpp # perturb with function rename CamelCase (index=0 defined in config.json) on humaneval and mbpp\n``` \n\nOur benchmark also provides [analysis] option to check how each sample is perturbed one by one\n```\npython run_robust.py analysis func_name --aug_method 0 --models None # check perturbed data one by one with function rename CamelCase (index=0 defined in config.json)\n```\n\nTo debug and customize perturbations, one can use low-level APIs. Turn on --print_sample to debug and check customized perturbations on each sample.\n```\npython perturb.py --method format --aug_method 0 --print_sample\n```\n",
                "type": "Text_excerpt",
                "original_header": "Step1: Create perturbed datasets [perturb]",
                "parent_header": [
                    "ReCode: Robustness Evaluation of Code Generation Models",
                    "Running our ReCode benchmark"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        },
        {
            "result": {
                "value": "[exec] option is used for evaluating targeted models on perturbed datasets. To evaluate models with our benchmark, please config the targeted nominal/perturbed datasets and model path correctly in `config.json`. One can then run with:\n```\npython run_robust.py nominal normal # nominal evaluation with non-perturbed datasets\npython run_robust.py nominal natgen # nominal evaluation with non-perturbed partial code datasets\npython run_robust.py exec nlaugmenter # nlaugmenter perturbed datasets evaluation\npython run_robust.py exec func_name # function rename perturbed datasets evaluation\npython run_robust.py exec natgen # code structure perturbed datasets evaluation\npython run_robust.py exec format # code format transformation perturbed datasets evaluation\n```\n\nIf one wants to evaluate specific augmentation method, one can easily run\n```\npython run_robust.py exec func_name --aug_method 0 # evaluate model on dataset with function rename CamelCase (index=0 defined in config.json)\n```\n\nFor targeted models please use augments --models and --datasets. Note that one has to correctly config the model names and path correctly in the running shell file in `run_script` in `config.json`. Detailed running hyperparameters can be configured in that shell file. Please make sure that shell file can run correctly for nominal evaluation on your own models/datasets. Our benchmark will mainly call that file for evaluation. The default one is `evaluate-public-models/run_eval_models.sh`\n```\npython run_robust.py perturb func_name --datasets humaneval mbpp --models codegen-350M-multi codegen-350M-mono # perturb dataset humaneval mbpp on codegen-350M-multi and codegen-350M-mono\npython run_robust.py exec func_name --datasets humaneval mbpp --models codegen-350M-multi codegen-350M-mono # evaluate model on dataset humaneval mbpp on codegen-350M-multi and codegen-350M-mono\n```\n",
                "type": "Text_excerpt",
                "original_header": "Step2: Run on perturbed datasets [exec]",
                "parent_header": [
                    "ReCode: Robustness Evaluation of Code Generation Models",
                    "Running our ReCode benchmark"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        },
        {
            "result": {
                "value": "In our paper, we proposed three main robustness metrics: robust pass@k, robust drop@k, and robust relative@k. To summarize and collect the evaluated results, one can run the following commands. In specific, `report_coarse` option summarizes the robustness numbers for all thee metrics (as shown in main tables in paper). `report` option summarizes the detailed robustness results into csv (detailed tables in appendix of paper). The results will be saved as tables in `csv_coarse` and `csv`.\n```\npython run_robust.py report_coarse func_name --models codegen-350M-multi codegen-350M-mono --datasets humaneval # get summarized results for dataset perturbed with function rename\npython run_robust.py report func_name --models codegen-350M-multi codegen-350M-mono --datasets humaneval # get detailed results for dataset perturbed with function rename\n```\n\n`analysis` option with --models given provides prints for the perturbed data and completion by the model for each prompt.\n```\npython run_robust.py analysis func_name --models codegen-350M-mono --datasets humaneval # analyze completion samples for dataset perturbed with function rename by codegen-350M-mono\n```\n\n",
                "type": "Text_excerpt",
                "original_header": "Step3: Summarize running results [report_coarse]",
                "parent_header": [
                    "ReCode: Robustness Evaluation of Code Generation Models",
                    "Running our ReCode benchmark"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "Please cite with the following bibtex\n\n```\n@article{recode_wang2022,\n  title = {ReCode: Robustness Evaluation of Code Generation Models},\n  author = {Wang, Shiqi and\n   Zheng, Li and\n   Qian, Haifeng and\n   Yang, Chenghao and\n   Wang, Zijian and\n   Kumar, Varun and\n   Shang, Mingyue and\n   Tan, Samson and\n   Ray, Baishakhi and\n   Bhatia, Parminder and\n   Nallapati, Ramesh and\n   Ramanathan, Murali Krishna and\n   Roth, Dan and\n   Xiang, Bing},\n  doi = {10.48550/arXiv.2212.10264},\n  url = {https://arxiv.org/abs/2212.10264},\n  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL)},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution 4.0 International}\n}\n\n```\n",
                "type": "Text_excerpt",
                "original_header": "Cite this work",
                "parent_header": [
                    "ReCode: Robustness Evaluation of Code Generation Models"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        },
        {
            "result": {
                "value": "@article{recode_wang2022,\n    copyright = {Creative Commons Attribution 4.0 International},\n    year = {2022},\n    publisher = {arXiv},\n    keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL)},\n    url = {https://arxiv.org/abs/2212.10264},\n    doi = {10.48550/arXiv.2212.10264},\n    author = {Wang, Shiqi and\nZheng, Li and\nQian, Haifeng and\nYang, Chenghao and\nWang, Zijian and\nKumar, Varun and\nShang, Mingyue and\nTan, Samson and\nRay, Baishakhi and\nBhatia, Parminder and\nNallapati, Ramesh and\nRamanathan, Murali Krishna and\nRoth, Dan and\nXiang, Bing},\n    title = {ReCode: Robustness Evaluation of Code Generation Models},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "doi": "10.48550/arXiv.2212.10264",
                "title": "ReCode: Robustness Evaluation of Code Generation Models",
                "author": "Wang, Shiqi and\nZheng, Li and\nQian, Haifeng and\nYang, Chenghao and\nWang, Zijian and\nKumar, Varun and\nShang, Mingyue and\nTan, Samson and\nRay, Baishakhi and\nBhatia, Parminder and\nNallapati, Ramesh and\nRamanathan, Murali Krishna and\nRoth, Dan and\nXiang, Bing",
                "url": "https://arxiv.org/abs/2212.10264"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "ReCode: Robustness Evaluation of Code Generation Models"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2212.10264"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2212.10264},\n  keywords = {Machine Learning (cs.LG"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/amazon-science/recode/main/README.md"
        }
    ]
}
{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 19:38:00"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/matteobiagiola/drl-testing-experiments",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "matteobiagiola",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2022-09-26T04:37:29Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-09-19T06:39:20Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/mit",
                "type": "License",
                "name": "MIT License",
                "url": "https://api.github.com/licenses/mit",
                "spdx_id": "MIT"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "MIT License\n\nCopyright (c) 2018 Roma Sokolkov\nCopyright (c) 2018 Antonin Raffin\nCopyright (c) 2022 matteobiagiola\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/LICENSE"
        }
    ],
    "description": [
        {
            "result": {
                "value": "Replication Package for paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "name": [
        {
            "result": {
                "value": "drl-testing-experiments",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "matteobiagiola/drl-testing-experiments",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/matteobiagiola/drl-testing-experiments/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/matteobiagiola/drl-testing-experiments/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 2,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 1,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/matteobiagiola/drl-testing-experiments/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 763976
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Dockerfile",
                "name": "Dockerfile",
                "type": "Programming_language",
                "size": 2610
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 1268
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "releases": [
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/matteobiagiola/drl-testing-experiments/releases/171005848",
                "tag": "v0.1.0",
                "name": "v0.1.0",
                "author": {
                    "name": "matteobiagiola",
                    "type": "User"
                },
                "tarball_url": "https://api.github.com/repos/matteobiagiola/drl-testing-experiments/tarball/v0.1.0",
                "zipball_url": "https://api.github.com/repos/matteobiagiola/drl-testing-experiments/zipball/v0.1.0",
                "html_url": "https://github.com/matteobiagiola/drl-testing-experiments/releases/tag/v0.1.0",
                "url": "https://api.github.com/repos/matteobiagiola/drl-testing-experiments/releases/171005848",
                "release_id": 171005848,
                "date_created": "2024-08-20T07:10:37Z",
                "date_published": "2024-08-20T07:16:11Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "has_build_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/Dockerfile",
                "type": "Url",
                "format": "dockerfile"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/Dockerfile"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "has_script_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/run_smoke_test.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "type": [
        {
            "result": {
                "value": "commandline-application",
                "type": "String"
            },
            "confidence": 0.82,
            "technique": "software_type_heuristics"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "Let's say we want to train a new Parking agent. The command we need to type is:\n\n```commandline\npython -m indago.train --algo her -tb logs/tensorboard \\\n\t--seed 2646669604 --env-name park \\\n\t--env-id parking-v0 \\\n\t--n-timesteps 50000\n``` \n\nThis will train a Parking agent for 50000 timesteps (1/3 of the default number of timesteps) and takes about 1.5 hours on docker running on a MacBook Pro. Moreover, the command will create a directory `logs/her/parking-v0_1` in your project where environment configurations and models will be saved. Since the `-tb` option is provided, we can look at the training metrics in tensorboard.\n\nTo do that head over to another terminal window and type:\n\n```commandline\ntensorboard --logdir logs/tensorboard/parking-v0\n```\n\nOpen your browser at `localhost:6006`. On the left-hand side of the screen look for `Runs` and select only `HER_1` to see the metrics for the current agent. You might also want to click on settings (gear on the right-hand side of the screen) and check the `Reload data` option. The panel has two sections, namely `rollout` and `time`. The latter shows how fast is the training while the former shows the trend of three metrics over time all averaged over 100 episodes: `ep_len_mean`, i.e. how long is an episode (the lower the better in Parking), `ep_len_rew`, i.e. how much reward the agent is getting in an episode (the higher the better in all cases) and `success_rate`, i.e. the percentage of episodes in which the agent is successful (the higher the better in all cases).\n",
                "type": "Text_excerpt",
                "original_header": "2.2 Example Train Parking Agent",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "2. Training agents"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "value": "Build a heldout test set for the Parking agent trained at step 2. \n\n```commandline\npython -m indago.avf.train --algo her \\\n\t--env-name park --env-id parking-v0 \\\n\t--exp-id 1 --avf-policy mlp \\\n\t--build-heldout-test \\\n\t--test-split 0.1 \\\n\t--seed 0\n```\n\nThe command will create the file `heldout-set-seed-0-0.1-split-5-filter-cls.npz` in the directory `logs/her/parking-v0_1`.\n",
                "type": "Text_excerpt",
                "original_header": "3.2 Example Build Test Set for Parking Agent",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "3. Training the Classifier"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "value": "Requires Section 3.2 to be completed. The command:\n\n```commandline\npython -m indago.avf.train --algo her \\\n\t--env-name park --env-id parking-v0 \\\n\t--exp-id 1 --test-split 0.2 --avf-policy mlp \\\n\t--training-progress-filter 20 --oversample 0.0 \\\n\t--n-epochs 2000 --learning-rate 3e-4 \\\n\t--batch-size 256 --patience 10 \\\n\t--weight-loss --layers 2 --seed 2216495700 \\\n\t--heldout-test-file heldout-set-seed-0-0.1-split-5-filter.npz\n```\n\ntrains a multi-layer perceptron with 4 hidden layers and filtering the initial 20% of the configurations in `logs/her/parking-v0_1`. If you followed the instructions above for training the Parking agent and the classifier you should obtain a precision of 0.29 and a recall of 0.11 in the test set.\n\nIn general, the number of hidden layers and the filtering level are not known a priori and they depend on the case study. In order to get the best classifier possible it is recommended to run different training runs (command above) with different seeds and choose the classifier with the best precision.\n",
                "type": "Text_excerpt",
                "original_header": "3.4 Example Train a Classifier for Parking Agent",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "3. Training the Classifier"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "value": "Requires Section 3.4 to be completed. All the commands below will run 10 experiments each with different random seeds.\n",
                "type": "Text_excerpt",
                "original_header": "4.2 Example Testing the Parking Agent",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "4. Testing the Agent"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "value": "```commandline\npython -m indago.experiments --algo her \\\n\t--exp-id 1 --env-name park --env-id parking-v0 \\\n\t--avf-test-policy random --failure-prob-dist \\\n\t--num-episodes 50 \\\n\t--num-runs-each-env-config 1 \\\n\t--num-runs-experiments 10\n```\n",
                "type": "Text_excerpt",
                "original_header": "4.2.1 Random",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "4. Testing the Agent",
                    "4.2 Example Testing the Parking Agent"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "value": "```commandline\npython -m indago.experiments --algo her \\\n\t--exp-id 1 --env-name park --env-id parking-v0 \\\n\t--avf-test-policy nn --failure-prob-dist \\\n\t--num-episodes 50 \\\n\t--num-runs-each-env-config 1 \\\n\t--training-progress-filter 20 \\\n\t--layers 4 \\\n\t--budget 3 \\\n\t--num-runs-experiments 10\n```\n",
                "type": "Text_excerpt",
                "original_header": "4.2.2 Sampling",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "4. Testing the Agent",
                    "4.2 Example Testing the Parking Agent"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "value": "```commandline\npython -m indago.experiments --algo her \\\n\t--exp-id 1 --env-name park --env-id parking-v0 \\\n\t--avf-test-policy hc_saliency_failure --failure-prob-dist \\\n\t--num-episodes 50 \\\n\t--num-runs-each-env-config 1 \\\n\t--training-progress-filter 20 \\\n\t--layers 4 \\\n\t--budget 3 \\\n\t--num-runs-experiments 10\n```\n",
                "type": "Text_excerpt",
                "original_header": "4.2.3 Hill Climbing Saliency Failure",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "4. Testing the Agent",
                    "4.2 Example Testing the Parking Agent"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "value": "```commandline\npython -m indago.experiments --algo her \\\n\t--exp-id 1 --env-name park --env-id parking-v0 \\\n\t--avf-test-policy ga_saliency_failure --failure-prob-dist \\\n\t--num-episodes 50 \\\n\t--num-runs-each-env-config 1 \\\n\t--training-progress-filter 20 \\\n\t--layers 4 \\\n\t--budget 3 \\\n\t--num-runs-experiments 10\n```\n",
                "type": "Text_excerpt",
                "original_header": "4.2.4 Genetic Algorithm Saliency Failure",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "4. Testing the Agent",
                    "4.2 Example Testing the Parking Agent"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "value": "Requires Section 4.2 to be completed.\n\n```commandline\npython -m indago.env_logs_analysis_trials \\\n\t--folder logs/her/parking-v0_1 \\\n\t--env-name park\n\t--names random nn hc_saliency_failure ga_saliency_failure\n```\n",
                "type": "Text_excerpt",
                "original_header": "5.1.1 Example Analyze Failure Search Results for the Parking Agent",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "5. Analyze the Results",
                    "5.1 Analyze Failure Search Results"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "value": "Requires Section 5.1.1 to be completed.\n\nType:\n\n```commandline\npython -m indago.experiments \\\n\t--algo her \\\n\t--exp-id 1 \\\n\t--env-name park \\\n\t--env-id parking-v0 \\\n\t--avf-test-policy replay_test_failure \\\n\t--failure-prob-dist \\\n\t--num-runs-each-env-config 1 \\\n\t--exp-file testing-random-failure-prob-dist-50-1-0-trial.txt\n```\n\nfor replaying failures generated by `random`.\n\nType:\n\n```commandline\npython -m indago.experiments \\\n\t--algo her \\\n\t--exp-id 1 \\\n\t--env-name park \\\n\t--env-id parking-v0 \\\n\t--avf-test-policy replay_test_failure \\\n\t--failure-prob-dist \\\n\t--num-runs-each-env-config 1 \\\n\t--exp-file testing-mlp-nn-original-20-0.0-4-100000-failure-prob-dist-50-1-budget-3-0-trial.txt\n```\n\nfor replaying failures generated by `nn` (i.e., sampling).\n\nType:\n\n```commandline\npython -m indago.experiments \\\n\t--algo her \\\n\t--exp-id 1 \\\n\t--env-name park \\\n\t--env-id parking-v0 \\\n\t--avf-test-policy replay_test_failure \\\n\t--failure-prob-dist \\\n\t--num-runs-each-env-config 1 \\\n\t--exp-file testing-mlp-hc_saliency_failure-30-0.0-4-50-100-0.005-failure-prob-dist-50-1-budget-3-0-trial.txt\n```\n\nfor replaying failures generated by `hc_saliency_failure`.\n\nType:\n\n```commandline\npython -m indago.experiments \\\n\t--algo her \\\n\t--exp-id 1 \\\n\t--env-name park \\\n\t--env-id parking-v0 \\\n\t--avf-test-policy replay_test_failure \\\n\t--failure-prob-dist \\\n\t--num-runs-each-env-config 1 \\\n\t--exp-file testing-mlp-ga_saliency_failure-30-0.0-4-50-0.75-failure-prob-dist-50-1-budget-3-0-trial.txt\n```\n\nfor replaying failures generated by `ga_saliency_failure`.\n\nThen type:\n\n```commandline\npython -m indago.diversity \\\n\t--folder logs/her/parking-v0_1 \\\n\t--env-name park \\\n\t--pattern \\\n\t--names random nn hc_saliency_failure ga_saliency_failure \\\n\t--type input \\\n\t--sil-threshold 20 \\\n\t--visualize\n```\n\nto compute input coverage and entropy and type:\n\n```commandline\npython -m indago.diversity \\\n\t--folder logs/her/parking-v0_1 \\\n\t--env-name park \\\n\t--pattern \\\n\t--names random nn hc_saliency_failure ga_saliency_failure \\\n\t--type output \\\n\t--sil-threshold 20 \\\n\t--visualize\n```\n\nto compute output coverage and entropy.\n",
                "type": "Text_excerpt",
                "original_header": "5.2.1 Example Analyze Analyze Diversity Results for the Parking Agent",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "5. Analyze the Results",
                    "5.2 Analyze Diversity Results"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        }
    ],
    "installation": [
        {
            "result": {
                "value": "Type:\n\n```commandline\npython -m indago.avf.train --algo <algo-name> \\\n\t--env-name <env-name> --env-id <env-id> \\\n\t--exp-id <exp-id> --avf-policy mlp \\\n\t--build-heldout-test \\\n\t--test-split 0.1 \\\n\t--seed 0 \\\n\t[--regression]\n```\n\nto build a heldout test set where:\n\n`<algo-name> = her | tqc | sac` for Parking, Humanoid and Donkey respectively;\n\n`<env-name> = park | humanoid | donkey`;\n\n`<env-id> = parking-v0 | Humanoid-v0 | DonkeyVAE-v0`;\n\n`<exp-id>` is written on the directory `logs/<algo-name>/<env-id>_<exp-id>`. For example for Parking agent trained above we have `logs/her/parking-v0_1`, i.e. `<exp-id> = 1`.\n\nThe command will create the file `heldout-set-seed-0-0.1-split-5-filter-cls.npz` in the directory `logs/<algo-name>/<env-id>_<exp-id>`. The `--regression` flag is optional, and, if provided, it saves the file `heldout-set-seed-0-0.1-split-5-filter-rgr.npz` that prepares for training a regressor failure predictor rather than a classifier. If the `--regression` flag is provided, it must be provided consistently to the commands below.\n",
                "type": "Text_excerpt",
                "original_header": "3.1 Build Held-out Test Set",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "3. Training the Classifier"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "value": "Build a heldout test set for the Parking agent trained at step 2. \n\n```commandline\npython -m indago.avf.train --algo her \\\n\t--env-name park --env-id parking-v0 \\\n\t--exp-id 1 --avf-policy mlp \\\n\t--build-heldout-test \\\n\t--test-split 0.1 \\\n\t--seed 0\n```\n\nThe command will create the file `heldout-set-seed-0-0.1-split-5-filter-cls.npz` in the directory `logs/her/parking-v0_1`.\n",
                "type": "Text_excerpt",
                "original_header": "3.2 Example Build Test Set for Parking Agent",
                "parent_header": [
                    "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\".",
                    "3. Training the Classifier"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "```commandline\ndocker run --rm -it --mount type=bind,source=\"$(pwd)\",target=/home/indago --workdir /home/indago --name indago-container -p 6006:6006 dockercontainervm/indago:0.1.0\n# do not activate the environment before running the run_smoke_test.sh script\n./run_smoke_test.sh --env-name parking\n./run_smoke_test.sh --env-name humanoid\n./run_smoke_test.sh --env-name donkey\n``` \n",
                "original_header": "1. Docker image"
            },
            "confidence": 0.9999999999839702,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "```commandline\ndocker build --no-cache -t indago:latest .\ndocker run --rm -it --mount type=bind,source=\"$(pwd)\",target=/home/indago --workdir /home/indago --name indago-container -p 6006:6006 indago:latest\n# do not activate the environment before running the run_smoke_test.sh script\n./run_smoke_test.sh --env-name parking\n./run_smoke_test.sh --env-name humanoid\n./run_smoke_test.sh --env-name donkey\n``` \nDocker build tested with version (MacOS and Ubuntu 22.04 LTS): \n",
                "original_header": "1.1 (Optional) Docker build"
            },
            "confidence": 0.999995819169918,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "To activate the environment inside the docker container type:\n```commandline\nconda activate indago\n```\nThen, type:\n```commandline\npython -m indago.train --algo her -tb logs/tensorboard \\\n\t--seed 2646669604 --env-name park --env-id parking-v0\n``` \n \nType:\n```commandline\npython -m indago.train --algo tqc -tb logs/tensorboard \\\n\t--seed 2646669604 --env-name humanoid --env-id Humanoid-v0\n```\n \nType:\n```commandline\nxvfb-run -a python -m indago.train --algo sac -tb logs/tensorboard \\\n\t--seed 2646669604 --env-name donkey \\\n\t--env-id DonkeyVAE-v0 --log-interval 1000 \\\n\t--exe-path /root/DonkeySimLinuxIndago/donkey_sim.x86_64 \\\n\t--vae-path logs/generated_track/vae-64.pkl --z-size 64 \\\n\t--simulation-mul 5 --headless\n``` \n \nPrepending the python command with `xvfb-run` makes it possible to run the training (and testing) of the Donkey agent within a docker container, by automatically creating a virtual display and destroying it once the command terminates. The rendering is done through the CPU.\n \n",
                "original_header": "2. Training agents"
            },
            "confidence": 0.9975723579671423,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Type:\n```commandline\ntensorboard --logdir logs/tensorboard/<env-id> --host 0.0.0.0\n```\n \n`<env-id> = parking-v0 | Humanoid-v0 | DonkeyVAE-v0-scene-generated_track` \nThe `--host 0.0.0.0` is to be able to access tensorboard from the host machine using `localhost`.\n \n",
                "original_header": "2.1 Tensorboard Logs"
            },
            "confidence": 0.9715282010681424,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Type:\n```commandline\nconda activate indago\n```\n \nto activate the environment.\n \n",
                "original_header": "3. Training the Classifier"
            },
            "confidence": 0.9944113186820889,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "`<env-id> = parking-v0 | Humanoid-v0 | DonkeyVAE-v0`; \n",
                "original_header": "3.1 Build Held-out Test Set"
            },
            "confidence": 0.9995487049906547,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Given a trained agent you can test it using random without a trained classifier. If the agent under test is the Donkey agent then at the commands below you need to append the Donkey simulator related parameters, i.e.:\n```commandline\n--exe-path </path/to/donkey-sim-mac/donkey_sim.app> \\\n--vae-path logs/generated_track/vae-64.pkl \\\n--z-size 64 \\\n--simulation-mul 5 \\\n--headless\n```\n \nMoreover, the python command needs to be prepended by `xvfb-run -a` to enable rendering on a virtual screen within the docker container. \n",
                "original_header": "4. Testing the Agent"
            },
            "confidence": 0.984050248428354,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "```commandline\npython -m indago.experiments --algo <algo-name> \\\n\t--exp-id <exp-id> --env-name <env-name> --env-id <env-id> \\\n\t--avf-test-policy random --failure-prob-dist \\\n\t--num-episodes <num-episodes> \\\n\t--num-runs-each-env-config <num-runs> \\\n\t--num-runs-experiments <num-runs-experiments>\n``` \n",
                "original_header": "4.1.1 Random"
            },
            "confidence": 0.9999976701912059,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "It requires a trained classifier. For example, if the classifier trained with `<filter> = 20` and `<layers> = 4` is available, then the sampling approach can be applied.\n```commandline\npython -m indago.experiments --algo <algo-name> \\\n\t--exp-id <exp-id> --env-name <env-name> --env-id <env-id> \\\n\t--avf-test-policy nn --failure-prob-dist \\\n\t--num-episodes <num-episodes> \\\n\t--num-runs-each-env-config <num-runs> \\\n\t--training-progress-filter <filter> \\\n\t--layers <layers> \\\n\t--budget <budget> \\\n\t--num-runs-experiments <num-runs-experiments> \\\n\t[--regression] \\\n\t[--minimize]\n```\n \n",
                "original_header": "4.1.2 Sampling"
            },
            "confidence": 0.999989272851746,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "It requires a trained classifier. For example, if the classifier trained with `<filter> = 20` and `<layers> = 4` is available, then the hill climbing approaches can be applied.\n```commandline\npython -m indago.experiments --algo <algo-name> \\\n\t--exp-id <exp-id> --env-name <env-name> --env-id <env-id> \\\n\t--avf-test-policy <hc-policy> --failure-prob-dist \\\n\t--num-episodes <num-episodes> \\\n\t--num-runs-each-env-config <num-runs> \\\n\t--training-progress-filter <filter> \\\n\t--layers <layers> \\\n\t--hc-counter <hc-counter> \\\n\t--neighborhood-size <neighborhood-size> \\\n\t--budget <budget> \\\n\t--num-runs-experiments <num-runs-experiments> \\\n\t[--regression] \\\n\t[--minimize]\n```\n \n",
                "original_header": "4.1.3 Hill Climbing Methods"
            },
            "confidence": 0.9997983530374996,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "It requires a trained classifier. For example, if the classifier trained with `<filter> = 20` and `<layers> = 4` is available, then the hill climbing approaches can be applied.\n```commandline\npython -m indago.experiments --algo <algo-name> \\\n\t--exp-id <exp-id> --env-name <env-name> --env-id <env-id> \\\n\t--avf-test-policy <ga-policy> --failure-prob-dist \\\n\t--num-episodes <num-episodes> \\\n\t--num-runs-each-env-config <num-runs> \\\n\t--training-progress-filter <filter> \\\n\t--layers <layers> \\\n\t--population-size <population-size> \\\n\t--crossover-rate <crossover-rate> \\\n\t--budget <budget> \\\n\t--num-runs-experiments <num-runs-experiments> \\\n\t[--regression] \\\n\t[--minimize]\n```\n \n",
                "original_header": "4.1.4 Genetic Algorithms Methods"
            },
            "confidence": 0.9989680807669057,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Type:\n```commandline\npython -m indago.env_logs_analysis_trials \\\n\t--folder <folder-name> \\\n\t--env-name <env-name> \n\t--names <[list-of-names]>\n```\n \n",
                "original_header": "5.1 Analyze Failure Search Results"
            },
            "confidence": 0.998194831270154,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Type:\n```commandline\npython -m indago.experiments --algo <algo-name> \\\n\t--exp-id <exp-id> --env-name <env-name> --env-id <env-id> \\\n\t--avf-test-policy replay_test_failure --failure-prob-dist \\\n\t--exp-file <exp-file>\n```\n \n`<exp-file>` is a log file starting with `testing-*-trial.txt` in the logs folder. The command will parse the file to look for environment configurations that caused a failure at testing time and replay those configurations (`replay_test_failure`). \nAfterwards, diversity can be computed by typing:\n```commandline\npython -m indago.diversity \\\n\t--folder <folder-name> \\\n\t--env-name <env-name> \\\n\t--pattern \n\t--names <[list-of-names]>  \\\n\t--type <type> \\\n\t--sil-threshold 20 \\\n\t--visualize\n```\n \n",
                "original_header": "5.2 Analyze Diversity Results"
            },
            "confidence": 0.9831108979490288,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        }
    ],
    "invocation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "`<heldout-test-file>` created in [Section 3.1](#31-build-held-out-test-set). \n",
                "original_header": "3.3 Train a Classifier"
            },
            "confidence": 0.900592365390047,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Replication Package for the paper \"Testing of Deep Reinforcement Learning Agents with Surrogate Models\"."
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/matteobiagiola/drl-testing-experiments/ts/README.md"
        }
    ]
}
{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 18:57:24"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/EngineeringSoftware/time-segmented-evaluation",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "EngineeringSoftware",
                "type": "Organization"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2022-03-10T17:15:41Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2023-10-27T02:06:33Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/mit",
                "type": "License",
                "name": "MIT License",
                "url": "https://api.github.com/licenses/mit",
                "spdx_id": "MIT"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "MIT License\n\nCopyright (c) 2022 EngineeringSoftware\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/LICENSE"
        }
    ],
    "description": [
        {
            "result": {
                "value": "Code and data for \"Impact of Evaluation Methodologies on Code Summarization\" in ACL 2022.",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "This repo contains the code and data for producing the experiments in\n[Impact of Evaluation Methodologies on Code\nSummarization][paper-utcs]. In this work, we study the impact of\nevaluation methodologies, i.e., the way people split datasets into\ntraining, validation, and test sets, in the field of code\nsummarization. We introduce the time-segmented evaluation methodology,\nwhich is novel to the code summarization research community, and\ncompare it with the mixed-project and cross-project methodologies that\nhave been commonly used.\n\nThe code includes:\n* a data collection tool for collecting (method, comment) pairs with\n  timestamps.\n* a data processing pipeline for splitting a dataset following the\n  three evaluation methodologies.\n* scripts for running four recent machine learning models for code\n  summarization and comparing their results across methodologies.\n\n**How to...**\n* **reproduce the training and evaluation of ML models on our\n  collected dataset**: [install dependency][sec-dependency], [download\n  all data][sec-downloads], and follow the instructions\n  [here][sec-traineval].\n* **reproduce our full study from scratch**: [install\n  dependency][sec-dependency], [download `_work/src`][sec-downloads]\n  (the source code for the ML models used in our study), and follow\n  the instructions to [collect data][sec-collect], [process\n  data][sec-process], and [train and evaluate models][sec-traineval].\n\n",
                "type": "Text_excerpt",
                "original_header": "Introduction",
                "parent_header": [
                    "Impact of Evaluation Methodologies on Code Summarization"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "1. [Dependency][sec-dependency]\n2. [Data Downloads][sec-downloads]\n3. [Code for Collecting Data][sec-collect]\n4. [Code for Processing Data][sec-process]\n5. [Code for Training and Evaluating Models][sec-traineval]\n \n",
                "original_header": "Table of Contents"
            },
            "confidence": 0.952429642755293,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "* `github-java-repos.json` is the full list of projects returned by\n  the GitHub API.\n  \n* `filtered-repos.json` is the list of projects filtered according to\n  the conditions in our paper.\n  \n* `*-logs.json` documents the time, configurations, and metrics of the\n  collection/filtering of the list. \n",
                "original_header": "Collect the list of popular Java projects on GitHub"
            },
            "confidence": 0.9483187830755382,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "* `method-data.json` is the list of method samples (includes code, API\n  comments, etc.) extracted from the project at the selected revisions\n  (at Jan 1st of 2018, 2019, 2020, 2021).\n  \n* `revision-ids.json` is the mapping from revision to the method\n  samples that are available at that revision.\n  \n* `filtered-counters.json` is the count of samples discarded during\n  collection according to our paper.\n  \n* `log.txt` is the log of the collection.\n \n",
                "original_header": "Collect raw dataset"
            },
            "confidence": 0.9812496863451028,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "From this point on, we define two variables to use in our commands: \n* `data/` contains the dataset (jsonl files) and splits (ids in\n  Train/Val/TestT/TestC sets).\n  \n* `setup_config.json` documents the configurations of this\n  methodology.\n \n",
                "original_header": "Apply methodologies (task-specific part)"
            },
            "confidence": 0.9302835963689828,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Where `$exp_name` is the name of the output directory; `$seed` is the\nrandom seed (integer) to control the random process in the experiments\n(the `--seed=$seed` argument can be omitted for a random run using the\ncurrent timestamp as seed); `$model_args` is potential additional\narguments for the model and can be looked up in the following table: \n",
                "original_header": "Train ML models under a methodology"
            },
            "confidence": 0.9186716309358165,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "time-segmented-evaluation",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "EngineeringSoftware/time-segmented-evaluation",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/EngineeringSoftware/time-segmented-evaluation/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/EngineeringSoftware/time-segmented-evaluation/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 10,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "code-summarization, comment-generation, dataset, deep-learning, evaluation, machine-learning, method-naming, ml4code, time-segmented-evaluation",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 1,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/EngineeringSoftware/time-segmented-evaluation/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 245906
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Java",
                "name": "Java",
                "type": "Programming_language",
                "size": 39042
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 14320
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "has_script_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/python/switch-cuda.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/python/prepare_conda_env.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/python/run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "requirements": [
        {
            "result": {
                "value": "[sec-dependency]: #dependency\n\nOur code require the following hardware and software environments.\n\n* Operating system: Linux (tested on Ubuntu 20.04)\n* Minimum disk space: 4 GB\n* Python: 3.8\n* Java: 8\n* Maven: 3.6.3\n* Anaconda/Miniconda: appropriate versions for Python 3.8 or higher\n\nAdditional requirements for training and evaluating ML models:\n\n* GPU: NVIDIA GTX 1080 or better\n* CUDA: 10.0 ~ 11.0\n* Disk space: 2 GB per trained model\n\n[Anaconda](https://www.anaconda.com/products/individual#Downloads) or\n[Miniconda](https://docs.conda.io/en/latest/miniconda.html) is\nrequired for installing the other Python library dependencies.  Once\nAnaconda/Miniconda is installed, you can use the following command to\nsetup a virtual environment, named `tseval`, with the Python library\ndependencies installed:\n\n```\ncd python/\n./prepare_conda_env.sh\n```\n\nAnd then use `conda activate tseval` to activate the created virtual\nenvironment.\n\nThe Java code `collector` will automatically be compiled as needed in\nour Python code.  The Java library dependencies are automatically\ndownloaded, by the Maven build system, during this process.\n\n",
                "type": "Text_excerpt",
                "original_header": "Dependency",
                "parent_header": [
                    "Impact of Evaluation Methodologies on Code Summarization"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        }
    ],
    "download": [
        {
            "result": {
                "value": "[sec-downloads]: #data-downloads\n\nAll our data is hosted on UTBox via [a shared folder](https://utexas.box.com/s/32qq85ttp9js0qqnv68ebhvr19ajo7v9).\n\nData should be downloaded to this directory with the same directory\nstructure (e.g., `_work/src` from the shared folder should be\ndownloaded as `_work/src` under current directory).\n\n",
                "type": "Text_excerpt",
                "original_header": "Data Downloads",
                "parent_header": [
                    "Impact of Evaluation Methodologies on Code Summarization"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "Requires the raw data at `_raw_data/`.\n\n```\npython -m tseval.main process_raw_data\n```\n\nResults are generated to `_work/shared/`:\n\n* `*.jsonl` files are the dataset, where each file stores one field of\n  all samples, and each line stores the field for one sample.\n  \n* `filtered-counters.json` is the combined count of samples discarded\n  during collection.\n  \n",
                "type": "Text_excerpt",
                "original_header": "Process raw data to use our data structure (tseval.data.MethodData)",
                "parent_header": [
                    "Impact of Evaluation Methodologies on Code Summarization",
                    "Code for Processing Data"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        }
    ],
    "installation": [
        {
            "result": {
                "value": "Requires Anaconda/Miniconda, and the models' source code at `_work/src/`.\n\n```\npython -m tseval.main prepare_envs --which=$model_cls\n# Example: python -m tseval.main prepare_envs --which=TransformerACL20\n```\n\nWhere the `$model_cls` for each model can be looked up in this table\n(Transformer and Seq2Seq are using the same model class and\nenvironment):\n\n| $task | $model_cls         | Model         |\n|:------|:-------------------|:--------------|\n| CG    | DeepComHybridESE19 | DeepComHybrid |\n| CG    | TransformerACL20   | Transformer   |\n| CG    | TransformerACL20   | Seq2Seq       |\n| MN    | Code2VecPOPL19     | Code2Vec      |\n| MN    | Code2SeqICLR19     | Code2Seq      |\n\nThe name of the conda environment created is `tseval-$task-$model_cls`.\n",
                "type": "Text_excerpt",
                "original_header": "Prepare the Python environments for ML models",
                "parent_header": [
                    "Impact of Evaluation Methodologies on Code Summarization",
                    "Code for Training and Evaluating Models"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Requires the dataset at `_work/$task/setup/$method/`, and\nactivating the right conda environment\n(`conda activate tseval-$task-$model_cls`).\n```\npython -m tseval.main exp_train \\\n    --task=$task \\\n    --setup_name=$method \\\n    --model_name=$model_cls \\\n    --exp_name=$exp_name \\\n    --seed=$seed \\\n    $model_args\n# Example: python -m tseval.main exp_train \\\n#     --task=CG \\\n#     --setup_name=T \\\n#    --model_name=TransformerACL20 \\\n#    --exp_name=Transformer \\\n#    --seed=4182\n```\n \n",
                "original_header": "Train ML models under a methodology"
            },
            "confidence": 0.9995136901614255,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Requires the dataset at `_work/$task/setup/$method/`, the trained\nmodel at `_work/$task/exp/$method/$exp_name/`, and activating the\nright conda environment (`conda activate tseval-$task-$model_cls`).\n```\nfor $action in val test_standard test_common; do\n    python -m tseval.main exp_eval \\\n        --task=$task \\\n        --setup_name=$method \\\n        --exp_name=$exp_name \\\n        --action=$action\ndone\n# Example: for $action in val test_standard test_common; do\n#    python -m tseval.main exp_eval \\\n#        --task=CG \\\n#        --setup_name=T \\\n#        --exp_name=Transformer \\\n#        --action=$action\n#done\n```\n \n",
                "original_header": "Evaluate ML models"
            },
            "confidence": 0.9988459401605935,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Requires the evaluation results at\n`_work/$task/result/$method/$exp_name/`, and the use of `tseval`\nenvironment (`conda activate tseval`).\n```\nfor $action in val test_standard test_common; do\n    python -m tseval.main exp_compute_metrics \\\n        --task=$task \\\n        --setup_name=$method \\\n        --exp_name=$exp_name \\\n        --action=$action\ndone\n# Example: for $action in val test_standard test_common; do\n#    python -m tseval.main exp_compute_metrics \\\n#        --task=CG \\\n#        --setup_name=T \\\n#        --exp_name=Transformer \\\n#        --action=$action\n#done\n```\n \n[paper-arxiv]: https://arxiv.org/abs/2108.09619\n[paper-utcs]: https://www.cs.utexas.edu/users/ai-lab/downloadPublication.php?filename=http://www.cs.utexas.edu/users/ml/papers/nie.acl2022.pdf&pubid=127948\n \n",
                "original_header": "Compute automatic metrics"
            },
            "confidence": 0.9854270086253287,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "@inproceedings{NieETAL22EvalMethodologies,\n    year = {2022},\n    booktitle = {Annual Meeting of the Association for Computational Linguistics},\n    pages = {to appear},\n    author = {Pengyu Nie and Jiyang Zhang and Junyi Jessy Li and Raymond J. Mooney and Milos Gligoric},\n    title = {Impact of Evaluation Methodologies on Code Summarization},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "title": "Impact of Evaluation Methodologies on Code Summarization",
                "author": "Pengyu Nie and Jiyang Zhang and Junyi Jessy Li and Raymond J. Mooney and Milos Gligoric"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Impact of Evaluation Methodologies on Code Summarization"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2108.09619\n[paper-utcs]: https://www.cs.utexas.edu/users/ai-lab/downloadPublication.php?filename=http://www.cs.utexas.edu/users/ml/papers/nie.acl2022.pdf&pubid=127948"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/EngineeringSoftware/time-segmented-evaluation/main/README.md"
        }
    ]
}
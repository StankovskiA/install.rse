{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-04 01:10:35"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/squaresLab/LLMAO",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "squaresLab",
                "type": "Organization"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2023-03-26T22:57:29Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-09-17T03:48:12Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "name": [
        {
            "result": {
                "value": "LLMAO",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "squaresLab/LLMAO",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/squaresLab/LLMAO/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/squaresLab/LLMAO/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 22,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 4,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/squaresLab/LLMAO/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Java",
                "name": "Java",
                "type": "Programming_language",
                "size": 13725403
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 92164
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "C",
                "name": "C",
                "type": "Programming_language",
                "size": 2805
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 578
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "has_script_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/results_plot.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/demo.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/results_topscores.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/codegen_loading.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/fault_localizer.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "requirements": [
        {
            "result": {
                "value": "--------------------\nWe recommend using docker for LLMAO.\n```\n# Pull the huggingface docker image, which includes most requirements\n\ndocker pull huggingface/transformers-pytorch-gpu\n\n# Run a container. Make sure to mount the container to your own directory path. We assume an Nvidia GPU exists, as training and loading an LLM requires a significant amount of GPU VRAM.\n\ndocker run -it --mount type=bind,src=\"path-to-local-directory\",dst=/home huggingface/transformers-pytorch-gpu:4.21.0\n\n# Install some additional dependencies\npip install --upgrade pip\npip install accelerate\npip install torchdata\n```\n\n\nROC plots and AUC scores:\n```\npython3 plotter.py plotfiles\n```\n",
                "type": "Text_excerpt",
                "original_header": "I. Requirements",
                "parent_header": [
                    "LLMAO"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/README.md"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "---------------------------\nWe include two example code files here for demonstration: `demo_code.c` and `demo_code.java`.\n\nWith actual vulnerable lines 52-62 for `demo_code.c`,\nand actual buggy lines 20-30 for `demo_code.java`.\n\n```\npython3 demo.py $demo_type $pretrain_type $code_file_path\nexample: python3 demo.py devign 16B demo_code.c\n\n\noutput: \nline-52 sus-15.86%:         DISAS_INSN(divw)\n...\n```\n\nMinimum VRAM (GPU memory) required for loading each of the checkpoints:\n\n350M: 2.6GB\n\n6B: 14.7GB\n\n16B: 38GB (recommend at least 2-3 GPUs)\n\nThe 16B checkpoint for Defects4J is too large to fit on GitHub or standard drives, for replication results please use 350M or 6B.\n",
                "type": "Text_excerpt",
                "original_header": "II. Demo",
                "parent_header": [
                    "LLMAO"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/README.md"
        }
    ],
    "run": [
        {
            "result": {
                "value": "---------------------------\nLLMAO was neither trained nor evaluated on file level due to its limited context window of 128 lines.\nThe training and evaluation procedure of LLMAO is described in Section 3.1 of the paper.\n\nTo run LLMAO on a much larger file, one way is to split the file into multiple chunks of 128 lines and combine scores at the end. \nHowever, this way of using LLMAO removes valuable context across the entire file, and buggy or vulnerable lines across multiple chunks cannot be accuracy detected.\nWe include the method for running LLMAO on Defects4J entire files in this replication package to showcase the limitiation of our LLM-based fault localization.\nWe hope that this limitation can be reduced as LLMs grow larger and can process significantly larger context windows.\nEnter the following:\n```\npython3 top_score_window.py\n```\nOutput:\n\n```\nTop score for llmao_window\ntop 5: 77\ntop 3: 52\ntop 1: 24\n\nTop score for Transfer\ntop 5: 145\ntop 3: 126\ntop 1: 69\n```\n\nIn which LLMAO has much weaker results than Transfer-FL, a prior fault localization approach that is trained on Defects4J for each individual bug.\n\nTo remake LLMAO file level scores:\n```\npython3 llmao_d4j_window.py\n```\n\n\n",
                "type": "Text_excerpt",
                "original_header": "V. Run LLMAO on file level",
                "parent_header": [
                    "LLMAO"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/README.md"
        }
    ],
    "installation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "2. Unzip it and put the folder in the same path as this repo \n3. Load Codegen final hidden states:\n    change `biggest_model=1` to use Codegen-16B: requires significant amount of GPU vram and storage.\n    `bash codegen_loading.sh` \n4. Train \n    `bash fault_localizer.sh` \n",
                "original_header": "IV. Train model yourself"
            },
            "confidence": 0.946491202345229,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "LLMAO"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2310.01726"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/squaresLab/LLMAO/master/README.md"
        }
    ]
}
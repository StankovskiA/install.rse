{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-04 01:17:43"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/qibinhang/MwT",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "qibinhang",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2023-06-05T04:02:48Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-09-12T11:54:45Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "description": [
        {
            "result": {
                "value": "Modularizing while Training: A New Paradigm for Modularizing DNN Models (ICSE'24)",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Deep neural network (DNN) models have become increasingly crucial components in intelligent software systems. However, training a DNN model is typically expensive in terms of both time and money. To address this issue, researchers have recently focused on reusing existing DNN models - borrowing the idea of code reuse in software engineering.However, reusing an entire model could cause extra overhead or inherits the weakness from the undesired functionalities.Hence, existing work proposes to decompose an already trained model into modules, i.e., modularizing-after-training, and enable module reuse.Since trained models are not built for modularization, modularizing-after-training incurs huge overhead and model accuracy loss.In this paper, we propose a novel approach that incorporates modularization into the model training process, i.e., modularizing-while-training (MwT).We train a model to be structurally modular through two loss functions that optimize intra-module cohesion and inter-module coupling. We have implemented the proposed approach for modularizing Convolutional Neural Network (CNN) models in this work.The evaluation results on representative models demonstrate that MwT outperforms the state-of-the-art approach. Specifically, the accuracy loss caused by MwT is only 1.13%, which is 1.76% less than that of the latter. The kernel retention rate of the modules generated by MwT is only 14.58%, with a reduction of 74.31% over the state-of-the-art approach.Furthermore, the total time cost required for training and modularizing is only 108 minutes, half that of the latter. \n",
                "original_header": "Abstract"
            },
            "confidence": 0.9875217995741234,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/qibinhang/MwT/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "The value of threshold directly affects the results of modularizing and module reuse. \nAs shown in the figure below, as the threshold increases from 0.1 to 0.9, the kernel retention rate of the modules gradually decreases, from 37.36% to 24.74%. \nA larger threshold makes each module tend to retain convolutional kernels that are required by all samples of the corresponding category, leading to an increase in cohesion from 0.8572 to 0.9437 and a decrease in coupling from 0.3594 to 0.2412.  \n",
                "original_header": "Discussion of the effect of threshold on modularizing the modular ResNet18-CIFAR10 model."
            },
            "confidence": 0.9523265902963005,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/qibinhang/MwT/main/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "MwT",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "qibinhang/MwT",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/qibinhang/MwT/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/qibinhang/MwT/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 6,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "dnn-modularization, model-reuse",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 1,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/qibinhang/MwT/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 174685
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/qibinhang/MwT/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "type": [
        {
            "result": {
                "value": "commandline-application",
                "type": "String"
            },
            "confidence": 0.82,
            "technique": "software_type_heuristics"
        }
    ],
    "requirements": [
        {
            "result": {
                "value": "+ fvcore 0.1.5.post20221221<br>\n+ numpy 1.23.1<br>\n+ python 3.9.12<br>\n+ pytorch 1.12.0<br>\n+ tensorboard 2.10.1<br>\n+ torchvision 0.13.0<br>\n+ tqdm 4.64.0 <br>\n+ GPU with CUDA support is also needed\n\n<br>\n",
                "type": "Text_excerpt",
                "original_header": "Requirements",
                "parent_header": [
                    "Modularizing while Training: A New Paradigm for Modularizing DNN Models"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/qibinhang/MwT/main/README.md"
        }
    ],
    "download": [
        {
            "result": {
                "value": "The following sections describe how to reproduce the experimental results in our paper. \n1. We provide the resulting models trained by standard training and modular models trained by modular training<br>\nOne can download `data/` from [here](https://mega.nz/file/1T8ExJrL#uUr2Jh-j1NN0m575mojKDPiDvn0aZVw_tRIeq9GbhXE) and then move it to `MwT/`.<br>\nThe datasets will be downloaded automatically by PyTorch when running our project. \n2. Modify `self.root_dir` in `src/configs.py`.\n",
                "type": "Text_excerpt",
                "original_header": "Downloading experimental data",
                "parent_header": [
                    "Modularizing while Training: A New Paradigm for Modularizing DNN Models",
                    "Replication of experimental results"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/qibinhang/MwT/main/README.md"
        }
    ],
    "invocation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "1. Training a modular VGG16 model.\n```commandline\npython modular_trainer.py --model vgg16 --dataset cifar10 --lr_model 0.05 --alpha 0.5 --beta 1.5 --batch_size 128\n``` \n",
                "original_header": "Modular training, modularizing, and module reuse"
            },
            "confidence": 0.9078243642609831,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/qibinhang/MwT/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "1. Training a VGG16 model\n```commandline\npython standard_trainer.py --model vgg16 --dataset cifar10 --lr_model 0.05 --batch_size 128\n```\n \n",
                "original_header": "Standard training"
            },
            "confidence": 0.9159966422715216,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/qibinhang/MwT/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Modularizing while Training: A New Paradigm for Modularizing DNN Models"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/qibinhang/MwT/main/README.md"
        }
    ],
    "images": [
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/qibinhang/MwT/main/src/rq4_thres_modularize.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/qibinhang/MwT/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/qibinhang/MwT/main/src/rq4_thres_reuse.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/qibinhang/MwT/main/README.md"
        }
    ]
}
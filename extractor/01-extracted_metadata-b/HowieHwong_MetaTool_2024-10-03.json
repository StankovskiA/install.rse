{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-03 21:09:02"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/HowieHwong/MetaTool",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "HowieHwong",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2023-10-07T06:42:13Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-09-27T13:32:34Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/mit",
                "type": "License",
                "name": "MIT License",
                "url": "https://api.github.com/licenses/mit",
                "spdx_id": "MIT"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "MIT License\n\nCopyright (c) 2023 Yue Huang\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/LICENSE"
        }
    ],
    "description": [
        {
            "result": {
                "value": "[ICLR 2024] MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "We introduce **MetaTool**, a benchmark designed to evaluate whether LLMs have tool usage awareness and can correctly choose tools. It includes:\n\n- **ToolE Dataset**: This dataset contains various types of user queries in the form of prompts that trigger LLMs to use tools, including both single-tool and multi-tool scenarios.\n- **Various Tasks**: we set the tasks for both tool usage awareness and tool selection. We define four subtasks from different perspectives in tool selection, including tool selection with similar choices, tool selection in specific scenarios, tool selection with possible reliability issues, and multi-tool selection.\n- **Results on nine LLMs**: We conduct experiments involving nine popular LLMs and find that the majority of them still struggle to effectively select tools, highlighting the existing gaps between LLMs and genuine intelligent agents.\n\n\n<div align=\"center\">\n<img src=\"assets/benchmark_architecture_00.jpg\">\n</div>\n",
                "type": "Text_excerpt",
                "original_header": "Introduction",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "MetaTool",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "HowieHwong/MetaTool",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/HowieHwong/MetaTool/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/HowieHwong/MetaTool/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 63,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 8,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/HowieHwong/MetaTool/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 32438
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 1479
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "has_script_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/quickstart.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/src/generation/run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "<p align=\"center\">\n   <a href=\"https://atlas.nomic.ai/map/a43a6a84-4453-428a-8738-2534d7bf0b89/b2b8134b-a37e-45d2-a0d9-765911f27df6\" target=\"_blank\">\ud83c\udf10 Dataset Website</a> | <a href=\"https://arxiv.org/abs/2310.03128\" target=\"_blank\">\ud83d\udcc3 Paper </a> | <a href=\"https://github.com/HowieHwong/MetaTool/issues\"> \ud83d\ude4b Welcome Contribution  </a> | <a href=\"https://github.com/HowieHwong/MetaTool/blob/master/LICENSE\"> \ud83d\udcdc License</a>\n</p>\n\n",
                "type": "Text_excerpt",
                "original_header": "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use"
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "We introduce the **ToolE** dataset with 21.1k diverse user queries related to tool usage. \nEach entry within the dataset comprises a user request (i.e., query) along with its corresponding tool name and tool description. These queries serve as triggers that prompt LLMs to utilize specific tools.\n\n<div align=\"center\">\n<img src=\"assets/dataset_gen_00.jpg\">\n</div>\n\n",
                "type": "Text_excerpt",
                "original_header": "Dataset generation",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                    "ToolE Dataset"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "<center>\n\n| Generation method              | Model                          | Sample number                                         |\n|--------------------------------|--------------------------------|-------------------------------------------------------|\n| Direct generation              | ChatGPT, GPT-4                 | 11,700                                                |\n| Emotional generation           | ChatGPT                        | 7,800                                                 |\n| Keyword generation             | ChatGPT                        | 1,950                                                 |\n| Details generation             | ChatGPT                        | 7,800                                                 |\n| Multi-tool generation          | ChatGPT, GPT-4                 | 1,624                                                 |\n| After checking                 | \\                              | 21,127 (20,630 single-tool + 497 multi-tool)          |\n\n</center>\n",
                "type": "Text_excerpt",
                "original_header": "Dataset statistics",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                    "ToolE Dataset"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "- Single-tool data: `dataset/data/all_clean_data.csv`\n- Multi-tool data: `dataset/data/multi_tool_query_golden.json`\n- All tool description: `dataset/plugin_des.json`\n- meta data from OpenAI plugin store: `dataset/plugin_info.json`\n- Merged data description: `dataset/big_tool_des.json`\n- Embedding of tool description: `dataset/tool_embedding.pkl`\n- Scenario tool list (Table 10 in the paper): `dataset/scenario`\n",
                "type": "Text_excerpt",
                "original_header": "Dataset files",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                    "ToolE Dataset"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "<center>\n<h3>Tool usage awareness</h3>\n</center>\n\n<div align=\"center\">\n<img src=\"assets/radar_awareness.png\" width=\"500\" height=\"530\">\n</div>\n\n\n<center>\n<h3>Tool selection</h3>\n</center>\n\n\n<div align=\"center\">\n<img src=\"assets/radar_selection.png\" width=\"500\" height=\"530\">\n</div>\n\n\n\n## Quick Start\n\nFirst, create an `.env` file in the (put it next to `src/generation/.example.env` and include the same fields). \n\nNow, you can run the following command for a quickstart (which downloads the model and prepares the data for you): `bash quickstart.sh -m <model_name> -t <task>`. \n\nAlternatively, you can perform the below. Then, follow the results generation section.\n\n### Install the packages:\n```shell\npip install --upgrade pip\npip install -r requirements.txt\n```\n\n### Download the models:\n- Set the `HF_HOME` environment variable in the `src/generation/.env` file to specify the Hugging Face model cache folder, e.g., `HF_HOME=/path/to/your/huggingface/cache`.\n\n- `--model-path`: Specify the Hugging Face model repository name to download.\n```shell\npython src/generation/model_download.py --model_path lmsys/vicuna-7b-v1.3\n```\n\n### Tool embedding\nWe use `milvus` to  store tool embedding and conduct similarity searching.\n\nTo install and run `milvus` locally: https://milvus.io/docs/install_standalone-docker.md\n\n\nThen run the following command to build a `milvus` database.\n```python\npython src/embedding/milvus_database.py\n```\n\n### Construct prompt data:\nThe pre-defined prompt templates are in `src/prompt/prompt_template`\n\nIf you want to generate the prompts for all tasks, run following command:\n```shell\npython src/prompt/prompt_construction.py\n```\nFor single task prompts, run following command:\n```shell\npython src/prompt/prompt_construction.py [task]\n```\nReplace `[task]` with one of the following task options:\n\n- `similar`: Similar tool selection.\n- `scenario`: Scenario tool selection.\n- `reliable`: Reliability tool selection.\n- `multi`: Multi-tool prompt construction.\n- `all`: All tasks.\n\n### Generate the results:\n#### Parameters\nYou can generate results by running the run.sh script. You may need to modify the running parameters within the run.sh file to suit your specific needs.\n- `--test_type`: Choose between `tool_test_thought` or `tool_test_action` depending on your testing needs.\n- `--model-path`: Specify the Hugging Face model repository name.\n```shell\nsh src/generation/run.sh\n```\n\n\n## Troubleshooting\n\nIf you face an import error from Python, you may need to add this directory to your Python path:\n```shell\n# Add sys path\nsrc_path=\"$(pwd)/src\"\nexport PYTHONPATH=\"$PYTHONPATH:$src_path\"\n```\n\n\n## Citation\n\n```\n@article{huang2023metatool,\n  title   = {MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use},\n  author  = {Yue Huang and Jiawen Shi and Yuan Li and Chenrui Fan and Siyuan Wu and Qihui Zhang and Yixin Liu and Pan Zhou and Yao Wan and Neil Zhenqiang Gong and Lichao Sun},\n  year    = {2023},\n  journal = {arXiv preprint arXiv: 2310.03128}\n}\n```",
                "type": "Text_excerpt",
                "original_header": "Evaluation Results",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "<div align=\"center\">\n<img src=\"assets/MetaTool.png\" >\n</div>\n\n# MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use\n\n<p align=\"center\">\n   <a href=\"https://atlas.nomic.ai/map/a43a6a84-4453-428a-8738-2534d7bf0b89/b2b8134b-a37e-45d2-a0d9-765911f27df6\" target=\"_blank\">\ud83c\udf10 Dataset Website</a> | <a href=\"https://arxiv.org/abs/2310.03128\" target=\"_blank\">\ud83d\udcc3 Paper </a> | <a href=\"https://github.com/HowieHwong/MetaTool/issues\"> \ud83d\ude4b Welcome Contribution  </a> | <a href=\"https://github.com/HowieHwong/MetaTool/blob/master/LICENSE\"> \ud83d\udcdc License</a>\n</p>\n\n\n## Introduction\n\nWe introduce **MetaTool**, a benchmark designed to evaluate whether LLMs have tool usage awareness and can correctly choose tools. It includes:\n\n- **ToolE Dataset**: This dataset contains various types of user queries in the form of prompts that trigger LLMs to use tools, including both single-tool and multi-tool scenarios.\n- **Various Tasks**: we set the tasks for both tool usage awareness and tool selection. We define four subtasks from different perspectives in tool selection, including tool selection with similar choices, tool selection in specific scenarios, tool selection with possible reliability issues, and multi-tool selection.\n- **Results on nine LLMs**: We conduct experiments involving nine popular LLMs and find that the majority of them still struggle to effectively select tools, highlighting the existing gaps between LLMs and genuine intelligent agents.\n\n\n<div align=\"center\">\n<img src=\"assets/benchmark_architecture_00.jpg\">\n</div>\n\n## ToolE Dataset\n\n### Dataset generation\nWe introduce the **ToolE** dataset with 21.1k diverse user queries related to tool usage. \nEach entry within the dataset comprises a user request (i.e., query) along with its corresponding tool name and tool description. These queries serve as triggers that prompt LLMs to utilize specific tools.\n\n<div align=\"center\">\n<img src=\"assets/dataset_gen_00.jpg\">\n</div>\n\n\n### Dataset statistics\n\n<center>\n\n| Generation method              | Model                          | Sample number                                         |\n|--------------------------------|--------------------------------|-------------------------------------------------------|\n| Direct generation              | ChatGPT, GPT-4                 | 11,700                                                |\n| Emotional generation           | ChatGPT                        | 7,800                                                 |\n| Keyword generation             | ChatGPT                        | 1,950                                                 |\n| Details generation             | ChatGPT                        | 7,800                                                 |\n| Multi-tool generation          | ChatGPT, GPT-4                 | 1,624                                                 |\n| After checking                 | \\                              | 21,127 (20,630 single-tool + 497 multi-tool)          |\n\n</center>\n\n### Dataset files\n\n- Single-tool data: `dataset/data/all_clean_data.csv`\n- Multi-tool data: `dataset/data/multi_tool_query_golden.json`\n- All tool description: `dataset/plugin_des.json`\n- meta data from OpenAI plugin store: `dataset/plugin_info.json`\n- Merged data description: `dataset/big_tool_des.json`\n- Embedding of tool description: `dataset/tool_embedding.pkl`\n- Scenario tool list (Table 10 in the paper): `dataset/scenario`\n\n## Evaluation Results\n\n<center>\n<h3>Tool usage awareness</h3>\n</center>\n\n<div align=\"center\">\n<img src=\"assets/radar_awareness.png\" width=\"500\" height=\"530\">\n</div>\n\n\n<center>\n<h3>Tool selection</h3>\n</center>\n\n\n<div align=\"center\">\n<img src=\"assets/radar_selection.png\" width=\"500\" height=\"530\">\n</div>\n\n\n\n## Quick Start\n\nFirst, create an `.env` file in the (put it next to `src/generation/.example.env` and include the same fields). \n\nNow, you can run the following command for a quickstart (which downloads the model and prepares the data for you): `bash quickstart.sh -m <model_name> -t <task>`. \n\nAlternatively, you can perform the below. Then, follow the results generation section.\n\n### Install the packages:\n```shell\npip install --upgrade pip\npip install -r requirements.txt\n```\n\n### Download the models:\n- Set the `HF_HOME` environment variable in the `src/generation/.env` file to specify the Hugging Face model cache folder, e.g., `HF_HOME=/path/to/your/huggingface/cache`.\n\n- `--model-path`: Specify the Hugging Face model repository name to download.\n```shell\npython src/generation/model_download.py --model_path lmsys/vicuna-7b-v1.3\n```\n\n### Tool embedding\nWe use `milvus` to  store tool embedding and conduct similarity searching.\n\nTo install and run `milvus` locally: https://milvus.io/docs/install_standalone-docker.md\n\n\nThen run the following command to build a `milvus` database.\n```python\npython src/embedding/milvus_database.py\n```\n\n### Construct prompt data:\nThe pre-defined prompt templates are in `src/prompt/prompt_template`\n\nIf you want to generate the prompts for all tasks, run following command:\n```shell\npython src/prompt/prompt_construction.py\n```\nFor single task prompts, run following command:\n```shell\npython src/prompt/prompt_construction.py [task]\n```\nReplace `[task]` with one of the following task options:\n\n- `similar`: Similar tool selection.\n- `scenario`: Scenario tool selection.\n- `reliable`: Reliability tool selection.\n- `multi`: Multi-tool prompt construction.\n- `all`: All tasks.\n\n### Generate the results:\n#### Parameters\nYou can generate results by running the run.sh script. You may need to modify the running parameters within the run.sh file to suit your specific needs.\n- `--test_type`: Choose between `tool_test_thought` or `tool_test_action` depending on your testing needs.\n- `--model-path`: Specify the Hugging Face model repository name.\n```shell\nsh src/generation/run.sh\n```\n\n\n## Troubleshooting\n\nIf you face an import error from Python, you may need to add this directory to your Python path:\n```shell\n# Add sys path\nsrc_path=\"$(pwd)/src\"\nexport PYTHONPATH=\"$PYTHONPATH:$src_path\"\n```\n\n\n## Citation\n\n```\n@article{huang2023metatool,\n  title   = {MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use},\n  author  = {Yue Huang and Jiawen Shi and Yuan Li and Chenrui Fan and Siyuan Wu and Qihui Zhang and Yixin Liu and Pan Zhou and Yao Wan and Neil Zhenqiang Gong and Lichao Sun},\n  year    = {2023},\n  journal = {arXiv preprint arXiv: 2310.03128}\n}\n```",
                "type": "Text_excerpt",
                "original_header": "Tool usage awareness",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                    "Evaluation Results"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "<div align=\"center\">\n<img src=\"assets/MetaTool.png\" >\n</div>\n\n# MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use\n\n<p align=\"center\">\n   <a href=\"https://atlas.nomic.ai/map/a43a6a84-4453-428a-8738-2534d7bf0b89/b2b8134b-a37e-45d2-a0d9-765911f27df6\" target=\"_blank\">\ud83c\udf10 Dataset Website</a> | <a href=\"https://arxiv.org/abs/2310.03128\" target=\"_blank\">\ud83d\udcc3 Paper </a> | <a href=\"https://github.com/HowieHwong/MetaTool/issues\"> \ud83d\ude4b Welcome Contribution  </a> | <a href=\"https://github.com/HowieHwong/MetaTool/blob/master/LICENSE\"> \ud83d\udcdc License</a>\n</p>\n\n\n## Introduction\n\nWe introduce **MetaTool**, a benchmark designed to evaluate whether LLMs have tool usage awareness and can correctly choose tools. It includes:\n\n- **ToolE Dataset**: This dataset contains various types of user queries in the form of prompts that trigger LLMs to use tools, including both single-tool and multi-tool scenarios.\n- **Various Tasks**: we set the tasks for both tool usage awareness and tool selection. We define four subtasks from different perspectives in tool selection, including tool selection with similar choices, tool selection in specific scenarios, tool selection with possible reliability issues, and multi-tool selection.\n- **Results on nine LLMs**: We conduct experiments involving nine popular LLMs and find that the majority of them still struggle to effectively select tools, highlighting the existing gaps between LLMs and genuine intelligent agents.\n\n\n<div align=\"center\">\n<img src=\"assets/benchmark_architecture_00.jpg\">\n</div>\n\n## ToolE Dataset\n\n### Dataset generation\nWe introduce the **ToolE** dataset with 21.1k diverse user queries related to tool usage. \nEach entry within the dataset comprises a user request (i.e., query) along with its corresponding tool name and tool description. These queries serve as triggers that prompt LLMs to utilize specific tools.\n\n<div align=\"center\">\n<img src=\"assets/dataset_gen_00.jpg\">\n</div>\n\n\n### Dataset statistics\n\n<center>\n\n| Generation method              | Model                          | Sample number                                         |\n|--------------------------------|--------------------------------|-------------------------------------------------------|\n| Direct generation              | ChatGPT, GPT-4                 | 11,700                                                |\n| Emotional generation           | ChatGPT                        | 7,800                                                 |\n| Keyword generation             | ChatGPT                        | 1,950                                                 |\n| Details generation             | ChatGPT                        | 7,800                                                 |\n| Multi-tool generation          | ChatGPT, GPT-4                 | 1,624                                                 |\n| After checking                 | \\                              | 21,127 (20,630 single-tool + 497 multi-tool)          |\n\n</center>\n\n### Dataset files\n\n- Single-tool data: `dataset/data/all_clean_data.csv`\n- Multi-tool data: `dataset/data/multi_tool_query_golden.json`\n- All tool description: `dataset/plugin_des.json`\n- meta data from OpenAI plugin store: `dataset/plugin_info.json`\n- Merged data description: `dataset/big_tool_des.json`\n- Embedding of tool description: `dataset/tool_embedding.pkl`\n- Scenario tool list (Table 10 in the paper): `dataset/scenario`\n\n## Evaluation Results\n\n<center>\n<h3>Tool usage awareness</h3>\n</center>\n\n<div align=\"center\">\n<img src=\"assets/radar_awareness.png\" width=\"500\" height=\"530\">\n</div>\n\n\n<center>\n<h3>Tool selection</h3>\n</center>\n\n\n<div align=\"center\">\n<img src=\"assets/radar_selection.png\" width=\"500\" height=\"530\">\n</div>\n\n\n",
                "type": "Text_excerpt",
                "original_header": "Tool selection",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                    "Evaluation Results"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "First, create an `.env` file in the (put it next to `src/generation/.example.env` and include the same fields). \n\nNow, you can run the following command for a quickstart (which downloads the model and prepares the data for you): `bash quickstart.sh -m <model_name> -t <task>`. \n\nAlternatively, you can perform the below. Then, follow the results generation section.\n",
                "type": "Text_excerpt",
                "original_header": "Quick Start",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "We use `milvus` to  store tool embedding and conduct similarity searching.\n\nTo install and run `milvus` locally: https://milvus.io/docs/install_standalone-docker.md\n\n\nThen run the following command to build a `milvus` database.\n```python\npython src/embedding/milvus_database.py\n```\n",
                "type": "Text_excerpt",
                "original_header": "Tool embedding",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                    "Quick Start"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "The pre-defined prompt templates are in `src/prompt/prompt_template`\n\nIf you want to generate the prompts for all tasks, run following command:\n```shell\npython src/prompt/prompt_construction.py\n```\nFor single task prompts, run following command:\n```shell\npython src/prompt/prompt_construction.py [task]\n```\nReplace `[task]` with one of the following task options:\n\n- `similar`: Similar tool selection.\n- `scenario`: Scenario tool selection.\n- `reliable`: Reliability tool selection.\n- `multi`: Multi-tool prompt construction.\n- `all`: All tasks.\n",
                "type": "Text_excerpt",
                "original_header": "Construct prompt data:",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                    "Quick Start"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "You can generate results by running the run.sh script. You may need to modify the running parameters within the run.sh file to suit your specific needs.\n- `--test_type`: Choose between `tool_test_thought` or `tool_test_action` depending on your testing needs.\n- `--model-path`: Specify the Hugging Face model repository name.\n```shell\nsh src/generation/run.sh\n```\n\n",
                "type": "Text_excerpt",
                "original_header": "Parameters",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                    "Quick Start",
                    "Generate the results:"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "If you face an import error from Python, you may need to add this directory to your Python path:\n```shell\n# Add sys path\nsrc_path=\"$(pwd)/src\"\nexport PYTHONPATH=\"$PYTHONPATH:$src_path\"\n```\n\n",
                "type": "Text_excerpt",
                "original_header": "Troubleshooting",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        }
    ],
    "installation": [
        {
            "result": {
                "value": "```shell\npip install --upgrade pip\npip install -r requirements.txt\n```\n",
                "type": "Text_excerpt",
                "original_header": "Install the packages:",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                    "Quick Start"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        }
    ],
    "download": [
        {
            "result": {
                "value": "- Set the `HF_HOME` environment variable in the `src/generation/.env` file to specify the Hugging Face model cache folder, e.g., `HF_HOME=/path/to/your/huggingface/cache`.\n\n- `--model-path`: Specify the Hugging Face model repository name to download.\n```shell\npython src/generation/model_download.py --model_path lmsys/vicuna-7b-v1.3\n```\n",
                "type": "Text_excerpt",
                "original_header": "Download the models:",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                    "Quick Start"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "```\n@article{huang2023metatool,\n  title   = {MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use},\n  author  = {Yue Huang and Jiawen Shi and Yuan Li and Chenrui Fan and Siyuan Wu and Qihui Zhang and Yixin Liu and Pan Zhou and Yao Wan and Neil Zhenqiang Gong and Lichao Sun},\n  year    = {2023},\n  journal = {arXiv preprint arXiv: 2310.03128}\n}\n```",
                "type": "Text_excerpt",
                "original_header": "Citation",
                "parent_header": [
                    "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "value": "@article{huang2023metatool,\n    journal = {arXiv preprint arXiv: 2310.03128},\n    year = {2023},\n    author = {Yue Huang and Jiawen Shi and Yuan Li and Chenrui Fan and Siyuan Wu and Qihui Zhang and Yixin Liu and Pan Zhou and Yao Wan and Neil Zhenqiang Gong and Lichao Sun},\n    title = {MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "title": "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use",
                "author": "Yue Huang and Jiawen Shi and Yuan Li and Chenrui Fan and Siyuan Wu and Qihui Zhang and Yixin Liu and Pan Zhou and Yao Wan and Neil Zhenqiang Gong and Lichao Sun"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        }
    ],
    "logo": [
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/assets/MetaTool.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        }
    ],
    "images": [
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/assets/benchmark_architecture_00.jpg"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/assets/dataset_gen_00.jpg"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/assets/radar_awareness.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/assets/radar_selection.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2310.03128\" target=\"_blank\">\ud83d\udcc3 Paper </a> | <a href=\"https://github.com/HowieHwong/MetaTool/issues\"> \ud83d\ude4b Welcome Contribution  </a> | <a href=\"https://github.com/HowieHwong/MetaTool/blob/master/LICENSE\"> \ud83d\udcdc License</a>\n</p>\n\n\n## Introduction\n\nWe introduce **MetaTool**, a benchmark designed to evaluate whether LLMs have tool usage awareness and can correctly choose tools. It includes:\n\n- **ToolE Dataset**: This dataset contains various types of user queries in the form of prompts that trigger LLMs to use tools, including both single-tool and multi-tool scenarios.\n- **Various Tasks**: we set the tasks for both tool usage awareness and tool selection. We define four subtasks from different perspectives in tool selection, including tool selection with similar choices, tool selection in specific scenarios, tool selection with possible reliability issues, and multi-tool selection.\n- **Results on nine LLMs**: We conduct experiments involving nine popular LLMs and find that the majority of them still struggle to effectively select tools, highlighting the existing gaps between LLMs and genuine intelligent agents.\n\n\n<div align=\"center\">\n<img src=\"assets/benchmark_architecture_00.jpg\">\n</div>\n\n## ToolE Dataset\n\n### Dataset generation\nWe introduce the **ToolE** dataset with 21.1k diverse user queries related to tool usage. \nEach entry within the dataset comprises a user request (i.e., query"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/ 2310.03128"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/HowieHwong/MetaTool/master/README.md"
        }
    ]
}
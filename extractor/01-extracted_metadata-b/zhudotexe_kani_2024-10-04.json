{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-04 01:02:26"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/zhudotexe/kani",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "zhudotexe",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2023-07-14T15:18:23Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-10-03T18:15:26Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/mit",
                "type": "License",
                "name": "MIT License",
                "url": "https://api.github.com/licenses/mit",
                "spdx_id": "MIT"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "MIT License\n\nCopyright (c) 2023-present Andrew Zhu\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/LICENSE"
        }
    ],
    "description": [
        {
            "result": {
                "value": "kani (\u30ab\u30cb) is a highly hackable microframework for chat-based language models with tool use/function calling. (NLP-OSS @ EMNLP 2023)",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Compared to other LM frameworks, kani is less opinionated and offers more fine-grained customizability\nover the parts of the control flow that matter, making it the perfect choice for NLP researchers, hobbyists, and\ndevelopers alike. \nCheck out the [Model Zoo](examples/4_engines_zoo.py) to see how to use each of these models in your application! \n",
                "original_header": "kani (\u30ab\u30cb)"
            },
            "confidence": 0.9337729539792772,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "- **Lightweight and high-level** - kani implements common boilerplate to interface with language models without forcing\n  you to use opinionated prompt frameworks or complex library-specific tooling.\n- **Model agnostic** - kani provides a simple interface to implement: token counting and completion generation.\n  kani lets developers switch which language model runs on the backend without major code refactors.\n- **Automatic chat memory management** - Allow chat sessions to flow without worrying about managing the number of\n  tokens in the history - kani takes care of it.\n- **Function calling with model feedback and retry** - Give models access to functions in just one line of code.\n  kani elegantly provides feedback about hallucinated parameters and errors and allows the model to retry calls.\n- **You control the prompts** - There are no hidden prompt hacks. We will never decide for you how to format your own\n  data, unlike other popular language model libraries.\n- **Fast to iterate and intuitive to learn** - With kani, you only write Python - we handle the rest.\n- **Asynchronous design from the start** - kani can scale to run multiple chat sessions in parallel easily, without\n  having to manage multiple processes or programs.\n \n",
                "original_header": "Features"
            },
            "confidence": 0.9953759165356962,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "We built kani as a more flexible, simple, and robust alternative. A good analogy between frameworks would be to say that\nkani is to LangChain as Flask (or FastAPI) is to Django. \n",
                "original_header": "Why kani?"
            },
            "confidence": 0.9712257423545846,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "The core development team is made of three PhD students in the Department of Computer and Information Science at the\nUniversity of Pennsylvania. We're all members of\n[Prof. Chris Callison-Burch's](https://www.cis.upenn.edu/~ccb/) lab, working towards advancing the future of NLP. \n- [**Andrew Zhu**](https://zhu.codes/) started in Fall 2022. His research interests include natural language processing,\n  programming languages, distributed systems, and more. He's also a full-stack software engineer, proficient in all\n  manner of backend, devops, database, and frontend engineering. Andrew strives to make idiomatic, clean, performant,\n  and low-maintenance code \u2014 philosophies that are often rare in academia. His research is supported by the NSF Graduate\n  Research Fellowship.\n- [**Liam Dugan**](https://liamdugan.com/) started in Fall 2021. His research focuses primarily on large language models\n  and how humans interact with them. In particular, he is interested in human detection of generated text and whether we\n  can apply those insights to automatic detection systems. He is also interested in the practical application of large\n  language models to education.\n- [**Alyssa Hwang**](https://alyssahwang.com/) started in Fall 2020 and is advised by Chris Callison-Burch and Andrew\n  Head. Her research focuses on AI assistants that effectively communicate complex information, like voice assistants\n  guiding users through instructions or audiobooks allowing users to seamlessly navigate through spoken text. Beyond\n  research, Alyssa chairs the Penn CIS Doctoral Association, founded the CIS PhD Mentorship Program, and was supported\n  by the NSF Graduate Research Fellowship Program. \nWe use kani actively in our research, and aim to keep it up-to-date with modern NLP practices.\n \n",
                "original_header": "Who we are"
            },
            "confidence": 0.9570899643626625,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "kani",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "zhudotexe/kani",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/zhudotexe/kani/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/zhudotexe/kani/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 557,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "chatgpt, claude-2, framework, function-calling, gpt-3, gpt-4, large-language-models, llama, llama-2, llms, microframework, openai, tool-use",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 30,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/zhudotexe/kani/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 293286
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Jupyter Notebook",
                "name": "Jupyter Notebook",
                "type": "Programming_language",
                "size": 17084
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "releases": [
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/176710051",
                "tag": "v1.2.0",
                "name": "v1.2.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## New Features\r\n- Hugging Face: Models loaded through the `HuggingEngine` now use [chat templates](https://huggingface.co/docs/transformers/main/chat_templating) for conversational prompting and tool usage if available by default. This should make it much easier to get started with a Hugging Face model in Kani.\r\n- Added the ability to supply a custom tokenizer to the `OpenAIEngine` (e.g., for using OpenAI-compatible APIs)\\\r\n\r\n## Fixes/Improvements\r\n- Fixed a missing dependency in the `llama` extra\r\n- The `HuggingEngine` will now automatically set `device_map=\"auto\"` if the `accelerate` library is installed",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v1.2.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v1.2.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v1.2.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/176710051",
                "release_id": 176710051,
                "date_created": "2024-09-23T18:32:28Z",
                "date_published": "2024-09-24T20:26:47Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/167748108",
                "tag": "v1.1.1",
                "name": "v1.1.1",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- Fixes an issue where `PromptPipeline.ensure_bound_function_calls()` could still let unbound function calls through in cases of particularly long prompts with prefixing system prompts",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v1.1.1",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v1.1.1",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v1.1.1",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/167748108",
                "release_id": 167748108,
                "date_created": "2024-07-30T00:21:48Z",
                "date_published": "2024-07-30T00:34:45Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/163434864",
                "tag": "v1.1.0",
                "name": "v1.1.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- Added `max_function_rounds` to `Kani.full_round`, `Kani.full_round_str`, and `Kani.full_round_stream`:\r\n  > The maximum number of function calling rounds to perform in this round. If this number is reached, the model is allowed to generate a final response without any functions defined.\r\n  > Default unlimited (continues until model's response does not contain a function call).\r\n- Added `__repr__` to engines\r\n- Fixed an issue where Kani could underestimate the token usage for certain OpenAI models using parallel function calling",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v1.1.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v1.1.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v1.1.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/163434864",
                "release_id": 163434864,
                "date_created": "2024-07-01T21:58:17Z",
                "date_published": "2024-07-01T22:01:52Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/158250527",
                "tag": "v1.0.2",
                "name": "v1.0.2",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- Add `Kani.add_completion_to_history` (useful for token counting, see #29)\r\n- Add an example of an AIFunction definition to `PromptPipeline.explain()` when a function-related step is included\r\n- Add `id_translator` arg to `PromptPipeline.ensure_bound_function_calls()`\r\n- Ensure that OpenAIEngine and HuggingEngine streams yield a completion including prompt and completion token usage\r\n- Various Mistral-7B Instruct v0.3 prompt fixes",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v1.0.2",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v1.0.2",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v1.0.2",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/158250527",
                "release_id": 158250527,
                "date_created": "2024-05-30T21:08:50Z",
                "date_published": "2024-05-30T21:34:31Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/155723217",
                "tag": "v1.0.1",
                "name": "v1.0.1",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- OpenAI: Added support for GPT-4o",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v1.0.1",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v1.0.1",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v1.0.1",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/155723217",
                "release_id": 155723217,
                "date_created": "2024-05-14T15:25:34Z",
                "date_published": "2024-05-14T15:26:32Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/155020417",
                "tag": "v1.0.0",
                "name": "v1.0.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "# New Features\r\n## Streaming\r\nkani now supports streaming to print tokens from the engine as they are received! Streaming is designed to be a drop-in superset of the `chat_round` and `full_round` methods, allowing you to gradually refactor your code without ever leaving it in a broken state.\r\n\r\nTo request a stream from the engine, use `Kani.chat_round_stream()` or `Kani.full_round_stream()`. These methods will return a `StreamManager`, which you can use in different ways to consume the stream.\r\n\r\nThe simplest way to consume the stream is to iterate over it with async for, which will yield a stream of str.\r\n```py\r\n# CHAT ROUND:\r\nstream = ai.chat_round_stream(\"What is the airspeed velocity of an unladen swallow?\")\r\nasync for token in stream:\r\n    print(token, end=\"\")\r\nmsg = await stream.message()\r\n\r\n# FULL ROUND:\r\nasync for stream in ai.full_round_stream(\"What is the airspeed velocity of an unladen swallow?\"):\r\n    async for token in stream:\r\n        print(token, end=\"\")\r\n    msg = await stream.message()\r\n```\r\nAfter a stream finishes, its contents will be available as a `ChatMessage`. You can retrieve the final message or BaseCompletion with:\r\n```py\r\nmsg = await stream.message()\r\ncompletion = await stream.completion()\r\n```\r\nThe final ChatMessage may contain non-yielded tokens (e.g. a request for a function call). If the final message or completion is requested before the stream is iterated over, the stream manager will consume the entire stream.\r\n\r\n> [!TIP]\r\n> For compatibility and ease of refactoring, awaiting the stream itself will also return the message, i.e.:\r\n> ```py\r\n> msg = await ai.chat_round_stream(\"What is the airspeed velocity of an unladen swallow?\")\r\n> ```\r\n> (note the await that is not present in the above examples). This allows you to refactor your code by changing chat_round to chat_round_stream without other changes.\r\n> ```diff\r\n> - msg = await ai.chat_round(\"What is the airspeed velocity of an unladen swallow?\")\r\n> + msg = await ai.chat_round_stream(\"What is the airspeed velocity of an unladen swallow?\")\r\n> ```\r\n\r\nIssue: #30 \r\n\r\n## New Models\r\nkani now has bundled support for the following new models:\r\n\r\n**Hosted**\r\n\r\n- Claude 3 (including function calling)\r\n\r\n**Open Source**\r\n\r\n- [Llama 3](https://huggingface.co/collections/meta-llama/meta-llama-3-66214712577ca38149ebb2b6) (all sizes)\r\n- [Command R](https://huggingface.co/CohereForAI/c4ai-command-r-v01) and [Command R+](https://huggingface.co/CohereForAI/c4ai-command-r-plus) (including function calling)\r\n- [Mistral-7B](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) and [Mixtral-8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)\r\n- [Gemma](https://huggingface.co/collections/google/gemma-release-65d5efbccdbb8c4202ec078b) (all sizes)\r\n\r\nAlthough these models have built-in support, kani supports every chat model available on Hugging Face through `transformers` or `llama.cpp` using the new Prompt Pipelines feature (see below)!\r\n\r\nIssue: #34\r\n\r\n### llama.cpp\r\n\r\nTo use GGUF-quantized versions of models, kani now supports the `LlamaCppEngine`, which uses the `llama-cpp-python` library to interface with the `llama.cpp` library. Any model with a GGUF version is compatible with this engine!\r\n\r\n## Prompt Pipelines\r\n\r\nA prompt pipeline creates a reproducible pipeline for translating a list of `ChatMessage` into an engine-specific format using fluent-style chaining.\r\n\r\nTo build a pipeline, create an instance of `PromptPipeline()` and add steps by calling the step methods documented below. Most pipelines will end with a call to one of the terminals, which translates the intermediate form into the desired output format.\r\n\r\nPipelines come with a built-in `explain()` method to print a detailed explanation of the pipeline and multiple examples (selected based on the pipeline steps).\r\n\r\nHere\u2019s an example using the PromptPipeline to build a LLaMA 2 chat-style prompt:\r\n\r\n```py\r\nfrom kani import PromptPipeline, ChatRole\r\n\r\nLLAMA2_PIPELINE = (\r\n    PromptPipeline()\r\n\r\n    # System messages should be wrapped with this tag. We'll translate them to USER\r\n    # messages since a system and user message go together in a single [INST] pair.\r\n    .wrap(role=ChatRole.SYSTEM, prefix=\"<<SYS>>\\n\", suffix=\"\\n<</SYS>>\\n\")\r\n    .translate_role(role=ChatRole.SYSTEM, to=ChatRole.USER)\r\n\r\n    # If we see two consecutive USER messages, merge them together into one with a\r\n    # newline in between.\r\n    .merge_consecutive(role=ChatRole.USER, sep=\"\\n\")\r\n    # Similarly for ASSISTANT, but with a space (kani automatically strips whitespace from the ends of\r\n    # generations).\r\n    .merge_consecutive(role=ChatRole.ASSISTANT, sep=\" \")\r\n\r\n    # Finally, wrap USER and ASSISTANT messages in the instruction tokens. If our\r\n    # message list ends with an ASSISTANT message, don't add the EOS token\r\n    # (we want the model to continue the generation).\r\n    .conversation_fmt(\r\n        user_prefix=\"<s>[INST] \",\r\n        user_suffix=\" [/INST]\",\r\n        assistant_prefix=\" \",\r\n        assistant_suffix=\" </s>\",\r\n        assistant_suffix_if_last=\"\",\r\n    )\r\n)\r\n\r\n# We can see what this pipeline does by calling explain()...\r\nLLAMA2_PIPELINE.explain()\r\n\r\n# And use it in our engine to build a string prompt for the LLM.\r\nprompt = LLAMA2_PIPELINE(ai.get_prompt())\r\n```\r\n\r\n### Integration with HuggingEngine and LlamaCppEngine\r\n\r\nPreviously, to use a model with a different prompt format than the ones bundled with the library, one had to create a subclass of the `HuggingEngine` to implement the prompting scheme. With the release of Prompt Pipelines, you can now supply a `PromptPipeline` in addition to the model ID to use the `HuggingEngine` directly!\r\n\r\nFor example, the `LlamaEngine` (huggingface) is now equivalent to the following:\r\n\r\n```py\r\nengine = HuggingEngine(\r\n  \"meta-llama/Llama-2-7b-chat-hf\",\r\n  prompt_pipeline=LLAMA2_PIPELINE\r\n)\r\n```\r\n\r\nThe engine will use the passed pipeline to automatically infer a model's token usage, making it easier than ever to implement new models.\r\n\r\nIssue: #32 \r\n\r\n# Improvements\r\n\r\n- The `OpenAIEngine` now uses the official `openai-python` package. (#31)\r\n  - This means that `aiohttp` is no longer a direct dependency, and the `HTTPClient` has been deprecated. For API-based models, we recommend using the `httpx` library.\r\n- Added arguments to the `chat_in_terminal` helper to control maximum width, echo user inputs, show function call arguments and results, and other interactive utilities (#33)\r\n- The `HuggingEngine` can now automatically determine a model's context length.\r\n- Added a warning message if an `@ai_function` is missing a docstring. (#37)\r\n- Added\u00a0`WrapperEngine`\u00a0to make writing wrapper extensions easier.\r\n\r\n# Breaking Changes\r\n- All `kani` models (e.g. `ChatMessage`) are no longer immutable. This means that you can edit the chat history directly, and token counting will still work correctly.\r\n- As the `ctransformers` library does not appear to be maintained, we have removed the `CTransformersEngine` and replaced it with the `LlamaCppEngine`.\r\n- The arguments to `chat_in_terminal` (except the first) are now keyword-only.\r\n- The arguments to `HuggingEngine` (except `model_id`, `max_context_size`, and `prompt_pipeline`) are now keyword-only.\r\n- Generation arguments for OpenAI models now take dictionaries rather than `kani.engines.openai.models.*` models. (If you aren't sure if you're affected by this, you probably aren't.)\r\n\r\n# Bug Fixes\r\n- Fixed an issue with Claude 3 and parallel function calling.\r\n\r\nIt should be a painless upgrade from kani v0.x to kani v1.0! We tried our best to ensure that we didn't break any existing code. If you encounter any issues, please reach out on [our Discord](https://discord.gg/Zvp89dsU5b).",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v1.0.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v1.0.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v1.0.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/155020417",
                "release_id": 155020417,
                "date_created": "2024-05-09T21:19:59Z",
                "date_published": "2024-05-09T21:28:35Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/152245848",
                "tag": "v1.0.0rc1",
                "name": "v1.0.0rc1",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- Added support for Llama 3\r\n- Added `WrapperEngine` to make writing wrapper extensions easier\r\n- Refactored internal Command R prompt building for easier runtime extension\r\n- Updated documentation",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v1.0.0rc1",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v1.0.0rc1",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v1.0.0rc1",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/152245848",
                "release_id": 152245848,
                "date_created": "2024-04-22T15:58:51Z",
                "date_published": "2024-04-22T15:59:58Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/150966360",
                "tag": "v1.0.0rc0",
                "name": "v1 Release Candidate 0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "# New Features\r\n## Streaming\r\nkani now supports streaming to print tokens from the engine as they are received! Streaming is designed to be a drop-in superset of the `chat_round` and `full_round` methods, allowing you to gradually refactor your code without ever leaving it in a broken state.\r\n\r\nTo request a stream from the engine, use `Kani.chat_round_stream()` or `Kani.full_round_stream()`. These methods will return a `StreamManager`, which you can use in different ways to consume the stream.\r\n\r\nThe simplest way to consume the stream is to iterate over it with async for, which will yield a stream of str.\r\n```py\r\n# CHAT ROUND:\r\nstream = ai.chat_round_stream(\"What is the airspeed velocity of an unladen swallow?\")\r\nasync for token in stream:\r\n    print(token, end=\"\")\r\nmsg = await stream.message()\r\n\r\n# FULL ROUND:\r\nasync for stream in ai.full_round_stream(\"What is the airspeed velocity of an unladen swallow?\"):\r\n    async for token in stream:\r\n        print(token, end=\"\")\r\n    msg = await stream.message()\r\n```\r\nAfter a stream finishes, its contents will be available as a `ChatMessage`. You can retrieve the final message or BaseCompletion with:\r\n```py\r\nmsg = await stream.message()\r\ncompletion = await stream.completion()\r\n```\r\nThe final ChatMessage may contain non-yielded tokens (e.g. a request for a function call). If the final message or completion is requested before the stream is iterated over, the stream manager will consume the entire stream.\r\n\r\n> [!TIP]\r\n> For compatibility and ease of refactoring, awaiting the stream itself will also return the message, i.e.:\r\n> ```py\r\n> msg = await ai.chat_round_stream(\"What is the airspeed velocity of an unladen swallow?\")\r\n> ```\r\n> (note the await that is not present in the above examples). This allows you to refactor your code by changing chat_round to chat_round_stream without other changes.\r\n> ```diff\r\n> - msg = await ai.chat_round(\"What is the airspeed velocity of an unladen swallow?\")\r\n> + msg = await ai.chat_round_stream(\"What is the airspeed velocity of an unladen swallow?\")\r\n> ```\r\n\r\nIssue: #30 \r\n\r\n## New Models\r\nkani now has bundled support for the following new models:\r\n\r\n**Hosted**\r\n\r\n- Claude 3 (including function calling)\r\n\r\n**Open Source**\r\n\r\n- [Command R](https://huggingface.co/CohereForAI/c4ai-command-r-v01) and [Command R+](https://huggingface.co/CohereForAI/c4ai-command-r-plus) (including function calling)\r\n- [Mistral-7B](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) and [Mixtral-8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)\r\n- [Gemma](https://huggingface.co/collections/google/gemma-release-65d5efbccdbb8c4202ec078b) (all sizes)\r\n\r\nAlthough these models have built-in support, kani supports every chat model available on Hugging Face through `transformers` or `llama.cpp` using the new Prompt Pipelines feature (see below)!\r\n\r\nIssue: #34\r\n\r\n### llama.cpp\r\n\r\nTo use GGUF-quantized versions of models, kani now supports the `LlamaCppEngine`, which uses the `llama-cpp-python` library to interface with the `llama.cpp` library. Any model with a GGUF version is compatible with this engine!\r\n\r\n## Prompt Pipelines\r\n\r\nA prompt pipeline creates a reproducible pipeline for translating a list of `ChatMessage` into an engine-specific format using fluent-style chaining.\r\n\r\nTo build a pipeline, create an instance of `PromptPipeline()` and add steps by calling the step methods documented below. Most pipelines will end with a call to one of the terminals, which translates the intermediate form into the desired output format.\r\n\r\nPipelines come with a built-in `explain()` method to print a detailed explanation of the pipeline and multiple examples (selected based on the pipeline steps).\r\n\r\nHere\u2019s an example using the PromptPipeline to build a LLaMA 2 chat-style prompt:\r\n\r\n```py\r\nfrom kani import PromptPipeline, ChatRole\r\n\r\nLLAMA2_PIPELINE = (\r\n    PromptPipeline()\r\n\r\n    # System messages should be wrapped with this tag. We'll translate them to USER\r\n    # messages since a system and user message go together in a single [INST] pair.\r\n    .wrap(role=ChatRole.SYSTEM, prefix=\"<<SYS>>\\n\", suffix=\"\\n<</SYS>>\\n\")\r\n    .translate_role(role=ChatRole.SYSTEM, to=ChatRole.USER)\r\n\r\n    # If we see two consecutive USER messages, merge them together into one with a\r\n    # newline in between.\r\n    .merge_consecutive(role=ChatRole.USER, sep=\"\\n\")\r\n    # Similarly for ASSISTANT, but with a space (kani automatically strips whitespace from the ends of\r\n    # generations).\r\n    .merge_consecutive(role=ChatRole.ASSISTANT, sep=\" \")\r\n\r\n    # Finally, wrap USER and ASSISTANT messages in the instruction tokens. If our\r\n    # message list ends with an ASSISTANT message, don't add the EOS token\r\n    # (we want the model to continue the generation).\r\n    .conversation_fmt(\r\n        user_prefix=\"<s>[INST] \",\r\n        user_suffix=\" [/INST]\",\r\n        assistant_prefix=\" \",\r\n        assistant_suffix=\" </s>\",\r\n        assistant_suffix_if_last=\"\",\r\n    )\r\n)\r\n\r\n# We can see what this pipeline does by calling explain()...\r\nLLAMA2_PIPELINE.explain()\r\n\r\n# And use it in our engine to build a string prompt for the LLM.\r\nprompt = LLAMA2_PIPELINE(ai.get_prompt())\r\n```\r\n\r\n### Integration with HuggingEngine and LlamaCppEngine\r\n\r\nPreviously, to use a model with a different prompt format than the ones bundled with the library, one had to create a subclass of the `HuggingEngine` to implement the prompting scheme. With the release of Prompt Pipelines, you can now supply a `PromptPipeline` in addition to the model ID to use the `HuggingEngine` directly!\r\n\r\nFor example, the `LlamaEngine` (huggingface) is now equivalent to the following:\r\n\r\n```py\r\nengine = HuggingEngine(\r\n  \"meta-llama/Llama-2-7b-chat-hf\",\r\n  prompt_pipeline=LLAMA2_PIPELINE\r\n)\r\n```\r\n\r\nIssue: #32 \r\n\r\n# Improvements\r\n\r\n- The `OpenAIEngine` now uses the official `openai-python` package. (#31)\r\n  - This means that `aiohttp` is no longer a direct dependency, and the `HTTPClient` has been deprecated. For API-based models, we recommend using the `httpx` library.\r\n- Added arguments to the `chat_in_terminal` helper to control maximum width, echo user inputs, show function call arguments and results, and other interactive utilities (#33)\r\n- The `HuggingEngine` can now automatically determine a model's context length.\r\n- Added a warning message if an `@ai_function` is missing a docstring. (#37)\r\n\r\n# Breaking Changes\r\n- All `kani` models (e.g. `ChatMessage`) are no longer immutable. This means that you can edit the chat history directly, and token counting will still work correctly.\r\n- As the `ctransformers` library does not appear to be maintained, we have removed the `CTransformersEngine` and replaced it with the `LlamaCppEngine`.\r\n- The arguments to `chat_in_terminal` (except the first) are now keyword-only.\r\n- The arguments to `HuggingEngine` (except `model_id`, `max_context_size`, and `prompt_pipeline`) are now keyword-only.\r\n- Generation arguments for OpenAI models now take dictionaries rather than `kani.engines.openai.models.*` models. (If you aren't sure if you're affected by this, you probably aren't.)\r\n\r\nIt should be a painless upgrade from kani v0.x to kani v1.0! We tried our best to ensure that we didn't break any existing code. If you encounter any issues, please reach out on [our Discord](https://discord.gg/Zvp89dsU5b).",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v1.0.0rc0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v1.0.0rc0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v1.0.0rc0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/150966360",
                "release_id": 150966360,
                "date_created": "2024-04-12T17:18:04Z",
                "date_published": "2024-04-12T17:22:15Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/148303552",
                "tag": "v0.8.0",
                "name": "v0.8.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "Most likely the last release before v1.0! This update mostly contains improvements to `chat_in_terminal` to improve usability in interactive environments like Jupyter Notebook.\r\n\r\n## Possible Breaking Change\r\n\r\nAll arguments to `chat_in_terminal` except the Kani instance must now be keyword arguments; positional arguments are no longer accepted.\r\n\r\nFor example, `chat_in_terminal(ai, 1, \"!stop\")` must now be written `chat_in_terminal(ai, rounds=1, stopword=\"!stop\")`.\r\n\r\n## Improvements\r\n\r\n- You may now specify `None` as the user query in `chat_round` and `full_round`. This will request a new ASSISTANT message without adding a USER message to the chat history (e.g. to continue an unfinished generation).\r\n\r\nAdded the following keyword args to `chat_in_terminal` to improve usability in interactive environments like Jupyter Notebook:\r\n\r\n- echo: Whether to echo the user's input to stdout after they send a message (e.g. to save in interactive notebook outputs; default false)\r\n- ai_first: Whether the user should send the first message (default) or the model should generate a completion before prompting the user for a message.\r\n- width: The maximum width of the printed outputs (default unlimited).\r\n- show_function_args: Whether to print the arguments the model is calling functions with for each call (default false).\r\n- show_function_returns: Whether to print the results of each function call (default false).\r\n- verbose: Equivalent to setting ``echo``, ``show_function_args``, and ``show_function_returns`` to True.",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.8.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.8.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.8.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/148303552",
                "release_id": 148303552,
                "date_created": "2024-03-25T18:34:42Z",
                "date_published": "2024-03-25T18:41:13Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/139995165",
                "tag": "v0.7.2",
                "name": "v0.7.2",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- OpenAI: Added support for Jan 25 models without specifying `max_context_length` explicitly\r\n- OpenAI: Fixed an issue where the token count for parallel function calls would only consider the first function call",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.7.2",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.7.2",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.7.2",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/139995165",
                "release_id": 139995165,
                "date_created": "2024-02-05T21:31:47Z",
                "date_published": "2024-02-05T21:36:01Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/132470383",
                "tag": "v0.7.1",
                "name": "v0.7.1",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- OpenAI: Fixes an issue where a tool call could have an unbound tool call ID when using `always_included_messages` near the maximum context length\r\n",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.7.1",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.7.1",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.7.1",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/132470383",
                "release_id": 132470383,
                "date_created": "2023-12-04T09:24:34Z",
                "date_published": "2023-12-04T09:28:59Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/131274911",
                "tag": "v0.7.0",
                "name": "v0.7.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## New Features\r\n- Added support for the Claude API through the `AnthropicEngine`\r\n  - Currently, this is only for chat messages - we don't yet have access to the new function calling API. We plan to add Claude function calling to Kani as soon as we get access!\r\n- Renamed `ToolCallError` to a more general `PromptError`\r\n  - Technically a minor breaking change, though a search of GitHub shows that no one has used `ToolCallError` yet\r\n\r\n## Fixes\r\n- Fixed an issue where parallel tool calls could not be validated (thanks @arturoleon!) ",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.7.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.7.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.7.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/131274911",
                "release_id": 131274911,
                "date_created": "2023-11-23T17:44:25Z",
                "date_published": "2023-11-23T17:52:40Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/129030014",
                "tag": "v0.6.2",
                "name": "v0.6.2",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- Fixes an issue where emoji in a chat history might cause issues when saving/loading the kani state\r\n- (OpenAI) Fixes an issue where the `content` field might get omitted in certain requests, causing an API error",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.6.2",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.6.2",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.6.2",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/129030014",
                "release_id": 129030014,
                "date_created": "2023-11-11T19:10:29Z",
                "date_published": "2023-11-11T19:16:41Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/128611571",
                "tag": "v0.6.1",
                "name": "v0.6.1",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- Internal changes to the OpenAIEngine to make extending it easier\r\n- No consumer-facing changes",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.6.1",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.6.1",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.6.1",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/128611571",
                "release_id": 128611571,
                "date_created": "2023-11-08T20:45:55Z",
                "date_published": "2023-11-08T20:54:09Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/128583518",
                "tag": "v0.6.0",
                "name": "v0.6.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "As of Nov 6, 2023, OpenAI added the ability for a single assistant message to request calling multiple functions in\r\nparallel, and wrapped all function calls in a `ToolCall` wrapper. In order to add support for this in kani while\r\nmaintaining backwards compatibility with OSS function calling models, a `ChatMessage` now actually maintains the\r\nfollowing internal representation:\r\n\r\n`ChatMessage.function_call` is actually an alias for `ChatMessage.tool_calls[0].function`. If there is more\r\nthan one tool call in the message, when trying to access this property, kani will raise an exception.\r\n\r\nTo translate kani's FUNCTION message types to OpenAI's TOOL message types, the OpenAIEngine now performs a translation based on binding free tool call IDs to following FUNCTION messages deterministically.\r\n\r\n## Breaking Changes\r\n\r\nTo the kani end user, there should be no change to how functions are defined and called. One breaking change was necessary:\r\n\r\n- `Kani.do_function_call` and `Kani.handle_function_call_exception` now take an additional `tool_call_id` parameter, which may break overriding functions. The documentation has been updated to encourage overriders to handle `*args, **kwargs` to prevent this happening again.\r\n\r\n## New Features\r\n\r\nkani can now handle making multiple function calls in parallel if the model requests it. Rather than returning an ASSISTANT message with a single `function_call`, an engine can now return a list of `tool_calls`. kani will resolve these tool calls in parallel using asyncio, and add their results to the chat history in the order of the list provided.\r\n\r\nReturning a single `function_call` will continue to work for backwards compatibility.",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.6.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.6.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.6.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/128583518",
                "release_id": 128583518,
                "date_created": "2023-11-08T18:21:06Z",
                "date_published": "2023-11-08T18:23:00Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/126652728",
                "tag": "v0.5.1",
                "name": "v0.5.1",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- OpenAI: The OpenAIClient (internal class used by OpenAIEngine) now expects `OpenAIChatMessage`s as input rather than `kani.ChatMessage` in order to better type-validate API requests\r\n- OpenAI: Updated token estimation to better reflect current token counts returned by the API ",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.5.1",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.5.1",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.5.1",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/126652728",
                "release_id": 126652728,
                "date_created": "2023-10-25T17:50:03Z",
                "date_published": "2023-10-25T17:53:38Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/126459267",
                "tag": "v0.5.0",
                "name": "v0.5.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## New Feature: Message Parts API\r\nThe Message Parts API is intended to provide a foundation for future multimodal LLMs and other engines that require engine-specific input without compromising kani's model-agnostic design. This is accomplished by allowing `ChatMessage.content` to be a list of `MessagePart` objects, in addition to a string.\r\n\r\n*This change is fully backwards-compatible and will not affect existing code.*\r\n\r\nWhen writing code with compatibility in mind, the `ChatMessage` class exposes `ChatMessage.text` (always a string or None) and `ChatMessage.parts` (always a list of message parts), which we recommend using instead of `ChatMessage.content`. These properties are dynamically generated based on the underlying content, and it is safe to mix messages with different content types in a single Kani.\r\n\r\nGenerally, message part classes are defined by an engine, and consumed by the developer. Message parts can be used in any role\u2019s message - for example, you might use a message part in an assistant message to separate out a chain of thought from a user reply, or in a user message to supply an image to a multimodal model.\r\n\r\nFor more information, see the [Message Parts documentation](https://kani.readthedocs.io/en/latest/advanced.html#message-parts).\r\n\r\n*Up next: we're adding support for multimodal vision-language models like LLaVA and GPT-Vision through a kani extension!*\r\n\r\n## Improvements\r\n- LLaMA 2: Improved the prompting in non-strict mode to group consecutive user/system messages into a single `[INST]` wrapper. See [the tests](https://github.com/zhudotexe/kani/blob/main/tests/test_llama2_prompt.py) for how kani translates consecutive message types into the LLaMA prompt.\r\n- Other documentation and minor improvements",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.5.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.5.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.5.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/126459267",
                "release_id": 126459267,
                "date_created": "2023-10-24T17:02:57Z",
                "date_published": "2023-10-24T17:06:46Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/123917547",
                "tag": "v0.4.0",
                "name": "v0.4.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## BREAKING CHANGES\r\n- `Kani.full_round` now emits *every* message generated during the round, not just assistant messages\r\n  - This means that you will need to handle `FUNCTION` messages, and potentially `SYSTEM` messages from a function exception handler.\r\n  - `Kani.full_round_str`'s default behaviour is unchanged.\r\n- `Kani.full_round_str` now takes in a `message_formatter` rather than a `function_call_formatter`\r\n  - By default, this handler only returns the contents of `ASSISTANT` messages.\r\n- `Kani.do_function_call` now returns a `FunctionCallResult` rather than a `bool` \r\n  - To migrate any overriding functions, you should change the following:\r\n  - Rather than calling `Kani.add_to_history` in the override, save the ChatMessage to a variable\r\n  - Update the return value from a boolean to `FunctionCallResult(is_model_turn=<old return value>, message=<message from above>)`\r\n- `Kani.handle_function_call_exception` now returns a `ExceptionHandleResult` rather than a `bool` \r\n  - To migrate any overriding functions, you should change the following:\r\n  - Rather than calling `Kani.add_to_history` in the override, save the ChatMessage to a variable\r\n  - Update the return value from a boolean to `ExceptionHandleResult(should_retry=<old return value>, message=<message from above>)`\r\n\r\n## Improvements\r\n- Added `kani.utils.message_formatters`\r\n- Added `kani.ExceptionHandleResult` and `kani.FunctionCallResult`\r\n- Documentation improvements\r\n\r\n## Fixes\r\n- Fixed an issue where `ChatMessage.copy_with` could cause unset values to appear in JSON serializations",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.4.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.4.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.4.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/123917547",
                "release_id": 123917547,
                "date_created": "2023-10-04T20:18:53Z",
                "date_published": "2023-10-05T18:43:36Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/122670389",
                "tag": "v0.3.4",
                "name": "v0.3.4",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## Improvements\r\n- Updated dependencies to allow more recent versions\r\n- The documentation now shows fully-qualified class names in reference sections\r\n- Added `.copy_with` method to ChatMessage and FunctionCall to make updating chat history easier\r\n- Various documentation updates",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.3.4",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.3.4",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.3.4",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/122670389",
                "release_id": 122670389,
                "date_created": "2023-09-26T18:48:36Z",
                "date_published": "2023-09-26T18:53:11Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/121578024",
                "tag": "v0.3.3",
                "name": "v0.3.3",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## Improvements\r\n- Added a warning in `Kani.chat_round` to use `Kani.full_round` when AI functions are defined\r\n- Added examples in Google Colab\r\n- Other documentation improvements\r\n\r\n## Fixes\r\n- Fixed an issue where the ctransformers engine could overrun its context length (e.g. see https://github.com/zhudotexe/kani/actions/runs/6152842183/job/16695721588)",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.3.3",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.3.3",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.3.3",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/121578024",
                "release_id": 121578024,
                "date_created": "2023-09-18T15:29:25Z",
                "date_published": "2023-09-18T18:08:48Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/120679872",
                "tag": "v0.3.2",
                "name": "v0.3.2",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## Improvements\r\n- Made `chat_in_terminal` work in Google Colab, rather than having to use `await chat_in_terminal_async`",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.3.2",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.3.2",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.3.2",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/120679872",
                "release_id": 120679872,
                "date_created": "2023-09-11T17:39:51Z",
                "date_published": "2023-09-11T17:41:52Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/120663298",
                "tag": "v0.3.1",
                "name": "v0.3.1",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- HuggingFace Engine: Fixed an issue where completion message lengths were overreported by an amount equal to the prompt length.\r\n- Other documentation improvements\r\n",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.3.1",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.3.1",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.3.1",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/120663298",
                "release_id": 120663298,
                "date_created": "2023-09-11T15:22:47Z",
                "date_published": "2023-09-11T15:27:58Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/120150862",
                "tag": "v0.3.0",
                "name": "v0.3.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## Improvements\r\n- Added `Kani.add_to_history`, a method that is called whenever kani adds a new message to the chat context\r\n- `httpclient.BaseClient.request` now returns a `Response` to aid low-level implementation\r\n  - `.get()` and `.post()` are unchanged\r\n- Add additional documentation about GPU support for local models\r\n- Other documentation improvements",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.3.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.3.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.3.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/120150862",
                "release_id": 120150862,
                "date_created": "2023-09-06T16:08:15Z",
                "date_published": "2023-09-06T16:15:25Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/119090712",
                "tag": "v0.2.0",
                "name": "v0.2.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## Improvements\r\n\r\n- Engines: Added `Engine.function_token_reserve()` to dynamically reserve a number of tokens for a function list\r\n- OpenAI: The OpenAIEngine now reads the `OPENAI_API_KEY` environment variable by default if no api key or client is specified\r\n- Documentation improvements (polymorphism, mixins, extension packages)",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.2.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.2.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.2.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/119090712",
                "release_id": 119090712,
                "date_created": "2023-08-22T21:58:29Z",
                "date_published": "2023-08-29T14:44:04Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/115977394",
                "tag": "v0.1.0",
                "name": "v0.1.0",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## BREAKING CHANGES\r\n\r\n*These should hopefully be the last set of breaking changes until v1.0. We're finalizing some of the attribute names for clarity and publication.*\r\n\r\n- renamed `Kani.always_include_messages` to `Kani.always_included_messages`\r\n\r\n## Features & Improvements\r\n\r\n- `@ai_function`s with synchronous signatures now run in a thread pool in order to prevent blocking the asyncio event loop\r\n- OpenAI: Added the ability to specify the API base and additional headers (e.g. for proxy APIs).\r\n- Various documentation improvements",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.1.0",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.1.0",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.1.0",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/115977394",
                "release_id": 115977394,
                "date_created": "2023-08-10T18:58:26Z",
                "date_published": "2023-08-10T19:06:05Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/115144146",
                "tag": "v0.0.3",
                "name": "v0.0.3",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "## BREAKING CHANGES\r\n- Renamed `Kani.get_truncated_chat_history` to `Kani.get_prompt`\r\n\r\n## Additions & Improvements\r\n- Added `CTransformersEngine` and `LlamaCTransformersEngine` (thanks @Maknee!) \r\n- Added a lower-level `Kani.get_model_completion` to make a prediction at the current chat state (without modifying the chat history)\r\n- Added the `auto_truncate` param to `@ai_function` to opt in to kani trimming long responses from a function (i.e., responses that do not fit in a model's context)\r\n- Improved the internal handling of tokens when the chat history is directly modified\r\n- `ChatMessage.[role]()` classmethods now pass kwargs to the constructor\r\n- LLaMA: Improved the fidelity of non-strict-mode LLaMA prompting\r\n- OpenAI: Added support for specifying an OpenAI organization and configuring retry\r\n- Many documentation improvements\r\n\r\n## Fixes\r\n- OpenAI message length could return too short on messages with no content\r\n- Other minor fixes and improvements",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.0.3",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.0.3",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.0.3",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/115144146",
                "release_id": 115144146,
                "date_created": "2023-08-04T00:42:26Z",
                "date_published": "2023-08-04T17:23:45Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/112902869",
                "tag": "v0.0.2",
                "name": "v0.0.2",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "- Add `chat_in_terminal_async` for async environments (e.g. Google Colab)\r\n- Add quickstart Colab notebook",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.0.2",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.0.2",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.0.2",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/112902869",
                "release_id": 112902869,
                "date_created": "2023-07-20T03:32:45Z",
                "date_published": "2023-07-20T03:33:40Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/zhudotexe/kani/releases/112897089",
                "tag": "v0.0.1",
                "name": "v0.0.1",
                "author": {
                    "name": "zhudotexe",
                    "type": "User"
                },
                "description": "Initial release!",
                "tarball_url": "https://api.github.com/repos/zhudotexe/kani/tarball/v0.0.1",
                "zipball_url": "https://api.github.com/repos/zhudotexe/kani/zipball/v0.0.1",
                "html_url": "https://github.com/zhudotexe/kani/releases/tag/v0.0.1",
                "url": "https://api.github.com/repos/zhudotexe/kani/releases/112897089",
                "release_id": 112897089,
                "date_created": "2023-07-20T01:40:05Z",
                "date_published": "2023-07-20T01:58:58Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "cff-version: 1.0.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n- family-names: \"Zhu\"\n  given-names: \"Andrew\"\n  orcid: \"https://orcid.org/0000-0002-6664-3215\"\n- family-names: \"Dugan\"\n  given-names: \"Liam\"\n  orcid: \"https://orcid.org/0009-0006-5382-5235\"\n- family-names: \"Hwang\"\n  given-names: \"Alyssa\"\n  orcid: \"https://orcid.org/0009-0006-4827-8505\"\n- family-names: \"Callison-Burch\"\n  given-names: \"Chris\"\n  orcid: \"https://orcid.org/0000-0001-8196-1943\"\ntitle: \"kani\"\ndate-released: 2023-09-11\nurl: \"https://github.com/zhudotexe/kani\"\npreferred-citation:\n  type: generic\n  authors:\n  - family-names: \"Zhu\"\n    given-names: \"Andrew\"\n    orcid: \"https://orcid.org/0000-0002-6664-3215\"\n  - family-names: \"Dugan\"\n    given-names: \"Liam\"\n    orcid: \"https://orcid.org/0009-0006-5382-5235\"\n  - family-names: \"Hwang\"\n    given-names: \"Alyssa\"\n    orcid: \"https://orcid.org/0009-0006-4827-8505\"\n  - family-names: \"Callison-Burch\"\n    given-names: \"Chris\"\n    orcid: \"https://orcid.org/0000-0001-8196-1943\"\n  year: 2023\n  month: 12\n  title: \"Kani: A Lightweight and Highly Hackable Framework for Building Language Model Applications\"\n  collection-title: \"Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023)\"\n  collection-type: proceedings\n  location: \"Singapore\"\n  doi: \"10.18653/v1/2023.nlposs-1.8\"\n  url: \"https://aclanthology.org/2023.nlposs-1.8\"\n  publisher: \"Association for Computational Linguistics\"\n  start: 65\n  end: 77\n",
                "type": "File_dump",
                "format": "cff"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/citation.cff"
        },
        {
            "result": {
                "value": "If you use Kani, please cite us as:\n\n```\n@inproceedings{zhu-etal-2023-kani,\n    title = \"Kani: A Lightweight and Highly Hackable Framework for Building Language Model Applications\",\n    author = \"Zhu, Andrew  and\n      Dugan, Liam  and\n      Hwang, Alyssa  and\n      Callison-Burch, Chris\",\n    editor = \"Tan, Liling  and\n      Milajevs, Dmitrijs  and\n      Chauhan, Geeticka  and\n      Gwinnup, Jeremy  and\n      Rippeth, Elijah\",\n    booktitle = \"Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023)\",\n    month = dec,\n    year = \"2023\",\n    address = \"Singapore\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.nlposs-1.8\",\n    doi = \"10.18653/v1/2023.nlposs-1.8\",\n    pages = \"65--77\",\n}\n```\n",
                "type": "Text_excerpt",
                "original_header": "Citation",
                "parent_header": [
                    "kani (\u30ab\u30cb)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        },
        {
            "result": {
                "value": "@inproceedings{zhu-etal-2023-kani,\n    pages = {65--77},\n    doi = {10.18653/v1/2023.nlposs-1.8},\n    url = {https://aclanthology.org/2023.nlposs-1.8},\n    publisher = {Association for Computational Linguistics},\n    address = {Singapore},\n    year = {2023},\n    month = {December},\n    booktitle = {Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023)},\n    editor = {Tan, Liling  and\nMilajevs, Dmitrijs  and\nChauhan, Geeticka  and\nGwinnup, Jeremy  and\nRippeth, Elijah},\n    author = {Zhu, Andrew  and\nDugan, Liam  and\nHwang, Alyssa  and\nCallison-Burch, Chris},\n    title = {Kani: A Lightweight and Highly Hackable Framework for Building Language Model Applications},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "doi": "10.18653/v1/2023.nlposs-1.8",
                "title": "Kani: A Lightweight and Highly Hackable Framework for Building Language Model Applications",
                "author": "Zhu, Andrew  and\nDugan, Liam  and\nHwang, Alyssa  and\nCallison-Burch, Chris",
                "url": "https://aclanthology.org/2023.nlposs-1.8"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "executable_example": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/zhudotexe/kani/main/sandbox/tokencounting.ipynb",
                "type": "Url",
                "format": "jupyter_notebook"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/sandbox/tokencounting.ipynb"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/zhudotexe/kani/main/sandbox/mistral-tokenizer.ipynb",
                "type": "Url",
                "format": "jupyter_notebook"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/sandbox/mistral-tokenizer.ipynb"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/zhudotexe/kani/main/examples/colab_examples.ipynb",
                "type": "Url",
                "format": "jupyter_notebook"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/examples/colab_examples.ipynb"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/zhudotexe/kani/main/examples/colab_quickstart.ipynb",
                "type": "Url",
                "format": "jupyter_notebook"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/examples/colab_quickstart.ipynb"
        }
    ],
    "installation": [
        {
            "result": {
                "value": "kani requires Python 3.10 or above. To install model-specific dependencies, kani uses various extras (brackets after\nthe library name in `pip install`). To determine which extra(s) to install, see\nthe [model table](https://kani.readthedocs.io/en/latest/engines.html), or use the `[all]` extra to install everything.\n\n```shell\n# for OpenAI models\n$ pip install \"kani[openai]\"\n# for Hugging Face models\n$ pip install \"kani[huggingface]\" torch\n# or install everything:\n$ pip install \"kani[all]\"\n```\n\nFor the most up-to-date changes and new models, you can also install the development version from Git's `main` branch:\n\n```shell\n$ pip install \"kani[all] @ git+https://github.com/zhudotexe/kani.git@main\"\n```\n",
                "type": "Text_excerpt",
                "original_header": "Installation",
                "parent_header": [
                    "kani (\u30ab\u30cb)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "<a href=\"https://colab.research.google.com/github/zhudotexe/kani/blob/main/examples/colab_examples.ipynb\">\n  <img alt=\"Quickstart in Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\">\n</a> \nkani requires Python 3.10 or above. \n",
                "original_header": "Quickstart"
            },
            "confidence": 0.9537426618631607,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "Want to see kani in action? Using 4-bit quantization to shrink the model, we run LLaMA v2 as part of our test suite\nright on GitHub Actions:\n\nhttps://github.com/zhudotexe/kani/actions/workflows/pytest.yml?query=branch%3Amain+is%3Asuccess\n\nSimply click on the latest build to see LLaMA's output!\n",
                "type": "Text_excerpt",
                "original_header": "Demo",
                "parent_header": [
                    "kani (\u30ab\u30cb)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        }
    ],
    "acknowledgement": [
        {
            "result": {
                "value": "We would like to thank the members of the lab of Chris Callison-Burch for their testing and detailed feedback on the\ncontents of both our paper and the Kani repository. In addition, we\u2019d like to thank Henry Zhu (no relation to the first\nauthor) for his early and enthusiastic support of the project.\n\nThis research is based upon work supported in part by the Air Force Research Laboratory (contract FA8750-23-C-0507), the\nIARPA HIATUS Program (contract 2022-22072200005), and the NSF (Award 1928631). Approved for Public Release, Distribution\nUnlimited. The views and conclusions contained herein are those of the authors and should not be interpreted as\nnecessarily representing the official policies, either expressed or implied, of IARPA, NSF, or the U.S. Government.\n",
                "type": "Text_excerpt",
                "original_header": "Acknowledgements",
                "parent_header": [
                    "kani (\u30ab\u30cb)",
                    "Citation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "kani (\u30ab\u30cb)"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        }
    ],
    "documentation": [
        {
            "result": {
                "type": "Url",
                "value": "https://kani.readthedocs.io/",
                "format": "readthedocs"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "http://kani.readthedocs.io/",
                "format": "readthedocs"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        }
    ],
    "logo": [
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/zhudotexe/kani/main/docs/_static/penn-logo.jpg"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        }
    ],
    "images": [
        {
            "result": {
                "type": "Url",
                "value": "https://colab.research.google.com/assets/colab-badge.svg"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://colab.research.google.com/assets/colab-badge.svg"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/zhudotexe/kani/main/docs/_static/lib-comparison_white.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2309.05542"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/zhudotexe/kani/main/README.md"
        }
    ]
}
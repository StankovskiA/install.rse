{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-04 18:50:10"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/Sizeless/ReplicationPackage",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "Sizeless",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2020-12-25T12:11:19Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-04-25T06:47:36Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "name": [
        {
            "result": {
                "value": "ReplicationPackage",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "Sizeless/ReplicationPackage",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/Sizeless/ReplicationPackage/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/Sizeless/ReplicationPackage/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 13,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 4,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/sizeless/replicationpackage/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "JavaScript",
                "name": "JavaScript",
                "type": "Programming_language",
                "size": 368856
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Lua",
                "name": "Lua",
                "type": "Programming_language",
                "size": 125992
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 109070
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "TypeScript",
                "name": "TypeScript",
                "type": "Programming_language",
                "size": 59720
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Vue",
                "name": "Vue",
                "type": "Programming_language",
                "size": 56611
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 46957
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Go",
                "name": "Go",
                "type": "Programming_language",
                "size": 30321
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Makefile",
                "name": "Makefile",
                "type": "Programming_language",
                "size": 15888
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Dockerfile",
                "name": "Dockerfile",
                "type": "Programming_language",
                "size": 9694
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "CSS",
                "name": "CSS",
                "type": "Programming_language",
                "size": 1442
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "HTML",
                "name": "HTML",
                "type": "Programming_language",
                "size": 1015
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Stylus",
                "name": "Stylus",
                "type": "Programming_language",
                "size": 990
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "has_script_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/AirlineBooking/meta-run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/AirlineBooking/run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/AirlineBooking/cmd.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/AirlineBooking/load/generateConstantLoad.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/AirlineBooking/files/genFlights.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/AirlineBooking/files/addhosting.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/AirlineBooking/files/build.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/AirlineBooking/files/cognitocurl.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/meta-run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/generateConstantLoad.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/install.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/runner.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/deploy.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/remove.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/web/deploy.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/build/2.sls.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/build/1.install.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/build/0.env.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/EventProcessing/meta-run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/EventProcessing/generateConstantLoad.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/EventProcessing/run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/EventProcessing/runner.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/FacialRecognition/meta-run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/FacialRecognition/generateConstantLoad.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/FacialRecognition/run.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/FacialRecognition/runner.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/FacialRecognition/src/cloudformation/publish-template.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "license": [
        {
            "result": {
                "value": "CC0 1.0 Universal\n\nStatement of Purpose\n\nThe laws of most jurisdictions throughout the world automatically confer\nexclusive Copyright and Related Rights (defined below) upon the creator and\nsubsequent owner(s) (each and all, an \"owner\") of an original work of\nauthorship and/or a database (each, a \"Work\").\n\nCertain owners wish to permanently relinquish those rights to a Work for the\npurpose of contributing to a commons of creative, cultural and scientific\nworks (\"Commons\") that the public can reliably and without fear of later\nclaims of infringement build upon, modify, incorporate in other works, reuse\nand redistribute as freely as possible in any form whatsoever and for any\npurposes, including without limitation commercial purposes. These owners may\ncontribute to the Commons to promote the ideal of a free culture and the\nfurther production of creative, cultural and scientific works, or to gain\nreputation or greater distribution for their Work in part through the use and\nefforts of others.\n\nFor these and/or other purposes and motivations, and without any expectation\nof additional consideration or compensation, the person associating CC0 with a\nWork (the \"Affirmer\"), to the extent that he or she is an owner of Copyright\nand Related Rights in the Work, voluntarily elects to apply CC0 to the Work\nand publicly distribute the Work under its terms, with knowledge of his or her\nCopyright and Related Rights in the Work and the meaning and intended legal\neffect of CC0 on those rights.\n\n1. Copyright and Related Rights. A Work made available under CC0 may be\nprotected by copyright and related or neighboring rights (\"Copyright and\nRelated Rights\"). Copyright and Related Rights include, but are not limited\nto, the following:\n\n  i. the right to reproduce, adapt, distribute, perform, display, communicate,\n  and translate a Work;\n\n  ii. moral rights retained by the original author(s) and/or performer(s);\n\n  iii. publicity and privacy rights pertaining to a person's image or likeness\n  depicted in a Work;\n\n  iv. rights protecting against unfair competition in regards to a Work,\n  subject to the limitations in paragraph 4(a), below;\n\n  v. rights protecting the extraction, dissemination, use and reuse of data in\n  a Work;\n\n  vi. database rights (such as those arising under Directive 96/9/EC of the\n  European Parliament and of the Council of 11 March 1996 on the legal\n  protection of databases, and under any national implementation thereof,\n  including any amended or successor version of such directive); and\n\n  vii. other similar, equivalent or corresponding rights throughout the world\n  based on applicable law or treaty, and any national implementations thereof.\n\n2. Waiver. To the greatest extent permitted by, but not in contravention of,\napplicable law, Affirmer hereby overtly, fully, permanently, irrevocably and\nunconditionally waives, abandons, and surrenders all of Affirmer's Copyright\nand Related Rights and associated claims and causes of action, whether now\nknown or unknown (including existing as well as future claims and causes of\naction), in the Work (i) in all territories worldwide, (ii) for the maximum\nduration provided by applicable law or treaty (including future time\nextensions), (iii) in any current or future medium and for any number of\ncopies, and (iv) for any purpose whatsoever, including without limitation\ncommercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes\nthe Waiver for the benefit of each member of the public at large and to the\ndetriment of Affirmer's heirs and successors, fully intending that such Waiver\nshall not be subject to revocation, rescission, cancellation, termination, or\nany other legal or equitable action to disrupt the quiet enjoyment of the Work\nby the public as contemplated by Affirmer's express Statement of Purpose.\n\n3. Public License Fallback. Should any part of the Waiver for any reason be\njudged legally invalid or ineffective under applicable law, then the Waiver\nshall be preserved to the maximum extent permitted taking into account\nAffirmer's express Statement of Purpose. In addition, to the extent the Waiver\nis so judged Affirmer hereby grants to each affected person a royalty-free,\nnon transferable, non sublicensable, non exclusive, irrevocable and\nunconditional license to exercise Affirmer's Copyright and Related Rights in\nthe Work (i) in all territories worldwide, (ii) for the maximum duration\nprovided by applicable law or treaty (including future time extensions), (iii)\nin any current or future medium and for any number of copies, and (iv) for any\npurpose whatsoever, including without limitation commercial, advertising or\npromotional purposes (the \"License\"). The License shall be deemed effective as\nof the date CC0 was applied by Affirmer to the Work. Should any part of the\nLicense for any reason be judged legally invalid or ineffective under\napplicable law, such partial invalidity or ineffectiveness shall not\ninvalidate the remainder of the License, and in such case Affirmer hereby\naffirms that he or she will not (i) exercise any of his or her remaining\nCopyright and Related Rights in the Work or (ii) assert any associated claims\nand causes of action with respect to the Work, in either case contrary to\nAffirmer's express Statement of Purpose.\n\n4. Limitations and Disclaimers.\n\n  a. No trademark or patent rights held by Affirmer are waived, abandoned,\n  surrendered, licensed or otherwise affected by this document.\n\n  b. Affirmer offers the Work as-is and makes no representations or warranties\n  of any kind concerning the Work, express, implied, statutory or otherwise,\n  including without limitation warranties of title, merchantability, fitness\n  for a particular purpose, non infringement, or the absence of latent or\n  other defects, accuracy, or the present or absence of errors, whether or not\n  discoverable, all to the greatest extent permissible under applicable law.\n\n  c. Affirmer disclaims responsibility for clearing rights of other persons\n  that may apply to the Work or any use thereof, including without limitation\n  any person's Copyright and Related Rights in the Work. Further, Affirmer\n  disclaims responsibility for obtaining any necessary consents, permissions\n  or other rights required for any use of the Work.\n\n  d. Affirmer understands and acknowledges that Creative Commons is not a\n  party to this document and has no duty or obligation with respect to this\n  CC0 or use of the Work.\n\nFor more information, please see\n<http://creativecommons.org/publicdomain/zero/1.0/>",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/FacialRecognition/images/selfie/LICENSE"
        }
    ],
    "has_build_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/AirlineBooking/Dockerfile",
                "type": "Url",
                "format": "dockerfile"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/AirlineBooking/Dockerfile"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/Dockerfile",
                "type": "Url",
                "format": "dockerfile"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/HelloRetail/Dockerfile"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/EventProcessing/Dockerfile",
                "type": "Url",
                "format": "dockerfile"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/EventProcessing/Dockerfile"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/FacialRecognition/Dockerfile",
                "type": "Url",
                "format": "dockerfile"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/FacialRecognition/Dockerfile"
        }
    ],
    "support": [
        {
            "result": {
                "value": "The Airline Booking application is a fully serverless web application that implements the flight booking aspect of an airline on AWS ([GitHub](https://github.com/aws-samples/aws-serverless-airline-booking)). Customers can search for flights, book flights, pay using a credit card, and earn loyalty points with each booking. The airline booking application was the subject of the [AWS Build On Serverless](https://pages.awscloud.com/GLOBAL-devstrategy-OE-BuildOnServerless-2019-reg-event.html) series and presented in the AWS re:Invent session [Production-grade full-stack apps with AWS Amplify](https://www.youtube.com/watch?v=DcrtvgaVdCU).\n",
                "type": "Text_excerpt",
                "original_header": "Airline Booking Case Study",
                "parent_header": [
                    "Sizeless Replication Package"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "value": "The frontend of the serverless airline is implemented using CloudFront, Amplify/S3, Vue.js, the Quasar framework, and stripe elements. \nThis frontend sends queries to five backend APIs: _Search Flights_, _Create Charge_, _Create Booking_, _List Bookings_, and _Get Loyalty_. The five APIs are implemented as GraphQL queries using AWS AppSync, a managed GraphQL service. \n<p align=\"center\">\n<img src=\"https://github.com/Sizeless/ReplicationPackage/blob/main/images/serverlessairline.png?raw=true\" width=\"800\">\n</p>\n\nThe _Search Flights_ API retrieves all flights for a given date, arrival airport and departure airport from a DynamoDB table using the DynamoDB GraphQL resolver. \nThe _Create Charge_ API executes the _ChargeCard_ Lambda function, which wraps a call to the Stripe API. \nThe _Create Booking_ API executes a step function workflow that reserves a seat on a flight, creates an unconfirmed booking, and attempts to collect the charge on the customer's credit card. This workflow includes the functions _ReserveBooking_, _CollectPayment_, _ConfirmBooking_, and _NotifyBooking_, which edit DynamoDB tables, manage calls to Stripe, and push a message to an SNS topic. The _IngestLoyalty_ function reads from this SNS topic to update the loyalty points in a DynamoDB table. When the _Get Loyalty_ API is called, the function _GetLoyalty_ retrieves the relevant loyalty data from this DynamoDB table.\n",
                "type": "Text_excerpt",
                "original_header": "System Architecture",
                "parent_header": [
                    "Sizeless Replication Package",
                    "Hello Retail Case Study"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "value": "We have made the following changes to the original system:\n* As with any of the three case studies, we wrapped every function with the resource consumption metrics monitoring and generated a corresponding DynamoDB table for each function where the monitoring data is collected.\n* Configured step functions workflow as an express workflow to reduce execution cost\n* The Stripe API test mode has a concurrency limit of 25 requests. After contacting the support, we adapted the application to distribute the requests to the StripeAPI across multiple Stripe keys.\n* Reconfigured the Stripe integration to timeout and retry long-running requests, which significantly reduced the number of failed requests.\n* We requested an increase of the Lambda concurrent executions service quota from the default of 1.000 to 5.000.\n* Implemented caching for SSM parameters to reduce the number of requests to the System Manager Parameter Store.\n* Enabled the higher throughput option of the System Manager Parameter Store.\n",
                "type": "Text_excerpt",
                "original_header": "Changelog",
                "parent_header": [
                    "Sizeless Replication Package",
                    "Hello Retail Case Study"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "value": "For this case study, we configured the following user behavior:\n1. Search for a flight\n2. Tokenize credit card details using [Stripe](https://stripe.com/)\n3. Place a charge on a credit card using [Stripe](https://stripe.com/)\n4. Book a flight\n5. List booked flights\n6. Display loyalty points\n\nThis sequence of requests ensures that all functions are executed. For our case study, this behavior is traversed concurrently by 128 users at a total rate of 200 requests per second for ten minutes, resulting in at least 20000 executions per function. \n",
                "type": "Text_excerpt",
                "original_header": "Workload",
                "parent_header": [
                    "Sizeless Replication Package",
                    "Hello Retail Case Study"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "value": "The event processing case study uses the event processing system that was introduced in the paper _Facing the Unplanned Migration of Serverless Applications: A Study on Portability Problems, Solutions, and Dead Ends_ by Yussupov et al. and can be found [here](https://github.com/iaas-splab/faas-migration/tree/master/Event-Processing). In this\npaper, the authors investigate the challenges of migrating serverless, FaaS-based applications across cloud providers by migrating different systems across multiple cloud providers. For our case study, we use the AWS implementation of the IoT-inspired event processing system, where the data obtained from multiple sensors are aggregated for further processing.\n\n### System Architecture\n<p align=\"center\">\n<img src=\"https://github.com/Sizeless/ReplicationPackage/blob/main/images/EventProcessing.png?raw=true\" width=\"800\">\n</p>\n\nThis system consists of an API Gateway, six Lambda functions, an Aurora database, three SNS topics, and a SQS queue. The API Gateway exposes three endpoints: `/ingest`, `/list`, `/latest`. Any request to `/ingest` triggers the Lambda function _ingest_, which publishes the event to one of the three available SNS topics depending on the event type. This triggers one of the functions _formatTemperature_, _formatForecast_, and _formatStateChanged_, which format/enrich the event and insert it into the SQS queue. Items from this queue are processed by the function _eventInserter_, which writes them to the Aurora database. The API Gateway endpoints `/list` and `/latest` trigger the Lambda functions _list_ and _latest_, which retrieve the ten latest events or all events from the Aurora database, respectively.\n\n### Changelog\nWe have made the following changes to the original system:\n* As with any of the three case studies, we wrapped every function with the resource consumption metrics monitoring and generated a corresponding DynamoDB table for each function where the monitoring data is collected.\n* The functions that interact with the Aurora database are within a VPC. We added a DynamoDB VPC Endpoint, so these Lambda functions can connect to the DynamoDB tables containing the metrics.\n* Upgraded from nodejs8.10 to nodejs12.X\n* Fixed an issue where newer versions of the serverless framework no longer support the following syntax:\n    * Old: `- Fn::GetAtt: ServerlessVPC.DefaultSecurityGroup`\n    * New: `- Fn::GetAtt: [ServerlessVPC, DefaultSecurityGroup]`\n\n\n### Workload\nFor this case study, we configured the following user behavior:\n1. Insert a new temperature event\n2. Insert a new forecast event\n3. Insert a new state change event\n4. Retrieve the ten latest events\n5. List all events\n\nThis sequence of requests ensures that all functions are executed. For our case study, this behavior is traversed concurrently by 24 users at a total rate of 10 requests per second for ten minutes, resulting in at least 1200 executions per function. \n\n\n### Replicating our measurements\nTo replicate our measurements, run the following commands in the folder `EventProcessing`:\n```\ndocker build --build-arg AWS_ACCESS_KEY_ID=YOUR_PUBLIC_KEY --build-arg AWS_SECRET_ACCESS_KEY=YOUR_SECRET_KEY . -t eventprocessing\ndocker run -d --name eventprocessing eventprocessing\ndocker exec -it eventprocessing bash /ReplicationPackage/EventProcessing/runner.sh\n```\n\nMake sure to replace `YOUR_PUBLIC_KEY` and`YOUR_SECRET_KEY` with your [AWS Credentials](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html). \n\nTo retrieve the collected monitoring data run the following command:\n```\ndocker cp eventprocessing:/results .\n```\nIf the experiments are still running, this command will retrieve the data for the already finished memory sizes and repetitions.\n\nMeasuring the ten repetitions for six different function memory sizes took 2-3 days but was comparatively cheap (<50$) in comparison to the other case studies.\n    \n\n",
                "type": "Text_excerpt",
                "original_header": "Event Processing Case Study",
                "parent_header": [
                    "Sizeless Replication Package"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "value": "This case study uses the facial recognition/image processing segment of the AWS Wild Rydes Workshop ([Github](https://github.com/aws-samples/aws-serverless-workshops/tree/master/ImageProcessing)), which was also used in the evaluation of the paper _Costless: Optimizing Cost of Serverless Computing through Function Fusion and Placement_ by Elgamal et al.. In this application, users of a fictional transportation app, Wild Rydes, upload their profile picture, which triggers the execution of a workflow that performance facial recognition, matching, and indexing.\n\n### System Architecture\n<p align=\"center\">\n<img src=\"https://github.com/Sizeless/ReplicationPackage/blob/main/images/imageprocessing.png?raw=true\" width=\"400\"><img src=\"https://github.com/Sizeless/ReplicationPackage/blob/main/images/imageprocessing_stepfunctions.png?raw=true\" width=\"400\">\n</p>\n\nThis system uses a step functions workflow, six Lambda functions, S3 for thumbnail storage, DynamoDB to store metadata, and AWS Rekognition for facial detection and recognition. Whenever the step functions workflow is executed, the function _FaceDetection_ uses AWS Rekognition to detect any faces in the image. If the photo contains more than one or no face at all, the function _PhotoDoesNotMeetRequirement_ is called, which is a placeholder function for a messaging functionality. Otherwise, the function _CheckFaceDuplicate_ queries the AWS Rekognition collection to check if this face is already registered. If it is already registered, the function _PhotoDoesNotMeetRequirement_ is called, if it is a previously unknown face, then the function _AddFaceToIndex_ uploads the face to the AWS Rekognition collection and the function _Thumbnail_ uses [ImageMagick](https://imagemagick.org/index.php) to create a thumbnail based on the detected image. Finally, the function _Persistmetadata_ saves the image metadata to a DynamoDB table.\n\n### Changelog\nWe have made the following changes to the original system:\n* As with any of the three case studies, we wrapped every function with the resource consumption metrics monitoring and generated a corresponding DynamoDB table for each function where the monitoring data is collected.\n* Added an API gateway that triggers the execution of the step functions workflow, which allows us to use a normal HTTP load driver to generate the load.\n* Switched the DynamoDB tables from provisioned throughput to pay per request so the system incurs no costs while not in use.\n* Upgraded from nodejs10.x to nodejs12.x\n* Fixed an issue where the setup function copyS3object used the cfnresponse package which is not available when using zipfiles for the deployment (see [AWS lambda: No module named 'cfnresponse'](https://stackoverflow.com/questions/49885243/aws-lambda-no-module-named-cfnresponse))\n* Added a lambda layer containing ImageMagick for the thumbnail function, as this is no longer available in the newer runtimes (see [ImageMagick for AWS Lambda](https://github.com/serverlesspub/imagemagick-aws-lambda-2))\n* After looking for the face in the database, the function _CheckFaceDuplicate_ always returns that the image is not yet contained, as otherwise the workload would have to consist of thousands of images that Rekognition recognizes as a single face.\n* Configured step functions workflow as an express workflow to reduce execution cost.\n* Excluded the function _PhotoDoesNotMeetRequirement_ from evaluation as it is a no-op stub.\n\n### Workload\nFor this case study, we configured the following user behavior:\n1. Upload valid picture\n2. Upload invalid picture\n\nThis rather simple sequence of requests already ensures that all functions are executed. For our case study, this behavior is traversed concurrently by 12 users at a total rate of 10 requests per second for five minutes, resulting in at least 1500 executions per function. This case study uses a comparatively short measurement duration and load, as the usage of AWS Rekognition can get quite expensive.\n\n### Replicating our measurements\nTo replicate our measurements, run the following commands in the folder `FacialRecognition`:\n```\ndocker build --build-arg AWS_ACCESS_KEY_ID=YOUR_PUBLIC_KEY --build-arg AWS_SECRET_ACCESS_KEY=YOUR_SECRET_KEY . -t facialrecognition\ndocker run -d --name facialrecognition facialrecognition\ndocker exec -it facialrecognition bash /ReplicationPackage/FacialRecognition/runner.sh\n```\n\nMake sure to replace `YOUR_PUBLIC_KEY` and`YOUR_SECRET_KEY` with your [AWS Credentials](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html). \n\nTo retrieve the collected monitoring data run the following command:\n```\ndocker cp facialrecognition:/results .\n```\nIf the experiments are still running, this command will retrieve the data for the already finished memory sizes and repetitions.\n\nMeasuring the ten repetitions for six different function memory sizes took only ~8 hours but was comparatively expensive (~400$) for a load of 10 requests per second.\n",
                "type": "Text_excerpt",
                "original_header": "Facial Recognition Case Study",
                "parent_header": [
                    "Sizeless Replication Package"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "value": "Hello Retail is a proof-of-concept serverless architecture for a retail store by the online retailer Nordstrom. It was the winner of the serverless architecture competition at  Serverlessconf Austin. The team at Nordstrom built Hello Retail with one scenario in mind: a merchant adding a product to their store. When a product is added to the store, two things need to occur. A photographer needs to take a photo of the product. After this, customers should see the new product with the new photo in the product catalog.\n\n### System Architecture\n<p align=\"center\">\n<img src=\"https://github.com/Sizeless/ReplicationPackage/blob/main/images/helloretail.gif?raw=true\" width=\"800\">\n</p>\n\nThe Hello Retail application uses Kinesis a a central event bus. All incomming events are validated and written to the eventstream by the function `eventwriter`. New product events are handled by the `product-catalog-builder` function and written to dynamo DB. This triggers the execution of a step functions workflow where first the function `photo-assign` assigns the new product that should be photographed to a photographer. The photographer can now upload the corresponding photo, which is recieved by the function `photo-recieve` and then processed by the function `photo-processor`. Finally the function `photo-report` updates the dynamo db entry for the product. The products can be retrieved via the function `product-catalog-api`.\n\n### Changelog\n* As with any of the three case studies, we wrapped every function with the resource consumption metrics monitoring and generated a corresponding DynamoDB table for each function where the monitoring data is collected.\n* We adjusted the photographer messaging per SMS over Twilio to an HTTP request.\n* We removed the Amazon Login authentication, so any user role can be assumed at any time.\n* We fixed the out-of-date deployment configuration and many bugs.\n* We removed the stubs for the cart functionality (add to cart, etc.).\n* Removed the requirement to provide AWS credentials.\n\n### Workload\nFor this case study, we configured the following user behavior:\n1. Register a new photographer\n2. Add a new product\n3. List available categories\n4. List all products for a category\n5. Commit a photo for the new product\n\nThis sequence of requests ensures that all functions are executed. For our case study, this behavior is traversed concurrently by 12 users at a total rate of 10 requests per second for ten minutes, resulting in at least 1000 executions per function. \n\n### Replicating our measurements\nTo replicate our measurements, run the following commands in the folder `HelloRetail`:\n```\ndocker build --build-arg AWS_ACCESS_KEY_ID=YOUR_PUBLIC_KEY --build-arg AWS_SECRET_ACCESS_KEY=YOUR_SECRET_KEY . -t helloretail\ndocker run -d --name helloretail helloretail\ndocker exec -it helloretail bash /hello-retail/runner.sh\n```\n\nMake sure to replace `YOUR_PUBLIC_KEY` and`YOUR_SECRET_KEY` with your [AWS Credentials](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html). \n\nTo retrieve the collected monitoring data run the following command:\n```\ndocker cp helloretail:/results .\n```\nIf the experiments are still running, this command will retrieve the data for the already finished memory sizes and repetitions.\n\nMeasuring the ten repetitions for six different function memory sizes took only ~12 hours but was quite cheap (~30$) for a load of 10 requests per second.\n",
                "type": "Text_excerpt",
                "original_header": "Hello Retail Case Study",
                "parent_header": [
                    "Sizeless Replication Package"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        }
    ],
    "acknowledgement": [
        {
            "result": {
                "value": "This case study uses the facial recognition/image processing segment of the AWS Wild Rydes Workshop ([Github](https://github.com/aws-samples/aws-serverless-workshops/tree/master/ImageProcessing)), which was also used in the evaluation of the paper _Costless: Optimizing Cost of Serverless Computing through Function Fusion and Placement_ by Elgamal et al.. In this application, users of a fictional transportation app, Wild Rydes, upload their profile picture, which triggers the execution of a workflow that performance facial recognition, matching, and indexing.\n\n### System Architecture\n<p align=\"center\">\n<img src=\"https://github.com/Sizeless/ReplicationPackage/blob/main/images/imageprocessing.png?raw=true\" width=\"400\"><img src=\"https://github.com/Sizeless/ReplicationPackage/blob/main/images/imageprocessing_stepfunctions.png?raw=true\" width=\"400\">\n</p>\n\nThis system uses a step functions workflow, six Lambda functions, S3 for thumbnail storage, DynamoDB to store metadata, and AWS Rekognition for facial detection and recognition. Whenever the step functions workflow is executed, the function _FaceDetection_ uses AWS Rekognition to detect any faces in the image. If the photo contains more than one or no face at all, the function _PhotoDoesNotMeetRequirement_ is called, which is a placeholder function for a messaging functionality. Otherwise, the function _CheckFaceDuplicate_ queries the AWS Rekognition collection to check if this face is already registered. If it is already registered, the function _PhotoDoesNotMeetRequirement_ is called, if it is a previously unknown face, then the function _AddFaceToIndex_ uploads the face to the AWS Rekognition collection and the function _Thumbnail_ uses [ImageMagick](https://imagemagick.org/index.php) to create a thumbnail based on the detected image. Finally, the function _Persistmetadata_ saves the image metadata to a DynamoDB table.\n\n### Changelog\nWe have made the following changes to the original system:\n* As with any of the three case studies, we wrapped every function with the resource consumption metrics monitoring and generated a corresponding DynamoDB table for each function where the monitoring data is collected.\n* Added an API gateway that triggers the execution of the step functions workflow, which allows us to use a normal HTTP load driver to generate the load.\n* Switched the DynamoDB tables from provisioned throughput to pay per request so the system incurs no costs while not in use.\n* Upgraded from nodejs10.x to nodejs12.x\n* Fixed an issue where the setup function copyS3object used the cfnresponse package which is not available when using zipfiles for the deployment (see [AWS lambda: No module named 'cfnresponse'](https://stackoverflow.com/questions/49885243/aws-lambda-no-module-named-cfnresponse))\n* Added a lambda layer containing ImageMagick for the thumbnail function, as this is no longer available in the newer runtimes (see [ImageMagick for AWS Lambda](https://github.com/serverlesspub/imagemagick-aws-lambda-2))\n* After looking for the face in the database, the function _CheckFaceDuplicate_ always returns that the image is not yet contained, as otherwise the workload would have to consist of thousands of images that Rekognition recognizes as a single face.\n* Configured step functions workflow as an express workflow to reduce execution cost.\n* Excluded the function _PhotoDoesNotMeetRequirement_ from evaluation as it is a no-op stub.\n\n### Workload\nFor this case study, we configured the following user behavior:\n1. Upload valid picture\n2. Upload invalid picture\n\nThis rather simple sequence of requests already ensures that all functions are executed. For our case study, this behavior is traversed concurrently by 12 users at a total rate of 10 requests per second for five minutes, resulting in at least 1500 executions per function. This case study uses a comparatively short measurement duration and load, as the usage of AWS Rekognition can get quite expensive.\n\n### Replicating our measurements\nTo replicate our measurements, run the following commands in the folder `FacialRecognition`:\n```\ndocker build --build-arg AWS_ACCESS_KEY_ID=YOUR_PUBLIC_KEY --build-arg AWS_SECRET_ACCESS_KEY=YOUR_SECRET_KEY . -t facialrecognition\ndocker run -d --name facialrecognition facialrecognition\ndocker exec -it facialrecognition bash /ReplicationPackage/FacialRecognition/runner.sh\n```\n\nMake sure to replace `YOUR_PUBLIC_KEY` and`YOUR_SECRET_KEY` with your [AWS Credentials](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html). \n\nTo retrieve the collected monitoring data run the following command:\n```\ndocker cp facialrecognition:/results .\n```\nIf the experiments are still running, this command will retrieve the data for the already finished memory sizes and repetitions.\n\nMeasuring the ten repetitions for six different function memory sizes took only ~8 hours but was comparatively expensive (~400$) for a load of 10 requests per second.\n",
                "type": "Text_excerpt",
                "original_header": "Facial Recognition Case Study",
                "parent_header": [
                    "Sizeless Replication Package"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        }
    ],
    "installation": [
        {
            "result": {
                "value": "In order to install and configure the synthetic function generator, the following steps are required:\n\n* Install the required dependencies:\n   * Install `golang` (tested for versions 1.14+)\n   * Install `nodejs` (tested for versions 12.0+)\n   * Install the [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html)\n   * Install the [SAM CLI](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html)\n* Build the synthetic function generator CLI: Inside the `function-generator` directory run the command `go build .`. By default this results in a file named `synthetic-function-generator`.\n* Both the AWS CLI and SAM CLI read the AWS Credentials that are needed to perform actions on AWS from either environment variables or by convention from a file in `$HOME/.aws/credentials`. Make sure that a valid **Access Key** and **Secret Key** can be found by both CLIs. See the [official documentation](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html) for more details on configuring the AWS CLI.\n* The monitoring add-on has some dependencies on certain npm packages.\nTo avoid that each synthetic function package has to bring these dependencies, the use of a dependency layer proved to be the most efficient way.\nThe file `dependencyLayer.zip` represents a ready-to-deploy package to add the required dependencies as a Lambda Layer. Follow the instructions on `AWS Console -> Lambda -> Additional resources -> Layers` to deploy the package. The dependency layer will be assigned a **Version ARN**, which is needed to generate functions using the CLI.\nFor more information about AWS Lambda Layers, see [here](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html).\n* The synthetic Lambda functions need to be assigned a role ARN to allow the function to access other AWS services. Either create a new role that defines what services the Lambda functions are allowed to access or use an existing role. Make sure that AWS Lambda is listed in the **Trusted Entities** section so that it can be used by Lambda. To generate synthetic functions using the CLI the **Role ARN** will be needed.\n",
                "type": "Text_excerpt",
                "original_header": "Setup",
                "parent_header": [
                    "Sizeless Replication Package",
                    "Synthetic Function Generator"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "To replicate our measurements, run the following commands in the folder `AirlineBooking`:\n```\ndocker build --build-arg AWS_ACCESS_KEY_ID=YOUR_PUBLIC_KEY --build-arg AWS_SECRET_ACCESS_KEY=YOUR_SECRET_KEY --build-arg STRIPE_PUBLIC_KEYS=YOUR_KEYS --build-arg STRIPE_SECRET_KEYS=YOUR_KEYS . -t airlinebooking\ndocker run -d --name airlinebooking airlinebooking\ndocker exec -it airlinebooking bash ./meta-run.sh\n``` \nMake sure to replace `YOUR_PUBLIC_KEY` and`YOUR_SECRET_KEY` with your [AWS Credentials](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html).  \n",
                "original_header": "Replicating our measurements"
            },
            "confidence": 0.976841015102851,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "<p align=\"center\">\n<img src=\"https://github.com/Sizeless/ReplicationPackage/blob/main/images/generator.png?raw=true\" width=\"800\">\n</p> \n",
                "original_header": "Synthetic Function Generator"
            },
            "confidence": 0.986380675463032,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "To add additional function segments, create a new folder in `SyntheticFunctionGenerator/function_segments/` that contains a `function.js`file that contains the function code, a `setup.js` file that creates any additional required resoures e.g., S3 buckets, a `teardown.js` that removes any resources created in `setup.js`, and a `variables.yaml`file that contains any shared variables.\n \n",
                "original_header": "Function segments"
            },
            "confidence": 0.9681157237078384,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "```\nThis command generates AWS Lambda deployable serverless function artifacts.\nThe generated artifacts are compatible for use with the runload command.\n\nUsage:\n  synthetic-function-generator generate [flags]\n\nFlags:\n  -d, --dependency-layern-arn string   The ARN of the dependency layer, see README (required)\n      --exclude string                 Path to file containing roll strings to be excluded from generation (use --save flag for an example)\n  -f, --func-segments string           Path to function segments to be used for generation (required)\n  -h, --help                           help for generate\n  -l, --lambda-role-arn string         The ARN of the lambda role, see README (required)\n  -m, --max-roll int                   Maximum number of rolled function segments (ignored if replayFile is provided) (default 3)\n  -n, --num-funcs int                  Number of functions to generate (ignored if replayFile is provided) (default 1)\n      --replay string                  Path to file containing roll strings to be regenerated (use --save flag for an example)\n      --save                           Whether the generated function combinations should be saved\n  -s, --sizes ints                     Specify function sizes to be generated, need to be supported by the platform! (default [128,416,704,992,1280,1568,1856,2144,2432,2720,3008])\n```\n \n",
                "original_header": "Command `generate`"
            },
            "confidence": 0.9907527376717638,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "```\nThis command can be used to delete all generated functions\n\nUsage:\n  synthetic-function-generator clean [flags]\n\nFlags:\n  -h, --help   help for clean\n``` \nMake sure to replace `LAYER_ARN` and `LAMBDA_ROLE_ARN` with the corresponding ARNs from the setup step. The results are saved to the folder `./result-data`. \n",
                "original_header": "Command `clean`"
            },
            "confidence": 0.9773420253429825,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "<p align=\"center\">\n<img src=\"https://github.com/Sizeless/ReplicationPackage/blob/main/images/Codeocean.png?raw=true\" width=\"800\">\n</p>\n \n",
                "original_header": "Measurement data and analysis scripts"
            },
            "confidence": 0.9790928175704064,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        }
    ],
    "description": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "The implemented function generator makes heavy use of template engines. Given a set of function segments, first the `variables.yaml`file of each segment is parsed to determine which variables should be generated for each segment.  Additionally, the list of files to copy is extracted as well as the npmpackages that need to be installed. From that information the set of variables needed for the final template execution is created. Afterwards  the  finalized  function  segments  are  generated  by  executing  the segment templates. These are then combined with the previously generated variables to perform the final template execution in order to obtain the deployable Lambda package. The deployable Lambda package is constructed from the following template files and also contains the additional required files specified in the `variables.yaml` file:\n* **setup.js.tmpl**  This template file acts as a base for the resulting `setup.js`file which contains the combined setup logic of each included function segment.\n* **teardown.js.tmpl** This template, after the generation is done, results in the `tear-down.js`file which contains the combined teardown logic of each included functionsegment.\n* **function.js.tmpl** This file is the base for the resulting `function.js`file that contains the fused business logic of each included function segment. Further, it contains the function monitoring code that is responsible for both metrics collection as well as persisting those metrics. By wrapping the generated business logic function using a function reference, the monitoring is instrumented at generation time.\n* **package.json.tmpl** The base for the `package.json`file which is usually used to describe an npmpackage. In this work it is generated and generically enriched with  all additional npm packages as specified in the `variables.yaml` file.\n* **samconfig.toml.tmpl** To  deploy  the  generated  functions  to  AWS  Lambda,  AWS SAM and its corresponding CLI is used. To enable a fully automated deployment without user input, the deplyoment configuration for SAM need to be provided beforehand.  This is done with the help of  this  template  file,  which  results  in  a `samconfig.toml` file  inside  the  deploymentpackage.\n* **template.yml.tmpl** SAM describes all resources in a `template.yml` file.  This file also contains information about the AWS Lambda function, which is why this file needs to be generated as well. \n",
                "original_header": "Synthetic Function Generator"
            },
            "confidence": 0.9775464927518817,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "We implemented the following sixteen function segments:\n* **FloatingPointOperations** Floating-point operations are common in microbenchmarks as they represent the most basic CPU-intensive tasks. This segment calculates the square root,  sine,  cosine, and tangent of several varying input parameters. \n* **ImageCompress** Image manipulations are a textbook example use case for serverless functions. This segment generates a random image of varying dimensions and compresses it to varying degrees. \n* **ImageResize** This segment generates a random image of varying dimensions and resizes it to varying sizes. \n* **ImageRotate** This segment generates a random image of varying dimensions and rotates it by varying angles. \n* **JSON2YAML** Another common use case for serverless functions is as an adapter for an external API. This function segment transforms JSON files to the YAML format. \n* **DynamoDBRead** Serverless functions are stateless, so state is commonly saved in external databases. This segment reads varying amounts of data from DynamoDB, a serverless database. \n* **S3Write** This segment uploads files of varying sizes to an S3 bucket. \n* **Sleep** This segment keeps the system idle for varying durations. This is equivalent to waiting for an external service during an API call. \n",
                "original_header": "Function segments"
            },
            "confidence": 0.9272516679763233,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Generating this training data set of resource consumption metrics and execution duration of 2000 functions at six different memory levels took ~2 weeks and incurred costs of ~2000$.\n \n",
                "original_header": "Command `clean`"
            },
            "confidence": 0.9569642960429274,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "All measurement data collected for our manuscript is publically available together with all analysis scripts used to implement the mulitarget regression modeling and to generate any figures shown in the manuscript. For this part of our replication package, we use CodeOcean, which generates a standard, secure, and executable research package called a Capsule. The Code Ocean Capsule format is open, exportable, reproducible, and interoperable. Each capsule is versioned and contains code, data, environment, and the associated results. You can find a private copy of our CodeOcean capsule here: \n",
                "original_header": "Measurement data and analysis scripts"
            },
            "confidence": 0.9983609064072367,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "The CodeOcean capsule also contains all data that was collected for this manuscript in the folder labled as \"Data\" in the screenshot above. It contains the following data: \n",
                "original_header": "Viewing the data from the manuscript"
            },
            "confidence": 0.9346654227644938,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Aside from enabling simple reproducability, the CodeOcean capsule also allows to adapt the analysis. As an example, let's say we are interested in how often our approach selects the optimal memorysize for a tradeoff factor of 0.6 (only shown in the paper for 0.75, 0.5, and 0.25) and what the resulting cost/performance benefits would be. This requires only to edit the `evaluation.py` file to set the variable `tradeoff` to 0.6 (no need to be shy, CodeOcean creates a private copy of the capsule when you start editing) and press the \"Reproducible Run\" button. After some computation time, there will be a new folder in the right bar, that shows the results for this run.\n \n",
                "original_header": "Adapting the capsule"
            },
            "confidence": 0.9048595408843642,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Sizeless Replication Package"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        }
    ],
    "images": [
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/Sizeless/ReplicationPackage/main/images/serverlessairline.png?raw=true"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/Sizeless/ReplicationPackage/main/images/EventProcessing.png?raw=true"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/Sizeless/ReplicationPackage/main/images/imageprocessing.png?raw=true"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/Sizeless/ReplicationPackage/main/images/imageprocessing_stepfunctions.png?raw=true"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/Sizeless/ReplicationPackage/main/images/helloretail.gif?raw=true"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/Sizeless/ReplicationPackage/main/images/generator.png?raw=true"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://raw.githubusercontent.com/Sizeless/ReplicationPackage/main/images/Codeocean.png?raw=true"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/sizeless/replicationpackage/main/README.md"
        }
    ]
}
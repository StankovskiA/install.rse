{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-04 18:25:07"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/michaelpradel/LExecutor",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "michaelpradel",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2021-09-17T06:41:39Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-08-09T01:21:48Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/mit",
                "type": "License",
                "name": "MIT License",
                "url": "https://api.github.com/licenses/mit",
                "spdx_id": "MIT"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Copyright 2021 Michael Pradel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/LICENSE"
        }
    ],
    "description": [
        {
            "result": {
                "value": "A learning-guided approach for executing arbitrary Python code snippets",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "This repository contains the implementation of LExecutor and supplementary material for the paper \"LExecutor: Learning-Guided Execution\" (FSE'23). \n",
                "original_header": "LExecutor: Learning-Guided Execution"
            },
            "confidence": 0.9543927168133453,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "LExecutor",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "michaelpradel/LExecutor",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/michaelpradel/LExecutor/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/michaelpradel/LExecutor/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 15,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 3,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/michaelpradel/lexecutor/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Jupyter Notebook",
                "name": "Jupyter Notebook",
                "type": "Programming_language",
                "size": 1013639
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 158505
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Shell",
                "name": "Shell",
                "type": "Programming_language",
                "size": 3260
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "releases": [
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/michaelpradel/LExecutor/releases/92525655",
                "tag": "Models_20230105",
                "name": "Models_20230105",
                "author": {
                    "name": "michaelpradel",
                    "type": "User"
                },
                "description": "CodeT5-based models, fine-tuned on 226k data points on Jan 5, 2023\r\nCodeBERT-based models, fine-tuned on 226k data points on Jun 29, 2023",
                "tarball_url": "https://api.github.com/repos/michaelpradel/LExecutor/tarball/Models_20230105",
                "zipball_url": "https://api.github.com/repos/michaelpradel/LExecutor/zipball/Models_20230105",
                "html_url": "https://github.com/michaelpradel/LExecutor/releases/tag/Models_20230105",
                "url": "https://api.github.com/repos/michaelpradel/LExecutor/releases/92525655",
                "release_id": 92525655,
                "date_created": "2023-02-08T07:45:04Z",
                "date_published": "2023-02-15T10:01:18Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Release",
                "value": "https://api.github.com/repos/michaelpradel/LExecutor/releases/91146752",
                "tag": "20230202",
                "name": "20230202",
                "author": {
                    "name": "michaelpradel",
                    "type": "User"
                },
                "tarball_url": "https://api.github.com/repos/michaelpradel/LExecutor/tarball/20230202",
                "zipball_url": "https://api.github.com/repos/michaelpradel/LExecutor/zipball/20230202",
                "html_url": "https://github.com/michaelpradel/LExecutor/releases/tag/20230202",
                "url": "https://api.github.com/repos/michaelpradel/LExecutor/releases/91146752",
                "release_id": 91146752,
                "date_created": "2023-02-02T13:25:45Z",
                "date_published": "2023-02-02T15:46:57Z"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "installation": [
        {
            "result": {
                "value": "# Installation Guide\n\nCreate and enter a virtual environment:\n\n```\nvirtualenv -p /usr/bin/python3.8 myenv\nsource myenv/bin/activate\n```\n\nInstall requirements:\n\n```\npip install -r requirements.txt\n```\n\nLocally install the package in development/editable mode:\n\n```\npip install -e ./\n```\n\n# Usage Guide\n\n1. Instrument the Python files that will be LExecuted\n\n2. Run the Python files instrumented in step 1\n\nAs a simple example, consider that the following code is in `./files/file.py`. \n\n```python\nif (not has_min_size(all_data)):\n    raise RuntimeError(\"not enough data\")\n\ntrain_len = round(0.8 * len(all_data))\n\nlogger.info(f\"Extracting training data with {config_str}\")\n\ntrain_data = all_data[0:train_len]\n```\nThen, to *LExecute* the code, do as follows:\n\n1. Instrument the code:\n```\npython -m lexecutor.Instrument --files ./files/file.py\n```\n\n2. Run the instrumented code:\n```\npython ./files/file.py\n```\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/INSTALL.md"
        },
        {
            "result": {
                "value": "1. Check that your setup meets the [REQUIREMENTS.md](REQUIREMENTS.md).\n2. Follow the installation instructions in [INSTALL.md](INSTALL.md).\n",
                "type": "Text_excerpt",
                "original_header": "Getting Started Guide",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "To reproduce the results from the paper, follow these instructions. The results of the following instructions are provided in the [artifact](https://zenodo.org/record/8270900), i.e., you can also inspect them there to skip some of the below steps.\n\nFirst, install LExecutor using the instructions above.\n",
                "type": "Text_excerpt",
                "original_header": "Replication Guide",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "To gather a corpus of value-use events for training and evaluating the neural model, we proceed as follows:\n\n1. Set the LExecutor mode to RECORD at `./src/lexecutor/Runtime.py`\n\n2. Make `get_traces.sh` executable:\n```\nchmod +x get_traces.sh\n```\n\n3. For every considered project, execute `get_traces.sh` giving the required arguments, e.g.:\n```\n./get_traces.sh https://github.com/Textualize/rich rich tests\n```\n\n4. Get the path of all the generated traces:\n```\nfind ./data/repos/ -type f -name \"trace_*.h5\" > traces.txt\n```\n\nThe output is stored as follows: the repositories with instrumented files and trace files are stored in `./data/repos`; the instruction ids is stored in `./iids.json`; the trace paths are stored in `./traces.txt`.\n",
                "type": "Text_excerpt",
                "original_header": "Value-use events dataset",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution",
                    "Replication Guide",
                    "Accuracy of the Neural Model (RQ1)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "Our current implementation integrates two pre-trained models, CodeT5 and CodeBERT, which we fine-tune for our prediction task as follows.\n",
                "type": "Text_excerpt",
                "original_header": "Model training and validation",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution",
                    "Replication Guide",
                    "Accuracy of the Neural Model (RQ1)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "1. Create a folder to store the output:\n```\nmkdir ./data/codeT5_models_fine-grained\n```\n\n2. Prepare the dataset:\n```\npython -m lexecutor.predictors.codet5.PrepareData \\\n  --iids iids.json \\\n  --traces traces.txt \\\n  --output_dir ./data/codeT5_models_fine-grained\n```\n\n3. Fine-tune the model:\n```\npython -m lexecutor.predictors.codet5.FineTune \\\n  --train_tensors ./data/codeT5_models_fine-grained/train.pt \\\n  --validate_tensors ./data/codeT5_models_fine-grained/validate.pt \\\n  --output_dir ./data/codeT5_models_fine-grained \\\n  --stats_dir ./data/codeT5_models_fine-grained\n```\n\nThe output, i.e. the tensors, models for every epoch, training loss and validation accuracy, is stored in `./data/codeT5_models_fine-grained`.\n",
                "type": "Text_excerpt",
                "original_header": "CodeT5",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution",
                    "Replication Guide",
                    "Accuracy of the Neural Model (RQ1)",
                    "Model training and validation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "1. Create a folder to store the output:\n```\nmkdir ./data/codeBERT_models_fine-grained\n```\n\n2. Prepare the dataset:\n```\npython -m lexecutor.predictors.codebert.PrepareData \\\n  --iids iids.json \\\n  --traces traces.txt \\\n  --output_dir ./data/codeBERT_models_fine-grained\n```\n\n3. Fine-tune the model:\n```\npython -m lexecutor.predictors.codeBERT.FineTune \\\n  --train_tensors ./data/codeBERT_models_fine-grained/train.pt \\\n  --validate_tensors ./data/codeBERT_models_fine-grained/validate.pt \\\n  --output_dir ./data/codeBERT_models_fine-grained \\\n  --stats_dir ./data/codeBERT_models_fine-grained\n```\n\nThe output, i.e. the tensors, the models for every epoch, training loss and validation accuracy, is stored in `./data/codeBERT_models_fine-grained`.\n\nBy default, we train and use the models based on the fine-grained abstraction of values. To fine-tune the models based on the coarse-grained abstraction of values, set `value_abstraction` to `coarse-grained-deterministic` or `coarse-grained-randomized` in `./src/lexecutor/Hyperparams.py`. Then, replace `fine-grained` by `coarse-grained` in the steps 1-3 above. \n",
                "type": "Text_excerpt",
                "original_header": "CodeBERT",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution",
                    "Replication Guide",
                    "Accuracy of the Neural Model (RQ1)",
                    "Model training and validation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "To gather a dataset of functions extracted from open-source Python projects, we proceed as follows:\n\n1. Make `get_function_bodies_dataset.sh` executable:\n```\nchmod +x get_function_bodies_dataset.sh\n```\n\n2. Execute `get_function_bodies_dataset.sh`:\n```\n./get_function_bodies_dataset.sh\n```\n\nThe output contains two extra versions of each function to fit the considered baseline approaches: 1) for functions that are methods, we wrapp them in a `Wrapper` class, otherwise we would not be able run Pynguin on them; 2) we add a function invocation to each function for them to be executed. This is required to run the code inside each function when running the baseline predictor based on Type4Py.\n\nThe output is stored as follows: the repositories are stored in `./data/repos`; the randomly selected functions are stored in `./popular_projects_snippets_dataset`; the paths to the files in each version of the dataset are stored in `popular_projects_function_bodies_dataset.txt`, `popular_projects_functions_dataset.txt` and `popular_projects_functions_with_invocation_dataset.txt`. Finally, auxiliary information useful to calculate line coverage afterwards are stored in `wrapp_info.csv` and `aux_data_functions_with_invocation_dataset.csv`.\n",
                "type": "Text_excerpt",
                "original_header": "Open-source functions",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution",
                    "Replication Guide",
                    "Effectiveness at Covering Code and Efficiency at Guiding Executions (RQ2 and RQ3)",
                    "Datasets"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "To gather a dataset of code snippets from Stack Overflow, we proceed as follows:\n\n1. Create a folder to store the code snippets:\n```\nmkdir so_snippets_dataset\n```\n\n2. Get the code snippets:\n```\npython get_stackoverflow_snippets_dataset.py --dest_dir so_snippets_dataset\n```\n\n3. Get the path of all the collected snippets:\n```\nfind ./so_snippets_dataset -type f -name \"*.py\" > so_snippets_dataset.txt\n```\n\nThe output is stored as follows: the code snippets from Stack Overflow are stored in `./so_snippets_dataset` and their paths are stored in `so_snippets_dataset.txt`.\n",
                "type": "Text_excerpt",
                "original_header": "Stack Overflow snippets",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution",
                    "Replication Guide",
                    "Effectiveness at Covering Code and Efficiency at Guiding Executions (RQ2 and RQ3)",
                    "Datasets"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "1. Set the dataset under evaluation at `./src/lexecutor/Hyperparams.py`\n\n2. Calculate the total lines in each file on the dataset under evaluation, e.g.:\n```\npython -m lexecutor.evaluation.CountTotalLines --files popular_projects_function_bodies_dataset.txt\n```\n\n3. Instrument the files in the dataset under evaluation, e.g.:\n```\npython -m lexecutor.Instrument --files popular_projects_function_bodies_dataset.txt --iids iids.json\n```\n\n4. Execute each predictor/baseline on the dataset under evaluation as follows:\n\n   1. Set `./src/lexecutor/Runtime.py` to use the desired predictor. Some predictors/baselines require additional steps:\n      - For the predictors based on CodeT5 and CodeBERT, the value abstraction must also be set at `./src/lexecutor/Hyperparams.py`\n      - For the predictor based on Type4Py, make sure that the docker image containing Type4Py's pre-trained model is running according to [this tutorial](https://github.com/saltudelft/type4py/wiki/Type4Py's-Local-Model)\n      - For the Pynguin baseline, execute the following steps:\n           1. Create and enter a virtual environment for Python 3.10 (required by the newest Pynguin version):\n               ```\n               python3.10 -m venv myenv_py3.10\n               source myenv_3.10/bin/activate\n               ```\n\n           2. Generate tests with Pynguin for the extracted functions:\n               ```\n               mkdir pynguin_tests\n               python -m lexecutor.evaluation.RunPynguin --files popular_projects_functions_dataset.txt --dest pynguin_tests\n               ```\n\n           3. Get the path of all the generated tests:\n               ```\n               find ./pynguin_tests -type f -name \"test_*.py\" > pynguin_tests.txt\n               ```\n\n           4. Set the predictor to `AsIs` and the file_type to `TESTE` in `./src/lexecutor/Runtime.py`\n           \n   2. Create a folder to store the log files, e.g.:\n      ```\n      mkdir logs\n      mkdir logs/popular_projects_functions_dataset\n      mkdir logs/popular_projects_functions_dataset/RandomPredictor\n      ```\n\n   3. Execute `RunExperiments.py` with the required arguments, e.g.:\n      ```\n      python -m lexecutor.evaluation.RunExperiments \\\n        --files popular_projects_functions_dataset.txt \\\n        --log_dest_dir logs/popular_projects_functions_dataset/RandomPredictor\n      ```\n\n      For the Pynguin baseline, make sure to include `--tests` and give the path to the generated tests, i.e. `pynguin_tests.txt`, to `--files` when executing `RunExperiments.py`\n\n5. Process and combine the raw data generated:\n   ```\n   python -m lexecutor.evaluation.CombineData\n   ```\n",
                "type": "Text_excerpt",
                "original_header": "Data generation",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution",
                    "Replication Guide",
                    "Effectiveness at Covering Code and Efficiency at Guiding Executions (RQ2 and RQ3)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "The code to get the plots for RQ2 and table content for RQ3 is available at `./src/notebooks/analyze_code_coverage_effectiveness_and_efficiency.ipynb`\n  ",
                "type": "Text_excerpt",
                "original_header": "Data analysis and plots generation",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution",
                    "Replication Guide",
                    "Effectiveness at Covering Code and Efficiency at Guiding Executions (RQ2 and RQ3)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "To gather a corpus of pairs of old + new function from commits, we proceed as follows:\n\n1. Create a folder to store the function pairs for every considered project, e.g.:\n```\nmkdir data/function_pairs && mkdir data/function_pairs/flask\n```\n\n2. For every considered project, execute `FunctionPairExtractor.py` providing the required arguments, e.g.:\n```\npython -m lexecutor.evaluation.FunctionPairExtractor \\\n  --repo data/repos_with_commit_history/flask/ \\\n  --dest data/function_pairs/flask/\n```\n\nThe output, i.e. the function pairs with code that invokes both functions and compares their return values, is stored in `compare.py` files under `data/function_pairs/`\n",
                "type": "Text_excerpt",
                "original_header": "Pairs of old + new function from commits dataset",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution",
                    "Replication Guide",
                    "Using LExecutor to Find Semantics-Changing Commits (RQ4)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        },
        {
            "result": {
                "value": "1. Instrument the code in the `compare.py` files, e.g.:\n```\npython -m lexecutor.Instrument --files `find data/function_pairs/flask -name compare.py | xargs`\n```\n\n2. Run the instrumented code to compare its runtime behavior, e.g.:\n```\nfor f in `find data/function_pairs/flask -name compare.py | xargs`; do timeout 30 python $f; done > out_flask\n```\n",
                "type": "Text_excerpt",
                "original_header": "Finding semantics-changing commits",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution",
                    "Replication Guide",
                    "Using LExecutor to Find Semantics-Changing Commits (RQ4)"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "has_script_file": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/get_traces.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/get_function_bodies_dataset.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/src/lexecutor/evaluation/findSemanticsChangingCommit.sh",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "executable_example": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/src/notebooks/analyze_code_coverage_effectiveness_and_efficiency.ipynb",
                "type": "Url",
                "format": "jupyter_notebook"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/src/notebooks/analyze_code_coverage_effectiveness_and_efficiency.ipynb"
        },
        {
            "result": {
                "value": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/src/notebooks/analyze_model_validation.ipynb",
                "type": "Url",
                "format": "jupyter_notebook"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/src/notebooks/analyze_model_validation.ipynb"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "1. Check that your setup meets the [REQUIREMENTS.md](REQUIREMENTS.md).\n2. Follow the installation instructions in [INSTALL.md](INSTALL.md).\n",
                "type": "Text_excerpt",
                "original_header": "Getting Started Guide",
                "parent_header": [
                    "LExecutor: Learning-Guided Execution"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        }
    ],
    "identifier": [
        {
            "result": {
                "type": "Url",
                "value": "https://doi.org/10.5281/zenodo.8270900"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "LExecutor: Learning-Guided Execution"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2302.02343\n\n## Getting Started Guide\n\n1. Check that your setup meets the [REQUIREMENTS.md](REQUIREMENTS.md"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/michaelpradel/lexecutor/main/README.md"
        }
    ]
}
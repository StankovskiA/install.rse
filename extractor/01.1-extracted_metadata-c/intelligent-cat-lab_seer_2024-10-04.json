{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-04 20:16:43"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/Intelligent-CAT-Lab/SEER",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "Intelligent-CAT-Lab",
                "type": "Organization"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2022-06-23T03:10:42Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-05-08T02:03:15Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "license": [
        {
            "result": {
                "value": "https://api.github.com/licenses/mit",
                "type": "License",
                "name": "MIT License",
                "url": "https://api.github.com/licenses/mit",
                "spdx_id": "MIT"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "MIT License\n\nCopyright (c) 2022 Intelligent CAT Lab\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/LICENSE"
        }
    ],
    "description": [
        {
            "result": {
                "value": "Artifact repository for the paper \"Perfect Is the Enemy of Test Oracle\", In Proceedings of The 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2022), Singapore, November 2022",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "The artifact mainly consists of Python scripts which were used for automating dataset generation, mutation testing, and deep learning model implementation. We have split each distinct component of SEER into a separate directory in this repository. Please refer to each directory for a detailed explanation of the component. \n",
                "original_header": "Perfect Is the Enemy of Test Oracle"
            },
            "confidence": 0.9563342539587196,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Please find the model checkpoints and final datasets for both phase-1 and phase-2 of model training on [Zenodo](https://doi.org/10.5281/zenodo.6970062). Below is a description for each file of our data archive on Zenodo.\n* `attention_analysis.zip`: This zip contains the necessary files for attention analysis. Please refer to [attention_analysis](attention_analysis) for further explanations.\n* `defects4j_randoop_tests.zip`: This zip contains the generated randoop tests for all 17 projects available in Defects4J. We use the content of this file in [dataset_generation](dataset_generation)\n* `epoch_21_fold_1.h5`: This file is a checkpoint of the best performing model from phase-1. The model has been saved after epoch 21 in fold 1.\n* `epoch_29_fold_1.h5`: This file is a checkpoint of the best performing model model from phase-2. The model has been saved after epoch 29 in fold 1.\n* `phase1_dataset_final.zip`: This zip contains the cleaned and preprocessed dataset for phase-1 of model training.\n* `phase2_dataset_final_unseen.zip`: This zip contains the cleaned and preprocessed dataset for phase-2 of model training. The keyword \"unseen\" in the file name represents that minor projects are not included in model training.\n* `phase2_dataset_final_whole.zip`: This zip contains the cleaned and preprocessed dataset for phase-2 of model training. The keyword \"whole\" in the file name represents that all projects are included in model training, testing, and validation.\n* `data.zip`: This zip contains all necessary files for reproducing the result of each RQ from the paper. We use this file in [scripts](scripts)\n \n",
                "original_header": "Data Archive"
            },
            "confidence": 0.9896487768953119,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Automation of test oracles is one of the most challenging facets of software testing, but remains comparatively less addressed compared to automated test input generation. Test oracles rely on a ground-truth that can distinguish between the correct and buggy behavior to determine whether a test fails (detects a bug) or passes. What makes the oracle problem challenging and undecidable is the assumption that the ground-truth should know the exact expected, correct or buggy behavior. However, we argue that one can still build an accurate oracle without knowing the exact correct or buggy behavior, but how these two might differ. This paper presents SEER, a Deep Learning-based approach that in the absence of test assertions or other types of oracle, can automatically determine whether a unit test passes or fails on a given method under test (MUT). To build the ground-truth, SEER jointly embeds unit tests and the implementation of MUTs into a unified vector space, in such a way that the neural representation of tests are similar to that of MUTs they pass on them, but dissimilar to MUTs they fail on them. The classifier built on top of this vector representation serves as the oracle to generate \u201cfail\u201d labels, when test inputs detect a bug in MUT or \u201cpass\u201d labels, otherwise. Our extensive experiments on applying SEER to more than 5K unit tests from a diverse set of opensource Java projects show that the produced oracle is (1) effective in predicting the fail or pass labels, achieving an overall accuracy, precision, recall, and F1 measure of 93%, 86%, 94%, and 90%, (2) generalizable, predicting the labels for the unit test of projects that were not in training or validation set with negligible performance drop, and (3) efficient, detecting the existence of bugs in only 6.5 milliseconds on average. Moreover, by interpreting the proposed neural model and looking at it beyond a closed-box solution, we confirm that the oracle is valid, i.e., it predicts the labels through learning relevant features.\n \n",
                "original_header": "SEER Overview"
            },
            "confidence": 0.9818479063879253,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "     SEER\n       |\n       |--- attention_analysis:       The Multi-Head Attention Analysis related to model interpretation\n       |\n       |--- embedding_analysis:       The Embedding Analysis related to model interpretation\n       |\n       |--- dataset_generation:       The module which contains all scripts related to dataset generation\n       |\n       |--- models:                   The module which contains the deep learning models implemented in PyTorch\n       |\n       |--- learning:                 The module which contains everything related to model training and evaluation\n       |\n       |--- scripts:                  The module which reproduces RQs from the paper\n       |\n       |--- mutant_generation:        The module which contains all scripts related to mutant generation\n           |\n           |--- mutation_operators:   A directory which contains all mutation operators used in Major\n \n",
                "original_header": "Implementation Details"
            },
            "confidence": 0.946053915221001,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "SEER",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "Intelligent-CAT-Lab/SEER",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/Intelligent-CAT-Lab/SEER/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/Intelligent-CAT-Lab/SEER/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 12,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "machine-learning, research, software-testing, test-automation, test-oracles",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 6,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/intelligent-cat-lab/seer/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 174674
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Java",
                "name": "Java",
                "type": "Programming_language",
                "size": 13019
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "installation": [
        {
            "result": {
                "value": "# Installation Instructions\nIn this guide, we will go through how to set up and use SEER. Please read on for step-by-step installation instructions.\n\n## 1. Clone SEER from GitHub\nIn order to download our code repository, please use git and execute the following in order to clone our repository in your local machine.\n\n`git clone https://github.com/Intelligent-CAT-Lab/SEER.git`\n\nAfter cloning has been completed, please change the directory by executing the following:\n\n`cd SEER`\n\n## 2. Install Dependencies\nAs mentioned in [REQUIREMENTS.md](REQUIREMENTS.md), SEER has some software dependencies. Please execute the following in order to install all dependencies. It is important to note that we have developed SEER on Ubuntu 18.04 LTS and Python 3.6.9.\n\n`pip3 install -r requirements.txt`\n\n## 3. Taking SEER for a Ride\nWe provide a small demo from the learning module of SEER in order to make sure it has been set up properly, and all components are functional. The learning module is one of the core and most important component of SEER. In particular, we will show a sample output, or what a user expects to see when he/she wants to train phase-1 of SEER.\n\nIn order to download all necessary files from Zenodo, please execute the following in order:\n\n* `cd learning`\n* `sudo apt install curl`\n* `sudo apt install unzip`\n* `curl https://zenodo.org/record/6970062/files/phase1_dataset_final.zip?download=1 --output phase1_dataset_final.zip`\n* `unzip phase1_dataset_final.zip`\n\nAt this point, we are ready to start phase-1 of model training. To do that, please execute the following:\n\n* `python3 train_phase1.py --data_path phase1_dataset_final/ --model JointEmbedder --dataset TestOracleInferencePhase1 --fold 1 --gpu_id 0`\n\nIf everything is sound and correct, you should be able to see the following output on your console:\n\n```\nloading data...\n18736 entries\nloading data...\n986 entries\nConstructing Model ...\n```\n\nAfter seeing this, the training phase has been started and the model is consistently fetching a batch from the training dataset, and use it for learning purposes. It could take some time until you see the evaluation results after the first epoch.\n\nIf you do not see the output above, it indicates that something is not right. Please get in touch with the authors in order to resolve your problem.\n",
                "type": "File_dump"
            },
            "confidence": 1,
            "technique": "file_exploration",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/INSTALL.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "[<img padding=\"10\" align=\"right\" src=\"https://www.acm.org/binaries/content/gallery/acm/publications/artifact-review-v1_1-badges/artifacts_evaluated_functional_v1_1.png\" alt=\"ACM Artifacts Evaluated - Functional v1.1\" width=\"114\" height=\"113\"/>][paper]\n[<img padding=\"10\" align=\"right\" src=\"https://www.acm.org/binaries/content/gallery/acm/publications/artifact-review-v1_1-badges/artifacts_available_v1_1.png\" alt=\"ACM Artifacts Available v1.1\" width=\"114\" height=\"113\"/>][paper] \n[ali]: https://alibrahimzada.github.io/\n[yigit]: https://github.com/yigitv4rli\n[dilara]: https://dtekinoglu.github.io/\n[reyhaneh]: https://reyhaneh.cs.illinois.edu/index.htm \n",
                "original_header": "Perfect Is the Enemy of Test Oracle"
            },
            "confidence": 0.9996769361734316,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "```\n@inproceedings{10.1145/3540250.3549086,\n    author = {Ibrahimzada, Ali Reza and Varli, Yigit and Tekinoglu, Dilara and Jabbarvand, Reyhaneh},\n    title = {Perfect is the Enemy of Test Oracle},\n    year = {2022},\n    isbn = {9781450394130},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    url = {https://doi.org/10.1145/3540250.3549086},\n    doi = {10.1145/3540250.3549086},\n    abstract = {Automation of test oracles is one of the most challenging facets of software testing, but remains comparatively less addressed compared to automated test input generation. Test oracles rely on a ground-truth that can distinguish between the correct and buggy behavior to determine whether a test fails (detects a bug) or passes. What makes the oracle problem challenging and undecidable is the assumption that the ground-truth should know the exact expected, correct, or buggy behavior. However, we argue that one can still build an accurate oracle without knowing the exact correct or buggy behavior, but how these two might differ. This paper presents , a learning-based approach that in the absence of test assertions or other types of oracle, can determine whether a unit test passes or fails on a given method under test (MUT). To build the ground-truth, jointly embeds unit tests and the implementation of MUTs into a unified vector space, in such a way that the neural representation of tests are similar to that of MUTs they pass on them, but dissimilar to MUTs they fail on them. The classifier built on top of this vector representation serves as the oracle to generate \u201cfail\u201d labels, when test inputs detect a bug in MUT or \u201cpass\u201d labels, otherwise. Our extensive experiments on applying to more than 5K unit tests from a diverse set of open-source Java projects show that the produced oracle is (1) effective in predicting the fail or pass labels, achieving an overall accuracy, precision, recall, and F1 measure of 93%, 86%, 94%, and 90%, (2) generalizable, predicting the labels for the unit test of projects that were not in training or validation set with negligible performance drop, and (3) efficient, detecting the existence of bugs in only 6.5 milliseconds on average. Moreover, by interpreting the neural model and looking at it beyond a closed-box solution, we confirm that the oracle is valid, i.e., it predicts the labels through learning relevant features.},\n    booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},\n    pages = {70\u201381},\n    numpages = {12},\n    keywords = {Test Oracle, Software Testing, Test Automation, Deep Learning},\n    location = {Singapore, Singapore},\n    series = {ESEC/FSE 2022}\n}\n```",
                "type": "Text_excerpt",
                "original_header": "Please Cite as",
                "parent_header": [
                    "Perfect Is the Enemy of Test Oracle"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        },
        {
            "result": {
                "value": "@inproceedings{10.1145/3540250.3549086,\n    series = {ESEC/FSE 2022},\n    location = {Singapore, Singapore},\n    keywords = {Test Oracle, Software Testing, Test Automation, Deep Learning},\n    numpages = {12},\n    pages = {70\u201381},\n    booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},\n    abstract = {Automation of test oracles is one of the most challenging facets of software testing, but remains comparatively less addressed compared to automated test input generation. Test oracles rely on a ground-truth that can distinguish between the correct and buggy behavior to determine whether a test fails (detects a bug) or passes. What makes the oracle problem challenging and undecidable is the assumption that the ground-truth should know the exact expected, correct, or buggy behavior. However, we argue that one can still build an accurate oracle without knowing the exact correct or buggy behavior, but how these two might differ. This paper presents , a learning-based approach that in the absence of test assertions or other types of oracle, can determine whether a unit test passes or fails on a given method under test (MUT). To build the ground-truth, jointly embeds unit tests and the implementation of MUTs into a unified vector space, in such a way that the neural representation of tests are similar to that of MUTs they pass on them, but dissimilar to MUTs they fail on them. The classifier built on top of this vector representation serves as the oracle to generate \u201cfail\u201d labels, when test inputs detect a bug in MUT or \u201cpass\u201d labels, otherwise. Our extensive experiments on applying to more than 5K unit tests from a diverse set of open-source Java projects show that the produced oracle is (1) effective in predicting the fail or pass labels, achieving an overall accuracy, precision, recall, and F1 measure of 93%, 86%, 94%, and 90%, (2) generalizable, predicting the labels for the unit test of projects that were not in training or validation set with negligible performance drop, and (3) efficient, detecting the existence of bugs in only 6.5 milliseconds on average. Moreover, by interpreting the neural model and looking at it beyond a closed-box solution, we confirm that the oracle is valid, i.e., it predicts the labels through learning relevant features.},\n    doi = {10.1145/3540250.3549086},\n    url = {https://doi.org/10.1145/3540250.3549086},\n    address = {New York, NY, USA},\n    publisher = {Association for Computing Machinery},\n    isbn = {9781450394130},\n    year = {2022},\n    title = {Perfect is the Enemy of Test Oracle},\n    author = {Ibrahimzada, Ali Reza and Varli, Yigit and Tekinoglu, Dilara and Jabbarvand, Reyhaneh},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "doi": "10.1145/3540250.3549086",
                "title": "Perfect is the Enemy of Test Oracle",
                "author": "Ibrahimzada, Ali Reza and Varli, Yigit and Tekinoglu, Dilara and Jabbarvand, Reyhaneh",
                "url": "https://doi.org/10.1145/3540250.3549086"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        }
    ],
    "contact": [
        {
            "result": {
                "value": "Please don't hesitate to open issues or pull-requests, or to contact us directly (alirezai@illinois.edu). We are thankful for any questions, constructive criticism, or interest. :blush:\n",
                "type": "Text_excerpt",
                "original_header": "Contact",
                "parent_header": [
                    "Perfect Is the Enemy of Test Oracle"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        }
    ],
    "invocation": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Please check the following descriptions related to each .py file in this directory:\n* `configs.py`: This file is used as a configuration when training deep learning models. We control hyperparameters, dataset, etc. from this file.\n* `utils.py`: This file contains independent functions which are used throughout the project.\n  * For creating the vocabulary for both phase-1 and phase-2, please execute the following:  \n  `python3 utils.py create_vocabulary all`\n  * For creating the .h5 files from JSONs, please execute the following if JSON type is train, fold is 1, and model type is JointEmbedder:  \n  `python3 utils.py json_to_h5 train 1 JointEmbedder`\n  * For extracting the length of the longest sequence (Code, Test) in phase-1 dataset, please execute the following:  \n  `python3 utils.py get_max_len phase1_dataset_final`\n  * For splitting the raw dataset in phase-1 into train (90%), valid (5%), and test sets (5%), please execute the following:  \n  `python3 utils.py train_valid_test_split phase1_dataset_final 0.05 0.05`\n  * For filtering the assert statements in the dataset, please execute the following:  \n  `python3 utils.py filter_asserts` \n",
                "original_header": "Implementation Details"
            },
            "confidence": 0.9226734249343844,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        }
    ],
    "identifier": [
        {
            "result": {
                "type": "Url",
                "value": "https://doi.org/10.5281/zenodo.6970062"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Perfect Is the Enemy of Test Oracle"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        }
    ],
    "images": [
        {
            "result": {
                "type": "Url",
                "value": "https://www.acm.org/binaries/content/gallery/acm/publications/artifact-review-v1_1-badges/artifacts_evaluated_functional_v1_1.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        },
        {
            "result": {
                "type": "Url",
                "value": "https://www.acm.org/binaries/content/gallery/acm/publications/artifact-review-v1_1-badges/artifacts_available_v1_1.png"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/intelligent-cat-lab/seer/main/README.md"
        }
    ]
}
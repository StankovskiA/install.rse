{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-04 19:40:21"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/kiv-air/StackOverflowDataset",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "kiv-air",
                "type": "Organization"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2022-03-21T09:37:36Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2022-10-29T11:28:50Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "name": [
        {
            "result": {
                "value": "StackOverflowDataset",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "kiv-air/StackOverflowDataset",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/kiv-air/StackOverflowDataset/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/kiv-air/StackOverflowDataset/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 3,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 1,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/kiv-air/stackoverflowdataset/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/kiv-air/stackoverflowdataset/master/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "type": [
        {
            "result": {
                "value": "non-software",
                "type": "String"
            },
            "confidence": 1,
            "technique": "software_type_heuristics"
        }
    ],
    "contact": [
        {
            "result": {
                "value": "\r\nIn case of any questions do not hesitate to contact us using email `pasekj{at}ntis.zcu.cz`.\r\n\r",
                "type": "Text_excerpt",
                "original_header": "Contact us",
                "parent_header": [
                    "Stack Overflow (Duplicity) Dataset"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/kiv-air/stackoverflowdataset/master/README.md"
        }
    ],
    "license": [
        {
            "result": {
                "value": "This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. http://creativecommons.org/licenses/by-nc-sa/4.0/\r\n\r",
                "type": "Text_excerpt",
                "original_header": "Licence",
                "parent_header": [
                    "Stack Overflow (Duplicity) Dataset"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/kiv-air/stackoverflowdataset/master/README.md"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "For now, please cite [the Arxiv paper](https://arxiv.org/abs/2203.14093):\r\n```\r\n@misc{https://doi.org/10.48550/arxiv.2203.14093,\r\n  doi = {10.48550/ARXIV.2203.14093},\r\n  url = {https://arxiv.org/abs/2203.14093},\r\n  author = {Pa\u0161ek, Jan and Sido, Jakub and Konop\u00edk, Miloslav and Pra\u017e\u00e1k, Ond\u0159ej},\r\n  title = {MQDD -- Pre-training of Multimodal Question Duplicity Detection for Software Engineering Domain},\r\n  publisher = {arXiv},\r\n  year = {2022},\r\n  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}\r\n}\r\n```\r\n",
                "type": "Text_excerpt",
                "original_header": "How should I cite the MQDD?",
                "parent_header": [
                    "Stack Overflow (Duplicity) Dataset"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/kiv-air/stackoverflowdataset/master/README.md"
        },
        {
            "result": {
                "value": "@misc{https://doi.org/10.48550/arxiv.2203.14093,\n    copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},\n    year = {2022},\n    publisher = {arXiv},\n    title = {MQDD -- Pre-training of Multimodal Question Duplicity Detection for Software Engineering Domain},\n    author = {Pa\u0161ek, Jan and Sido, Jakub and Konop\u00edk, Miloslav and Pra\u017e\u00e1k, Ond\u0159ej},\n    url = {https://arxiv.org/abs/2203.14093},\n    doi = {10.48550/ARXIV.2203.14093},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "doi": "10.48550/ARXIV.2203.14093",
                "title": "MQDD -- Pre-training of Multimodal Question Duplicity Detection for Software Engineering Domain",
                "author": "Pa\u0161ek, Jan and Sido, Jakub and Konop\u00edk, Miloslav and Pra\u017e\u00e1k, Ond\u0159ej",
                "url": "https://arxiv.org/abs/2203.14093"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/kiv-air/stackoverflowdataset/master/README.md"
        }
    ],
    "application_domain": [
        {
            "result": {
                "type": "String",
                "value": "Natural Language Processing"
            },
            "confidence": 0.9013333333333332,
            "technique": "supervised_classification"
        }
    ],
    "description": [
        {
            "result": {
                "type": "Text_excerpt",
                "value": "\r\nThis repository publishes two novel datasets for (pre-)training NLP models applicable for software engineering domain.\r\nThe datasets were presented in the paper [MQDD \u2013 Pre-training of Multimodal Question Duplicity Detection for Software Engineering Domain](https://arxiv.org/abs/2203.14093),\r\nwhich contains detailed information about the datasets.\r\n\r\n\r \n",
                "original_header": "Stack Overflow (Duplicity) Dataset"
            },
            "confidence": 0.9207389059356782,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/kiv-air/stackoverflowdataset/master/README.md"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "\r\nThe Stack Overflow Dataset (SOD) represents a large corpus of natural language-programming language (NL-PR) pairs. The dataset can be leveraged to pre-train multimodal encoders targetting software engineering domain. The dataset's structure (described below) is specifically tailor for our novel pre-training objectives (see our paper) designed for improving duplicate question detection. However, the dataset can be simply transformed into a general parallel corpus can be used in many different ways. The resulting dataset is based on a StackOverflow data dump acquired from [archive.org](https://archive.org/download/stackexchange) in June 2020. For more information see our [paper](https://arxiv.org/abs/2203.14093)\r\n\r\n**Download the dataset:**\r\n\r\nThe SOD dataset can be obtained from our GoogleDrive via the following [link](https://drive.google.com/drive/folders/16dyzRNrJLe9g0KVpsoaIJhW7-nmf6j1V?usp=sharing).\r\n\r\n**Data Structure**\r\n\r\nThe Stack Overflow Dataset (SOD) consists of a metadata file and several data files. Each line of the metadata file (`dataset_meta.csv`) contains a JSON array with the following information:\r\n\r\n- `question_id` - identifier of the question in format `<id>-<page>` (in our case the `page` = `stackoverflow`)\r\n- `answer_id` - identifier of the answer in format `<id>-<page>` (in our case the `page` = `stackoverflow`)\r\n- `title` - title of the question\r\n- `tags` - tags associated with the question\r\n- `is_answered` - boolean flag indicating whether the answer represents an accepted answer for the question\r\n\r\nThe dataset export is organized in such a way that `i`-th row in the metadata file corresponds to training examples located on the `i`-th row in the data files. There are six different data file types, each comprising training examples of different _input pair types_. A complete list of the data file types follows:\r\n\r\n- `dataset_AC_AT.csv` - code from an answer with text from the same answer\r\n- `dataset_QC_AC.csv` - code from a question with code from a related answer \r\n- `dataset_QC_AT.csv` - code from a question with text from a related answer\r\n- `dataset_QC_QT.csv` - code from a question with text from the same question\r\n- `dataset_QT_AC.csv` - text from a question with code from a related answer\r\n- `dataset_QT_AT.csv` - text from a question with text from a related answer\r\n\r\nEach row in the data file then represents a single example whose metadata can be obtained from a corresponding row in the metadata file. A training example is represented by a JSON array containing two strings. For example, in the `dataset_QC_AC.csv`, the first element in the array contains code from a question, whereas the second element contains code from the related answer. It shall be noted that the dataset export does not contain negative examples since they would significantly increase the disk space required for storing the dataset. The negative examples must be randomly sampled during pre-processing (Section 3.1 in our paper).\r\n\r\nSince the resulting dataset takes up a lot of disk space, we split the individual data files and the metadata file into nine smaller ones. Therefore, files such as, for example, `dataset_meta_1.csv` and corresponding `dataset_QC_AT_1.csv` can then be found in the repository.\r\n\r\n**Dataset Statistics:**\r\n\r\nThe following table provides a detailed statistics of the released Stack Overflow Dataset (SOD). The table shows the average number of characters, tokens, and words in different source codes present in questions (QC) or answers (AC) and texts present in questions (QT) or answers (AT). Besides the average statistics, the table provides a total count of tokens, words, or characters. To calculate the statistics related to token counts, we utilized our wordpiece tokenizer, whereas we employed a simple space tokenization for the word statistics. \r\n\r\nThe resulting number of training examples highle depends on how are the data utilize. In our work, we have extracted `218.5M` NL-PL pairs that we used for the pre-training.\r\n\r\n| **Statistic**                             | **QC**    | **QT**    | **AC**   | **AT**   | **Total**         |\r\n|---------------------------------------|-------|-------|------|------|---------------------------|\r\n| average \\# of characters              | 846   | 519   | 396  | 369  | -                         |\r\n| average \\# of tokens                  | 298   | 130   | 140  | 92   | -                         |\r\n| average \\# of words                   | 83    | 89    | 44   | 60   | -                         |\r\n| \\# of characters                      | 16.1B | 13.5B | 6.6B | 9.6B | 45.8B                     |\r\n| \\# of tokens                          | 5.7B  | 3.4B  | 2.3B | 2.4B | 13.8B                     |\r\n| \\# of words                           | 1.6B  | 2.3B  | 0.7B | 1.6B |  6.2B                     |\r\n\r\nFurthermore, the table below presents a tag-based analysis of the percentage of individual programming languages in the SOD dataset. The table shows the 15 most frequent programming languages included in the dataset. Together they form approximately 70% of all the examples. The remaining 30% are then made up of less popular programming languages or specific technologies.\r\n\r\n| **Order** | **Tag**         | **Percentage** |\r\n|-------|-------------|------------|\r\n| 1     | javascript  | 10,95      |\r\n| 2     | java        | 9,88       |\r\n| 3     | c#          | 8,04       |\r\n| 4     | php         | 7,95       |\r\n| 5     | python      | 6,32       |\r\n| 6     | html        | 6,18       |\r\n| 7     | css         | 4,28       |\r\n| 8     | c++         | 4,15       |\r\n| 9     | sql         | 3,42       |\r\n| 10    | c           | 2,29       |\r\n| 11    | objective-c | 1,93       |\r\n| 12    | r           | 1,36       |\r\n| 13    | ruby        | 1,32       |\r\n| 14    | swift       | 1,05       |\r\n| 15    | bash        | 0,8        |\r\n| -     | total       | 69,92      |\r\n\r\n\r \n",
                "original_header": "Stack Overflow Dataset (SOD)"
            },
            "confidence": 0.9811667122268208,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/kiv-air/stackoverflowdataset/master/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Stack Overflow (Duplicity) Dataset"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/kiv-air/stackoverflowdataset/master/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2203.14093"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/kiv-air/stackoverflowdataset/master/README.md"
        }
    ]
}
{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-04 19:23:26"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/yangyixiaof/CodeCompletionModels",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "yangyixiaof",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2019-10-21T09:00:45Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2024-06-25T09:01:06Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "name": [
        {
            "result": {
                "value": "CodeCompletionModels",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "yangyixiaof/CodeCompletionModels",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/yangyixiaof/CodeCompletionModels/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/yangyixiaof/CodeCompletionModels/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 0,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 0,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/yangyixiaof/codecompletionmodels/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/yangyixiaof/codecompletionmodels/master/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "type": [
        {
            "result": {
                "value": "non-software",
                "type": "String"
            },
            "confidence": 1,
            "technique": "software_type_heuristics"
        }
    ],
    "download": [
        {
            "result": {
                "value": "[PCC implementation (with dataset, data preprocessing code, video and tutorial)](https://github.com/yangyixiaof/CodeCompletionPlugin)  \n",
                "type": "Text_excerpt",
                "original_header": "Chapter 2 PCC model implementation",
                "parent_header": [
                    "Download links to all models of my doctoral dissertation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/yangyixiaof/codecompletionmodels/master/README.md"
        },
        {
            "result": {
                "value": "[HLM-SLM implementation (github address, this project is mixed with REP model, containing tutorial)](https://github.com/GrowingCode/FrameTokenMemAtten)  \n",
                "type": "Text_excerpt",
                "original_header": "Chapter 3 HLM and SLM model implementation",
                "parent_header": [
                    "Download links to all models of my doctoral dissertation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/yangyixiaof/codecompletionmodels/master/README.md"
        },
        {
            "result": {
                "value": "[REP implementation (github address, this project is mixed with HLM-SLM model, containing tutorial)](https://github.com/GrowingCode/FrameTokenMemAtten)\n",
                "type": "Text_excerpt",
                "original_header": "Chapter 4 REP model implementation",
                "parent_header": [
                    "Download links to all models of my doctoral dissertation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/yangyixiaof/codecompletionmodels/master/README.md"
        },
        {
            "result": {
                "value": "\u3000\u3000In Chapter 4, REP model (proposed by me) and Pointer-Mixture (proposed by JianLi) are compared. We use the similar setting as Pointer-Mixture meaning that we ignore grammar tokens when learning token repetition. \n* only consider identifier tokens\n   * In this experiment, REP model and Pointer-Mixture only consider identifiers. REP model further splits identifier tokens into different types and use different REP models to learn the repetition of tokens of different types. The distinct tokens in the paper refer to tokens which should be specifically handled. \n* for non-identifier tokens\u3000\n   * For grammar tokens or other non-variable tokens, we use Hierarchical Language Model described in Chapter 3 to further improve the prediction accuracy. This optimization is described at length in Chapter 5 (there may be some confusion in the arrangement of paper content). The final accuracy is the weighted average of the two kinds of tokens (variable-tokens and non-variable tokens). \n* Please check [paper](https://doi.org/10.1142/S0218194019400229) and [corrigendum paper](https://arxiv.org/abs/2005.04137) for further details and [`experimental comparison results`](https://arxiv.org/abs/2005.04137). \n",
                "type": "Text_excerpt",
                "original_header": "Detailed experiments for REP and Pointer-Mixture in Chapter 4 of doctoral dissertation",
                "parent_header": [
                    "Download links to all models of my doctoral dissertation",
                    "Chapter 4 REP model implementation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/yangyixiaof/codecompletionmodels/master/README.md"
        },
        {
            "result": {
                "value": "\u3000\u3000First of all, for different kinds of tokens, we apply independent REP model to learn token repetition. For example, for grammar tokens, we use one REP model to learn token repetition, for variables, we use another isolated REP model to learn token repetition. \n<br>\n* grammar tokens\n    * For grammar tokens, we also try to apply REP to learn the token repetition, however, we found that grammar tokens have no regularity of token repetition. When a large number of grammar tokens are not repeated while only a small number of grammar tokens are repeated, this leads to the situation that the model will think all grammar tokens in test set are not repeated. Thus this is equivalent to directly use traditional language model to predict token. Here we use Hierarchical Language Model as traditional language model.\u3000\n* literals\n    * For string literals or char literals or number literals, in test set, most of such tokens are marked UNK. If we think predicting UNK correctly is good, then applying REP will improve the model performance. Otherwise, it will degenerate into a similar situation as grammar tokens due to the reason that few string literals or char literals or number literals are repeated in training set or test set. \n",
                "type": "Text_excerpt",
                "original_header": "Explanation for \"we learn the repetition patterns of all kinds of tokens.\" in dissertation:",
                "parent_header": [
                    "Download links to all models of my doctoral dissertation",
                    "Chapter 4 REP model implementation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/yangyixiaof/codecompletionmodels/master/README.md"
        },
        {
            "result": {
                "value": "[Data preprocessing module (aim for translating raw java files to the tensor format which REP or HLM-SLM can directly handle, github address, containing tutorial)](https://github.com/GrowingCode/JavaCodePreProcess.git)  \n[Data set (note that the separation (train, test, valid) of data set is remaked so the results may differ from the data presented in the dissertation or the already published paper, github address, containing tutorial)](https://github.com/GrowingCode/CodeCorpus.git)  \n\n\n\n",
                "type": "Text_excerpt",
                "original_header": "Data preprocessor implementation",
                "parent_header": [
                    "Download links to all models of my doctoral dissertation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/yangyixiaof/codecompletionmodels/master/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Download links to all models of my doctoral dissertation"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/yangyixiaof/codecompletionmodels/master/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2005.04137"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/yangyixiaof/codecompletionmodels/master/README.md"
        }
    ]
}
{
    "somef_provenance": {
        "somef_version": "0.9.5",
        "somef_schema_version": "1.0.0",
        "date": "2024-10-04 19:07:20"
    },
    "code_repository": [
        {
            "result": {
                "value": "https://github.com/martin-wey/metamodel-concepts-bert",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "owner": [
        {
            "result": {
                "value": "martin-wey",
                "type": "User"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_created": [
        {
            "result": {
                "value": "2021-04-02T10:56:43Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "date_updated": [
        {
            "result": {
                "value": "2023-12-02T14:57:04Z",
                "type": "Date"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "description": [
        {
            "result": {
                "value": "Replication package for the paper \"Recommending Metamodel Concepts during Modeling Activities with Pre-Trained Language Models\" (SoSym - MODELS 2022)",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "type": "Text_excerpt",
                "value": "Our dataset is based on [MAR dataset]([http://mar-search.org/experiments/models20/](http://mar-search.org/experiments/models20/)) from which we extracted tree-representations of Ecore metamodels. \nWe also make our data extraction tool available in the folder ```./ecore-to-tree```.\n \n",
                "original_header": "Data acquisition"
            },
            "confidence": 0.9120594441566533,
            "technique": "supervised_classification",
            "source": "https://raw.githubusercontent.com/martin-wey/metamodel-concepts-bert/main/README.md"
        }
    ],
    "name": [
        {
            "result": {
                "value": "metamodel-concepts-bert",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "full_name": [
        {
            "result": {
                "value": "martin-wey/metamodel-concepts-bert",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "issue_tracker": [
        {
            "result": {
                "value": "https://api.github.com/repos/martin-wey/metamodel-concepts-bert/issues",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_url": [
        {
            "result": {
                "value": "https://api.github.com/repos/martin-wey/metamodel-concepts-bert/forks",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "stargazers_count": [
        {
            "result": {
                "value": 3,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "keywords": [
        {
            "result": {
                "value": "bert, mde, metamodel, pretrained-language-model",
                "type": "String"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "forks_count": [
        {
            "result": {
                "value": 1,
                "type": "Number"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "download_url": [
        {
            "result": {
                "value": "https://github.com/martin-wey/metamodel-concepts-bert/releases",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "programming_languages": [
        {
            "result": {
                "value": "Python",
                "name": "Python",
                "type": "Programming_language",
                "size": 61621
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Java",
                "name": "Java",
                "type": "Programming_language",
                "size": 10931
            },
            "confidence": 1,
            "technique": "GitHub_API"
        },
        {
            "result": {
                "value": "Xtend",
                "name": "Xtend",
                "type": "Programming_language",
                "size": 2492
            },
            "confidence": 1,
            "technique": "GitHub_API"
        }
    ],
    "readme_url": [
        {
            "result": {
                "value": "https://raw.githubusercontent.com/martin-wey/metamodel-concepts-bert/main/README.md",
                "type": "Url"
            },
            "confidence": 1,
            "technique": "file_exploration"
        }
    ],
    "requirements": [
        {
            "result": {
                "value": "To run the training and evaluation scripts, you need Python>=3.7. \nWe use [HuggingFace](https://huggingface.co/) transformer library to train and evaluate our RoBERTa language model. You can find installation instructions here: https://huggingface.co/transformers/installation.html. \nAdditionally, we use both [Datasets](https://huggingface.co/docs/datasets/) and [Tokenizers](https://huggingface.co/docs/tokenizers/python/latest/) libraries to load and manipulate our datasets.\n",
                "type": "Text_excerpt",
                "original_header": "Dependencies",
                "parent_header": [
                    "Learning metamodel concepts with BERT-like language models"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/martin-wey/metamodel-concepts-bert/main/README.md"
        }
    ],
    "usage": [
        {
            "result": {
                "value": "To run the evaluation for a specific use case, you can use each script associated to RQ1, RQ2 and RQ3 by specifying its corresponding ```--test_file```. \nFor instance, to evaluate the local context sampling strategy with the Java use case:\n```\npython evaluate_probing_local.py\n    --model_path ./models/ecorebert-large \\\n    --tokenizer_path ./tokenizers/ecorebert-bpe-30k \\\n    --test_file ./data/test/use_case2/test_probing_local_context.txt\n```\n",
                "type": "Text_excerpt",
                "original_header": "RQ4 -- Use cases",
                "parent_header": [
                    "Learning metamodel concepts with BERT-like language models",
                    "Evaluation"
                ]
            },
            "confidence": 1,
            "technique": "header_analysis",
            "source": "https://raw.githubusercontent.com/martin-wey/metamodel-concepts-bert/main/README.md"
        }
    ],
    "application_domain": [
        {
            "result": {
                "type": "String",
                "value": "Natural Language Processing"
            },
            "confidence": 0.9108333333333334,
            "technique": "supervised_classification"
        }
    ],
    "citation": [
        {
            "result": {
                "value": "@article{weyssow2021recommending,\n    year = {2021},\n    journal = {arXiv preprint arXiv:2104.01642},\n    author = {Weyssow, Martin and Sahraoui, Houari and Syriani, Eugene},\n    title = {Recommending Metamodel Concepts during Modeling Activities with Pre-Trained Language Models},\n}",
                "type": "Text_excerpt",
                "format": "bibtex",
                "title": "Recommending Metamodel Concepts during Modeling Activities with Pre-Trained Language Models",
                "author": "Weyssow, Martin and Sahraoui, Houari and Syriani, Eugene"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/martin-wey/metamodel-concepts-bert/main/README.md"
        }
    ],
    "full_title": [
        {
            "result": {
                "type": "String",
                "value": "Learning metamodel concepts with BERT-like language models"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/martin-wey/metamodel-concepts-bert/main/README.md"
        }
    ],
    "related_papers": [
        {
            "result": {
                "type": "Url",
                "value": "https://arxiv.org/abs/2104.01642"
            },
            "confidence": 1,
            "technique": "regular_expression",
            "source": "https://raw.githubusercontent.com/martin-wey/metamodel-concepts-bert/main/README.md"
        }
    ]
}
search,id,arxiv_url,topic,arxiv_title,github_URL,Star,has_installation,h1,h2,h3,h4,h5,h6,steps,method_type,time_accessed,notes
arxiv.API,arXiv:2409.00613,arXiv:2409.00613,q-bio.GN,BWT construction and search at the terabase scale,https://github.com/lh3/ropebwt3,75,FALSE,,,,,,,,,,
arxiv.API,https://arxiv.org/abs/2409.02143,https://arxiv.org/abs/2409.02143,"q-bio.GN, cs.LG","CMOB: Large-Scale Cancer Multi-Omics Benchmark with Open Datasets, Tasks, and Baselines",https://github.com/chenzRG/Cancer-Multi-Omics-Benchmark,1,TRUE,Installations,,,,,,"Here, we provide guidelines for setting up the library. 
```bash
# Set up the environment
conda create -n cmob python=3.9
conda activate 

# Installation
pip install -r requirements.txt
```",source,,
arxiv.API,arXiv:2409.05484 ,https://arxiv.org/abs/2409.05484,"cs.LG, cs.AI, q-bio.GN, q-bio.QM",CRADLE-VAE: Enhancing Single-Cell Gene Perturbation Modeling with Counterfactual Reasoning-based Artifact Disentanglemen,CRADLE-VAE: Enhancing Single-Cell Gene Perturbation Modeling with Counterfactual Reasoning-based Artifact Disentanglement,5,TRUE,,,Install environment (Linux),,,,"```
conda env create --file environment.yml
conda activate cradle_vae_env
```
- If you encounter a conflict, run this command: `conda config --set channel_priority disabled`

```
pip install 'rapids-singlecell[rapids11]' --extra-index-url=https://pypi.nvidia.com #CUDA11.X
pip install 'rapids-singlecell[rapids12]' --extra-index-url=https://pypi.nvidia.com #CUDA12
```
- Install `rapids-singlecell` according to your CUDA version",source,,
arxiv.API,https://arxiv.org/abs/2408.09896,https://arxiv.org/abs/2408.09896, cs.LG physics.chem-ph q-bio.BM , Instruction-Based Molecular Graph Generation with Unified Text-Graph Diffusion Model ,https://github.com/ran1812/utgdiff,5,TRUE,,Environment setup,,,,,"
The basic environment requirement is pytorch, here's an example for environment setup:

```
cd ./text-graph-diffusion/
conda create -n UTGDiff python=3.10
conda activate UTGDiff
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
pip install -r requirements.txt 
```

All the model checkpoint is saved at https://drive.google.com/drive/folders/18EqQ7MDHesmtiMiZz2o09PyeSwyf0hXb?usp=drive_link",source,,
arxiv.API,https://arxiv.org/abs/2408.11884,https://arxiv.org/abs/2408.11884,q-bio.NC cs.LG,ST-USleepNet: A Spatial-Temporal Coupling Prominence Network for Multi-Channel Sleep Staging,https://github.com/Majy-Yuji/ST-USleepNet.git,0,FALSE,README,,,,,,"This README provides a step-by-step guide on how to run the model using the `ISRUC-S3` dataset.

1. Run `sh get_ISRUC_S3.sh` to download the data.
2. run `python process_slice.py` to preprocess the data.
3. Run `python src/main.py` to execute the model.",source,,"how to run, instead of how to install"
arxiv.API,https://arxiv.org/abs/2408.05420,https://arxiv.org/abs/2408.05420,q-bio.QM,Facilitating bootstrapped and rarefaction-based microbiome diversity analysis with q2-boots,https://github.com/caporaso-lab/q2-boots,3,FALSE,,,,,,,,,,External doc URL: https://q2-boots.readthedocs.io/en/latest/
arxiv.API,https://arxiv.org/abs/2408.06377,https://arxiv.org/abs/2408.06377,q-bio.GN cs.AI cs.LG,Masked Graph Autoencoders with Contrastive Augmentation for Spatially Resolved Transcriptomics Data,https://github.com/wenwenmin/STMGAC,13,TRUE,Setup,,,,,,-   `pip install -r requirement.txt`,source,,
arxiv.API,https://arxiv.org/abs/2408.01869,https://arxiv.org/abs/2408.01869, cs.CL cs.AI cs.IR cs.LG cs.MA q-bio.QM ,MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance,https://github.com/jihyechoi77/malade,8,TRUE,,**__ Set up environment and install dependencies**,,,,,"We leverage the awesome [Langroid](https://github.com/langroid/langroid) 
open-source Python library for multi-agent LLM applications.

IMPORTANT: Please ensure you are using Python 3.11+. If you are using poetry,
you may be able to just run `poetry env use 3.11` if you have Python 3.11 available in your system.

```bash
# clone this repository 
git clone [this-repository]
cd malade
```

Environment setup with conda:
```bash
# create empty environment:
conda env create -n malade python=3.11 -c conda-forge
conda activate malade
```

Setup with venv:
```bash
# create a virtual env under project root, .venv directory
python3 -m venv .venv

# activate the virtual env
. .venv/bin/activate
```

Install dependencies with Poetry:
```bash
# Optionally: poetry lock
poetry install
```",,,to discuss: setup versus steps on setup environment variables
arxiv.API,https://arxiv.org/abs/2408.09344,https://arxiv.org/abs/2408.09344,q-bio.OT,GitHub is an effective platform for collaborative and reproducible laboratory research,https://github.com/rasilab/github_demo,5,FALSE,,,,,,,,,,its not a RS perse
arxiv.API,https://arxiv.org/abs/2408.14343,https://arxiv.org/abs/2408.14343,cs.CV q-bio.QM,A Brief Analysis of the Iterative Next Boundary Detection Network for Tree Rings Delineation in Images of Pinus taeda,https://github.com/hmarichal93/mlbrief_inbd,1,TRUE,,Installation,,,,,"### INBD
Go to ./INBD

### UruDendro
Go to ./urudendro

## Procedure
1. Download the dataset from the following link:
```bash
python uruDendro/dataset.py --download --dataset_path DATASET_DIR
```

Where: 
- `DATASET_DIR` is the path where the dataset will be downloaded. `DATASET_DIR` must be an absolute path.


2. Transform the UruDendro annotations to the INBD format:
```bash
python uruDendro/src/dataset_urudendro.py --dataset_dir DATASET_DIR --output_folder DATASET_SIZE_DIR --size SIZE
```

Where:
- `DATASET_DIR` is the path to the dataset folder.
- `DATASET_SIZE_DIR` is the path to the output folder.
- `SIZE` is the size of the images in pixels

It is possible to resize the INBD dataset using the following command:
```bash
python uruDendro/src/dataset_inbd.py --resize --dataset_dir DATASET_DIR --output_folder DATASET_SIZE_DIR --size SIZE
```

Where:
- `DATASET_DIR` is the path to the dataset folder.
- `DATASET_SIZE_DIR` is the path to the output folder.
- `SIZE` is the size of the images in pixels

3. Train the model using the following command (INBD Readme):
```bash
python INBD/main.py train segmentation DATASET_SIZE_DIR/train_inputimages.txt DATASET_SIZE_DIR/train_annotations.txt
```
```bash
python INBD/main.py train INBD DATASET_SIZE_DIR/train_inputimages.txt DATASET_SIZE_DIR/train_annotations.txt --segmentationmodel=checkpoints/segmentationmodel/model.pt.zip
```

4. Inference using the following command (test annotations are used to get the pith center boundary):
```bash
python src/inbd_inference_with_center_boundary.py --input_images_path
DATASET_SIZE_DIR/test_images.txt
--input_annotations_path
DATASET_SIZE_DIR/test_annotations.txt
--root_dataset
DATASET_SIZE_DIR
--output_dir
INBD_RESULTS
--inbd_model_path
INBD_MODEL_PATH
```
    
Where:
    - `DATASET_SIZE_DIR` is the path to the dataset folder.
    - `INBD_RESULTS` is the path to the output folder.
    - `INBD_MODEL_PATH` is the path to the INBD model.

5. Evaluate the model using the following command (INBD metric):
```bash
python INBD/main.py evaluate INBD_RESULTS DATASET_SIZE_DIR/test_annotations.txt
```

Where:
- `INBD_RESULTS` is the path to the INBD results folder.
- `DATASET_SIZE_DIR` is the path to the dataset folder.

6. Evaluate the model using the following command (UruDendro metric). First INBD results are transformed to UruDendro format:
```bash
python src/from_inbd_to_urudendro.py --root_dataset DATASET_SIZE_DIR 
--root_inbd_results
/data/maestria/resultados/mlbrief_PinusTaedaV1_1500/inference/inbd_results/inbd_
--output_dir
/data/maestria/resultados/mlbrief_PinusTaedaV1_1500/inference/inbd_results/inbd_
```
Then, the UruDendro metric is computed:
```bash
python src/compute_urudendro_metric.py ----annotations_file_path ANNOTATIONS_FILE_PATH  --root_original_dataset DATASET_DIR
--output_dir OUTPUT_DIR --inbd_inference_results_dir INBD_RESULTS --inbd_center_mask_dir INBD_RESULTS/center
```

Where:
- `ANNOTATIONS_FILE_PATH` is the path to the UruDendro annotations file.
- `DATASET_DIR` is the path to the original dataset folder.
- `INBD_RESULTS` is the path to the INBD results folder. INBD_RESULTS/center is where the center mask images are located using during the inference.",source,,
arxiv.API,https://arxiv.org/abs/2408.11707,https://arxiv.org/abs/2408.11707,q-bio.OT,biorecap: an R package for summarizing bioRxiv preprints with a local LLM,https://github.com/stephenturner/biorecap,47,TRUE,,Installation,,,,,"install biorecap from GitHub (keep `dependencies=TRUE` to get Suggests
packages needed to create the HTML report):

``` r
# install.packages(""remotes"")
remotes::install_github(""stephenturner/biorecap"", dependencies=TRUE)",package,,
arxiv.API,https://arxiv.org/abs/2408.05258,https://arxiv.org/abs/2408.05258,q-bio.GN cs.AI cs.LG,scASDC: Attention Enhanced Structural Deep Clustering for Single-cell RNA-seq Data,https://github.com/wenwenmin/scASDC,13,FALSE,,,,,,,,source,,it provides only requirement.txt
arxiv.API,https://arxiv.org/abs/2408.08316,https://arxiv.org/abs/2408.08316,q-bio.TO cs.LG,SepAl: Sepsis Alerts On Low Power Wearables With Digital Biomarkers and On-Device Tiny Machine Learning,https://github.com/mgiordy/sepsis-prediction,0,TRUE,,,Installation,,,,"###  Installation

<h4>From <code>source</code></h4>

> 1. Clone the  repository:
>
> ```console
> $ git clone https://git.ee.ethz.ch/pbl/research/sepsis_prediction
> ```
>
> 2. Change to the project directory:
> ```console
> $ cd sepsis_prediction
> ```
>
> 3. Install the dependencies:
> ```console
> $ pip install -r requirements.txt
> ```",source,,
awesome-ai-devtools,,,,,,,,,,,,,,,,,
awesome-healthcare,,,,,,,,,,,,,,,,,
awesome-genome-visualization,,,,,,,,,,,,,,,,,
https://github.com/codefuse-ai/Awesome-Code-LLM,,,,,,,,,,,,,,,,,
https://github.com/burglarhobbit/Awesome-Medical-Large-Language-Models,,,,,,,,,,,,,,,,,
pwc.greatest,,,,,https://github.com/tensorflow/tensorflow,"185,472",,,,,,,,,,,
pwc.greatest,,,,,https://github.com/huggingface/transformers,"132,008",,,,,,,,,,,
pwc.greatest,,,,,https://github.com/huggingface/pytorch-transformers,"132,009",,,,,,,,,,,
pwc.greatest,,,,,https://github.com/hwchase17/langchain,"92,298",,,,,,,,,,,
pwc.greatest,,,,,https://github.com/pytorch/pytorch,"82,127",,,,,,,,,,,
pwc.greatest,,,,,https://github.com/tensorflow/models,"76,950",,,,,,,,,,,
pwc.greatest,,,,,https://github.com/compvis/stable-diffusion,"69,141",,,,,,,,,,,
pwc.greatest,,,,,https://github.com/openai/whisper,"67,527",,,,,,,,,,,
pwc.greatest,,,,,https://github.com/Developer-Y/cs-video-courses,"66,450",,,,,,,,,,,
pwc.greatest,,,,,https://github.com/ggerganov/llama.cpp,"64,931",,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/crocodeel,,,,https://github.com/metagenopolis/CroCoDeEL,5,TRUE,,Installations,,,,,"## Installation

CroCoDeEL is available on bioconda:
```
conda create --name crocodeel_env -c conda-forge -c bioconda crocodeel
conda activate crocodeel_env
```

Alternatively, you can use pip:
```
pip install crocodeel
```

Finally, you can test that CroCoDeEL is correctly installed with the following command:
```
crocodeel test_install
```","source,pacakge",,
bio.tools.updated.latest,https://bio.tools/bcftools,,,,,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/samtools,,,,,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/htslib,,,,,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/sirius,,,,,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/qcxms,,,,https://github.com/qcxms/QCxMS,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/xtb_molecular_optimization,,,,https://github.com/grimme-lab/xtb,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/MSIdV,,,,,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/msigen,,,,https://github.com/LabLaskin/MSIGen,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/alphaesm_hfolds,,,,,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/scGraph2Vec,,,,https://github.com/LPH-BIG/scGraph2Vec,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/imzmlconverter,,,,,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/AluMine,,,,https://github.com/bioinfo-ut/AluMine,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/cytoviewer,,,,,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/ecti_atopic_dermatitis,,,,https://github.com/JenHungWang/ECTI_Atopic_Dermatitis,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/Fiji,,,,,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/demuxSNP,,,,,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/artem,,,,https://github.com/david-bogdan-r/ARTEM,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/squarna,,,,https://github.com/febos/SQUARNA,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/artemis3D,,,,https://github.com/david-bogdan-r/ARTEMIS,,,,,,,,,,,,
bio.tools.updated.latest,https://bio.tools/bdpn,,,,https://github.com/evolbioinfo/bdpn,,,,,,,,,,,,
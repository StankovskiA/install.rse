{
    "0": {
        "filename": "EduardoGarrido90_iit_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "1": {
        "filename": "ViscousLemming_Technical-Appendices_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-08-22T00:40:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-02-14T04:23:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 24749
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "2": {
        "filename": "sienna-wxy_KDGene_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-01-17T02:39:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-06-12T09:39:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 22388
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "3": {
        "filename": "JoD_exact_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The easiest way is to use Exact's Python interfaces is on an **x86_64** machine with **Windows** or **Linux**. In that case, install this precompiled [PyPi package](https://pypi.org/project/exact), e.g., by running `pip install exact`.\n \n",
                    "original_header": "PyPI package"
                },
                "confidence": 0.9999998779324318,
                "technique": "supervised_classification",
                "source": "https://gitlab.com/nonfiction-software/exact/-/blob/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To use the Exact Python interface with optimal binaries for your machine (and the option to include SoPlex in the binary), compile as a shared library and install it with your package manager.\nE.g., on Linux systems, running `pip install .` in Exact's root directory should do the trick. On Windows, uncomment the build options below `# FOR WINDOWS` and comment out those for `# FOR LINUX`.\nMake sure to have the Boost libraries installed (see dependencies).\n \n",
                    "original_header": "Compile your own Python package"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://gitlab.com/nonfiction-software/exact/-/blob/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "    cd build\n    cmake .. -DCMAKE_BUILD_TYPE=Release\n    make\n\t\nReplace `make` by `cmake --build .` on Windows. For more builds, similar build directories can be created. \nFor installing system-wide or to the `CMAKE_INSTALL_PREFIX` root, use `make install` (on Linux).\n \n",
                    "original_header": "Compilation from source"
                },
                "confidence": 0.9999951642247593,
                "technique": "supervised_classification",
                "source": "https://gitlab.com/nonfiction-software/exact/-/blob/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Exact supports an integration with the LP solver [SoPlex](https://soplex.zib.de) to improve its search routine.\nFor this, checkout SoPlex from its [git repository](https://github.com/scipopt/soplex) as a submodule, compile it in some separate directory, and configure the right CMake options when compiling Exact. \nBy default, the following commands in Exact's root directory should work with a freshly checked out repository:\n```\n    git submodule init\n    git submodule update\n\n    mkdir soplex_build\n    cd soplex_build\n    cmake ../soplex -DBUILD_TESTING=\"0\" -DSANITIZE_UNDEFINED=\"0\" -DCMAKE_BUILD_TYPE=\"Release\" -DBOOST=\"0\" -DGMP=\"0\" -DCMAKE_WINDOWS_EXPORT_ALL_SYMBOLS=\"0\" -DZLIB=\"0\"\n    make -j 8\n\n    cd ../build_debug\n    cmake .. -DCMAKE_BUILD_TYPE=\"Release\" -Dsoplex=\"ON\"\n    make -j 8\n```\nThe CMake options `soplex_src` and `soplex_build` allow to look for SoPlex in a different location. \n",
                    "original_header": "SoPlex (on Linux)"
                },
                "confidence": 0.9969072018864628,
                "technique": "supervised_classification",
                "source": "https://gitlab.com/nonfiction-software/exact/-/blob/main/README.md"
            }
        ],
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "4": {
        "filename": "Sergey-Zeltyn_MIP-dataset_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-05-08T11:36:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-05-08T11:36:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "5": {
        "filename": "rte-france_grid2viz_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```commandline\npip3 install -U virtualenv\npython3 -m virtualenv venv_grid2viz\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "(Optional, recommended) Step 1: Create a virtual environment",
                    "parent_header": [
                        "Grid2Viz: The Grid2Op Visualization companion app",
                        "Installation",
                        "Requirements:"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/rte-france/grid2viz/master/README.md"
            },
            {
                "result": {
                    "value": "```commandline\nsource venv_grid2viz/bin/activate\npip install -U grid2viz\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Step 2: Install from pypi",
                    "parent_header": [
                        "Grid2Viz: The Grid2Op Visualization companion app",
                        "Installation",
                        "Requirements:"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/rte-france/grid2viz/master/README.md"
            },
            {
                "result": {
                    "value": "```commandline\nsource venv_grid2viz/bin/activate\ngit clone https://github.com/rte-france/grid2viz.git\ncd grid2Viz/\npip install -U\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Step 2 (bis): Install from sources",
                    "parent_header": [
                        "Grid2Viz: The Grid2Op Visualization companion app",
                        "Installation",
                        "Requirements:"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/rte-france/grid2viz/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The cache system allows you to only compute long calculations of the app once per agent/scenario.\nThe app will create a folder `_cache` in the `base_dir` of the config.ini which will contain these long calculations serialized. \nIf you add a new folder in your `base_dir` (either an agent, or a scenario) you will have to restart the server so the app\nreads the folder tree again. \n",
                    "original_header": "Caching"
                },
                "confidence": 0.9617428336356582,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/rte-france/grid2viz/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Some mac users have been experimenting issues when lauching the app, raising the following message: \nThe following steps might help you to overcome the issue: \n1. Open your terminal\n2. Type `echo $HOST` and copy the results\n3. Open the file `/etc/hosts` and make sure you include: <br>\n `127.0.0.1 PASTE RESULTS FROM echo $HOST`\n4. Save it and close it\n5. Launch grid2viz \n",
                    "original_header": "MacOS"
                },
                "confidence": 0.9987775576031214,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/rte-france/grid2viz/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-11-18T12:58:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-03T02:59:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 438052
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 7470
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 6095
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Procfile",
                    "name": "Procfile",
                    "type": "Programming_language",
                    "size": 41
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "6": {
        "filename": "cmungall_owlstar_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": " * [owlstar.ttl](owlstar.ttl) - raw turtle files\n * https://cmungall.github.io/owlstar/ - owldoc rendition\n * TODO: online browser \n",
                    "original_header": "Browse Ontology Online"
                },
                "confidence": 0.9979395711646085,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmungall/owlstar/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For cases where the PG is encoded in RDFStar or RDF (the former being\nsyntactic sugar for the latter), it should be straightforward to\nimplement owlMapping using SPARQLStar or SPARQL constructs (the latter\nusing the reification vocabulary). \n",
                    "original_header": "OWLStar as a proposed standard"
                },
                "confidence": 0.9794529511354,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmungall/owlstar/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-03-10T06:52:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-07-15T20:30:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 640
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "7": {
        "filename": "HaitaoMao_baidu_ultr_page_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-08-09T01:18:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-11-18T08:24:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 1271489
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 186824
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "8": {
        "filename": "BerenMillidge_Active_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "9": {
        "filename": "tengz-sudo_BEDS_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "10": {
        "filename": "lilv98_LogicRec_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Download and unzip the preprocessed [amazon-book](https://drive.google.com/file/d/10sLVpfbBEBLp-MFc7_Bfz75puYEIaMSM/view?usp=share_link) and [yelp2018](https://drive.google.com/file/d/1NYYzSOmuLZ37PIYc5OIoLAcVDqrZ0rd5/view?usp=share_link) datasets to **./data/**. If you wanna run query generation, please run the following commands after you have downloaded the datasets:\n```powershell\npython ppc_amazon_book.py \n```\n \n",
                    "original_header": "Datasets"
                },
                "confidence": 0.9997558164998882,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/lilv98/LogicRec/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-10-27T21:35:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-10-26T05:18:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 92317
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 559
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "11": {
        "filename": "FMZennaro_CategoricalCausalAbstraction_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**Notebooks are best visualized on [nbviewer](https://nbviewer.jupyter.org/)**: equations, in particular, may not be rendered on github. \n",
                    "original_header": "Disclaimers"
                },
                "confidence": 0.9516613048040234,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/FMZennaro/CategoricalCausalAbstraction/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-07-04T09:57:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-02-01T20:18:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 2909692
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 122673
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "12": {
        "filename": "jetou_FEPSS_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-08-05T11:36:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-14T02:33:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 34058
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "13": {
        "filename": "NVlabs_stylegan2_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Datasets are stored as multi-resolution TFRecords, similar to the [original StyleGAN](https://github.com/NVlabs/stylegan). Each dataset consists of multiple `*.tfrecords` files stored under a common directory, e.g., `~/datasets/ffhq/ffhq-r*.tfrecords`. In the following sections, the datasets are referenced using a combination of `--dataset` and `--data-dir` arguments, e.g., `--dataset=ffhq --data-dir=~/datasets`.\n\n**FFHQ**. To download the [Flickr-Faces-HQ](https://github.com/NVlabs/ffhq-dataset) dataset as multi-resolution TFRecords, run:\n\n```.bash\npushd ~\ngit clone https://github.com/NVlabs/ffhq-dataset.git\ncd ffhq-dataset\npython download_ffhq.py --tfrecords\npopd\npython dataset_tool.py display ~/ffhq-dataset/tfrecords/ffhq\n```\n\n**LSUN**. Download the desired LSUN categories in LMDB format from the [LSUN project page](https://www.yf.io/p/lsun). To convert the data to multi-resolution TFRecords, run:\n\n```.bash\npython dataset_tool.py create_lsun_wide ~/datasets/car ~/lsun/car_lmdb --width=512 --height=384\npython dataset_tool.py create_lsun ~/datasets/cat ~/lsun/cat_lmdb --resolution=256\npython dataset_tool.py create_lsun ~/datasets/church ~/lsun/church_outdoor_train_lmdb --resolution=256\npython dataset_tool.py create_lsun ~/datasets/horse ~/lsun/horse_lmdb --resolution=256\n```\n\n**Custom**. Create custom datasets by placing all training images under a single directory. The images must be square-shaped and they must all have the same power-of-two dimensions. To convert the images to multi-resolution TFRecords, run:\n\n```.bash\npython dataset_tool.py create_from_images ~/datasets/my-custom-dataset ~/my-custom-images\npython dataset_tool.py display ~/datasets/my-custom-dataset\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Preparing datasets"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NVlabs/stylegan2/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can import the networks in your own Python code using `pickle.load()`. For this to work, you need to include the `dnnlib` source directory in `PYTHONPATH` and create a default TensorFlow session by calling `dnnlib.tflib.init_tf()`. See [run_generator.py](./run_generator.py) and [pretrained_networks.py](./pretrained_networks.py) for examples.\n \n",
                    "original_header": "Using pre-trained networks"
                },
                "confidence": 0.9998017938750114,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/NVlabs/stylegan2/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To reproduce the training runs for config F in Tables 1 and 3, run:\n```.bash\npython run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\\n  --dataset=ffhq --mirror-augment=true\npython run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\\n  --dataset=car --total-kimg=57000\npython run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\\n  --dataset=cat --total-kimg=88000\npython run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\\n  --dataset=church --total-kimg 88000 --gamma=100\npython run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\\n  --dataset=horse --total-kimg 100000 --gamma=100\n```\n \n",
                    "original_header": "Training networks"
                },
                "confidence": 0.99999503152197,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/NVlabs/stylegan2/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "| Metric      | FFHQ config F  | 1 GPU  | 2 GPUs  | 4 GPUs | Description |\n| :---------- | :------------: | :----: | :-----: | :----: | :---------- |\n| `fid50k`    | 2.84 &pm; 0.03 | 22 min | 14 min  | 10 min | [Fr&eacute;chet Inception Distance](https://arxiv.org/abs/1706.08500)\n| `is50k`     | 5.13 &pm; 0.02 | 23 min | 14 min  | 8 min  | [Inception Score](https://arxiv.org/abs/1606.03498)\n| `ppl_zfull` | 348.0 &pm; 3.8 | 41 min | 22 min  | 14 min | [Perceptual Path Length](https://arxiv.org/abs/1812.04948) in Z, full paths\n| `ppl_wfull` | 126.9 &pm; 0.2 | 42 min | 22 min  | 13 min | [Perceptual Path Length](https://arxiv.org/abs/1812.04948) in W, full paths\n| `ppl_zend`  | 348.6 &pm; 3.0 | 41 min | 22 min  | 14 min | [Perceptual Path Length](https://arxiv.org/abs/1812.04948) in Z, path endpoints\n| `ppl_wend`  | 129.4 &pm; 0.8 | 40 min | 23 min  | 13 min | [Perceptual Path Length](https://arxiv.org/abs/1812.04948) in W, path endpoints\n| `ppl2_wend` | 145.0 &pm; 0.5 | 41 min | 23 min  | 14 min | [Perceptual Path Length](https://arxiv.org/abs/1812.04948) without center crop\n| `ls`        | 154.2 / 4.27   | 10 hrs | 6 hrs   | 4 hrs  | [Linear Separability](https://arxiv.org/abs/1812.04948)\n| `pr50k3`    | 0.689 / 0.492  | 26 min | 17 min  | 12 min | [Precision and Recall](https://arxiv.org/abs/1904.06991) \n",
                    "original_header": "Evaluation metrics"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/NVlabs/stylegan2/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-11-26T20:52:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T17:52:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 369008
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cuda",
                    "name": "Cuda",
                    "type": "Programming_language",
                    "size": 23649
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 362
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "14": {
        "filename": "caoyu-noob_Multi-GPT2_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2020-10-03T10:33:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-07-22T20:06:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 378921
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Perl",
                    "name": "Perl",
                    "type": "Programming_language",
                    "size": 48898
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "15": {
        "filename": "AI-Decision_DecisionHoldem_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "1. Clone repositories:\r\n```\r\n$ git clone https://github.com/AI-Decision/DecisionHoldem.git\r\n```\r\n2. copy followed file to DecisionHoldem/PokerAI/cluster\r\n```\r\nsevencards_strength.bin\r\npreflop_hand_cluster.bin\r\nflop_hand_cluster.bin\r\nturn_hand_cluster.bin\r\nriver_hand_cluster.bin\r\nblueprint_strategy.dat\r\n```\r\nThese data can be obtained through Baidu Netdisk.\r\n```\r\nLink: https://pan.baidu.com/s/157n-H1ECjEryAx0Z03p2_w\r\nExtraction code: q1pv\r\n```\r\n\r\n\r",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "DecisionHoldem",
                        "Blueprint Strategy"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/AI-Decision/DecisionHoldem/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "GUI is based on a project which can be found here:\r\nhttps://github.com/ishikota/PyPokerGUI  \r\ndemo project:\r\nhttps://github.com/zqbAse/PokerAI_Sim\r\n\r\n\r\n\r \n",
                    "original_header": "Related projects"
                },
                "confidence": 0.9999757897560237,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/AI-Decision/DecisionHoldem/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "[1] www.holdem.ia.ac.cn  \r\n[2] www.slumbot.com  \r\n[3] https://github.com/ericgjackson/slumbot2017/issues/11  \r\n[4] Development Environment\uff1aA workstation with an Intel(R) Xeon(R) Gold 6240R CPU, and 512GB of RAM.  \r\n[5] Currently some source codes only provide compiled files, and they will be open sourced in the near future. \r\n\r \n",
                    "original_header": "Note"
                },
                "confidence": 0.9999893730913163,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/AI-Decision/DecisionHoldem/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-01-10T13:59:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-19T17:26:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 153518
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 131743
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 18291
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 7867
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 4795
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 2558
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "16": {
        "filename": "almeidawarley_tsp-competition_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For subsequent runs, we initialised the dictionary parameter in order to take advantage of the previous runs : `dico_filename = os.path.join(os.getcwd(), \"20210707-125553-env-65-6537855_pop-25600-200_gen-4.json\")`.\n \n",
                    "original_header": "Generation of the solutions with the highest score"
                },
                "confidence": 0.9993437380840619,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/almeidawarley/tsp-competition/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-06-14T22:57:20Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2021-12-23T03:55:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 176930
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "17": {
        "filename": "dhiyu_UPLLRS_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-05-05T11:57:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-05-05T11:57:14Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "18": {
        "filename": "Maneuver-Identification to access the starter code and Maneuver-ID-mit-edu_data_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "19": {
        "filename": "HongyangDu_AttentionQoE_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "To create a new conda environment, execute the following command:\n\n```bash\nconda create --name aqoe python==3.10\n```",
                    "type": "Text_excerpt",
                    "original_header": "\ud83d\udd27 Environment Setup",
                    "parent_header": [
                        "<a href=\"https://hongyangdu.github.io/AttentionQoE\">Attention-aware Resource Allocation and QoE Analysis for Metaverse xURLLC Services</a>"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/HongyangDu/AttentionQoE/main/README.md"
            },
            {
                "result": {
                    "value": "The following package can be installed using pip:\n\n```bash\npip install eals\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "\ud83d\udce6 Install Required Packages",
                    "parent_header": [
                        "<a href=\"https://hongyangdu.github.io/AttentionQoE\">Attention-aware Resource Allocation and QoE Analysis for Metaverse xURLLC Services</a>"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/HongyangDu/AttentionQoE/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Activate the created environment with:\n```bash\nconda activate aqoe\n```\n \n",
                    "original_header": "\u26a1Activate Environment"
                },
                "confidence": 0.9999942829215841,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/HongyangDu/AttentionQoE/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-06-12T22:52:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-02-18T08:26:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 99640
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 41733
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 11068
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "MATLAB",
                    "name": "MATLAB",
                    "type": "Programming_language",
                    "size": 3753
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 1760
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "20": {
        "filename": "CompVis_stable-diffusion_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "A simple way to download and sample Stable Diffusion is by using the [diffusers library](https://github.com/huggingface/diffusers/tree/main#new--stable-diffusion-is-now-fully-compatible-with-diffusers):\n```py\n# make sure you're logged in with `huggingface-cli login`\nfrom torch import autocast\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\n\t\"CompVis/stable-diffusion-v1-4\", \n\tuse_auth_token=True\n).to(\"cuda\")\n\nprompt = \"a photo of an astronaut riding a horse on mars\"\nwith autocast(\"cuda\"):\n    image = pipe(prompt)[\"sample\"][0]  \n    \nimage.save(\"astronaut_rides_horse.png\")\n``` \n",
                    "original_header": "Diffusers Integration"
                },
                "confidence": 0.990793703384746,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-08-10T14:36:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T09:13:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 4172390
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 520234
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 3005
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "21": {
        "filename": "IsolationKernel_TIDKC_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-09-19T14:20:38Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-29T09:00:27Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "MATLAB",
                    "name": "MATLAB",
                    "type": "Programming_language",
                    "size": 20293
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 11363
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "22": {
        "filename": "aureliendelage1_hsviforzsposgs_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You need to set the environment variables for GUROBI as follows, where <installdir> is GUROBI's install directory:\n- GUROBI_HOME should point to your <installdir>.\n- PATH should be extended to include <installdir>/bin.\n- LD_LIBRARY_PATH should be extended to include <installdir>/lib.  \nFor instance:\n```shell\n$ export GUROBI_HOME=\"/opt/gurobi911/linux64\"\n$ export PATH=\"${PATH}:${GUROBI_HOME}/bin\"\n$ export LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:${GUROBI_HOME}/lib\"\n```\n \n",
                    "original_header": "GUROBI configuration :"
                },
                "confidence": 0.9999865586958345,
                "technique": "supervised_classification",
                "source": "https://gitlab.com/aureliendelage1/hsviforzsposgs/-/blob/main/Readme.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```shell\n$ cd src/\n$ javac -classpath .:../lib/cplex.jar:../lib/gurobi.jar:../lib/Jama-1.0.3.jar */*.java\n```\n \n",
                    "original_header": "compile with:"
                },
                "confidence": 0.9996644844651233,
                "technique": "supervised_classification",
                "source": "https://gitlab.com/aureliendelage1/hsviforzsposgs/-/blob/main/Readme.md"
            }
        ],
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "23": {
        "filename": "inpefess_basic-rl-prover_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The best way to install this package is to use ``pip``:\n\n.. code:: sh\n\n   pip install git+https://github.com/inpefess/basic-rl-prover.git\n",
                    "type": "Text_excerpt",
                    "original_header": "How to Install"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/inpefess/basic-rl-prover/master/README.rst"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "``basic-rl-prover`` is an example of using the `Ray Projects\nreinforcement learning library\n<https://docs.ray.io/en/latest/rllib/index.html>`_, `ast2vec encoder\nfor abstract syntax trees <https://gitlab.com/bpaassen/ast2vec>`_ and\n`a Gymnasium environment for saturation provers\n<https://pypi.org/project/gym-saturation>`_ to train an automated\ntheorem prover. \n",
                    "original_header": "Basic Reinforcement Learning Prover"
                },
                "confidence": 0.9999954632746745,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/inpefess/basic-rl-prover/master/README.rst"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at \n      https://www.apache.org/licenses/LICENSE-2.0 \n"
                },
                "confidence": 0.9845591436310213,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/inpefess/basic-rl-prover/master/README.rst"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-04-02T16:52:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-03-29T03:37:26Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 71714
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 49944
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "OpenEdge ABL",
                    "name": "OpenEdge ABL",
                    "type": "Programming_language",
                    "size": 1096
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 226
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "24": {
        "filename": "MoonBlvd_tad-IROS2019_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\tpython train_ego_pred.py --load_config config/fol_ego_train.yaml\n\tpython train_fol.py --load_config config/fol_ego_train.yaml\n \n",
                    "original_header": "Train"
                },
                "confidence": 0.9975647421131236,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/MoonBlvd/tad-IROS2019/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\tpython run_fol_for_AD.py --load_config config/test_A3D.yaml \n\tpython run_AD.py --load_config config/test_A3D.yaml \n",
                    "original_header": "Test FOL and anomaly detection"
                },
                "confidence": 0.9529487315932719,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/MoonBlvd/tad-IROS2019/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\tpython datasets/A3D_download.py --download_dir VIDEO_DIR --url_file datasets/A3D_urls.txt \n",
                    "original_header": "A3D dataset"
                },
                "confidence": 0.9690619656536502,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/MoonBlvd/tad-IROS2019/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-03-21T19:51:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T16:44:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 118776
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "25": {
        "filename": "ataitler_pyRDDLGym_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We require Python 3.8+ and the following packages: ``ply``, ``pillow>=9.2.0``, ``numpy>=1.22``, ``matplotlib>=3.5.0``, ``gymnasium``, ``pygame``, ``termcolor``.\nYou can install our package, along with all of its prerequisites, using pip\n\n```shell\npip install pyRDDLGym\n```\n\nSince pyRDDLGym does not come with any premade environments, you can either load RDDL documents from your local file system, or install rddlrepository for easy access to preexisting domains\n\n```shell\npip install rddlrepository\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "pyRDDLGym"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ataitler/pyRDDLGym/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "> [!WARNING]  \n> As of Feb 9, 2024, the pyRDDLGym API has been updated to version 2.0, and is no longer backwards compatible with the previous stable version 1.4.4.\n> While we strongly recommend that you update to 2.0, in case you require the old API, you can install the last stable version with pip:\n> ``pip install pyRDDLGym==1.4.4``, or directly from github ``pip install git+https://github.com/pyrddlgym-project/pyRDDLGym@version_1.4.4_stable``. \n",
                    "original_header": "pyRDDLGym"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ataitler/pyRDDLGym/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "A complete archive of past and present RDDL problems, including all IPPC problems, is also available to clone\\pip\n* [rddlrepository](https://github.com/pyRDDLGym-project/rddlrepository) (``pip install rddlrepository``) \n",
                    "original_header": "Status"
                },
                "confidence": 0.999999652298488,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ataitler/pyRDDLGym/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-07-10T20:34:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-07T22:34:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 406309
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "26": {
        "filename": "soledad921_TEA-GNN_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Anaconda>=4.3.30\nPython>=3.5\nKeras>=2.2.4\nTensorflow>=1.13.1\nScipy\nNumpy \n",
                    "original_header": "Enviroment"
                },
                "confidence": 0.9995995428279222,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/soledad921/TEA-GNN/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-09-02T18:17:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-11-21T08:42:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 33857
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "27": {
        "filename": "guoyinwang_LEAM_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We consider the following datasets: Yahoo, AGnews, DBPedia, yelp, yelp binary. For convenience, we provide pre-processed versions of all datasets. Data are prepared in pickle format. Each `.p` file has the same fields in same order: `train text`, `val text`, `test text`, `train label`, `val label`, `test label`, `dictionary` and `reverse dictionary`.\n\nDatasets can be downloaded [here](https://drive.google.com/open?id=1QmZfoKSgZl8UMN8XenAYqHaRzbW5QA26). Put the download data in data directory. Each dataset has two files: tokenized data and corresponding pretrained Glove embedding.\n\nTo run your own dataset, please follow the code in `preprocess_yahoo.py` to tokenize and split train/dev/test datsset. To build pretrained word embeddings, first download [Glove word embeddings](https://nlp.stanford.edu/projects/glove/) and then follow `glove_generate.py`. \n",
                    "type": "Text_excerpt",
                    "original_header": "Prepare datasets",
                    "parent_header": [
                        "LEAM"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/guoyinwang/LEAM/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-04-22T19:33:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-11T08:13:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 513038
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 47297
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "28": {
        "filename": "VictorYXL_ReplenishmentEnv_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "* Create new virtual environment (Optional)\npython -m venv myenv\nIn Windows \n```\nmyenv\\Scripts\\activate\n```\nIn macOS and Linux:\n```\nsource myenv/bin/activate\n```\n\n* Build and install MABIM\n```\npython setup.py install\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "install MABIM",
                    "parent_header": [
                        "MABIM"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/VictorYXL/ReplenishmentEnv/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "| Folder      | Description                                                                                       |\n| ----------- | ------------------------------------------------------------------------------------------------- |\n| [ReplenishmentEnv](ReplenishmentEnv)      | Replenishment env source code.                                      |\n| [ReplenishmentEnv/config](ReplenishmentEnv/config)      | Config for building the env.                          |\n| [ReplenishmentEnv/data](ReplenishmentEnv/data)      | Csv based data for skus, including sku_list, info and other dynamic data|\n| [ReplenishmentEnv/env](ReplenishmentEnv/env)      | Kernel simulator for env                                    |\n| [ReplenishmentEnv/utility](ReplenishmentEnv/utility)      | Utility simulator for env and wrapper               |\n| [ReplenishmentEnv/wrapper](ReplenishmentEnv/wrapper)      | Wrapper for env                 |\n| [Baseline](Baseline)                        | Show case of replenishment env.                                     |\n \n",
                    "original_header": "Contents"
                },
                "confidence": 0.9107065893900664,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/VictorYXL/ReplenishmentEnv/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-11-30T11:59:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-31T08:44:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 385452
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 173
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "29": {
        "filename": "Cranial-XIX_Continual-Learning-Private-Unlearning_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-07-19T00:40:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-22T07:55:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 77225
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2846
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "30": {
        "filename": "trangnnp_RSM_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-02-15T14:32:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-05-05T23:11:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "31": {
        "filename": "nathansttt_hog2_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Typical research usage of HOG2 would not involve installing applications from HOG2.\n\nTo fully install the programs to /usr/local/bin, run `sudo make install` under the `hog2/build/gmake/` directory; to uninstall run `sudo make uninstall` in the same directory. The installation location can be changed with `make install prefix=</path/to/dir>`.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "HOG2",
                        "Getting Started"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/nathansttt/hog2/PDB-refactor/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2015-08-19T21:02:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-14T06:25:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 8039528
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 327399
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Objective-C++",
                    "name": "Objective-C++",
                    "type": "Programming_language",
                    "size": 66795
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "PHP",
                    "name": "PHP",
                    "type": "Programming_language",
                    "size": 25026
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Objective-C",
                    "name": "Objective-C",
                    "type": "Programming_language",
                    "size": 8912
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 5650
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Rich Text Format",
                    "name": "Rich Text Format",
                    "type": "Programming_language",
                    "size": 436
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "32": {
        "filename": "BomBooooo_CNTS_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-11-27T03:55:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-25T12:51:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 149606
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "33": {
        "filename": "ramonpereira_paladinus_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The planner is set-up as a Java Maven project. So, the easiest way to build and test is as follows (to skip the tests add `-Dmaven.test.skip.exec`):\n```shell\n$ mvn clean package\n```\n \nWe can test it by getting the help with `-h` (or `-help`) using the provided script or directly via Java (using the generated packaged JAR file or complied classes):\n```shell\n$ # using the provided bash script\n$ ./paladinus -h\n\nPaladinus: An Iterative Depth-First Search FOND Planner\n\n -h (--help)                            : print this message (default: true)\n -debug [ON | OFF]                      : use debug option (default: OFF)\n -t (-type) [FOND]                      : use fond translate (Example: -t FOND\n                                          <domain_file> <problem_file>)\n                                          (default: FOND)\n -printPolicy                           : print policy to stdout (default:\n                                          false)\n -exportPolicy FILENAME                 : export policy to file\n -exportDot FILENAME                    : export policy as DOT graph (GraphViz)\n -translatorPath DIRNAME                : path to SAS translator script\n                                          (default: ./translator-fond/translate.\n                                          py)\n -timeout N                             : set timeout in seconds\n -as (-actionSelectionCriterion) VAL    : set actionSelectionCriterion\n                                          (default: MIN_MAX_H)\n...\n...\n```\n \nCheck below for running the system directly via the JAR file or compiled classes (mostly when developing further the system).\n \n",
                    "original_header": "Build (and test)"
                },
                "confidence": 0.9875250765841832,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ramonpereira/paladinus/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To report the policy solution, one can use the following options: \n",
                    "original_header": "Policy Output and Visualization"
                },
                "confidence": 0.9743641100112131,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ramonpereira/paladinus/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "When developing in a Maven aware IDE (e.g., VSCODE) it may be convenient to run the planner using the compiled classes in `target/classes` (instead of the JAR file) and the main class `paladinus.PaladinusPlanner` , as these will be automatically re-generated by the IDE when there is a change in source code:\n```shell\n$ java [java_options] -cp ./target/classes/:lib/commons-io-2.11.0.jar:lib/args4j-2.33.jar  paladinus.PaladinusPlanner \\\n    [planner_options] \\\n    (<domain.pddl> <problem.pddl> OR <problem.sas>)\n```\nWe can also run the system directly from the Maven produced JAR file (which includes all dependencies):\n```shell\n$ # using the packaged JAR (includes all dependencies)\n$ java [java_options] -jar target/paladinus-1.1-jar-with-dependencies.jar \\\n    [planner_options] \\\n    (<domain.pddl> <problem.pddl> OR <problem.sas>)\n```\n \n",
                    "original_header": "Developing"
                },
                "confidence": 0.9986880932351427,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ramonpereira/paladinus/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To run it from a directory different than that of the planner, we can use option `-translatorPath` to specify the location of the Python translator:\n```shell\n-translatorPath $HOME/planners/paladinus.git/translator-fond/translate.py\n```\n \n",
                    "original_header": "SAS translator"
                },
                "confidence": 0.999777993243027,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ramonpereira/paladinus/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-03-22T22:56:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-07T12:58:06Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "PDDL",
                    "name": "PDDL",
                    "type": "Programming_language",
                    "size": 5030505
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 1031312
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 308766
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "SAS",
                    "name": "SAS",
                    "type": "Programming_language",
                    "size": 118958
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 854
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 390
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "34": {
        "filename": "BorealisAI_de-simple_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "- Create a conda environment:\r\n```\r\n$ conda create -n tkgc python=3.6 anaconda\r\n```\r\n- Run\r\n```\r\n$ source activate tkgc\r\n```\r\n- Change directory to TKGC folder\r\n- Run\r\n```\r\n$ pip install -r requirements.txt\r\n```\r",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/BorealisAI/de-simple/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-07-02T17:10:26Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-20T10:00:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 30039
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "35": {
        "filename": "Wadaboa_3d-bpp_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "In order to install all the dependecies required by the project, you can either rely on `pip` or `conda`. If you want to use the former, `cd` to the root folder of the project and run the following commands:\n```bash\npython3 -m venv venv\nsource venv/bin/activate\npip install -r init/requirements.txt\n```\n\nInstead, for the latter you'd have to run the following commands (after changing directory to the project's root):\n```bash\nconda env create --name 3d-bpp -f init/environment.yml\nconda activate environment.yml\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "3D Bin Packing"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Wadaboa/3d-bpp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Below you can find a broad explanation of each implemented solution. Every procedure can be called through the same function (`main()` in module `main.py`), by changing the `procedure` parameter (it could be `bl` for baseline, `mr` for maxrects or `cg` for the column generation approach). Down below you can find a MWE on how to use the library:\n```python\nfrom src import config, dataset, main\n\n# Load dataset\nproduct_dataset = dataset.ProductDataset(\n    \"data/products.pkl\",\n    config.NUM_PRODUCTS,\n    config.MIN_PRODUCT_WIDTH,\n    config.MAX_PRODUCT_WIDTH,\n    config.MIN_PRODUCT_DEPTH,\n    config.MAX_PRODUCT_DEPTH,\n    config.MIN_PRODUCT_HEIGHT,\n    config.MAX_PRODUCT_HEIGHT,\n    config.MIN_PRODUCT_WEIGHT,\n    config.MAX_PRODUCT_WEIGHT,\n    force_overload=False,\n)\n\n# Get random order\norder = product_dataset.get_order(50)\n\n# Solve bin packing using the specified procedure to get\n# a pool of bins without \"flying\" products\nbin_pool = main.main(\n    order,\n    procedure=\"bl\",\n)\n\n# Plot the bin pool\nbin_pool.plot()\n```\n \n",
                    "original_header": "Solutions"
                },
                "confidence": 0.9999261206218574,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Wadaboa/3d-bpp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For a more entertaining and interactive solution, you can also run the implemented [Streamlit](https://streamlit.io/) dashboard, by simply running the following command from the root of the project:\n```bash\npython3 -m streamlit run src/dashboard.py\n```\n \n",
                    "original_header": "Execution"
                },
                "confidence": 0.9987140296535048,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Wadaboa/3d-bpp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "1. Change directory to `slides/`\n1. Run `npm install` and `npm run dev`\n2. Visit http://localhost:3030 \n",
                    "original_header": "Slides"
                },
                "confidence": 0.9999999905857777,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Wadaboa/3d-bpp/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-04-11T07:46:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-15T08:51:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 3255225
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 134501
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "36": {
        "filename": "yohayt_Resource-Sharing-Through-Multi-Round-Matchings_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-11-19T18:55:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-11-30T12:09:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 268325
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "37": {
        "filename": "elsevier-AI-Lab_BioBLP_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We recommend using [Anaconda](https://www.anaconda.com/) to manage the dependencies. The following command will create and activate a new conda environment with all the required dependencies.\n\n```bash\nconda create -f environment.yml && conda activate bioblp\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "1. Install the requirements",
                    "parent_header": [
                        "BioBLP: A Modular Framework for Learning on Multimodal Biomedical Knowledge Graphs",
                        "Usage"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/elsevier-AI-Lab/BioBLP/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<div>\n<a href=\"https://github.com/dfdazac/blp/blob/master/LICENSE\">\n    <img src=\"https://img.shields.io/badge/License-MIT-blue.svg\"></a>\n    <a href=\"https://doi.org/10.5281/zenodo.8005711\"><img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.8005711.svg\" alt=\"DOI\"></a>\n    <a href=\"https://arxiv.org/abs/2306.03606\"><img src=\"http://img.shields.io/badge/Paper-PDF-red.svg\"></a>\n</div> \n",
                    "original_header": "BioBLP: A Modular Framework for Learning on Multimodal Biomedical Knowledge Graphs"
                },
                "confidence": 0.9999866492538474,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/elsevier-AI-Lab/BioBLP/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-05-20T13:10:16Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-12T17:44:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 7384438
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 172108
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 25395
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 3340
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "38": {
        "filename": "tatsu-lab_stanford_alpaca_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "1. Set environment variables `OPENAI_API_KEY` to your OpenAI API key.\n2. Install the dependencies with `pip install -r requirements.txt`.\n3. Run `python -m generate_instruction generate_instruction_following_data` to generate the data. \n",
                    "original_header": "Data Generation Process"
                },
                "confidence": 0.9999999999815827,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To reproduce our fine-tuning runs for LLaMA, first install the requirements\n```bash\npip install -r requirements.txt\n```\nBelow is a command that fine-tunes LLaMA-7B with our dataset on a machine with 4 A100 80G GPUs in FSDP `full_shard` mode.\nWe were able to reproduce a model of similar quality as the one we hosted in our demo with the following command using **Python 3.10**.\nReplace `<your_random_port>` with a port of your own, `<your_path_to_hf_converted_llama_ckpt_and_tokenizer>` with the\npath to your converted checkpoint and tokenizer (following instructions in the PR), and `<your_output_dir>` with where you want to store your outputs.\n```bash\ntorchrun --nproc_per_node=4 --master_port=<your_random_port> train.py \\\n    --model_name_or_path <your_path_to_hf_converted_llama_ckpt_and_tokenizer> \\\n    --data_path ./alpaca_data.json \\\n    --bf16 True \\\n    --output_dir <your_output_dir> \\\n    --num_train_epochs 3 \\\n    --per_device_train_batch_size 4 \\\n    --per_device_eval_batch_size 4 \\\n    --gradient_accumulation_steps 8 \\\n    --evaluation_strategy \"no\" \\\n    --save_strategy \"steps\" \\\n    --save_steps 2000 \\\n    --save_total_limit 1 \\\n    --learning_rate 2e-5 \\\n    --weight_decay 0. \\\n    --warmup_ratio 0.03 \\\n    --lr_scheduler_type \"cosine\" \\\n    --logging_steps 1 \\\n    --fsdp \"full_shard auto_wrap\" \\\n    --fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \\\n    --tf32 True\n```\nThe same script also works for OPT fine-tuning. Here's an example for fine-tuning OPT-6.7B\n```bash\ntorchrun --nproc_per_node=4 --master_port=<your_random_port> train.py \\\n    --model_name_or_path \"facebook/opt-6.7b\" \\\n    --data_path ./alpaca_data.json \\\n    --bf16 True \\\n    --output_dir <your_output_dir> \\\n    --num_train_epochs 3 \\\n    --per_device_train_batch_size 4 \\\n    --per_device_eval_batch_size 4 \\\n    --gradient_accumulation_steps 8 \\\n    --evaluation_strategy \"no\" \\\n    --save_strategy \"steps\" \\\n    --save_steps 2000 \\\n    --save_total_limit 1 \\\n    --learning_rate 2e-5 \\\n    --weight_decay 0. \\\n    --warmup_ratio 0.03 \\\n    --lr_scheduler_type \"cosine\" \\\n    --logging_steps 1 \\\n    --fsdp \"full_shard auto_wrap\" \\\n    --fsdp_transformer_layer_cls_to_wrap 'OPTDecoderLayer' \\\n    --tf32 True\n```\n \n",
                    "original_header": "Fine-tuning"
                },
                "confidence": 0.9999999997495479,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The weight diff between Alpaca-7B and LLaMA-7B is located [here](https://huggingface.co/tatsu-lab/alpaca-7b-wdiff/tree/main).\nTo recover the original Alpaca-7B weights, follow these steps:\n```text\n1. Convert Meta's released weights into huggingface format. Follow this guide:\n    https://huggingface.co/docs/transformers/main/model_doc/llama\n2. Make sure you cloned the released weight diff into your local machine. The weight diff is located at:\n    https://huggingface.co/tatsu-lab/alpaca-7b/tree/main\n3. Run this function with the correct paths. E.g.,\n    python weight_diff.py recover --path_raw <path_to_step_1_dir> --path_diff <path_to_step_2_dir> --path_tuned <path_to_store_recovered_weights>\n``` \nOnce step 3 completes, you should have a directory with the recovered weights, from which you can load the model like the following\n```python\nimport transformers\nalpaca_model = transformers.AutoModelForCausalLM.from_pretrained(\"<path_to_store_recovered_weights>\")\nalpaca_tokenizer = transformers.AutoTokenizer.from_pretrained(\"<path_to_store_recovered_weights>\")\n```\n \n",
                    "original_header": "Recovering Alpaca Weights"
                },
                "confidence": 0.9815278027929876,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-03-10T23:33:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T07:37:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 29262
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "39": {
        "filename": "cmu-phil_tetrad_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "# Tetrad Application\n\nThis is a user interface tool that divides the analysis of causal problems into modular pieces which can be connected\ntogether to reflect how causal problems should ideally be analyzed. This can helpful as an educational tool or for data\nanalysis for those who prefer a point and click interface.\n\nPlease use a recent Java JDK.\nSee [Setting up Java for Tetrad](https://github.com/cmu-phil/tetrad/wiki/Setting-up-Java-for-Tetrad).\n\nTo download the Tetrad jar, please click the following link (which will always be updated to the latest version):\n\nhttps://s01.oss.sonatype.org/content/repositories/releases/io/github/cmu-phil/tetrad-gui/7.6.5/tetrad-gui-7.6.5-launch.jar\n\nYou may be able to launch this jar by double-clicking the jar file name. However, on a Mac, this presents some security\nchallenges. On all platforms, the jar may be launched at the command line (with a specification of the amount of RAM you\nwill allow it to use) using this command:\n\njava -Xmx[g]G -jar *-launch.jar\n\nHere, [g] is the maximum number of Gigabytes you wish to allocate to the process.\n\nSee our Documentation for more details about the Tetrad application.\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/cmu-phil/tetrad/development/INSTALL_APPLICATION.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "See our instructions\nfor [Installing the Tetrad Application](https://github.com/cmu-phil/tetrad/blob/development/INSTALL_APPLICATION.md).\n \n",
                    "original_header": "Tetrad Application"
                },
                "confidence": 0.9249334123335089,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/tetrad/development/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We also have a project, [rpy-tetrad](https://github.com/cmu-phil/py-tetrad/tree/main/pytetrad/R), that allows you to\nincorporate _some_ Tetrad functionality in R. It's also new, and the installation for it is also still nonstandard, but\nhas gotten good feedback. This requires Python 3.5+ and Java JDK 17+. \n",
                    "original_header": "Tetrad in R"
                },
                "confidence": 0.961639513093104,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/tetrad/development/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Here's the git command to clone our project:\n```\ngit clone https://github.com/cmu-phil/tetrad\n```\n \nOr, you can use GitHub's Code button. \nIf you have Maven installed, you can type the following to compile:\n```\nmvn clean compile\n```\nTo run the unit tests:\n```\nmvn clean test\n```\nTo generate an executable jar:\n```\nmvn clean package\n```\n \n",
                    "original_header": "Installallation for Programmers"
                },
                "confidence": 0.9914938390062428,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/tetrad/development/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2015-10-27T18:28:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-15T20:31:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 16825177
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 1135854
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "PostScript",
                    "name": "PostScript",
                    "type": "Programming_language",
                    "size": 201132
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Fortran",
                    "name": "Fortran",
                    "type": "Programming_language",
                    "size": 8724
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 7732
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 5953
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Haskell",
                    "name": "Haskell",
                    "type": "Programming_language",
                    "size": 3077
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "40": {
        "filename": "RMLio_rmlmapper-java_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The standalone jar file (that has a [commandline interface](#cli)) for every release can be found on the release's page on GitHub.\nYou can find the latest release [here](https://github.com/RMLio/rmlmapper-java/releases/latest).\nThis is the recommended way to get started with RMLMapper.\nDo you want to build from source yourself? Check [Build](#build).\n \n",
                    "original_header": "Releases"
                },
                "confidence": 0.9999993017320485,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/RMLio/rmlmapper-java/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The RMLMapper is built using Maven.\nAs it is also tested against Oracle (check [here](#accessing-oracle-database) for details),\nit needs a specific set-up to run all tests.\nThat's why we recommend to build without testing: `mvn install -DskipTests=true`.\nIf you want, you can install with tests, and just skip the Oracle tests: `mvn test -Dtest=!Mapper_OracleDB_Test`. \n",
                    "original_header": "Build"
                },
                "confidence": 0.9999927513820336,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/RMLio/rmlmapper-java/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Run the tests via `test.sh`. \n \n",
                    "original_header": "Command line"
                },
                "confidence": 0.9558018477304929,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/RMLio/rmlmapper-java/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-06-26T08:22:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-13T08:29:38Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 616082
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 5592
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 4803
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 389
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "41": {
        "filename": "domain-independent-dp_didp-rs_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Follow the instruction on the official webpage: <https://www.rust-lang.org/tools/install>\n",
                    "type": "Text_excerpt",
                    "original_header": "Install Rust",
                    "parent_header": [
                        "Domain-Independent Dynamic Programming (DIDP)",
                        "Development"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/domain-independent-dp/didp-rs/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "If you want to develop the DyPDL library, solvers, and interfaces, install Rust and clone this repository.\n```bash\ngit clone https://github.com/domain-independent-dp/didp-rs\ncd didp-rs\n```\n \n",
                    "original_header": "Development"
                },
                "confidence": 0.9999999999911608,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/domain-independent-dp/didp-rs/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- I recommend using VSCode as an editor: <https://code.visualstudio.com/>\n- To develop a Rust project with VSCode, this guide may be helpful: <https://code.visualstudio.com/docs/languages/rust>\n- I recommend using `clippy` for linting as described here: <https://code.visualstudio.com/docs/languages/rust#_linting>\n \n",
                    "original_header": "Development Environment"
                },
                "confidence": 0.9999999993701181,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/domain-independent-dp/didp-rs/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- The official tutorial is very helpful: <https://doc.rust-lang.org/stable/book/>\n- If you want to learn by example, see this document: <https://doc.rust-lang.org/stable/rust-by-example/>\n \n",
                    "original_header": "Learn Rust"
                },
                "confidence": 0.9999258444212583,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/domain-independent-dp/didp-rs/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-02-14T15:48:38Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-25T23:11:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Rust",
                    "name": "Rust",
                    "type": "Programming_language",
                    "size": 5794373
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 282909
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 77650
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 8326
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 800
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 634
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "42": {
        "filename": "koulanurag_ma-gym_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "- Setup (important):\n   ```bash\n      pip install 'pip<24.1'\n      pip install 'setuptools<=66'\n      pip install 'wheel<=0.38.4'\n   ```\n- Install package:\n   - Using PyPI:\n      ```bash\n      pip install ma-gym\n      ```\n\n   - Directly from source (recommended):\n      ```bash\n      git clone https://github.com/koulanurag/ma-gym.git\n      cd ma-gym\n      pip install -e .\n      ```",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "ma-gym"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/koulanurag/ma-gym/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- Install: ```pip install -e \".[test]\" ```\n- Run: BASH2* \n",
                    "original_header": "Testing:"
                },
                "confidence": 0.9999999385152752,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/koulanurag/ma-gym/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-06-10T15:28:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T01:46:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 165911
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "43": {
        "filename": "Aman-4-Real_MMTG_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Create a new virtual environment:\n```\n$ git clone https://github.com/Aman-4-Real/MMTG.git\n$ cd MMTG/\n$ conda create -n mmtg python=3.7\n$ conda activate mmtg\n```\nInstall the Python packages. Change the cudatoolkit version according to your environment if necessary.\n```\n$ conda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch -c conda-forge\n$ pip install -r requirements.txt\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Aman-4-Real/MMTG/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-07-06T07:47:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-12T10:12:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 62437
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1004
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "44": {
        "filename": "JHL-HUST_BandMaxSAT_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "On a Unix/Linux machine execute the following commands: <br> <br>\n\nunzip BandMaxSAT-main.zip <br>\ncd BandMaxSAT-main <br>\nmake <br> <br>\n\nAn executable file called BandMaxSAT will now be available in the directory BandMaxSAT-main. <br>\nThen enter the command ./BandMaxSAT instance_name, to run the algorithm. <br> <br>\n\nFor BandMaxSAT-c, we refer to the DT-HyWalk solver submitted to MSE 2022 (available at https://maxsat-evaluations.github.io/2022/mse22-solver-src/incomplete/DT-HyWalk.zip). Fix the variable selected_strategy to 3 in files MaxSAT.cc and Alg_LinearSU_Clustering.cc in DT-HyWalk results in an implementation of BandMaxSAT-c. <br> <br>\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/JHL-HUST/BandMaxSAT/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-04-29T14:26:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-23T14:04:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 36112
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 35183
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 111
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "45": {
        "filename": "zjukg_RMPI_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-07-08T12:07:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-24T06:27:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 481305
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "46": {
        "filename": "TamSiuhin_KRACL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```python\ntorch==1.8.0\ntorch-cluser==1.6.0\ntorch-scatter==2.0.9\ntorch-sparse==0.6.12\ntorch-spline-conv==1.2.1\npytorch-lightning==1.6.1\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "KRACL: Contrastive Learning with Graph Context Modeling for Sparse Knowledge Graph Completion"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/TamSiuhin/KRACL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-06-02T06:46:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-16T09:35:20Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 256404
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "47": {
        "filename": "facebook_duckling_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To compile and run the binary:\n```bash\nstack build\nstack exec duckling-example-exe\n```\n \nThe first time you run it, it will download all required packages. \nThis runs a basic HTTP server. Example request:\n```bash\ncurl -XPOST http://0.0.0.0:8000/parse --data 'locale=en_GB&text=tomorrow at eight'\n```\nIn the example application, all dimensions are enabled by default. Provide the parameter `dims` to specify which ones you want. Examples:\n```bash\nIdentify credit card numbers only:\n$ curl -XPOST http://0.0.0.0:8000/parse --data 'locale=en_US&text=\"4111-1111-1111-1111\"&dims=\"[\"credit-card-number\"]\"'\nIf you want multiple dimensions, comma-separate them in the array:\n$ curl -XPOST http://0.0.0.0:8000/parse --data 'locale=en_US&text=\"3 cups of sugar\"&dims=\"[\"quantity\",\"numeral\"]\"'\n```\n \nSee `exe/ExampleMain.hs` for an example on how to integrate Duckling in your\nproject.\nIf your backend doesn't run Haskell or if you don't want to spin your own Duckling server, you can directly use [wit.ai](https://wit.ai)'s built-in entities.\n \n",
                    "original_header": "Quickstart"
                },
                "confidence": 0.9943075604838099,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/facebook/duckling/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-03-02T01:45:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-17T09:02:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Haskell",
                    "name": "Haskell",
                    "type": "Programming_language",
                    "size": 11441032
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 954
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "48": {
        "filename": "huanzhang12_ATLA_robust_RL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "First clone this repository and install necessary Python packages:\n\n```bash\ngit submodule update --init\npip install -r requirements.txt\nsudo apt install parallel  # Only necessary for running the optimal attack experiments.\ncd src  # All code files are in the src/ folder\n```\n\nNote that you need to install MuJoCo 1.5 first to use the OpenAI Gym environments.\nSee [here](https://github.com/openai/mujoco-py/blob/9ea9bb000d6b8551b99f9aa440862e0c7f7b4191/README.md#requirements)\nfor instructions.\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "Robust Reinforcement Learning with Alternating Training of Learned Adversaries (ATLA)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/huanzhang12/ATLA_robust_RL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The above command only trains and tests one adversary using one set of adversary\nhyperparameters.  Since the learning of this optimal adversary is also an RL\nproblem (solved using PPO), to obtain the best attack results and evaluate the\ntrue robustness of an agent model, we need to train the adversary using multiple sets\nof hyperparameters and take the strongest (best) adversary. We provide scripts\nto easily scan the hyperparameters of the adversary and run each set of\nhyperparameters in parallel:\n```bash\ncd ../configs\n# This will generate 216 config files inside agent_configs_attack_ppo_ant.\n# Modify attack_ppo_ant_scan.py to change the hyperparameters for the grid search.\n# Typically, for a different environment you need a different set of hyperparameters for searching.\npython attack_ppo_ant_scan.py\ncd ../src\n# This command will run 216 configurations using all available CPUs. \n\n# You can also use \"-t \" to control the number of threads if you don't want to use all CPUs.\npython run_agents.py ../configs/agent_configs_attack_ppo_ant_scan/ --out-dir-prefix=../configs/agents_attack_ppo_ant_scan > attack_ant_scan.log\n\n```\nTo test all the optimal attack adversaries after the above training command\nfinishes, simply run the evaluation script:\n```bash\nbash example_evaluate_optimal_attack.sh\n```\nNote that you will need to change the line starting with with `scan_exp_folder`\nin `example_evaluate_optimal_attack.sh` to run evaluation of the learned\noptimal attack adversaries for another environment or results in another\nfolder. You need to change that line to:\n```bash\nscan_exp_folder <config file> <path to trained optimal attack adversarial> <path to the victim agent model> $semaphorename\n```\nThis script will run adversary evaluation in parallel (the \"GNU parallel\" tools\nare required), and will generate a log file\n`attack_scan/optatk_deterministic.log` containing attack results in each\nexperiment id folder. After the above command finishes, you can use\n`parse_optimal_attack_results.py` to parse the logs and get the best (strongest)\nattack result with lowest agent reward:\n```\npython parse_optimal_attack_results.py ../configs/agents_attack_ppo_ant_scan/attack_ppo_ant/agents\n```\n \n",
                    "original_header": "Finding the Best Optimal Attack Adversary"
                },
                "confidence": 0.9999746900729636,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/huanzhang12/ATLA_robust_RL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To train a agent, use `run.py` in `src` folder and specify a configuration file\npath.  Several configuration files are provided in the `src` folder, with\nfilenames starting with `config`. For example: \nHalfcheetah vanilla PPO (MLP) training:\n```bash\npython run.py --config-path config_halfcheetah_vanilla_ppo.json\n```\nHalfCheetah vanilla PPO (LSTM) training:\n```bash\npython run.py --config-path config_halfcheetah_vanilla_ppo_lstm.json\n```\nHalfCheetah ATLA (MLP) training:\n```bash\npython run.py --config-path config_halfcheetah_atla_ppo.json\n```\nHalfCheetah ATLA (LSTM) training:\n```bash\npython run.py --config-path config_halfcheetah_atla_ppo_lstm.json\n```\nHalfCheetah ATLA (LSTM) training with state-adversarial regularizer (this is\nthe best method):\n```bash\npython run.py --config-path config_halfcheetah_atla_lstm_sappo.json\n```\n \nThen the agent can be evaluated using `test.py`.  For example:\n```bash\n# Change the --exp-id to match the folder name in robust_atla_ppo_lstm_halfcheetah/agents/\npython test.py --config-path config_halfcheetah_atla_lstm_sappo.json --exp-id YOUR_EXP_ID --deterministic\n```\n \n",
                    "original_header": "Agent Training with Learned Optimal Adversaries (our ATLA framework)"
                },
                "confidence": 0.9999561828105655,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/huanzhang12/ATLA_robust_RL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "In this above example, you should see `minimum RS attack reward (deterministic\naction)` reported by the script to be below 300. For your convenience,\nthe `scan_attacks.sh` script will also run many other attacks including\nthe MAD attack, critic attack and random attack. Robust sarsa attack\nis usually the strongest one among them. \n",
                    "original_header": "Robust Sarsa (RS) Attack"
                },
                "confidence": 0.9956373219179881,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/huanzhang12/ATLA_robust_RL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-01-16T07:26:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-13T08:30:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 320375
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 13169
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "49": {
        "filename": "uoe-agents_pressureplate_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "After cloning the repo, ```cd``` into ```pressureplate``` and:\n```cli\npip install -e .\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/uoe-agents/pressureplate/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Within your Python script, access the three currently-available tasks as follows:\n```python\nenv = gym.make('pressureplate-linear-4p-v0')\nenv = gym.make('pressureplate-linear-5p-v0')\nenv = gym.make('pressureplate-linear-6p-v0')\n``` \n",
                    "original_header": "Using PressurePlate"
                },
                "confidence": 0.9999906210090193,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/uoe-agents/pressureplate/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-02-04T16:35:27Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-04T10:46:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 28461
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "50": {
        "filename": "gugarosa_mh_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "51": {
        "filename": "filecoin-project_bacalhau_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<p align=\"center\">\n  <a href=\"https://github.com/bacalhau-project/bacalhau\">\n    <img src=\"./docs/static/img/logo/Bacalhau-horizontal.svg\" alt=\"Bacalhau\" width=\"300\"/>\n  </a>\n</p> \n"
                },
                "confidence": 0.9998407095512024,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<p align=\"center\">\n    <a href=\"https://github.com/bacalhau-project/bacalhau/blob/dev/LICENSE\" alt=\"Contributors\">\n        <img src=\"https://img.shields.io/badge/license-Apache-green\" />\n        </a>\n    <a href=\"https://github.com/bacalhau-project/bacalhau/releases/\" alt=\"Release\">\n        <img src=\"https://img.shields.io/github/v/release/bacalhau-project/bacalhau?display_name=tag\" />\n        </a>\n    <a href=\"https://github.com/bacalhau-project/bacalhau/pulse\" alt=\"Activity\">\n        <img src=\"https://img.shields.io/github/commit-activity/m/bacalhau-project/bacalhau\" />\n        </a>\n    <a href=\"https://img.shields.io/github/downloads/bacalhau-project/bacalhau/total\">\n        <img src=\"https://img.shields.io/github/downloads/bacalhau-project/bacalhau/total\" alt=\"total download\">\n        </a>\n     <a href=\"https://github.com/bacalhau-project/bacalhau/graphs/contributors\">\n    <img src=\"https://img.shields.io/github/contributors/bacalhau-project/bacalhau\" alt=\"Bacalhau contributors\" >\n    </a>\n    <a href=\"https://www.bacalhau.org/\">\n    <img alt=\"Bacalhau website\" src=\"https://img.shields.io/badge/website-bacalhau.org-red\">\n  </a>\n      <a href=\"https://bit.ly/bacalhau-project-slack\" alt=\"Slack\">\n        <img src=\"https://img.shields.io/badge/slack-join_community-red.svg?color=0052FF&labelColor=090422&logo=slack\" />\n        </a>\n    <a href=\"https://twitter.com/intent/follow?screen_name=BacalhauProject\">\n        <img src=\"https://img.shields.io/twitter/follow/BacalhauProject?style=social&logo=twitter\" alt=\"follow on Twitter\">\n        </a>\n</p> \n",
                    "original_header": "The Distributed Computation Framework \u26a1<br>Compute Over Data (CoD)"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Go to the folder directory that you want to store your job results \nInstall the bacalhau client\n```bash\ncurl -sL https://get.bacalhau.org/install.sh | bash\n```\nSubmit a \"Hello World\" job\n```bash\nbacalhau docker run ubuntu echo Hello World\n```\nDownload your result\n```bash\nbacalhau get 63d08ff0..... # make sure to use the right job id from the docker run command\n```\n \n",
                    "original_header": "Getting started - Bacalhau in 1 minute"
                },
                "confidence": 0.9729887407626832,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "## Developers guide \n"
                },
                "confidence": 0.9503985634823351,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Developers can spin up bacalhau and run a local demo using the `devstack` command. \n",
                    "original_header": "Running Bacalhau locally"
                },
                "confidence": 0.9316498406366432,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Please see [running_locally.md](docs/docs/dev/running-locally.md) for instructions. Also, see [debugging_locally.md](docs/docs/dev/debugging_locally.md) for some useful tricks for debugging. \n"
                },
                "confidence": 0.9514952152025061,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Bacalhau's CI pipeline performs a variety of linting and formatting checks on new pull requests.\nTo have these checks run locally when you make a new commit, you can use the precommit hook in `./githooks`:\n```bash\nmake install-pre-commit\n\n# check if pre-commit works\nmake precommit\n```\nIf you want to run the linter manually:\n \n",
                    "original_header": "Notes for Dev contributors"
                },
                "confidence": 0.999999998645535,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```bash\ncurl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sudo sh -s -- -b /usr/local/go/bin\ngolangci-lint --version\nmake lint\n```\nThe config lives in `.golangci.yml` \n"
                },
                "confidence": 0.9999999999994031,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "OpenAPI v2 annotations sit by the endpoints in `pkg/publicapi`; these are built using [swag](https://github.com/swaggo/swag), a Go converter for Swagger documentation.\nFind more details about the Swag annotations [in their docs](https://github.com/swaggo/swag#declarative-comments-format).\nThe swagger specification is built automatically by the CI pipeline (see the `build_swagger` workflow) but you can trigger a local build with `make swagger-docs`. \n* `docs/docs.go`\n* `docs/swagger.json`\n* `docs/swagger.yaml` \n",
                    "original_header": "OpenAPI"
                },
                "confidence": 0.9599486775071356,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Note that the CI pipeline will open and automatically merge a pull request titled `[circleci] Build swagger reference - this is an automatic commit ...` containing *only* the updated spec files. \n### Python Libraries \n"
                },
                "confidence": 0.947425104373135,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We ship two Python Bacalhau libraries: \n",
                    "original_header": "Python Libraries"
                },
                "confidence": 0.9577703015955165,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We explicitly grant permission for you to make a build that includes our trademarks while developing Bacalhau software itself. You may not publish or share the build, and you may not use that build to run Bacalhau software for any other purpose. \n",
                    "original_header": "Open Source"
                },
                "confidence": 0.9988785803983541,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filecoin-project/bacalhau/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-11-05T15:30:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T08:04:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Go",
                    "name": "Go",
                    "type": "Programming_language",
                    "size": 2976007
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 635372
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TypeScript",
                    "name": "TypeScript",
                    "type": "Programming_language",
                    "size": 91263
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 71487
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HCL",
                    "name": "HCL",
                    "type": "Programming_language",
                    "size": 69822
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 31405
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 30418
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "SCSS",
                    "name": "SCSS",
                    "type": "Programming_language",
                    "size": 16193
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Open Policy Agent",
                    "name": "Open Policy Agent",
                    "type": "Programming_language",
                    "size": 13226
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Earthly",
                    "name": "Earthly",
                    "type": "Programming_language",
                    "size": 11962
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "MDX",
                    "name": "MDX",
                    "type": "Programming_language",
                    "size": 11271
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 7237
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 954
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Smarty",
                    "name": "Smarty",
                    "type": "Programming_language",
                    "size": 612
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "52": {
        "filename": "johannestreutlein_scoring-rules-performative_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-05-26T17:59:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-07T04:54:27Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Mathematica",
                    "name": "Mathematica",
                    "type": "Programming_language",
                    "size": 1800361
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "53": {
        "filename": "hoergems_ADVT_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-05-21T09:54:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-09-04T06:58:14Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 228988
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 11761
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 234
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "54": {
        "filename": "DillonZChen_cpp-mossp-planner_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-12-01T10:05:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-28T09:19:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "55": {
        "filename": "jia-wei-zheng_alignment-over-probabilistic-events_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-11-29T20:20:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-06-07T12:51:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 63098
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "56": {
        "filename": "sail-sg_PatchAIL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "  - Download pkl files from [[link](https://drive.google.com/file/d/1I2wTuIFLaX_5wD7DI_QME2oYTJDBHiWb/view?usp=sharing)]\n  or\n  ```python generate_atari_rlunplugged.py``` (change the env name contained in the script before running). \n",
                    "original_header": "Obtain Atari games demonstrations:"
                },
                "confidence": 0.9988628122927201,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/sail-sg/PatchAIL/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- Install [Mujoco](http://www.mujoco.org/) based on the instructions given [here](https://github.com/facebookresearch/drqv2).\n- Install the following libraries:\n  ```\n  sudo apt update\n  sudo apt install libosmesa6-dev libgl1-mesa-glx libglfw3\n  ```\n- Install dependencies\n  - Set up Environment (Conda)\n  BASH2*\n  - Set up Environment (Pip)\n  BASH3*\n- (If you want to run Atari games) Install Atari ROMS:\n  BASH4*\n- Main Imitation Experiments (Observations only) (10 exp trajs) - Commands for running the code on the DeepMind Control Suite, for pixel-based input\n  - Train PatchAIL (w.o. Reg) agent on DMC\n    BASH5*\n  - Train PatchAIL (w.o. Reg) agent on Atari\n    BASH6* \n  - Train ROT\n    ```\n    python train.py agent=potil suite=dmc obs_type=pixels suite/dmc_task=walker_run bc_regularize=true num_demos=1 replay_buffer_size=150000 suite.num_train_frames=1101000 algo_name=rot\n    ```\n- If you want to resume experiments from previous experiment:\n    BASH18*\n    This will load models from the snapshot of previous log directory. \n",
                    "original_header": "Instructions"
                },
                "confidence": 0.9997255362553062,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/sail-sg/PatchAIL/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-01-13T02:46:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-03T20:00:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 293348
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "57": {
        "filename": "bi3mer_LinkingLevelSegments_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-11-03T18:02:27Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-03-09T19:45:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 88417
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 399
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "58": {
        "filename": "AI-S2-Lab_EmoPP_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-09-20T08:43:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T13:48:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 53028
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 3317
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "59": {
        "filename": "ChampiB_BTAI_3MF_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-05-01T12:39:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-16T14:14:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 99392
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "60": {
        "filename": "wingsweihua_colight_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* ``config.py`` \n",
                    "original_header": "Others"
                },
                "confidence": 0.9092214965612194,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/wingsweihua/colight/master/readme.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-08-20T19:03:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-03T07:30:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 375315
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 19585
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 4035
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 579
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 65
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "61": {
        "filename": "jhudsy_Gradual_Attack_Inference_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-07-14T14:31:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-11-30T01:58:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 10580
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "62": {
        "filename": "stan5dard_IJCAI-CoachAI-Challenge-2023_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "This is a repository of IJCAI-CoachAI-Challenge-2023 Team Badminseok [https://sites.google.com/view/coachai-challenge-2023/, https://github.com/wywyWang/CoachAI-Projects/tree/main] \n",
                    "original_header": "IJCAI-CoachAI-Challenge-2023"
                },
                "confidence": 0.9957034327098736,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/stan5dard/IJCAI-CoachAI-Challenge-2023/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-07-06T02:36:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-03T05:57:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 494073
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 193
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "63": {
        "filename": "atticusg_InterchangeInterventions_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-06-05T05:13:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-24T20:14:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 826242
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 131962
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "64": {
        "filename": "google-research_bert_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "In certain cases, rather than fine-tuning the entire pre-trained model\nend-to-end, it can be beneficial to obtained *pre-trained contextual\nembeddings*, which are fixed contextual representations of each input token\ngenerated from the hidden layers of the pre-trained model. This should also\nmitigate most of the out-of-memory issues.\n\nAs an example, we include the script `extract_features.py` which can be used\nlike this:\n\n```shell\n# Sentence A and Sentence B are separated by the ||| delimiter for sentence\n# pair tasks like question answering and entailment.\n# For single sentence inputs, put one sentence per line and DON'T use the\n# delimiter.\necho 'Who was Jim Henson ? ||| Jim Henson was a puppeteer' > /tmp/input.txt\n\npython extract_features.py \\\n  --input_file=/tmp/input.txt \\\n  --output_file=/tmp/output.jsonl \\\n  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n  --layers=-1,-2,-3,-4 \\\n  --max_seq_length=128 \\\n  --batch_size=8\n```\n\nThis will create a JSON file (one line per line of input) containing the BERT\nactivations from each Transformer layer specified by `layers` (-1 is the final\nhidden layer of the Transformer, etc.)\n\nNote that this script will produce very large output files (by default, around\n15kb for every input token).\n\nIf you need to maintain alignment between the original and tokenized words (for\nprojecting training labels), see the [Tokenization](#tokenization) section\nbelow.\n\n**Note:** You may see a message like `Could not find trained model in model_dir:\n/tmp/tmpuB5g5c, running initialization to predict.` This message is expected, it\njust means that we are using the `init_from_checkpoint()` API rather than the\nsaved model API. If you don't specify a checkpoint or specify an invalid\ncheckpoint, this script will complain.\n",
                    "type": "Text_excerpt",
                    "original_header": "Using BERT to extract fixed feature vectors (like ELMo)",
                    "parent_header": [
                        "BERT"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/google-research/bert/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can download all 24 from [here][all], or individually from the table below: \n[2_128]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-2_H-128_A-2.zip\n[2_256]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-2_H-256_A-4.zip\n[2_512]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-2_H-512_A-8.zip\n[2_768]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-2_H-768_A-12.zip\n[4_128]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-128_A-2.zip\n[4_256]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-256_A-4.zip\n[4_512]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-512_A-8.zip\n[4_768]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-768_A-12.zip\n[6_128]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-6_H-128_A-2.zip\n[6_256]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-6_H-256_A-4.zip\n[6_512]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-6_H-512_A-8.zip\n[6_768]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-6_H-768_A-12.zip\n[8_128]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-8_H-128_A-2.zip\n[8_256]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-8_H-256_A-4.zip\n[8_512]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-8_H-512_A-8.zip\n[8_768]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-8_H-768_A-12.zip\n[10_128]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-10_H-128_A-2.zip\n[10_256]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-10_H-256_A-4.zip\n[10_512]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-10_H-512_A-8.zip\n[10_768]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-10_H-768_A-12.zip\n[12_128]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-128_A-2.zip\n[12_256]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-256_A-4.zip\n[12_512]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-512_A-8.zip\n[12_768]: https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\n[all]: https://storage.googleapis.com/bert_models/2020_02_20/all_bert_models.zip \n**It is recommended to use this version for developing multilingual models,\nespecially on languages with non-Latin alphabets.** \nThis does not require any code changes, and can be downloaded here: \n",
                    "original_header": "BERT"
                },
                "confidence": 0.959918239886709,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/bert/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**When using a cased model, make sure to pass `--do_lower=False` to the training\nscripts. (Or pass `do_lower_case=False` directly to `FullTokenizer` if you're\nusing your own script.)** \n",
                    "original_header": "Pre-trained models"
                },
                "confidence": 0.9599905087051647,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/bert/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Most of the examples below assumes that you will be running training/evaluation\non your local machine, using a GPU like a Titan X or GTX 1080. \nHowever, if you have access to a Cloud TPU that you want to train on, just add\nthe following flags to `run_classifier.py` or `run_squad.py`:\n```\n  --use_tpu=True \\\n  --tpu_name=$TPU_NAME\n```\n \nPlease see the\n[Google Cloud TPU tutorial](https://cloud.google.com/tpu/docs/tutorials/mnist)\nfor how to use Cloud TPUs. Alternatively, you can use the Google Colab notebook\n\"[BERT FineTuning with Cloud TPUs](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\". \n",
                    "original_header": "Fine-tuning with Cloud TPUs"
                },
                "confidence": 0.9835389115795548,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/bert/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Before running this example you must download the\n[GLUE data](https://gluebenchmark.com/tasks) by running\n[this script](https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e)\nand unpack it to some directory `$GLUE_DIR`. Next, download the `BERT-Base`\ncheckpoint and unzip it to some directory `$BERT_BASE_DIR`. \nThis example code fine-tunes `BERT-Base` on the Microsoft Research Paraphrase\nCorpus (MRPC) corpus, which only contains 3,600 examples and can fine-tune in a\nfew minutes on most GPUs.\n```shell\nexport BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12\nexport GLUE_DIR=/path/to/glue\n\npython run_classifier.py \\\n  --task_name=MRPC \\\n  --do_train=true \\\n  --do_eval=true \\\n  --data_dir=$GLUE_DIR/MRPC \\\n  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n  --max_seq_length=128 \\\n  --train_batch_size=32 \\\n  --learning_rate=2e-5 \\\n  --num_train_epochs=3.0 \\\n  --output_dir=/tmp/mrpc_output/\n```\nYou should see output like this:\n```\n***** Eval results *****\n  eval_accuracy = 0.845588\n  eval_loss = 0.505248\n  global_step = 343\n  loss = 0.505248\n```\n \nNote: You might see a message `Running train on CPU`. This really just means\nthat it's running on something other than a Cloud TPU, which includes a GPU.\n \n",
                    "original_header": "Sentence (and sentence-pair) classification tasks"
                },
                "confidence": 0.9896975109001188,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/bert/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Once you have trained your classifier you can use it in inference mode by using\nthe --do_predict=true command. You need to have a file named test.tsv in the\ninput folder. Output will be created in file called test_results.tsv in the\noutput folder. Each line will contain output for each sample, columns are the\nclass probabilities.\n```shell\nexport BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12\nexport GLUE_DIR=/path/to/glue\nexport TRAINED_CLASSIFIER=/path/to/fine/tuned/classifier\n\npython run_classifier.py \\\n  --task_name=MRPC \\\n  --do_predict=true \\\n  --data_dir=$GLUE_DIR/MRPC \\\n  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  --init_checkpoint=$TRAINED_CLASSIFIER \\\n  --max_seq_length=128 \\\n  --output_dir=/tmp/mrpc_output/\n```\n \n",
                    "original_header": "Prediction from classifier"
                },
                "confidence": 0.999931264010527,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/bert/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To run on SQuAD, you will first need to download the dataset. The\n[SQuAD website](https://rajpurkar.github.io/SQuAD-explorer/) does not seem to\nlink to the v1.1 datasets any longer, but the necessary files can be found here: \nDownload these to some directory `$SQUAD_DIR`. \nThe state-of-the-art SQuAD results from the paper currently cannot be reproduced\non a 12GB-16GB GPU due to memory constraints (in fact, even batch size 1 does\nnot seem to fit on a 12GB GPU using `BERT-Large`). However, a reasonably strong\n`BERT-Base` model can be trained on the GPU with these hyperparameters:\n```shell\npython run_squad.py \\\n  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n  --do_train=True \\\n  --train_file=$SQUAD_DIR/train-v1.1.json \\\n  --do_predict=True \\\n  --predict_file=$SQUAD_DIR/dev-v1.1.json \\\n  --train_batch_size=12 \\\n  --learning_rate=3e-5 \\\n  --num_train_epochs=2.0 \\\n  --max_seq_length=384 \\\n  --doc_stride=128 \\\n  --output_dir=/tmp/squad_base/\n```\nThe dev set predictions will be saved into a file called `predictions.json` in\nthe `output_dir`:\n```shell\npython $SQUAD_DIR/evaluate-v1.1.py $SQUAD_DIR/dev-v1.1.json ./squad/predictions.json\n```\nWhich should produce an output like this:\n```shell\n{\"f1\": 88.41249612335034, \"exact_match\": 81.2488174077578}\n```\n \nIf you have access to a Cloud TPU, you can train with `BERT-Large`. Here is a\nset of hyperparameters (slightly different than the paper) which consistently\nobtain around 90.5%-91.0% F1 single-system trained only on SQuAD:\n```shell\npython run_squad.py \\\n  --vocab_file=$BERT_LARGE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_LARGE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt \\\n  --do_train=True \\\n  --train_file=$SQUAD_DIR/train-v1.1.json \\\n  --do_predict=True \\\n  --predict_file=$SQUAD_DIR/dev-v1.1.json \\\n  --train_batch_size=24 \\\n  --learning_rate=3e-5 \\\n  --num_train_epochs=2.0 \\\n  --max_seq_length=384 \\\n  --doc_stride=128 \\\n  --output_dir=gs://some_bucket/squad_large/ \\\n  --use_tpu=True \\\n  --tpu_name=$TPU_NAME\n```\nFor example, one random run with these parameters produces the following Dev\nscores:\n```shell\n{\"f1\": 90.87081895814865, \"exact_match\": 84.38978240302744}\n```\n \n",
                    "original_header": "SQuAD 1.1"
                },
                "confidence": 0.9530447248379363,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/bert/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To run on SQuAD 2.0, you will first need to download the dataset. The necessary\nfiles can be found here: \nOn Cloud TPU you can run with BERT-Large as follows:\n```shell\npython run_squad.py \\\n  --vocab_file=$BERT_LARGE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_LARGE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt \\\n  --do_train=True \\\n  --train_file=$SQUAD_DIR/train-v2.0.json \\\n  --do_predict=True \\\n  --predict_file=$SQUAD_DIR/dev-v2.0.json \\\n  --train_batch_size=24 \\\n  --learning_rate=3e-5 \\\n  --num_train_epochs=2.0 \\\n  --max_seq_length=384 \\\n  --doc_stride=128 \\\n  --output_dir=gs://some_bucket/squad_large/ \\\n  --use_tpu=True \\\n  --tpu_name=$TPU_NAME \\\n  --version_2_with_negative=True\n```\n \nRun this script to tune a threshold for predicting null versus non-null answers: \npython $SQUAD_DIR/evaluate-v2.0.py $SQUAD_DIR/dev-v2.0.json\n./squad/predictions.json --na-prob-file ./squad/null_odds.json \nAssume the script outputs \"best_f1_thresh\" THRESH. (Typical values are between\n-1.0 and -5.0). You can now re-run the model to generate predictions with the\nderived threshold or alternatively you can extract the appropriate answers from\n./squad/nbest_predictions.json.\n```shell\npython run_squad.py \\\n  --vocab_file=$BERT_LARGE_DIR/vocab.txt \\\n  --bert_config_file=$BERT_LARGE_DIR/bert_config.json \\\n  --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt \\\n  --do_train=False \\\n  --train_file=$SQUAD_DIR/train-v2.0.json \\\n  --do_predict=True \\\n  --predict_file=$SQUAD_DIR/dev-v2.0.json \\\n  --train_batch_size=24 \\\n  --learning_rate=3e-5 \\\n  --num_train_epochs=2.0 \\\n  --max_seq_length=384 \\\n  --doc_stride=128 \\\n  --output_dir=gs://some_bucket/squad_large/ \\\n  --use_tpu=True \\\n  --tpu_name=$TPU_NAME \\\n  --version_2_with_negative=True \\\n  --null_score_diff_threshold=$THRESH\n```\n \n",
                    "original_header": "SQuAD 2.0"
                },
                "confidence": 0.9789347967849362,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/bert/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Using the default training scripts (`run_classifier.py` and `run_squad.py`), we\nbenchmarked the maximum batch size on single Titan X GPU (12GB RAM) with\nTensorFlow 1.11.0: \n",
                    "original_header": "Out-of-memory issues"
                },
                "confidence": 0.904964938811927,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/bert/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "3.  Truncate to the maximum sequence length. (You can use up to 512, but you\n    probably want to use shorter if possible for memory and speed reasons.) \n",
                    "original_header": "Tokenization"
                },
                "confidence": 0.9543334571898751,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/bert/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-10-25T22:57:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T08:01:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 214335
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 66488
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "65": {
        "filename": "satviz_satviz_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Pre-built images for Linux/x64 can be found in the [releases section](https://github.com/satviz/satviz/releases) of this repository.\n\nDownload `satviz.zip` for the main application and (optionally) `satviz-producer.zip` for the standalone producer application (for externalised computing). Unzip the archives in a directory of your choice. `bin/satviz` or `bin/sat-prod` respectively can be used to run the applications.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "satviz"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/satviz/satviz/develop/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Clone this repository and run the following commands:\n```\ngit submodule init\ngit submodule update\n``` \nTo install the app on your system, run `sudo ./gradlew install`.  \nTo only get a zipped distribution and not install it directly, use `./gradlew satvizDist` instead.\nYou will find the visualisation app in `satviz-consumer/build/satviz.zip` and the producer app in `satviz-producer/build/satviz-producer.zip`. Both contain a script to run them in `bin/`.\n \n",
                    "original_header": "Build from Source"
                },
                "confidence": 0.9999999575887903,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/satviz/satviz/develop/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-01-13T13:30:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T14:05:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 434510
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 73255
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Kotlin",
                    "name": "Kotlin",
                    "type": "Programming_language",
                    "size": 6657
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 4443
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "GLSL",
                    "name": "GLSL",
                    "type": "Programming_language",
                    "size": 2326
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 2226
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1393
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "66": {
        "filename": "Michael-Beukman_MCHAMR_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "To set up your python environment, do the following to create an environment with the correct version.\n```\nconda create -n mchamr python=3.9\n```\n\nthen run this to activate it\n```\nconda activate mchamr\n```\nAnd finally, install the necessary packages using pip.\n\n```\npip install -r requirements.txt\n```\n\n**[Important]** Then, to run any python file in here, use `./run.sh path/to/python/file` from the root of this repository instead of using `python` directly, as otherwise modules are not recognised.\n",
                    "type": "Text_excerpt",
                    "original_header": "Environment Setup",
                    "parent_header": [
                        "MCHAMR - Multilevel Composition of Hierarchical and Adaptive Models via Recursion"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Michael-Beukman/MCHAMR/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For minecraft, follow the [instructions](https://github.com/real-itu/Evocraft-py), and start the minecraft server & client first. The TL; DR is that you must `cd src/external/Evocraft-py` and run `java -jar spongevanilla-1.12.2-7.3.0.jar`. Then, open the Minecraft client and connect to localhost. Then you can run the visualisation code in a separate terminal.\n```\n./run.sh src/runs/proper_experiments/group/mcc/eval/viz.py 3001-a\n```\nto visualise the demo results.\n \nTo visualise the final composition, please run `./run.sh src/contrib/theory/mcc_paper.py`\n \n",
                    "original_header": "Visualise"
                },
                "confidence": 0.9980221587421123,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Michael-Beukman/MCHAMR/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\nYou can now follow the visualisation steps outlined above.\n \n",
                    "original_header": "Create your own"
                },
                "confidence": 0.9958425239753863,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Michael-Beukman/MCHAMR/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can also use the following script to run a 2D visualisation:\n```bash\n./run.sh src/runs/proper_experiments/group/mcc/eval/viz2d.py <exp_name>\n``` \ne.g.\n```bash\n./run.sh src/runs/proper_experiments/group/mcc/eval/viz2d.py 3551-hlb\n```\n \n",
                    "original_header": "2D Visualisation"
                },
                "confidence": 0.9933923818664459,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Michael-Beukman/MCHAMR/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-12-16T10:38:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-24T04:53:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 562502
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 286
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "67": {
        "filename": "chenmeiqii_Teach-LLM-LR_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-10-13T13:51:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T15:33:21Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 77105
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "68": {
        "filename": "guolingbing_RLEA_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Use the following scripts to run RLEA with RDGCN as basic EEA model on D-Y:\n```bash\ncd run\npython runRLEA.py --model_name rdgcn --dataset D_Y\n```\nIf run with the stored embeddings:\n```bash\npython runRLEA.py --model_name rdgcn --dataset D_Y --restore_embeddings True\n```\nFor SEA which has projection matrices:\n```bash\npython runRLEA.py --model_name sea --dataset D_Y --mapping True\n```\n \n",
                    "original_header": "Training &amp; Evaluation"
                },
                "confidence": 0.999897484067816,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/guolingbing/RLEA/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-02-27T06:02:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-27T15:13:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 876514
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "69": {
        "filename": "nand1155_CausNet_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "You can install the development version from GitHub with:\n\n```{r installation, eval=FALSE}\nrequire(\"devtools\")\ninstall_github(\"https://github.com/nand1155/CausNet\")\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "CausNet"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/nand1155/CausNet/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n``` \n",
                    "original_header": "output: github_document"
                },
                "confidence": 0.9906103782686531,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/nand1155/CausNet/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-07-16T15:43:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-07-16T19:11:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "R",
                    "name": "R",
                    "type": "Programming_language",
                    "size": 44670
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 737
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "70": {
        "filename": "google-research_google-research_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Install through conda environment.yaml, but comment svox.\nThen install manually svox.\n\nconda env create -f environment.yml\npip install svox\npip install --upgrade pip",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/google-research/google-research/master/wavelet_fields/external/plenoctree/README_my_install.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "If you'd like to submit a pull request, you'll need to clone the repository;\nwe recommend making a shallow clone (without history).\n```\ngit clone git@github.com:google-research/google-research.git --depth=1\n```\n \n",
                    "original_header": "Google Research"
                },
                "confidence": 0.9999999999462261,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/google-research/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-10-04T18:42:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T07:21:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 77780062
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 70143877
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 4885765
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 1598936
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 1005332
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 981055
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 874625
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Starlark",
                    "name": "Starlark",
                    "type": "Programming_language",
                    "size": 264884
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "R",
                    "name": "R",
                    "type": "Programming_language",
                    "size": 109000
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "MATLAB",
                    "name": "MATLAB",
                    "type": "Programming_language",
                    "size": 103813
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "NASL",
                    "name": "NASL",
                    "type": "Programming_language",
                    "size": 97072
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Lua",
                    "name": "Lua",
                    "type": "Programming_language",
                    "size": 92587
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Julia",
                    "name": "Julia",
                    "type": "Programming_language",
                    "size": 67986
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Vim Snippet",
                    "name": "Vim Snippet",
                    "type": "Programming_language",
                    "size": 65130
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "GLSL",
                    "name": "GLSL",
                    "type": "Programming_language",
                    "size": 64504
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "ImageJ Macro",
                    "name": "ImageJ Macro",
                    "type": "Programming_language",
                    "size": 50488
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cuda",
                    "name": "Cuda",
                    "type": "Programming_language",
                    "size": 50111
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 31748
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 12121
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 11569
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Gnuplot",
                    "name": "Gnuplot",
                    "type": "Programming_language",
                    "size": 11125
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Perl",
                    "name": "Perl",
                    "type": "Programming_language",
                    "size": 8590
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 7380
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 6868
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Smarty",
                    "name": "Smarty",
                    "type": "Programming_language",
                    "size": 5966
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 2556
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Rust",
                    "name": "Rust",
                    "type": "Programming_language",
                    "size": 2389
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 1208
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "71": {
        "filename": "sgottsch_Tab2KG_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Create a directory for Tab2KG in your file system (e.g. \"/Documents/Tab2KG/\"). Insert that path in de.l3s.simpleml.tab2kg.util.Config. Optionally, you can also distinguish between a local and a server path there. \n",
                    "original_header": "Configuration"
                },
                "confidence": 0.9284537026348354,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/sgottsch/Tab2KG/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The corresponding directories for the Soccer and the Weapons dataset are in the [data folder](https://github.com/sgottsch/Tab2KG/tree/main/data/datasets). Unfortunately, the GitHub default license does not allow distribution of public repositories (https://help.github.com/en/github/creating-cloning-and-archiving-repositories/licensing-a-repository#choosing-the-right-license). Thus, we can not share our GitHub dataset. As we can not share this, we provide the scripts for creating them yourself. \nTo create datasets yourself, run the following processes: \n",
                    "original_header": "Datasets"
                },
                "confidence": 0.9345189593981473,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/sgottsch/Tab2KG/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We compare to T2KMatch (https://github.com/olehmberg/T2KMatch) and https://github.com/olehmberg/T2KMatch.\nFor the latter, we have edited the code to make it applicable in the Tab2KG setting. The edited code is available in src/main/python/baselines/dsl. \n",
                    "original_header": "Baselines"
                },
                "confidence": 0.9999993739529854,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/sgottsch/Tab2KG/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-02-12T03:24:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-05T12:04:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 596468
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 117996
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 21408
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "72": {
        "filename": "minjiyoon_MMGL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Create a new conda environment, install [PyTorch](https://pytorch.org) and the remaining requirements:\n```\nconda create python==3.7 -n mmgl\nconda activate mmgl\npip install -r requirements.txt\npip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117\n```\nThe code is implemented on PyTorch DistributedDataParallel.\nThe code supports the [WikiWeb2M](https://github.com/google-research-datasets/wit/blob/main/wikiweb2m.md) dataset.\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "Multimodal Graph Learning"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/minjiyoon/MMGL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "First, make a folder to download the WikiWeb2M dataset: `mkdir wikiweb2m/raw`.\nThen download all Train/Validation/Test files from the WikiWeb2M into `wikiweb2m/raw`.\nNext, make a folder to download images: `mkdir wikiweb2m/raw/images`.\nFinally, run `preprocess_data.py` to convert the WikiWeb2M dataset into pytorch format.\n```\npython preprocess_data.py\n```\n \n",
                    "original_header": "Data preprocessing"
                },
                "confidence": 0.999999869872974,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/minjiyoon/MMGL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-10-12T17:00:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-13T16:38:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 147076
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 820
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "73": {
        "filename": "Dimosts_ActiveConLearn_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "- **Paper**: [Guided Bottom-Up Interactive Constraint Acquisition](https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CP.2023.36)\n- **Authors**: Dimosthenis C. Tsouros, Senne Berden, Tias Guns\n- **Conference**: 29th International Conference on Principles and Practice of Constraint Programming (CP 2023)\n",
                    "type": "Text_excerpt",
                    "original_header": "Guided Bottom-Up Interactive Constraint Acquisition (CP2023)",
                    "parent_header": [
                        "Active Constraint Acquisition",
                        "Implemented Algorithms"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Dimosts/ActiveConLearn/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-07-11T09:21:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-23T17:40:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 249239
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 17610
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 17085
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 2218
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "74": {
        "filename": "ValerioB88_gestalt-DNNs_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-03-31T09:32:06Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-04-20T16:21:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 257576
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "75": {
        "filename": "conormuldoon_unison_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "If using GeoDB (Unison is configured for GeoDB in this repository), stop the server if it is in use.\n```\ncd back-end\n```\nIf not previously packaged: `./mvnw clean compile package`\nBASH2* \nEnter the user credentials (if the user name already exists, the password will be updated). \nAlternatively, the API can be used to add users or update passwords.\n \n",
                    "original_header": "Adding additional users"
                },
                "confidence": 0.9970926492553404,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/conormuldoon/unison/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```\ncd back-end\n./mvnw clean compile test\n```\nTo generate a coverage report:\nBASH2*\nThe coverage report will be located in the `back-end/target/site/jacoco` directory.\n \n",
                    "original_header": "Back-end"
                },
                "confidence": 0.9899571003437224,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/conormuldoon/unison/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```\ncd front-end\nyarn test\n```\nFor existing coverage of all files, watch needs to be disabled (see https://github.com/facebook/create-react-app/issues/6888).\nBASH2*\nThe coverage report will be located in the `front-end/coverage/locv-report` directory.\n \n",
                    "original_header": "Front-end"
                },
                "confidence": 0.9999992155013566,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/conormuldoon/unison/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-09-06T20:16:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-02T09:44:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 275537
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TypeScript",
                    "name": "TypeScript",
                    "type": "Programming_language",
                    "size": 92779
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 9615
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 9588
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 2533
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 2006
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1879
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1352
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "76": {
        "filename": "pellierd_pddl4j_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2014-12-10T12:49:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-19T13:30:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "PDDL",
                    "name": "PDDL",
                    "type": "Programming_language",
                    "size": 441035442
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 1605841
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 9824
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 1645
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "77": {
        "filename": "BioinformaticsIASBS_LCS-DSclassification_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To run the code in windows, do the following instruction: \n1. extract datasets and code in the same folder\n2. open cmd in the corresponding folder\n3. type the following command in cmd: python UB-HH.py \"dataset name\" \"beam width\" \n",
                    "original_header": "Longest Common Substring in Longest Common Subsequence's Solution Service: A Novel Hyper-Heuristic"
                },
                "confidence": 0.9870120326082199,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/BioinformaticsIASBS/LCS-DSclassification/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-10-13T08:11:20Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-07-10T08:58:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 3584422
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 30796
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "78": {
        "filename": "potassco_clingraph_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-12-07T08:36:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-02T12:15:26Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 85887
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 46795
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "79": {
        "filename": "neurosynth_neurosynth_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Dependencies:\n\n* NumPy/SciPy\n* pandas\n* NiBabel\n* [ply](http://www.dabeaz.com/ply/)\n* scikit-learn\n\nWe recommend installing the core scientific packages (NumPy, SciPy, pandas, sklearn) via a distribution like [https://store.continuum.io/cshop/anaconda/](Anaconda), which will keep clutter and conflicts to a minimum. The other packages can be installed with pip using the requirements file:\n\n\t> pip install -r requirements.txt\n\nOr by name:\n\n\t> pip install nibabel ply\n\nAssuming you have those packages in working order, the easiest way to install Neurosynth is from the command line with pip:\n\n\t> pip install neurosynth\n\nAlternatively, if you want the latest development version, you can install directly from the github repo:\n\n\t> pip install -e git+https://github.com/neurosynth/neurosynth.git#egg=neurosynth\n\nDepending on your operating system, you may need superuser privileges (prefix the above line with 'sudo').\n\nThat's it! You should now be ready to roll.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "What is Neurosynth?"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/neurosynth/neurosynth/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* [![tests status](https://secure.travis-ci.org/neurosynth/neurosynth.png?branch=master)](https://travis-ci.org/neurosynth/neurosynth) travis-ci.org (master branch) \n",
                    "original_header": "Code status"
                },
                "confidence": 0.9871434409260736,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/neurosynth/neurosynth/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2011-06-20T16:04:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-12T18:50:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 150431
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1390
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "80": {
        "filename": "Grottoh_WTA-Network_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-05-04T12:36:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-12-15T12:06:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 207658
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "81": {
        "filename": "guochengqian_TNAS_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```\ngit clone git@github.com:guochengqian/TNAS.git \ncd TNAS\nsource env_install.sh\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Install",
                    "parent_header": [
                        "TNAS"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/guochengqian/TNAS/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```\nCUDA_VISIBLE_DEVICES=0 python exps/NATS-algos/search-cell-tnas.py --cfg cfgs/search_cell/tnas.yaml\n\nsbatch --array=0-4 --time=5:00:00 a100_tnas_alpha.sh cfgs/search_cell/tnas_warmup.yaml d_a=4\n``` \n",
                    "original_header": "Search on NAS-Bench-201"
                },
                "confidence": 0.9180264360618713,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/guochengqian/TNAS/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-04-11T07:19:15Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-10T07:46:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1692665
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 552191
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 61169
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Vim Script",
                    "name": "Vim Script",
                    "type": "Programming_language",
                    "size": 2148
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "82": {
        "filename": "Mi-Peng_Systematic-Investigation-of-Sparse-Perturbed-Sharpness-Aware-Minimization-Optimizer_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "<details open>\n<summary>  Clone this repo  </summary>\n\n```bash\ngit clone git@github.com:Mi-Peng/Systematic-Investigation-of-Sparse-Perturbed-Sharpness-Aware-Minimization-Optimizer.git\n```\n</details>\n\n<details open>\n<summary>  Create a virtual environment (e.g. Anaconda3) </summary>\n\n```bash\nconda create -n ssam python=3.8 -y\nconda activate ssam\n```\n</details>\n\n<details open>\n<summary> Install the necessary packages </summary>\n\n1. Pytorch\n\nInstall Pytorch following the [official installation instructions](https://pytorch.org/get-started/locally/).\n\n```bash\nconda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch -y\n```\n\n2. cusparseLt\n\nDetails could be found in [cusparseLt.md](cusparseLt.md)\n\n3. Install other packages\n```bash\npip install einops\n```\n\n4. Install wandb(optional)\n\n[Wandb](https://wandb.ai/site) makes it easy to track your experiments, manage & version your data. This is optional, codes run without wandb.\n```bash\npip install wandb\n```\n\n5. Dataset preparation\nWe use CIFAR10, CIFAR100 and ImageNet in this repo.\n\nFor the CIFAR dataset, you don't need to do anything, pytorch will do the trivia about downloading.\n\nFor ImageNet dataset, we use standard ImageNet dataset, which could be found in http://image-net.org/. Your ImageNet file structure should look like:\n\n```bash\n$ tree data\nimagenet\n\u251c\u2500\u2500 train\n\u2502   \u251c\u2500\u2500 class1\n\u2502   \u2502   \u251c\u2500\u2500 img1.jpeg\n\u2502   \u2502   \u251c\u2500\u2500 img2.jpeg\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 class2\n\u2502   \u2502   \u251c\u2500\u2500 img3.jpeg\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 val\n    \u251c\u2500\u2500 class1\n    \u2502   \u251c\u2500\u2500 img4.jpeg\n    \u2502   \u251c\u2500\u2500 img5.jpeg\n    \u2502   \u2514\u2500\u2500 ...\n    \u251c\u2500\u2500 class2\n    \u2502   \u251c\u2500\u2500 img6.jpeg\n    \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 ...\n```\n</details>\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Systematic-Investigation-of-Sparse-Perturbed-Sharpness-Aware-Minimization-Optimizer"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Mi-Peng/Systematic-Investigation-of-Sparse-Perturbed-Sharpness-Aware-Minimization-Optimizer/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-06-30T06:18:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-30T14:11:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 98424
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 72462
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 292
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "83": {
        "filename": "unitn-sml_wmi-pa_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Base version:\n\n```bash\npip install wmipa\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "WMI-PA"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/unitn-sml/wmi-pa/master/README.md"
            },
            {
                "result": {
                    "value": "To install all the mandatory and optional requirements, run\n\n```bash\nwmipa-install --all\n```\n\nand then add the following lines to the `~/.bashrc` file:\n\n```\nPATH=$HOME/.wmipa/latte/bin:$PATH\nPATH=$HOME/.wmipa/approximate-integration/bin:$PATH\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "All-in-one installation",
                    "parent_header": [
                        "WMI-PA",
                        "Installation",
                        "Additional requirements"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/unitn-sml/wmi-pa/master/README.md"
            },
            {
                "result": {
                    "value": "If you want to install the requirements separately, you can use the following commands.\n\nAt least one following integration backend is needed:\n\n* [LattE integrale](https://www.math.ucdavis.edu/~latte/) - Exact integration (recommended):\n  ```bash\n  wmipa-install --latte\n  ```\n  Add `$HOME/latte/bin` to the PATH environment variable by adding the following line to the `~/.bashrc` file:\n  ```\n  PATH=$HOME/.wmipa/latte/bin:$PATH\n  ```\n\n* [VolEsti](https://github.com/masinag/approximate-integration) - Approximated integration:\n  ```bash\n  wmipa-install --volesti\n  ```\n  Add `bin` to the PATH environment variable by adding the following line to the `~/.bashrc` file:\n  ```\n  PATH=$HOME/.wmipa/approximate-integration/bin:$PATH\n  ```\n\n* [PyXadd](https://github.com/weighted-model-integration/pywmi) - Symbolic integration:\n  ```bash\n  wmipa-install --symbolic\n  ```\n\nThe [MathSAT5](http://mathsat.fbk.eu/) SMT solver is required\n\n```bash\nwmipa-install --msat\n```\n\nTo support NRA theory (PI, Sin, Exp,\necc.), [a customized version of PySMT](https://github.com/masinag/pysmt/tree/nrat) must be installed via\n\n```bash\nwmipa-install --nra\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Separate installation",
                    "parent_header": [
                        "WMI-PA",
                        "Installation",
                        "Additional requirements"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/unitn-sml/wmi-pa/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-08-30T15:19:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-07T10:33:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 216744
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "84": {
        "filename": "Nv7-GitHub_googlesearch_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "To install, run the following command:\n```bash\npython3 -m pip install googlesearch-python\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "googlesearch"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Nv7-GitHub/googlesearch/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "proxy = 'http://API:@proxy.host.com:8080/' \n",
                    "original_header": "Additional options"
                },
                "confidence": 0.9983357021290624,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Nv7-GitHub/googlesearch/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-07-05T22:20:14Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T15:47:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 4815
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "85": {
        "filename": "huawei-noah_xingtian_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "#### Installation\n\n\n##### System Dependencies\n\n- OpenCV\n\n\n```shell\n# ubuntu 18.04\nsudo apt-get install python3-pip libopencv-dev -y\npip3 install opencv-python\n```\n\n##### Python Dependencies\n\n```shell\ncd rl\npip3 install -r requirements.txt\n\n# install with pip \npip3 install -e . \n```\n\n> Note: XingTian only tested  with Tensorflow 1.15.0 & 2.3.1. Other versions may have unknown problems. Please let us know if there are any problems. \n\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/huawei-noah/xingtian/master/docs/install.md"
            },
            {
                "result": {
                    "value": "```zsh\n# cd PATH/TO/XingTian \npip3 install -e .\n```\n\nAfter installation, you could use `import xt; print(xt.__Version__)`  to check whether the installation is successful. \n\n```python\nIn [1]: import xt\n\nIn [2]: xt.__version__\nOut[2]: '0.3.0'\n```\n\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/huawei-noah/xingtian/master/README.md"
            },
            {
                "result": {
                    "value": "Follow's configuration shows a minimal example with [Cartpole](https://gym.openai.com/envs/CartPole-v0/) environment. \nMore detailed description with the parameters of agent, algorithm and environment could been find in the [User guide](./docs/user.en.md) . \n\n\n```yaml\nalg_para:\n  alg_name: PPO\n  alg_config:\n    process_num: 1\n    save_model: True  # default False\n    save_interval: 100\n\nenv_para:\n  env_name: GymEnv\n  env_info:\n    name: CartPole-v0\n    vision: False\n\nagent_para:\n  agent_name: PPO\n  agent_num : 1\n  agent_config:\n    max_steps: 200\n    complete_step: 1000000\n    complete_episode: 3550\n\nmodel_para:\n  actor:\n    model_name: PpoMlp\n    state_dim: [4]\n    action_dim: 2\n    input_dtype: float32\n    model_config:\n      BATCH_SIZE: 200\n      CRITIC_LOSS_COEF: 1.0\n      ENTROPY_LOSS: 0.01\n      LR: 0.0003\n      LOSS_CLIPPING: 0.2\n      MAX_GRAD_NORM: 5.0\n      NUM_SGD_ITER: 8\n      SUMMARY: False\n      VF_SHARE_LAYERS: False\n      activation: tanh\n      hidden_sizes: [64, 64]\n\nenv_num: 10\n```\n\nIn addition, your could find more configuration sets in [examples](./examples) directory.\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup configuration",
                    "parent_header": [
                        "Quick Start"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/huawei-noah/xingtian/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-08-15T14:13:06Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T07:14:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 2349406
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 235974
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 3150
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "86": {
        "filename": "liseda-lab_TrueWalks_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<img src=\"https://github.com/liseda-lab/TrueWalks/blob/main/TrueWalks.png\" width=\"450\"/> \n",
                    "original_header": "Overview"
                },
                "confidence": 0.9960866681266665,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/liseda-lab/TrueWalks/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To use TrueWalks embeddings as input to a random forest classifier, run the command:\n```\npython3 run_embedML.py  \n``` \nTo use TrueWalks embeddings to compute similarity, run the command:\n```\npython3 run_embedSS.py  \n``` \n",
                    "original_header": "Evaluation and Datasets"
                },
                "confidence": 0.9551722589195702,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/liseda-lab/TrueWalks/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-01-21T11:16:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-11-09T14:15:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 267493
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 38852
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 1309
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "87": {
        "filename": "Nanfeizhilu_FGS_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "88": {
        "filename": "lirmm_AHPRank_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "89": {
        "filename": "leandrocouto_sketch-learning_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-12-14T20:41:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-03-04T20:55:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "90": {
        "filename": "bjsmith_multi-objective-value-aggregation_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-11-30T03:15:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-07-28T21:12:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 34492688
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 770623
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 493509
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 151760
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 123916
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "R",
                    "name": "R",
                    "type": "Programming_language",
                    "size": 23321
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Perl",
                    "name": "Perl",
                    "type": "Programming_language",
                    "size": 9160
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 5030
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 2921
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 1782
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 952
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Raku",
                    "name": "Raku",
                    "type": "Programming_language",
                    "size": 727
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 530
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "M4",
                    "name": "M4",
                    "type": "Programming_language",
                    "size": 349
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "91": {
        "filename": "JianhaoChen-nju_PaTeCon_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "To get source code, run:\n\n```\ngit clone https://github.com/JianhaoChen-nju/PaTeCon.git\n```\n\nInstall requirements\n\n```shell\ncd PaTeCon\nconda create -n PaTeCon python=3.9\nconda activate PaTeCon\npip install -r requirements.txt\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "PaTeCon"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/JianhaoChen-nju/PaTeCon/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Our datasets WD50K, WD27M and FB37M can be downloaded in url [Google Drive URL](https://drive.google.com/drive/folders/1tFmSPK7RzYM1qVDlCB7d8vuk_pHwqYGV?usp=sharing). You can also find the original WD50k in https://github.com/dwslab/TeCoRe/tree/master/conf/resources/rockit. \nDownload all above files to PaTeCon/resource folder.\n \n",
                    "original_header": "Dataset"
                },
                "confidence": 0.950297828234619,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/JianhaoChen-nju/PaTeCon/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-01-17T05:25:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-05T07:14:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 546943
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 488026
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "92": {
        "filename": "eadietz_bst2asp_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-05-10T12:04:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-05-10T12:06:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 7327
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 2940
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 294
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "93": {
        "filename": "markopalangetic_FGAC_experiments_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You need to install Gurobi optimization solver. Using anaconda, you can do it with: \nconda config --add channels https://conda.anaconda.org/gurobi \nconda install gurobi \nYou will need to obtain the academic licence from Gurobi website which is for free. \n \n",
                    "original_header": "FGAC_experiments"
                },
                "confidence": 0.9781158268668247,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/markopalangetic/FGAC_experiments/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-05-10T19:00:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-05-10T19:06:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 96315
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "94": {
        "filename": "IDSIA_crepo_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The latest version of the Python package for CREPO can be installed from PyPI as follows.\n\n\n```python\n!pip install crepobenchmark\n```\n\nor from github source code:\n\n\n```python\n!pip install git+https://github.com/IDSIA-papers/crepo.git@main#\"subdirectory=src/python\"\n```\n\nImport the package.\n\n\n```python\nimport crepobenchmark as crb\n```\n\nIf you need to change the java binary used, the command\n\n```\ncrb.info.java_bin = \"/jdkpath/bin/java\"\n```\nwill make crepo use the java binary at `/jdkpath/bin/` instead of the default one.\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "CREPO: An Open Repository to Benchmark Credal Network Algorithms"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/IDSIA/crepo/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-01-12T11:36:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2021-08-27T08:05:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 181553
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 115570
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 11485
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "95": {
        "filename": "SUSTechGameAI_EngagementMetrics_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-05-31T07:58:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-10T13:56:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 2237252
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 118063
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 337
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "96": {
        "filename": "m4lvin_HasCacBDD_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2015-04-08T09:57:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-11-29T00:45:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 88950
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Haskell",
                    "name": "Haskell",
                    "type": "Programming_language",
                    "size": 31369
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 5107
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 522
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "97": {
        "filename": "Link-AGI_AutoAgents_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "### Installation\n\n```bash\ngit clone https://github.com/LinkSoul-AI/AutoAgents\ncd AutoAgents\npython setup.py install\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "AutoAgents: A Framework for Automatic Agent Generation",
                        "Installation and Usage"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Link-AGI/AutoAgents/main/README.md"
            },
            {
                "result": {
                    "value": "- Configure your `OPENAI_API_KEY` in any of `config/key.yaml / config/config.yaml / env`\n- Priority order: `config/key.yaml > config/config.yaml > env`\n\n```bash\n# Copy the configuration file and make the necessary modifications.\ncp config/config.yaml config/key.yaml\n```\n\n| Variable Name                              | config/key.yaml                           | env                                             |\n| ------------------------------------------ | ----------------------------------------- | ----------------------------------------------- |\n| OPENAI_API_KEY # Replace with your own key | OPENAI_API_KEY: \"sk-...\"                  | export OPENAI_API_KEY=\"sk-...\"                  |\n| OPENAI_API_BASE # Optional                 | OPENAI_API_BASE: \"https://<YOUR_SITE>/v1\" | export OPENAI_API_BASE=\"https://<YOUR_SITE>/v1\" |\n",
                    "type": "Text_excerpt",
                    "original_header": "Configuration",
                    "parent_header": [
                        "AutoAgents: A Framework for Automatic Agent Generation",
                        "Installation and Usage"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Link-AGI/AutoAgents/main/README.md"
            },
            {
                "result": {
                    "value": "- Build docker image:\n```bash\nIMAGE=\"linksoul.ai/autoagents\"\nVERSION=1.0\n\ndocker build -f docker/Dockerfile -t \"${IMAGE}:${VERSION}\" .\n```\n- Start docker container:\n```bash\ndocker run -it --rm -p 7860:7860 \"${IMAGE}:${VERSION}\"\n```\n- Open http://127.0.0.1:7860 in the browser.\n",
                    "type": "Text_excerpt",
                    "original_header": "Docker",
                    "parent_header": [
                        "AutoAgents: A Framework for Automatic Agent Generation",
                        "Installation and Usage"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Link-AGI/AutoAgents/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<p align=\"center\">\n<a href=\"https://arxiv.org/abs/2309.17288\"><img src=\"https://img.shields.io/badge/cs.CV-2309.17288-b31b1b?logo=arxiv&logoColor=red\" alt=\"Paper\"></a>\n<a href=\"docs/README_CN.md\"><img src=\"https://img.shields.io/badge/\u6587\u6863-\u4e2d\u6587\u7248-blue.svg\" alt=\"CN doc\"></a>\n<a href=\"README.md\"><img src=\"https://img.shields.io/badge/document-English-blue.svg\" alt=\"EN doc\"></a>\n<a href=\"docs/README_JA.md\"><img src=\"https://img.shields.io/badge/\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8-\u65e5\u672c\u8a9e-blue.svg\" alt=\"JA doc\"></a>\n<a href=\"https://opensource.org/licenses/MIT\"><img src=\"https://img.shields.io/badge/License-MIT-yellow.svg\" alt=\"License: MIT\"></a>\n</p> \n",
                    "original_header": "AutoAgents: A Framework for Automatic Agent Generation"
                },
                "confidence": 0.9999999999784563,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Link-AGI/AutoAgents/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-08-21T12:19:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T08:10:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 194774
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 127613
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 16034
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 15816
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 3961
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1104
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "98": {
        "filename": "cmu-phil_grasp_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://github.com/cmu-phil/causal-learn\n \n",
                    "original_header": "Python Translation"
                },
                "confidence": 0.9989149961985547,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/grasp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://github.com/cmu-phil/causal-cmd-python-wrapper\n \n",
                    "original_header": "Command-line Tool"
                },
                "confidence": 0.9995398022346715,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/grasp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://cmu.box.com/s/h2e6ab9a62u2yu7kytg5ejsbyijsoc1u \n",
                    "original_header": "Simulation Datasets"
                },
                "confidence": 0.9964132914474156,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/grasp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://github.com/cmu-phil/grasp/blob/main/files/grasp_results.zip \nhttps://github.com/cmu-phil/grasp/blob/main/files/grasp_results_comparing_to_true_CPDAG.zip \n",
                    "original_header": "Simulation Results"
                },
                "confidence": 0.9989792475044731,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/grasp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The 4-node ground truth models may be downloaded from their source as referenced in our paper.\nThe 5-node path-canceling models in Appendix F may be downloaded from this repository\nin this file: \nhttps://github.com/cmu-phil/grasp/blob/main/files/udags5.zip\n \n",
                    "original_header": "Ground truth Independence Models (IMs)"
                },
                "confidence": 0.963693995996617,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/grasp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://github.com/cmu-phil/example-causal-datasets \n",
                    "original_header": "Real Datasets Repository"
                },
                "confidence": 0.9974380540981147,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/grasp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "A slide presentation for these may be downloaded from this repository, here: \nhttps://github.com/cmu-phil/grasp/blob/main/files/SomeRealDataExamplesForGrasp.pdf \n",
                    "original_header": "PC/FGES/GRaSP2/SP on a subset of these real datasets."
                },
                "confidence": 0.9797071060285808,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/grasp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://github.com/cmu-phil/tetrad \nhttps://github.com/cmu-phil/tetrad/tree/grasp-pub \nhttps://github.com/cmu-phil/tetrad/blob/grasp-pub/tetrad-lib/src/main/java/edu/cmu/tetrad/search/Grasp.java \nhttps://github.com/cmu-phil/tetrad/blob/grasp-pub/tetrad-lib/src/main/java/edu/cmu/tetrad/search/TeyssierScorer.java \nTetrad uses Maven to build the project, which is easily set up in the IntelliJ app, nere: \nhttps://www.jetbrains.com/idea/ \nInstructions for setting up the project in IntelliJ may be found in the Wiki for the Tetrad project, here: \nhttps://github.com/cmu-phil/tetrad/wiki/Setting-up-Tetrad-in-IntelliJ-IDEA\n \n",
                    "original_header": "Code"
                },
                "confidence": 0.9912394584479438,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/grasp/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The Tetrad app build used to generate the examples above is in the Maven Cental Repository and may be downloaded using this link: \nhttps://s01.oss.sonatype.org/content/repositories/releases/io/github/cmu-phil/tetrad-gui/7.1.0/tetrad-gui-7.1.0-launch.jar \nTo launch the Tetrad app, install a Java JDK (default version 1.8), then type in a terminal window: \njava -Xmx[#gigbates-ram]g -jar [path-to-the-above-jar-file].jar \n",
                    "original_header": "Tetrad Jar"
                },
                "confidence": 0.9772041717136611,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/grasp/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-02-17T22:00:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-10-15T12:48:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "99": {
        "filename": "MR-BENjie_IDRL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The training code is designed for GPUs, thus, you need to first install CUDA.\n\nFirst, Make sure you have python 3.6+ installed. Install dependencies.\n```\ncd IDRL_in_Red_10\npip3 install -r requirements.txt\n```\n\nThen, the Red_10 game environment should be installed. The detail information is in the directory \"IDRL_in_Red_10/IDRL/env/rlcard_red10\"\n",
                    "type": "Text_excerpt",
                    "original_header": "installation",
                    "parent_header": [
                        "IDRL",
                        "Red-10 environment with evaluation and visualization tool",
                        "Red_10 game environment"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/MR-BENjie/IDRL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<img width=\"500\" src=\"https://github.com/MR-BENjie/IDRL/raw/main/over_all_framework.jpg\"/> \n",
                    "original_header": "IDRL Implementation in the Red-10 Game"
                },
                "confidence": 0.9686057197667647,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/MR-BENjie/IDRL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To use GPU for training policy module, run\n```\npython3 train.py\n```\nThis will train several policy sets of policy module on one GPU. To train on multiple GPUs. Use the following arguments.\nBASH2* \nFor example, if we have 4 GPUs, where we want to use the first 3 GPUs to have 15 actors each for simulating and the 4th GPU for training, we can run the following command:\n```\npython3 train.py --gpu_devices 0,1,2,3 --num_actor_devices 3 --num_actors 15 --training_device 3\n``` \n",
                    "original_header": "Training"
                },
                "confidence": 0.972328292145711,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/MR-BENjie/IDRL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```\npython3 evaluate.py\n```\nSome important hyperparameters are list below.\nBASH2*\n \n",
                    "original_header": "step two: self-play"
                },
                "confidence": 0.9914666243426976,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/MR-BENjie/IDRL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "#### installation \nMake sure you have installed **Python 3.6+** and **pip**. \nInstalled rlcard using pip.\n```\npip3 install rlcard\n```\nThe default installation will only include the card environments. To use PyTorch implementation of the training algorithms, run\nBASH2* \nThen installed with\n```\ncd Red_10\npip3 install -e .\npip3 install -e .[torch]\n```\n \n",
                    "original_header": "Red_10 game environment"
                },
                "confidence": 0.9999994976412436,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/MR-BENjie/IDRL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-11-11T11:09:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-11-11T11:10:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 925416
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 341544
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 207743
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 31559
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "SCSS",
                    "name": "SCSS",
                    "type": "Programming_language",
                    "size": 31334
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 7033
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 2764
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 1594
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 518
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "100": {
        "filename": "openai_miniF2F_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To install the project make sure you have [elan](https://github.com/leanprover/elan) installed,\nthen in the directory where you want the project installed run:\n```\ngit clone https://github.com/openai/miniF2F\ncd miniF2F\nleanpkg configure\nleanpkg build\n```\n \nPlease use `lean/scripts/lint_style.py` to check all the statements pass the linter. You can also\nmake use of `lean/scripts/simple_formatter.sh` to enforce a few basic formatting rules. \n",
                    "original_header": "Lean"
                },
                "confidence": 0.9810055955335628,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openai/miniF2F/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- Version: `v1`\n- Freeze date: August 2021\n- Branch: [v1](https://github.com/openai/miniF2F/tree/v1)\n \n",
                    "original_header": "Active version"
                },
                "confidence": 0.9427574051339581,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openai/miniF2F/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-05-04T09:46:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-16T07:09:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Objective-C++",
                    "name": "Objective-C++",
                    "type": "Programming_language",
                    "size": 173070
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Isabelle",
                    "name": "Isabelle",
                    "type": "Programming_language",
                    "size": 160721
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Lean",
                    "name": "Lean",
                    "type": "Programming_language",
                    "size": 101343
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "OCaml",
                    "name": "OCaml",
                    "type": "Programming_language",
                    "size": 34002
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Standard ML",
                    "name": "Standard ML",
                    "type": "Programming_language",
                    "size": 11527
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 11025
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1136
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "101": {
        "filename": "MBZUAI-nlp_Bactrian-X_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "conda create -n bactrian python=3.9\nconda activate bactrian\npip install -r requirements.txt\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Setting up the Environment",
                    "parent_header": [
                        "align=\"center\"> <p>\ud83d\udc2b MBZUAI Bactrian-X</p>",
                        "Hands-on Bactrian-X"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/MBZUAI-nlp/Bactrian-X/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We curate our [Bactrian instruction dataset](https://huggingface.co/datasets/MBZUAI/Bactrian-X) with the following steps: \n",
                    "original_header": "Dataset"
                },
                "confidence": 0.9548563108200373,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/MBZUAI-nlp/Bactrian-X/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-04-24T10:35:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-31T02:06:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 37658
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 3171
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "102": {
        "filename": "caoysh_GALOIS_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "103": {
        "filename": "cruiseresearchgroup_i-align_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-07-14T05:19:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-08-31T03:42:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 38325
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "104": {
        "filename": "DeepGraphLearning_KnowledgeGraphEmbedding_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For example, this command train a RotatE model on FB15k dataset with GPU 0.\n```\nCUDA_VISIBLE_DEVICES=0 python -u codes/run.py --do_train \\\n --cuda \\\n --do_valid \\\n --do_test \\\n --data_path data/FB15k \\\n --model RotatE \\\n -n 256 -b 1024 -d 1000 \\\n -g 24.0 -a 1.0 -adv \\\n -lr 0.0001 --max_steps 150000 \\\n -save models/RotatE_FB15k_0 --test_batch_size 16 -de\n```\n   Check argparse configuration at codes/run.py for more arguments and more details. \n    CUDA_VISIBLE_DEVICES=$GPU_DEVICE python -u $CODE_PATH/run.py --do_test --cuda -init $SAVE \n    bash run.sh train RotatE FB15k 0 0 1024 256 1000 24.0 1.0 0.0001 200000 16 -de \n",
                    "original_header": "RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space"
                },
                "confidence": 0.988470191900605,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/DeepGraphLearning/KnowledgeGraphEmbedding/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-01-23T18:21:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T04:34:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 36787
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 4697
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "105": {
        "filename": "ADLILog_ADLILog_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-03-22T15:36:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-11-17T09:09:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 77035
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "106": {
        "filename": "openai_Video-Pre-Training_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n> :page_facing_up: [Read Paper](https://cdn.openai.com/vpt/Paper.pdf) \\\n  :mega: [Blog Post](https://openai.com/blog/vpt) \\\n  :space_invader: [MineRL Environment](https://github.com/minerllabs/minerl) (note version 1.0+ required) \\\n  :checkered_flag: [MineRL BASALT Competition](https://www.aicrowd.com/challenges/neurips-2022-minerl-basalt-competition) \n",
                    "original_header": "Video-Pre-Training"
                },
                "confidence": 0.9948669722045831,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openai/Video-Pre-Training/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Setup:\n* Install requirements: `pip install -r requirements.txt`\n* Download `.weights` and `.model` file for model you want to fine-tune.\n* Download contractor data (below) and place the `.mp4` and `.jsonl` files to the same directory (e.g., `data`). With default settings, you need at least 12 recordings. \n",
                    "original_header": "Using behavioural cloning to fine-tune the models"
                },
                "confidence": 0.999999999978229,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openai/Video-Pre-Training/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "  This comes with a new recorder version 8.0 which you will need to update your recording script to download. \n  Since you will be unable to resume building after exiting Minecraft or going back to the main menu, you must finish these demonstrations in one session. Pausing via the menu is still supported. If you want to view your creations later, they will be saved locally so you can look at them in your own time. We may use these save files in a future task so if you have space, please leave the save files titled \u201cbuild-house-15-min-\u201c. \n  Changes:\n    * Timer ends episode after 10 realtime minutes\n    * Worlds are named: `\"build-house-15-min-\" + Math.abs(random.nextInt());` \n  * Note this version introduces 10-minute timer that ends the episode. It\n  cut experiments short occasionally and was fixed in 9.1\n  * 8.0 Simple House\n  * 8.2 Update upload script\n* **9.x** :clipboard: House Building from Random Starting Materials Task [:arrow_down: index](https://openaipublic.blob.core.windows.net/minecraft-rl/snapshots/all_9xx_Jun_29.json)\n    <details>\n    <summary>Changes and Prompt</summary> \n    You now will have 10 minutes to use the provided resources to build your house / home / or structure. In this version, the experiment will time out after 10 minutes if you are not complete so don't be alarmed if that happens, it is intentional. \n    Changes:\n    * Worlds are named: `\"design-house-10-min-\" + Math.abs(random.nextInt());`\n    * Starting inventory given by code below\n    </details> \n     * 9.0 First version\n     * 9.1 Fixed timer bug\n* **10.0** :clipboard: Obtain Diamond Pickaxe Task [:arrow_down: index](https://openaipublic.blob.core.windows.net/minecraft-rl/snapshots/all_10xx_Jun_29.json)\n  <details>\n  <summary>Changes and Prompt</summary>\n  Prompt: \n",
                    "original_header": "Versions"
                },
                "confidence": 0.9833926109802315,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openai/Video-Pre-Training/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Index files are provided for each version as a json file:\n```json\n{\n  \"basedir\": \"https://openaipublic.blob.core.windows.net/data/\",\n  \"relpaths\": [\n    \"8.0/cheeky-cornflower-setter-74ae6c2eae2e-20220315-122354\",\n    ...\n  ]\n}\n```\nRelative paths follow the following format:\n* `<recorder-version>/<contractor-alias>-<session-id>-<date>-<time>` \nYour data loader can then find following files:\n* Video observation: `<basedir>/<relpath>.mp4`\n* Action file: `<basedir>/<relpath>.jsonl`\n* Options file: `<basedir>/<relpath>-options.json`\n* Checkpoint save file: `<basedir>/<relpath>.zip` \n",
                    "original_header": "Data format"
                },
                "confidence": 0.9936127194975345,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openai/Video-Pre-Training/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "    ```\n    Look around for a cave. When you are inside one, quit the game by opening main menu and pressing \"Save and Quit To Title\".\n    You are not allowed to dig down from the surface to find a cave.\n\n    Timelimit: 3 minutes.\n    Example recordings: https://www.youtube.com/watch?v=TclP_ozH-eg\n    ```\n    </details>\n* **MakeWaterfall** [:arrow_down: index file](https://openaipublic.blob.core.windows.net/minecraft-rl/snapshots/waterfall-Jul-28.json)\n  * <details>\n    <summary>Prompt to contractors (click to show)</summary> \n    ```\n    After spawning in a village, build an animal pen next to one of the houses in a village. Use your fence posts to build one animal pen that contains at least two of the same animal. (You are only allowed to pen chickens, cows, pigs, sheep or rabbits.) There should be at least one gate that allows players to enter and exit easily. The animal pen should not contain more than one type of animal. (You may kill any extra types of animals that accidentally got into the pen.) Don\u2019t harm the village.\n    After you are done, quit the game by opening the menu and pressing \"Save and Quit to Title\".\n\n    You may need to terraform the area around a house to build a pen. When we say not to harm the village, examples include taking animals from existing pens, damaging existing houses or farms, and attacking villagers. Animal pens must have a single type of animal: pigs, cows, sheep, chicken or rabbits.\n\n    The food items can be used to lure in the animals: if you hold seeds in your hand, this attracts nearby chickens to you, for example.\n\n    Timelimit: 5 minutes.\n    Example recordings: https://youtu.be/SLO7sep7BO8\n    ```\n    </details>\n* **BuildVillageHouse** [:arrow_down: index file](https://openaipublic.blob.core.windows.net/minecraft-rl/snapshots/build-house-Jul-28.json)\n  * <details>\n    <summary>Prompt to contractors (click to show)</summary> \n",
                    "original_header": "BASALT 2022 dataset"
                },
                "confidence": 0.9900850075451804,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openai/Video-Pre-Training/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-06-22T18:06:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T22:20:21Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 148825
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "107": {
        "filename": "librahu_HIN-Datasets-for-Recommendation-a_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "108": {
        "filename": "IyarLin_simMixedDAG_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2019-07-21T13:31:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-04-10T07:33:15Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "R",
                    "name": "R",
                    "type": "Programming_language",
                    "size": 22995
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "109": {
        "filename": "tensorflow_agents_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "TF-Agents publishes nightly and stable builds. For a list of releases read the\n<a href='#Releases'>Releases</a> section. The commands below cover installing\nTF-Agents stable and nightly from [pypi.org](https://pypi.org) as well as from a\nGitHub clone.\n\n> :warning: If using Reverb (replay buffer), which is very common,\nTF-Agents will only work with Linux.\n\n> Note: Python 3.11 requires pygame 2.1.3+.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning."
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"
            },
            {
                "result": {
                    "value": "Run the commands below to install the most recent stable release. API\ndocumentation for the release is on\n[tensorflow.org](https://www.tensorflow.org/agents/api_docs/python/tf_agents).\n\n```shell\n$ pip install --user tf-agents[reverb]\n\n# Use keras-2\n$ export TF_USE_LEGACY_KERAS=1\n# Use this tag get the matching examples and colabs.\n$ git clone https://github.com/tensorflow/agents.git\n$ cd agents\n$ git checkout v0.18.0\n```\n\nIf you want to install TF-Agents with versions of Tensorflow or\n[Reverb](https://github.com/deepmind/reverb) that are flagged as not compatible\nby the pip dependency check, use the following pattern below at your own risk.\n\n```shell\n$ pip install --user tensorflow\n$ pip install --user tf-keras\n$ pip install --user dm-reverb\n$ pip install --user tf-agents\n```\n\nIf you want to use TF-Agents with TensorFlow 1.15 or 2.0, install version 0.3.0:\n\n```shell\n# Newer versions of tensorflow-probability require newer versions of TensorFlow.\n$ pip install tensorflow-probability==0.8.0\n$ pip install tf-agents==0.3.0\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Stable",
                    "parent_header": [
                        "TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"
            },
            {
                "result": {
                    "value": "Nightly builds include newer features, but may be less stable than the versioned\nreleases. The nightly build is pushed as `tf-agents-nightly`. We suggest\ninstalling nightly versions of TensorFlow (`tf-nightly`) and TensorFlow\nProbability (`tfp-nightly`) as those are the versions TF-Agents nightly are\ntested against.\n\nTo install the nightly build version, run the following:\n\n```shell\n# Use keras-2\n$ export TF_USE_LEGACY_KERAS=1\n\n# `--force-reinstall helps guarantee the right versions.\n$ pip install --user --force-reinstall tf-nightly\n$ pip install --user --force-reinstall tf-keras-nightly\n$ pip install --user --force-reinstall tfp-nightly\n$ pip install --user --force-reinstall dm-reverb-nightly\n\n# Installing with the `--upgrade` flag ensures you'll get the latest version.\n$ pip install --user --upgrade tf-agents-nightly\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Nightly",
                    "parent_header": [
                        "TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"
            },
            {
                "result": {
                    "value": "After cloning the repository, the dependencies can be installed by running `pip\ninstall -e .[tests]`. TensorFlow needs to be installed independently: `pip\ninstall --user tf-nightly`.\n\n<a id='Contributing'></a>\n",
                    "type": "Text_excerpt",
                    "original_header": "From GitHub",
                    "parent_header": [
                        "TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/tensorflow/agents/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-11-17T00:29:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T03:23:21Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 5054383
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 10295
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "110": {
        "filename": "potassco_plingo_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```\nconda install -c potassco plingo\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "With coda",
                    "parent_header": [
                        "Plingo",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/potassco/plingo/main/README.md"
            },
            {
                "result": {
                    "value": "```\npip install plingo\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "With pip",
                    "parent_header": [
                        "Plingo",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/potassco/plingo/main/README.md"
            },
            {
                "result": {
                    "value": "```\ngit clone https://github.com/potassco/plingo.git\ncd plingo\npip install .\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "From source",
                    "parent_header": [
                        "Plingo",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/potassco/plingo/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-05-10T20:08:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-24T15:26:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 54940
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "111": {
        "filename": "ontologyportal_sumo_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The main site for SUMO is https://www.ontologyportal.org \nLocal installation of SigmaKEE and SUMOjEdit is recommended when developing extensions to SUMO. \n"
                },
                "confidence": 0.9876335087886834,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ontologyportal/sumo/master/README.txt"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2015-09-06T23:01:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T21:08:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 12279
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 4088
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "sed",
                    "name": "sed",
                    "type": "Programming_language",
                    "size": 201
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "112": {
        "filename": "steve30572_DPAO_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```\ncd NonKG\npython main.py --dataset Gowalla\n```\n \n",
                    "original_header": "Gowalla"
                },
                "confidence": 0.9785770442900742,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/steve30572/DPAO/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "``` \ncd NonKG\npython main.py --dataset ml-1m\n```\n##### Amazon-Book\nBASH2*\n \n",
                    "original_header": "MovieLens1M"
                },
                "confidence": 0.9724685369709498,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/steve30572/DPAO/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-10-11T13:06:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-12-24T14:03:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 395536
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 6502
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 6
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "113": {
        "filename": "yohayt_RAR_EUMAS2022_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-08-09T11:42:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-08-09T11:42:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "114": {
        "filename": "PlaytikaResearch_public_waterfall2_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-01-14T10:33:06Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-08-29T02:06:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 81488
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "115": {
        "filename": "usail-hkust_Meta-Pec_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* Python=3.7\n* PyTorch=1.13.0\n* numpy=1.21.6\n* learn2learn=0.1.7\n \n",
                    "original_header": "Environment"
                },
                "confidence": 0.9965352829699087,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/usail-hkust/Meta-Pec/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-02-02T15:01:26Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-10-30T16:51:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 33249
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "116": {
        "filename": "banbaralab_recongo_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-07-05T07:24:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-05T08:55:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 7330
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "117": {
        "filename": "mana-ysh_knowledge-graph-embeddings_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2017-09-12T22:17:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-03T00:18:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 62050
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 683
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "118": {
        "filename": "qwerasdfzxcv852_demo-Lepus_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-02-14T02:14:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-05-27T03:10:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "119": {
        "filename": "wilrop_distributional-dominance_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-01-02T13:10:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-05-09T10:09:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 108216
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 10883
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "120": {
        "filename": "Shereen-Elsayed_ImgRec_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Requirements*\n1- numpy\n2- pandas\n3- tensorflow 2.3.0 \n4- scikit-learn \nTo run any of the scripts it is required to check the \"data path\" of the required file, then\nrunning command is ==> python file_name e.g. \"python imgrec_amazon_fashion_ResNetFeatures_FT.py\" \n",
                    "original_header": "ImgRec"
                },
                "confidence": 0.995596448751867,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Shereen-Elsayed/ImgRec/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-09-05T12:51:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-07-29T08:43:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 89011
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "121": {
        "filename": "KMY-SEU_HCE_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The main requirements on Python 3.6 is as follows:   \nnumpy == 1.19.5   \npandas == 1.1.5   \nscikit-learn == 0.24.2    \n",
                    "original_header": "HCE"
                },
                "confidence": 0.9989340864316852,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/KMY-SEU/HCE/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-08-01T02:48:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-09-01T01:25:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 675944
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cython",
                    "name": "Cython",
                    "type": "Programming_language",
                    "size": 4504
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "122": {
        "filename": "gpoesia_peano_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To compile it, you'll first need to install the Rust toolchain. For that, use [rustup](https://rustup.rs/). \nWith Rust installed, you can now compile the Peano environment:\n```sh\n[peano] $ cd environment\n[environment] $ cargo build --release\n```\nThis should eventually terminate without errors and produce a binary library\nin `target/release` (it will be called `libpeano.so` on Linux, or something like `peano.dylib` on Mac).\nTo use this library as a Python module, we'll use a simple symbolic link:\n```sh\n[environment] $ cd ../learning\n[learning] $ ln -s ../environment/target/release/libpeano.so ./peano.so\n```\n \nNote that this must be slightly adjusted on Mac (i.e., you'll link `peano.dylib` instead). With that, you should be able to do the following: \nIf this works, then you're ready to use Peano from Python. \nThe Python dependencies can be installed with:\n```sh\n[learning] $ pip install -r requirements.txt\n```\n \nWe use hydra for configuring the runs: the main configuration file to drive runs is `learning/config/trainer.yaml`.\nBy default, this config file will run an agent that (a) trains on all 5 Khan Academy domains at once (i.e., no curriculum),\nand (b) does tactic induction. This behavior can be changed in the config to run other ablations. \nTo run the default experiment, simply run:\n```sh\n[learning] $ python trainer.py ++trainer.n_searchers=1 ++trainer.gpus=[0]\n``` \n",
                    "original_header": "Compiling the environment"
                },
                "confidence": 0.9893609702476891,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/gpoesia/peano/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To get a concrete sense of the search problem that the agent is learning to solve, you can use the following command to interact with the environment yourself, choose a problem and pick actions until you solve it.\n```sh\n[learning] $ python interact.py --environment  --domain subst-eval\n```\nYou can type b to choose a problem, then the number of the problem. For example:\n```sh\n[learning] $ python interact.py --environment  --domain subst-eval\na) Type problem, b) select one from list, or Enter for debug mode: b\nPick a problem:\n[...]\n 2 -  (= x (+ -2 1))\n[...]\n\n> 2\n### Solution:\nG:(= x ?)\n(= x (+ -2 1))\nAction:\n 0 -  eval\n 1 -  rewrite\n> 0\n### Solution:\nG:(= x ?)\n(= x (+ -2 1))\neval:-###\nAction:\n 0 -  (= (+ -2 1) -1)\n> 0\n### Solution:\nG:(= x ?)\n(= x (+ -2 1))\neval:-(= (+ -2 1) -1)\nAction:\n 0 -  eval\n 1 -  rewrite\n> 1\n### Solution:\nG:(= x ?)\n(= x (+ -2 1))\neval:-(= (+ -2 1) -1)\nrewrite:-###\nAction:\n 0 -  (= (+ -2 1) (+ -2 1))\n 1 -  (= x -1)\n 2 -  (= -1 -1)\n> 1\nSolved in 4 steps!\nSolution:\n interactive: ?0 <- eval ?a@*; ?1 <- rewrite ?0, ?a@*\nArguments: [['equation@type@2'], ['!step0', 'equation@type@2']]\nProbability of this trajectory for a random policy: 0.08333333333333333\n```\n \n",
                    "original_header": "Play the policy yourself"
                },
                "confidence": 0.9999373552988382,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/gpoesia/peano/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-02-10T19:53:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-08T15:24:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 225896
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Rust",
                    "name": "Rust",
                    "type": "Programming_language",
                    "size": 146784
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "OpenEdge ABL",
                    "name": "OpenEdge ABL",
                    "type": "Programming_language",
                    "size": 26830
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "123": {
        "filename": "Lee-zix_CEN_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-03-16T02:40:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-02T13:32:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 151849
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "124": {
        "filename": "facebookresearch_EmpatheticDialogues_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To download the EmpatheticDialogues dataset:\n```\nwget https://dl.fbaipublicfiles.com/parlai/empatheticdialogues/empatheticdialogues.tar.gz\n```\n \n",
                    "original_header": "Dataset"
                },
                "confidence": 0.9999913327517989,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/facebookresearch/EmpatheticDialogues/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To reproduce paper numbers, see the evaluation commands in the Commands section, and use the following trained models:\n```\nwget https://dl.fbaipublicfiles.com/parlai/empatheticdialogues/models/normal_transformer_pretrained.mdl  # Normal Transformer, pretrained\nwget https://dl.fbaipublicfiles.com/parlai/empatheticdialogues/models/normal_transformer_finetuned.mdl  # Normal Transformer, fine-tuned\nwget https://dl.fbaipublicfiles.com/parlai/empatheticdialogues/models/bert_pretrained.mdl  # BERT, pretrained\nwget https://dl.fbaipublicfiles.com/parlai/empatheticdialogues/models/bert_finetuned.mdl  # BERT, fine-tuned\nwget https://dl.fbaipublicfiles.com/parlai/empatheticdialogues/models/bert_finetuned_emoprepend1.mdl  # BERT, fine-tuned (EmoPrepend-1)\nwget https://dl.fbaipublicfiles.com/parlai/empatheticdialogues/models/fasttext_empathetic_dialogues.mdl  # fastText classifier used for EmoPrepend-1\n```\n \n",
                    "original_header": "Models"
                },
                "confidence": 0.9999999999998863,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/facebookresearch/EmpatheticDialogues/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Add the following flags when calling `retrieval_train.py` or `retrieval_eval_bleu.py`:\n```\n--fasttext 1 \\\n--fasttext-path ${PATH_TO_TRAINED_FASTTEXT_MODEL} \\\n--fasttext-type emo\n```\nFor `${PATH_TO_TRAINED_FASTTEXT_MODEL}`, you can pass in the fastText classifier in the Models section above.\n \n",
                    "original_header": "EmoPrepend-1"
                },
                "confidence": 0.9994172289190434,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/facebookresearch/EmpatheticDialogues/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-06-17T23:15:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T09:04:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 81496
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "125": {
        "filename": "hill-a_stable-baselines_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "**Note:** Stable-Baselines supports Tensorflow versions from 1.8.0 to 1.14.0. Support for Tensorflow 2 API is planned.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Stable Baselines"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/hill-a/stable-baselines/master/README.md"
            },
            {
                "result": {
                    "value": "```bash\nsudo apt-get update && sudo apt-get install cmake libopenmpi-dev python3-dev zlib1g-dev\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Ubuntu",
                    "parent_header": [
                        "Stable Baselines",
                        "Installation",
                        "Prerequisites"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/hill-a/stable-baselines/master/README.md"
            },
            {
                "result": {
                    "value": "Installation of system packages on Mac requires [Homebrew](https://brew.sh). With Homebrew installed, run the following:\n```bash\nbrew install cmake openmpi\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Mac OS X",
                    "parent_header": [
                        "Stable Baselines",
                        "Installation",
                        "Prerequisites"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/hill-a/stable-baselines/master/README.md"
            },
            {
                "result": {
                    "value": "To install stable-baselines on Windows, please look at the [documentation](https://stable-baselines.readthedocs.io/en/master/guide/install.html#prerequisites).\n",
                    "type": "Text_excerpt",
                    "original_header": "Windows 10",
                    "parent_header": [
                        "Stable Baselines",
                        "Installation",
                        "Prerequisites"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/hill-a/stable-baselines/master/README.md"
            },
            {
                "result": {
                    "value": "Install the Stable Baselines package:\n```\npip install stable-baselines[mpi]\n```\n\nThis includes an optional dependency on MPI, enabling algorithms DDPG, GAIL, PPO1 and TRPO. If you do not need these algorithms, you can install without MPI:\n```\npip install stable-baselines\n```\n\nPlease read the [documentation](https://stable-baselines.readthedocs.io/) for more details and alternatives (from source, using docker).\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Install using pip",
                    "parent_header": [
                        "Stable Baselines",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/hill-a/stable-baselines/master/README.md"
            },
            {
                "result": {
                    "value": "All unit tests in baselines can be run using pytest runner:\n```\npip install pytest pytest-cov\nmake pytest\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Testing the installation",
                    "parent_header": [
                        "Stable Baselines"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/hill-a/stable-baselines/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Github repo: https://github.com/araffin/rl-baselines-zoo \nDocumentation: https://stable-baselines.readthedocs.io/en/master/guide/rl_zoo.html\n \n",
                    "original_header": "RL Baselines Zoo: A Collection of 100+ Trained RL Agents"
                },
                "confidence": 0.9998966780898568,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/hill-a/stable-baselines/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We try to maintain a list of project using stable-baselines in the [documentation](https://stable-baselines.readthedocs.io/en/master/misc/projects.html),\nplease tell us when if you want your project to appear on this page ;)\n \n",
                    "original_header": "Projects Using Stable-Baselines"
                },
                "confidence": 0.9953590649305923,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/hill-a/stable-baselines/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-07-02T14:28:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T13:51:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 994258
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2790
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1341
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 745
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "126": {
        "filename": "hwchase17_langchain_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "With pip:\n```bash\npip install langchain\n```\n\nWith conda:\n```bash\nconda install langchain -c conda-forge\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Quick Install",
                    "parent_header": [
                        "\ud83e\udd9c\ufe0f\ud83d\udd17 LangChain"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/hwchase17/langchain/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**\u2753 Question answering with RAG** \n",
                    "original_header": "\ud83e\uddf1 What can you build with LangChain?"
                },
                "confidence": 0.9020212554030128,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/hwchase17/langchain/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Components fall into the following **modules**: \n",
                    "original_header": "Components"
                },
                "confidence": 0.9337655521755545,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/hwchase17/langchain/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-10-17T02:58:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T09:37:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 31757364
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 19493270
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 67540
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "MDX",
                    "name": "MDX",
                    "type": "Programming_language",
                    "size": 56545
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 50289
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "XSLT",
                    "name": "XSLT",
                    "type": "Programming_language",
                    "size": 19446
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 9026
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 5137
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 2242
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 471
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "127": {
        "filename": "kenluck2001_anomalyMulti_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "pip install -r requirements.txt\n",
                    "type": "Text_excerpt",
                    "original_header": "How to install this package",
                    "parent_header": [
                        "anomalyMulti"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/kenluck2001/anomalyMulti/master/README.MD"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-04-05T05:16:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-05-10T06:42:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 12152
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "128": {
        "filename": "BerenMillidge_DeepActiveInference_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2019-08-14T19:52:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T12:39:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Julia",
                    "name": "Julia",
                    "type": "Programming_language",
                    "size": 171288
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "129": {
        "filename": "werner-duvaud_muzero-general_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```bash\ngit clone https://github.com/werner-duvaud/muzero-general.git\ncd muzero-general\n\npip install -r requirements.lock\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "MuZero General",
                        "Getting started"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/werner-duvaud/muzero-general/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<p align=\"center\">\n<a href=\"https://github.com/werner-duvaud/muzero-general/blob/master/docs/muzero-network-werner-duvaud.png\">\n<img src=\"https://github.com/werner-duvaud/muzero-general/blob/master/docs/muzero-network-werner-duvaud.png\" width=\"250\"/>\n</a>\n</p>\n \n",
                    "original_header": "Code structure"
                },
                "confidence": 0.9984880654267783,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/werner-duvaud/muzero-general/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-12-27T02:33:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-17T04:49:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 252225
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "130": {
        "filename": "zecevic-matej_Finding-Structure-and-Causality-in-Linear-Programs_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-02-24T20:12:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-04-01T15:26:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 130759
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "131": {
        "filename": "openai_gym_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "To install the base Gym library, use `pip install gym`.\n\nThis does not include dependencies for all families of environments (there's a massive number, and some can be problematic to install on certain systems). You can install these dependencies for one family like `pip install gym[atari]` or use `pip install gym[all]` to install all dependencies.\n\nWe support Python 3.7, 3.8, 3.9 and 3.10 on Linux and macOS. We will accept PRs related to Windows, but do not officially support it.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/openai/gym/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The Gym API's API models environments as simple Python `env` classes. Creating environment instances and interacting with them is very simple- here's an example using the \"CartPole-v1\" environment:\n```python\nimport gym\nenv = gym.make(\"CartPole-v1\")\nobservation, info = env.reset(seed=42)\n\nfor _ in range(1000):\n    action = env.action_space.sample()\n    observation, reward, terminated, truncated, info = env.step(action)\n\n    if terminated or truncated:\n        observation, info = env.reset()\nenv.close()\n```\n \n",
                    "original_header": "API"
                },
                "confidence": 0.9999999889625998,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openai/gym/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The latest \"\\_v4\" and future versions of the MuJoCo environments will no longer depend on `mujoco-py`. Instead `mujoco` will be the required dependency for future gym MuJoCo environment versions. Old gym MuJoCo environment versions that depend on `mujoco-py` will still be kept but unmaintained.\nTo install the dependencies for the latest gym MuJoCo environments use `pip install gym[mujoco]`. Dependencies for old MuJoCo environments can still be installed by `pip install gym[mujoco_py]`. \n \n",
                    "original_header": "MuJoCo Environments"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openai/gym/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2016-04-27T14:59:16Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T09:23:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1113386
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1016
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 484
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "132": {
        "filename": "NEU-DataMining_T-COL_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "133": {
        "filename": "hsu-aut_2UML_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "134": {
        "filename": "sisl_action_suggestions_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The development occurred using Julia v1.7 and v1.8. We recommend using the latest version of Julia. \n\nFirst, clone the repo, change to the main folder, and run Julia.\n```\ngit clone git@github.com:sisl/action_suggestions.git\ncd  action_suggestions\njulia\n```\n\nWe first need to activate the environment and include the supporting scripts. This process is scripted in [`setup.jl`](https://github.com/sisl/action_suggestions/blob/4b3834319cd86301a118fea0c62a66612e650c86/setup.jl). You can run this file by:\n```julia\njulia> include(\"setup.jl\")\n```\n\nThis repo contains polices and action value functions for RockSample(8, 4, 10, -1), Tag with the modified transition function, and the original implementation of Tag. You can start running those simulations immediately. Reference the Running Simulations section. To simulate the RockSample(7, 8, 20, 0) environment, you will need to generate the policy and action value matrix. Reference the [Generating Policies](#generating-policies) section for directions on completing that process. The problems are referenced using the `:rs84`, `:tag`, and `:tag_orig_tx` Symbols.  The RockSample(7, 8, 10, 0) problem has the `:rs78` Symbol defined and ready for use after a policy and action value matrix is generated.\n",
                    "type": "Text_excerpt",
                    "original_header": "Setting up the environment"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/sisl/action_suggestions/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-05-20T07:07:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-25T02:37:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Julia",
                    "name": "Julia",
                    "type": "Programming_language",
                    "size": 22503
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "135": {
        "filename": "leoprover_tptp-utils_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "You can use the pre-built executable .jar file (in the release section), without\nany other installation steps. \n\nYou may build `tptp-utils` from source: This requires a JDK and the scala build tool `sbt` in\na reasonably current version.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "tptp-utils"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/leoprover/tptp-utils/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-12-05T23:11:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-27T10:23:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Scala",
                    "name": "Scala",
                    "type": "Programming_language",
                    "size": 109795
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 458
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 221
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "136": {
        "filename": "Oschart_FLoBC_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "``` shell\n$ npm install express\n$ npm install \n````\n",
                    "type": "Text_excerpt",
                    "original_header": "Install the prerequisites",
                    "parent_header": [
                        "FLoBC: A Decentralized Blockchain-Based Federated Learning Framework",
                        "To Run the Tool",
                        "Using GUI"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Oschart/FLoBC/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-10-25T20:14:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-05T23:22:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Rust",
                    "name": "Rust",
                    "type": "Programming_language",
                    "size": 1443015
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 424345
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 242442
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "SCSS",
                    "name": "SCSS",
                    "type": "Programming_language",
                    "size": 167093
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 23343
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 22739
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 1918
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "137": {
        "filename": "GriddlyAI_escape-rooms_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "138": {
        "filename": "arminbiere_cadical_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Use `./configure && make` to configure and build `cadical` and the library\n`libcadical.a` in the default `build` sub-directory.  The header file of\nthe library is [`src/cadical.hpp`](src/cadical.hpp) and includes an example\nfor API usage.\n  \nSee [`BUILD.md`](BUILD.md) for options and more details related to the build\nprocess and [`test/README.md`](test/README.md) for testing the library and\nthe solver.  Since release 1.5.1 we have a [`NEWS.md`](NEWS.md) file.\nYou might also want to check out [`CONTRIBUTING.md`](CONTRIBUTING.md) on\nif you want to contribute. \n<p>\n<a\nhref=\"https://cca.informatik.uni-freiburg.de/papers/BiereFallerFazekasFleuryFroleyksPollitt-CAV24.pdf\">CaDiCaL\n2.0</a>\n<br>\n<a href=\"https://cca.informatik.uni-freiburg.de/biere\">Armin Biere</a>,\n<a href=\"https://cca.informatik.uni-freiburg.de/fallert\">Tobias Faller</a>,\n<a href=\"https://kfazekas.github.io\">Katalin Fazekas</a>,\n<a href=\"https://cca.informatik.uni-freiburg.de/fleury\">Mathias Fleury</a>,\n<a href=\"https://fmv.jku.at/froleyks\">Nils Froleyks</a> and\n<a href=\"https://cca.informatik.uni-freiburg.de/pollittf\">Florian Pollitt</a>\n<br>\n<i>\nProc.&nbsp;Computer Aidded Verification - 26th Intl.&nbsp;Conf.&nbsp;(CAV'24)</i>\n<br>\nLecture Notes in Computer Science (LNCS)\n<br>\nvol.&nbsp;14681,\npages 133-152,\nSpringer 2024\n<br>\n[ <a href=\"https://cca.informatik.uni-freiburg.de/papers/BiereFallerFazekasFleuryFroleyksPollitt-CAV24.pdf\">paper</a>\n| <a href=\"https://cca.informatik.uni-freiburg.de/papers/BiereFallerFazekasFleuryFroleyksPollitt-CAV24.bib\">bibtex</a>\n| <a href=\"https://cca.informatik.uni-freiburg.de/papers/BiereFallerFazekasFleuryFroleyksPollitt-CAV24-Springer.pdf\">official</a>\n| <a href=\"https://zenodo.org/records/10943125\">artifact</a>\n| <a href=\"https://github.com/arminbiere/cadical\">github</a>\n| <a href=\"https://doi.org/10.1007/978-3-031-37703-7\">doi</a>\n]\n</p>\n \n",
                    "original_header": "CaDiCaL Simplified Satisfiability Solver"
                },
                "confidence": 0.9937867506587104,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/arminbiere/cadical/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2016-08-17T11:32:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T01:33:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 1447609
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 159249
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 37501
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 944
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 904
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "139": {
        "filename": "alban-grastien_diagfwork_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* `antlr-3.2.jar`: used to parse input files.  Antlr\n  [https://www.antlr.org/] is a parser generator that transforms the\n  `*.g` files from the repository to java files.  Version 3.2 is an\n  old version.  Unfortunately, there seems to be incompatibilities\n  between this version and recent versions of Java, which makes it\n  tricky to use.  Fortunately, the lexers and parsers have already\n  been generated.  One does not need to regenerate the java files (but\n  `antlr` still needs to be included in the classpath). \n",
                    "original_header": "Compile and sources"
                },
                "confidence": 0.9888635482298227,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/alban-grastien/diagfwork/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-09-28T00:16:38Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-09-28T01:34:55Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 2273390
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 181495
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "GAP",
                    "name": "GAP",
                    "type": "Programming_language",
                    "size": 42508
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 4862
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 1763
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 590
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "140": {
        "filename": "BasemSuleiman_Personalized_Intelligent_Fitness__2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "141": {
        "filename": "snlemons_search_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can build with either GCC or clang.  If one or the other doesn't\nwork then it is a bug so please tell me. \nUbuntu package dependencies:\n\tlibboost-dev \nThe plat2d/watch binary and graphics code also need:\n\tlibsdl1.2-dev libsdl-image1.2-dev \nsearch/learnh/lms needs lapack:\n\tliblapack-dev \n"
                },
                "confidence": 0.9857043629256983,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/snlemons/search/main/README"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-06-30T20:11:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-03T08:35:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 691158
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 20043
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Pawn",
                    "name": "Pawn",
                    "type": "Programming_language",
                    "size": 3680
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2834
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 2735
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 1523
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Assembly",
                    "name": "Assembly",
                    "type": "Programming_language",
                    "size": 759
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Awk",
                    "name": "Awk",
                    "type": "Programming_language",
                    "size": 227
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "142": {
        "filename": "filipcano_safety-shields-delayed_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\nhttps://github.com/filipcano/safety-shields-delayed/assets/109427334/eafee78e-93ae-4484-a026-cb09b630a860 \n\nhttps://github.com/filipcano/safety-shields-delayed/assets/109427334/b230a7c5-fb15-4b42-ba44-1a373a9e7aac \n",
                    "original_header": "Safety Shielding under Delayed Observation"
                },
                "confidence": 0.9962897634739651,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filipcano/safety-shields-delayed/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "This file allows you to parse the shield `.txt` file and save it either compressed or as a pickle file. The shield file can then be loaded in `traffic_scenarios.py`.\n \n",
                    "original_header": "parse_shield.py"
                },
                "confidence": 0.9803609989738183,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/filipcano/safety-shields-delayed/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-03-17T10:30:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-07-19T15:27:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 106594
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 62756
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1790
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "143": {
        "filename": "hkharryking_labeled_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "144": {
        "filename": "boost-R_mboost_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "- Current version (from CRAN):\n  ```r\n  install.packages(\"mboost\")\n  ```\n\n- Latest **patch version** (patched version of CRAN package; under development) from GitHub:\n  ```r\n  library(\"devtools\")\n  install_github(\"boost-R/mboost\")\n  library(\"mboost\")\n  ```\n\n- Latest **development version** (version with new features; under development) from GitHub:\n  ```r\n  library(\"devtools\")\n  install_github(\"boost-R/mboost\", ref = \"devel\")\n  library(\"mboost\")\n  ```\n\n  To be able to use the `install_github()` command, one needs to install `devtools` first:\n  ```r\n  install.packages(\"devtools\")\n  ```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation Instructions",
                    "parent_header": [
                        "mboost"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/boost-R/mboost/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For installation instructions see below. \n",
                    "original_header": "Using mboost"
                },
                "confidence": 0.9996357036307232,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/boost-R/mboost/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For issues, bugs, feature requests etc. please use the [GitHub Issues](https://github.com/boost-R/mboost/issues).\n \n",
                    "original_header": "Issues &amp; Feature Requests"
                },
                "confidence": 0.9856965612238947,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/boost-R/mboost/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2015-04-10T09:58:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T09:36:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 936311
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "R",
                    "name": "R",
                    "type": "Programming_language",
                    "size": 503454
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 86572
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 10042
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 9554
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "PHP",
                    "name": "PHP",
                    "type": "Programming_language",
                    "size": 1599
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1471
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "145": {
        "filename": "theoad_dot-dmax_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We used [miniconda3](https://docs.conda.io/en/latest/miniconda.html) and [pip3](https://pip.pypa.io/en/stable/) to manage dependencies\n```bash\nconda create -n dmax python=3.8\nconda activate dmax\ngit clone git+https://github.com/theoad/dot-dmax\ncd dot-dmax\npip install -e .\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Install",
                    "parent_header": [
                        "DOT-Dmax"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/theoad/dot-dmax/main/README.md"
            },
            {
                "result": {
                    "value": "We abstract hardware dependency using hugging-face's [accelerate](https://huggingface.co/docs/accelerate/index) library.\nConfigure your environment before launching the scripts by running\n```bash\naccelerate config\n```\nBecause evaluation is quite heavy (we computed for many values of $\\alpha$ on 50K samples), we distributed across 8 A6000 GPUs with `batch_size=10`.\nReduce this value if you encounter any CUDA out-of-memory issues using\n```bash\nexport batch_size=8  # replace with your batch size\n```\nAfter configuring your hardware, launch distributed jobs by replacing `python main.py <args>`  by `accelerate launch main.py <args>`\n",
                    "type": "Text_excerpt",
                    "original_header": "Hardware Setup",
                    "parent_header": [
                        "DOT-Dmax",
                        "Paper Results"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/theoad/dot-dmax/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Note: The following only applies to *your* script, and does not give access to other users.\nNevertheless, we recommend revoking the script's access after the download is complete. \n- Follow the steps of [google's pydrive quickstart](https://developers.google.com/drive/api/v3/quickstart/python) and place your `credentials.json` under the `dot-dmax` repository.\n- Run `python data/gdrive.py init` (must be on a local machine, connected to a display). If the warning _\"Google hasn\u2019t verified this app\"_ occurs, click `advance` and then `Go to <Your App Name> (unsafe)`.\n- \\[Optional\\]: To be able to access the API from a remote machine, simply upload the `token.pickle` file generated by the previous step.\n \n",
                    "original_header": "PyDrive-API"
                },
                "confidence": 0.9993984695930522,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/theoad/dot-dmax/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "If you enabled the [PyDrive-API](#PyDrive-API), you are not required to download any dataset manually, except for [ImageNet](https://www.image-net.org/).\nOnce downloaded, you can declare its location with the following environment variable:\n```bash\nexport imagenet_path=~/data/ImageNet  # replace with your path\n```\n \n",
                    "original_header": "Datasets"
                },
                "confidence": 0.9999999989180139,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/theoad/dot-dmax/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\\[Optional\\]: see [Hardware Setup](#Hardware-Setup) for distributed commands\n```bash\ncd dmax                                                              # we must run main.py under the source directory\npython main.py --help                                                # displays all optional arguments\n```\nBASH2*\n \n",
                    "original_header": "Reproducing results"
                },
                "confidence": 0.9999994080060095,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/theoad/dot-dmax/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-22T10:32:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-26T11:55:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 197942
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "146": {
        "filename": "irfansha_Q-sage_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can play Hex game with QBF solver using the following command: \n\n    python3 interactive_play.py --problem Benchmarks/B-Hex/hein_04_3x3-05.pg \n",
                    "original_header": "Interactive game play:"
                },
                "confidence": 0.9289008225813198,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/irfansha/Q-sage/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-08-13T11:05:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-09T10:07:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1120096
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Modula-3",
                    "name": "Modula-3",
                    "type": "Programming_language",
                    "size": 24194
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "147": {
        "filename": "omron-sinicx_planning-datasets_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```sh\n$ git submodule update --init --recursive    # if you forget --recursive option\n$ python3 -m venv venv\n$ source activate venv/bin/activate\n$ pip install -e .\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Install using venv",
                    "parent_header": [
                        "Datasets for Path Planning using Neural A* Search (ICML'21)",
                        "Getting Started"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/omron-sinicx/planning-datasets/icml2021/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-06-30T23:44:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-15T08:53:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 273246
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 36193
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1770
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "148": {
        "filename": "cosmic-cortex_modAL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<p align=\"center\">\n  <img src=\"https://modal-python.readthedocs.io/en/latest/_images/motivating-example.png\" height=\"600px\" width=\"600px\"/>\n</p> \n<p align=\"center\">\n <img src=\"https://modal-python.readthedocs.io/en/latest/_images/active-learning.png\"/>\n</p> \n",
                    "original_header": "Active learning from bird's-eye view<a name=\"active-learning\"></a>"
                },
                "confidence": 0.9880455515059473,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cosmic-cortex/modAL/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "modAL requires\n- Python >= 3.5\n- NumPy >= 1.13\n- SciPy >= 0.18\n- scikit-learn >= 0.18 \nYou can install modAL directly with pip:  \n```\npip install modAL-python\n```\nAlternatively, you can install modAL directly from source:  \nBASH2*\n \n",
                    "original_header": "Installation<a name=\"installation\"></a>"
                },
                "confidence": 0.9998557652501139,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cosmic-cortex/modAL/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can find the documentation of modAL at [https://modAL-python.github.io](https://modAL-python.github.io), where several tutorials and working examples are available, along with a complete API reference. For running the examples, Matplotlib >= 2.0 is recommended.\n \n",
                    "original_header": "Documentation<a name=\"documentation\"></a>"
                },
                "confidence": 0.9847410176651407,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cosmic-cortex/modAL/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-11-14T14:01:15Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T17:59:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 231196
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 191
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "149": {
        "filename": "edramsalimi_NLGXAI_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-02-23T14:23:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-07-27T14:04:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 30134
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "150": {
        "filename": "microsoft_dowhy_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "`Microsoft Research Blog <https://www.microsoft.com/en-us/research/blog/dowhy-a-library-for-causal-inference/>`_ | `Video Tutorial for Effect Estimation <https://www.youtube.com/watch?v=LALfQStONEc&t=114s>`_ | `Video Tutorial for Root Cause Analysis <https://www.youtube.com/watch?v=icpHrbDlGaw>`_ | `Arxiv Paper <https://arxiv.org/abs/2011.04216>`_ | `Arxiv Paper (Graphical Causal Model extension) <https://arxiv.org/abs/2206.06821>`_ | `Slides <https://www2.slideshare.net/AmitSharma315/dowhy-an-endtoend-library-for-causal-inference>`_ \nIssues\n~~~~~~\nIf you encounter an issue or have a specific request for DoWhy, please `raise an issue <https://github.com/py-why/dowhy/issues>`_. \nThis project welcomes contributions and suggestions. For a guide to contributing and a list of all contributors, check out `CONTRIBUTING.md <https://github.com/py-why/dowhy/blob/main/CONTRIBUTING.md>`_ and our `docs for contributing code <https://github.com/py-why/dowhy/blob/main/docs/source/contributing/contributing-code.rst>`_. Our `contributor code of conduct is available here <https://github.com/py-why/governance/blob/main/CODE-OF-CONDUCT.md>`_.\n \n",
                    "original_header": "More Information &amp; Resources"
                },
                "confidence": 0.9932099641361183,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/microsoft/dowhy/main/README.rst"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-05-31T13:07:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T11:40:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1952377
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "151": {
        "filename": "tomsilver_llm-genplan_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "1. Recommended: create and source a virtualenv.\n2. `pip install -e \".[develop]\"`\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Generalized Planning in PDDL Domains with Pretrained Large Language Models"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/tomsilver/llm-genplan/master/README.md"
            },
            {
                "result": {
                    "value": "Run `./run_ci_checks.sh`. It should complete with all green successes in 5-10 seconds.\n",
                    "type": "Text_excerpt",
                    "original_header": "Check Installation",
                    "parent_header": [
                        "Generalized Planning in PDDL Domains with Pretrained Large Language Models"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/tomsilver/llm-genplan/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Run `./scripts/run_all.sh`. This reproduces results using cached chat logs. It will take 12-16 hours to complete.\n \n",
                    "original_header": "Reproduce Results"
                },
                "confidence": 0.9724067036882493,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/tomsilver/llm-genplan/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-04-03T15:05:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-25T10:21:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "PDDL",
                    "name": "PDDL",
                    "type": "Programming_language",
                    "size": 272332396
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 85595
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 9766
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "152": {
        "filename": "yuangh-x_2022-NIPS-Tenrec_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**Dataset link**: https://static.qblv.qq.com/qblv/h5/algo-frontend/tenrec_dataset.html \n**Leaderboard link:** https://tenrec0.github.io/ \n",
                    "original_header": "Dataset in Tenrec:"
                },
                "confidence": 0.9959821537288284,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/yuangh-x/2022-NIPS-Tenrec/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Recbole: https://recbole.io, DeepCTR: https://github.com/shenweichen/DeepCTR, DaisyRec: https://github.com/recsys-benchmark/DaisyRec-v2.0. \n",
                    "original_header": "Environments"
                },
                "confidence": 0.9999997849462492,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/yuangh-x/2022-NIPS-Tenrec/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-06-09T14:27:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T02:00:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 564647
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "153": {
        "filename": "kgqa4mat_KGQA4MAT10_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "154": {
        "filename": "deepkashiwa20_ODCRN_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-04-03T12:06:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-30T08:10:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 548102
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 312520
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "155": {
        "filename": "AAIR-lab_GRAPL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Use the following commands to install the GHN system on an Ubuntu 18.04 machine.\n\n    sudo apt install graphviz graphviz-dev python3-pip cmake\n\n    pip3 install --upgrade pip\n    pip3 install networkx\n    pip3 install tensorflow==2.3.1\n    pip3 install pygraphviz\n    pip3 install dulwich\n    pip3 install tqdm\n    pip3 install matplotlib\n    pip3 install pydot\n    pip3 install pyyaml==5.3.1\n    pip3 install tinydb\n    pip3 install pandas\n    pip3 install bokeh\n    pip3 install psutil\n\nNext from the project root directory,\n\n    cd bin/fast-downward\n    ./build.py release\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/AAIR-lab/GRAPL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The GHN system uses YAML config files for supported domains to run the experiments.\nThe AAAI-21 YAML files can be found in the experiments/ directory. \nUse the following command line to run the experiments from the root directory. \npython3 generalized_learning.py --base-dir `<directory_where_to_store_results>` --config-file `<path_to_yaml_file>`\n \n",
                    "original_header": "Reproducing the AAAI-21 experiments"
                },
                "confidence": 0.9613296909631579,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/AAIR-lab/GRAPL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "As an additional note, once you have trained a model, you can run pyperplan individually using the sourced version of pyperplan provided in the dependencies/ directory. \n",
                    "original_header": "Using your own data/new domains"
                },
                "confidence": 0.9942857537439205,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/AAIR-lab/GRAPL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-03-01T04:26:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-23T01:14:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 5117472
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 1872452
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 76842
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 50995
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 26706
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Perl",
                    "name": "Perl",
                    "type": "Programming_language",
                    "size": 6327
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 5613
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Smarty",
                    "name": "Smarty",
                    "type": "Programming_language",
                    "size": 2738
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "156": {
        "filename": "awjdean_CayleyTableGeneration_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-05-09T21:43:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-10-02T14:13:11Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 199181
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "157": {
        "filename": "rlworkgroup_garage_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```\npip install --user garage\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "garage"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/rlworkgroup/garage/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Need some help? Want to ask garage is right for your project? Have a question\nwhich is not quite a bug and not quite a feature request? \n",
                    "original_header": "Join the Community"
                },
                "confidence": 0.9128931506963142,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/rlworkgroup/garage/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "| Algorithm              | Framework(s)        |\n| ---------------------- | ------------------- |\n| CEM                    | numpy               |\n| CMA-ES                 | numpy               |\n| REINFORCE (a.k.a. VPG) | PyTorch, TensorFlow |\n| DDPG                   | PyTorch, TensorFlow |\n| DQN                    | PyTorch, TensorFlow |\n| DDQN                   | PyTorch, TensorFlow |\n| ERWR                   | TensorFlow          |\n| NPO                    | TensorFlow          |\n| PPO                    | PyTorch, TensorFlow |\n| REPS                   | TensorFlow          |\n| TD3                    | PyTorch, TensorFlow |\n| TNPG                   | TensorFlow          |\n| TRPO                   | PyTorch, TensorFlow |\n| MAML                   | PyTorch             |\n| RL2                    | TensorFlow          |\n| PEARL                  | PyTorch             |\n| SAC                    | PyTorch             |\n| MTSAC                  | PyTorch             |\n| MTPPO                  | PyTorch, TensorFlow |\n| MTTRPO                 | PyTorch, TensorFlow |\n| Task Embedding         | TensorFlow          |\n| Behavioral Cloning     | PyTorch             |\n \n",
                    "original_header": "Algorithms"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/rlworkgroup/garage/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "garage requires Python 3.6+. If you need Python 3.5 support, the last garage\nrelease to support Python 3.5 was\n[v2020.06](https://github.com/rlworkgroup/garage/releases/tag/v2020.06.0). \nThe package is tested on Ubuntu 18.04. It is also known to run on Ubuntu 16.04,\n18.04, and 20.04, and recent versions of macOS using Homebrew. Windows users can\ninstall garage via WSL, or by making use of the Docker containers. \nThe package is available for download on PyPI, and we ensure that it installs\nsuccessfully into environments defined using\n[conda](https://docs.conda.io/en/latest/),\n[Pipenv](https://pipenv.readthedocs.io/en/latest/), and\n[virtualenv](https://virtualenv.pypa.io/en/latest/).\n \n",
                    "original_header": "Supported Tools and Frameworks"
                },
                "confidence": 0.9988346426120459,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/rlworkgroup/garage/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "| Release | Build Status | Last date of support |\n| ------- | ------------ | -------------------- |\n| [v2021.03](https://github.com/rlworkgroup/garage/releases/tag/v2021.03.0) | [![Garage CI Release-2021.03](https://github.com/rlworkgroup/garage/workflows/Garage%20CI%20Release-2021.03/badge.svg)](https://github.com/rlworkgroup/garage/actions?query=workflow%3A%22Garage+CI+Release-2021.03%22) | May 31st, 2021 | \n",
                    "original_header": "Supported Releases"
                },
                "confidence": 0.9709080481067922,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/rlworkgroup/garage/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-06-10T21:31:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T17:49:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 2697508
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 281272
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 23905
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 6738
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 4766
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "158": {
        "filename": "stacs-cp_tabulation-exp_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-12-12T22:37:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-01T10:08:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "159": {
        "filename": "janothan_DL-TC-Generator_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-01-13T21:23:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-02-18T21:34:18Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 446630
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "160": {
        "filename": "FudanVI_generative-abstract-reasoning_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-06-03T12:34:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-07T12:28:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 521241
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 5866
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "161": {
        "filename": "hongzimao_decima-sim_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Simulator part of Decima (SIGCOMM '19) https://web.mit.edu/decima \n",
                    "original_header": "Decima"
                },
                "confidence": 0.9143023893347397,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/hongzimao/decima-sim/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-08-21T19:09:21Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T07:23:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 158299
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "162": {
        "filename": "ospur_htn-tm_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "163": {
        "filename": "cmu-phil_causal-learn_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Causal-learn needs the following packages to be installed beforehand:\n\n* python 3 (>=3.7)\n* numpy\n* networkx\n* pandas\n* scipy\n* scikit-learn\n* statsmodels\n* pydot\n\n(For visualization)\n\n* matplotlib\n* graphviz\n\nTo use causal-learn, we could install it using [pip](https://pypi.org/project/causal-learn/):\n\n```\npip install causal-learn\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Install"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/cmu-phil/causal-learn/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The package is actively being developed. Feedbacks (issues, suggestions, etc.) are highly encouraged.\n \n",
                    "original_header": "causal-learn: Causal Discovery in Python"
                },
                "confidence": 0.9277863662369592,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/cmu-phil/causal-learn/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-10-11T16:18:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T01:03:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 893131
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 13953
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "164": {
        "filename": "gglorian_Nacre1_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "165": {
        "filename": "fhtanaka_SGR_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-06-13T00:27:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-08-15T03:28:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 10959722
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 85740
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 8655
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 455
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "166": {
        "filename": "UzmaHasan_KGS-Causal-Discovery-Using-Constraints_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Our code for KGS is based on the GES implementation from the repository: https://github.com/py-why/causal-learn \n-------Step by step instructions to test KGS-------- \n1. To use KGS, please install the available package causal-learn using pip:  \"pip install causal-learn\" \n",
                    "original_header": "KGS-Causal-Discovery-Using-Knowledge-guided-Greedy-Equivalence-Search"
                },
                "confidence": 0.967801971917587,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/UzmaHasan/KGS-Causal-Discovery-Using-Constraints/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-04-11T20:11:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-08-29T09:49:20Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "167": {
        "filename": "JoeyHou_branching_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-12-01T16:30:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-04T16:28:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 77937
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "168": {
        "filename": "KULeuvenADVISE_CGGD_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "\nThis is the code repository for the experiments described in the paper _Constraint Guided Gradient Descent: Guided Training with Inequality Constraints, Quinten Van Baelen, Peter Karsmakers_ (available [here](https://doi.org/10.14428/esann/2022.ES2022-105)), and _Constraint Guided Gradient Descent: Guided Training with Inequality Constraints with Applications in Regression and Semantic Segmentation, Quinten Van Baelen, Peter Karsmakers_ (available [here](https://doi.org/10.1016/j.neucom.2023.126636)).\n\n\n\nThe code for the semantic segmentation experiments, as described in [2], is based upon [Sizeloss_WSS](https://github.com/LIVIAETS/SizeLoss_WSS/tree/master) and [extended_logbarrier](https://github.com/LIVIAETS/extended_logbarrier/tree/master) because semantic segmentation tasks are very similar to the ones done in the corresponding papers. In each script it is clearly stated what has been added in this repository and what already existed in either of the previously mentioned repositories. The full possibility of the code as presented in these repositories are not guaranteed in this repository. This code base will most likely only support the experiments described in [2].\n",
                    "type": "Text_excerpt",
                    "original_header": "Constraint Guided Gradient Descent: Guided Training with Inequality Constraints with Applications in Regression and Semantic Segmentation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/KULeuvenADVISE/CGGD/main/README.md"
            },
            {
                "result": {
                    "value": "- [regression](https://github.com/KULeuvenADVISE/CGGD/tree/main/regression):\n    - Contains the scripts necessary to perform the experiments described in [1].\n- [regression-sup-semisup](https://github.com/KULeuvenADVISE/CGGD/tree/main/regression-sup-semisup):\n    - Contains the scripts necessary to perform the experiments described in [2, Section 5.1] and a notebook to postprocess the results and visualize them in a similar fashion as was done in the corresponding paper.\n- [semanticsegmentation](https://github.com/KULeuvenADVISE/CGGD/tree/main/semanticsegmentation):\n    - Contains the scripts necessary to perform the experiments described in [2, Section 5.2] and a notebook to postprocess the results and visualize them in a similar fashion as was done in the corresponding paper.\n- [venv-requirements](https://github.com/KULeuvenADVISE/CGGD/tree/main/venv-requirements):\n    - Contains the virtual environments for running the experiments. This repository uses 3 different virtual environments. The first one ([requirements-regression](https://github.com/KULeuvenADVISE/CGGD/blob/main/venv-requirements/requirements-regression.txt)) is the virtual environment used for running the experiments in [**regression**](https://github.com/KULeuvenADVISE/CGGD/tree/main/regression). Note that this uses TensorFlow 2.2.0 and, thus, this is not supported for all GPUs (NVIDIA 30 series does not support this version of TensorFlow). The second one ([requirements-regression-sup-semisup.yml](https://github.com/KULeuvenADVISE/CGGD/blob/main/venv-requirements/requirements-regression-sup-semisup.yml)) contains the virtual environment for running the experiments in [**regression-sup-semisup**](https://github.com/KULeuvenADVISE/CGGD/tree/main/regression-sup-semisup). The third one ([requirements-semanticsegmentatio.ymln](https://github.com/KULeuvenADVISE/CGGD/blob/main/venv-requirements/requirements-semanticsegmentation.yml)) is the virtual environment used for running the experiments in [**semanticsegmentation**](https://github.com/KULeuvenADVISE/CGGD/tree/main/semanticsegmentation). This uses PyTorch because the implementation of the baselines was already available in PyTorch.\n\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Content of directories",
                    "parent_header": [
                        "Constraint Guided Gradient Descent: Guided Training with Inequality Constraints with Applications in Regression and Semantic Segmentation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/KULeuvenADVISE/CGGD/main/README.md"
            },
            {
                "result": {
                    "value": "This repository uses three publicly available data sets:\n- The Bias Correction data set is available [here](https://archive.ics.uci.edu/ml/datasets/Bias+correction+of+numerical+prediction+model+temperature+forecast). For running the experiments on this data set, please download it and put it in __./regressions/DataSets__. Make sure that the file is named __Bias_correction_ucl.csv__, but normally this should be satisfied automatically.\n- The Family Income data set is available [here](https://www.kaggle.com/grosvenpaul/family-income-and-expenditure).  For running the experiments on this data set, please download it and put it in __./regressions/DataSets__. Make sure that the file is named __Family Income and Expenditure.csv__, but normally this should be satisfied automatically.\n- The Prostate data set is available [here](https://promise12.grand-challenge.org/Download/). Only the training data is used in the experiments, so it is only necessary to have __TrainingDataPart1.zip__, __TrainingDataPart2.zip__, and __TrainingDataPart3.zip__ downloaded from [here](https://zenodo.org/record/8014041).\n\nThe toy data set for the semantic segmentation experiments is created by running a script provided in the corresponding directory.\n",
                    "type": "Text_excerpt",
                    "original_header": "Data Sets",
                    "parent_header": [
                        "Constraint Guided Gradient Descent: Guided Training with Inequality Constraints with Applications in Regression and Semantic Segmentation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/KULeuvenADVISE/CGGD/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-04-12T07:07:27Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-07-28T08:54:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 2194415
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 131080
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 41215
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "169": {
        "filename": "chuffed_chuffed_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Chuffed can be compiled on Windows, macOS and Linux.\n \n",
                    "original_header": "Compilation"
                },
                "confidence": 0.9949125090209232,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/chuffed/chuffed/develop/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To initialize the CMake build environment, using `build` as the build directory,\nuse the following command: \n    cmake -B build -S . \nTo then build the `fzn-chuffed` executable run: \n    cmake --build build \nTo install `fzn-chuffed` run the following command:  \n    cmake --build build --target install\n    \nThe installation directory can be chosen by appending\n`-DCMAKE_INSTALL_PREFIX=$LOCATION` with the chosen location to the initial CMake\ncommand. \nTo build the C++ examples: \n    cmake --build build --target examples \n    cmake --build build --target format\n \n",
                    "original_header": "CMake &amp; Co"
                },
                "confidence": 0.9881068295823892,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/chuffed/chuffed/develop/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2016-09-27T01:06:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T06:06:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 1682830
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 14922
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 5979
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 5782
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "170": {
        "filename": "sluxsr_r5_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "171": {
        "filename": "asoulet_superficiality_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-03-30T13:51:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-05-16T11:41:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 70607
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "172": {
        "filename": "SUSTechGameAI_GameAIPlatforms_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "- **VGLC:** <[VGLC : The video game level corpus](https://arxiv.org/abs/1606.07487)> <[Github Link](https://github.com/TheVGLC/TheVGLC)> by A. J. Summerville, S. Snodgrass, M. Mateas, and S. Ontanon, 2016.\n",
                    "type": "Text_excerpt",
                    "original_header": "Data set (Section IV.C)",
                    "parent_header": [
                        "Games for Artificial Intelligence Research: A Review and Perspectives",
                        "Designing Games by AI (Section IV)",
                        "Other"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/SUSTechGameAI/GameAIPlatforms/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-02-02T06:43:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-16T04:34:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "173": {
        "filename": "Zhang-Zijian_PromptST_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Pretrain/Full Train:\n  -Complaint: bash full_19.sh\n  -NYC Taxi: bash full_4.sh \nFinetune:\n  -Complaint: bash ft_19.sh\n  -NYC Taxi: bash ft_4.sh \nPrompt Tune:\n  -Complaint: bash pmt_st_19.sh\n  -NYC Taxi: bash pmt_st_4.sh\n  \nSingle Train:\n  -Complaint: bash sin_19.sh\n  -NYC Taxi: bash sin_4.sh\n \n"
                },
                "confidence": 0.9947490685004875,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Zhang-Zijian/PromptST/master/readme.txt"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-08-11T06:36:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-25T04:32:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 66477
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1684
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "174": {
        "filename": "solashirai_WWW-EvCBR_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The experiments can be run using 4 scripts to (1) split the Wikidata-based event data into\ntrain/test splits, (2) precompute stats and vectors for entity similarity, (3) run the \nEvCBR model, then (4) show results.\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup and Running the Experiments",
                    "parent_header": [
                        "EvCBR"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/solashirai/WWW-EvCBR/main/README.md"
            },
            {
                "result": {
                    "value": "The following assumes that you have the wikidata dataset placed in the `data/` directory.\nIt's small enough to be uploaded to github so it is already included, but it is also available\nat the aforementioned link on Zenodo. Additionally, we have files to specify which classes we\nconsider to be \"events\", and a file containing the subclass hierarchy of those events.\n\nTo split the data, run:\n\nIf desired, you can modify the default arguments such as the output directories. \n\n`python experiments/split_wikidata_dataset.py`\n\nThis will produce a new folders in `data/` - `pp_wiki/`, containing txt files of the \ntriples in the train/test datasets.\n",
                    "type": "Text_excerpt",
                    "original_header": "Split Data",
                    "parent_header": [
                        "EvCBR",
                        "Setup and Running the Experiments"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/solashirai/WWW-EvCBR/main/README.md"
            },
            {
                "result": {
                    "value": "Next, run the script to preprocess the data. The default arguments will point to the correct\ndata, but you can also specify the input/output directories. From the previous step, the `pp_wiki/`\nfolder will be the default input. By default output from this step will be placed in `evcbr_pp_wiki/`.\n\n`python experiments/preprocess_data_for_evcbr.py --process_wiki`\n",
                    "type": "Text_excerpt",
                    "original_header": "Preprocess Data",
                    "parent_header": [
                        "EvCBR",
                        "Setup and Running the Experiments"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/solashirai/WWW-EvCBR/main/README.md"
            },
            {
                "result": {
                    "value": "Lastly, the results can be output and saved using \n\n`python experiments/show_evcbr_eval_results.py --eval_res_dir wiki_results --data_dir pp_wiki`\n",
                    "type": "Text_excerpt",
                    "original_header": "Display Results",
                    "parent_header": [
                        "EvCBR",
                        "Setup and Running the Experiments"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/solashirai/WWW-EvCBR/main/README.md"
            },
            {
                "result": {
                    "value": "Split train/valid/test data for FB15k-237 and WN18RR are also included in `data/`.\nThe `preprocess_data_for_evcbr.py` can be called with the `--process_fb'/`--process_wn` flags, and then\nthe last 2 experiment scripts can be run.\nPlease keep in mind that the FB15k dataset contains many more triples to predict, the KG is also more\ndensely connected, which can lead to very long runtimes.\n",
                    "type": "Text_excerpt",
                    "original_header": "Additional Experiments",
                    "parent_header": [
                        "EvCBR",
                        "Setup and Running the Experiments"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/solashirai/WWW-EvCBR/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We recommend that you create a new python virtual env and install the requirements. Our \nexperiments were performed using Python 3.8 \n`source env/bin/activate`  \n`pip install -r requirements.txt`\n \n",
                    "original_header": "Preliminaries"
                },
                "confidence": 0.9996125031812587,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/solashirai/WWW-EvCBR/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-02-07T15:40:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-04T07:31:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 116731
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "175": {
        "filename": "DataScienceLab18_IndoorToolKit_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "   If you have any question, please contect Hui Bo (bzh0055@auburn.edu) or Wenlu Wang (wenluwang@auburn.edu).\n    \n \n",
                    "original_header": "Miscellaneous"
                },
                "confidence": 0.9644233934026739,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/DataScienceLab18/IndoorToolKit/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-08-13T17:32:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-09-20T03:21:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 56412
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 2067
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "176": {
        "filename": "HazyResearch_legalbench_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-08-19T18:27:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T08:53:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 27261
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 17405
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "177": {
        "filename": "huggingface_transformers_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "<!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\u26a0\ufe0f Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n-->\n\n# \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u4f7f\u7528\u3057\u3066\u3044\u308bDeep Learning\u30e9\u30a4\u30d6\u30e9\u30ea\u306b\u5bfe\u3057\u3066\u3001\ud83e\udd17 Transformers\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u30ad\u30e3\u30c3\u30b7\u30e5\u3092\u8a2d\u5b9a\u3001\u305d\u3057\u3066\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u30aa\u30d5\u30e9\u30a4\u30f3\u3067\u5b9f\u884c\u3067\u304d\u308b\u3088\u3046\u306b \ud83e\udd17 Transformers\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\n\n\ud83e\udd17 Transformers\u306fPython 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, Flax\u3067\u52d5\u4f5c\u78ba\u8a8d\u3057\u3066\u3044\u307e\u3059\u3002 \u4f7f\u7528\u3057\u3066\u3044\u308bDeep Learning\u30e9\u30a4\u30d6\u30e9\u30ea\u306b\u5408\u308f\u305b\u3066\u3001\u4ee5\u4e0b\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5\u306b\u5f93\u3063\u3066\u304f\u3060\u3055\u3044:\n\n* [PyTorch](https://pytorch.org/get-started/locally/)\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u624b\u9806\u3002\n* [TensorFlow 2.0](https://www.tensorflow.org/install/pip)\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u624b\u9806\u3002\n* [Flax](https://flax.readthedocs.io/en/latest/)\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u624b\u9806\u3002\n\n## pip\u3067\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\ud83e\udd17 Transformers\u3092[\u4eee\u60f3\u74b0\u5883](https://docs.python.org/3/library/venv.html)\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002 \u3082\u3057\u3001Python\u306e\u4eee\u60f3\u74b0\u5883\u306b\u99b4\u67d3\u307f\u304c\u306a\u3044\u5834\u5408\u306f\u3001\u3053\u306e[\u30ac\u30a4\u30c9](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002\u4eee\u60f3\u74b0\u5883\u306b\u3088\u3063\u3066\u7570\u306a\u308b\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u7ba1\u7406\u304c\u3088\u308a\u7c21\u5358\u306b\u306a\u308a\u3001\u4f9d\u5b58\u95a2\u4fc2\u9593\u306e\u4e92\u63db\u6027\u306e\u554f\u984c\u3092\u56de\u907f\u3067\u304d\u307e\u3059\u3002\n\n\u307e\u305a\u3001\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4eee\u60f3\u74b0\u5883\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u304b\u3089\u59cb\u3081\u307e\u3057\u3087\u3046:\n\n```bash\npython -m venv .env\n```\n\n\u4eee\u60f3\u74b0\u5883\u3092\u8d77\u52d5\u3057\u307e\u3057\u3087\u3046\u3002Linux\u3068MacOs\u306e\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067\u8d77\u52d5\u3057\u307e\u3059:\n\n```bash\nsource .env/bin/activate\n```\nWindows\u3067\u4eee\u60f3\u74b0\u5883\u3092\u8d77\u52d5\u3057\u307e\u3059\n\n```bash\n.env/Scripts/activate\n```\n\n\u3053\u308c\u3067\u3001\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3067\ud83e\udd17 Transformers\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u6e96\u5099\u304c\u6574\u3044\u307e\u3057\u305f:\n\n```bash\npip install transformers\n```\n\nCPU\u5bfe\u5fdc\u306e\u307f\u5fc5\u8981\u306a\u5834\u5408\u3001\ud83e\udd17 Transformers\u3068Deep Learning\u30e9\u30a4\u30d6\u30e9\u30ea\u30921\u884c\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u3066\u4fbf\u5229\u3067\u3059\u3002\u4f8b\u3048\u3070\u3001\ud83e\udd17 Transformers\u3068PyTorch\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u4e00\u7dd2\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u307e\u3059:\n\n```bash\npip install transformers[torch]\n```\n\n\ud83e\udd17 Transformers\u3068TensorFlow 2.0:\n\n```bash\npip install transformers[tf-cpu]\n```\n\n\ud83e\udd17 Transformers\u3068Flax:\n\n```bash\npip install transformers[flax]\n```\n\n\u6700\u5f8c\u306b\u3001\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3053\u3068\u3067\ud83e\udd17 Transformers\u304c\u6b63\u3057\u304f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u304b\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u304c\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u307e\u3059:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n```\n\n\u305d\u306e\u5f8c\u3001\u30e9\u30d9\u30eb\u3068\u30b9\u30b3\u30a2\u304c\u51fa\u529b\u3055\u308c\u307e\u3059:\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n```\n\n## \u30bd\u30fc\u30b9\u304b\u3089\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067\u30bd\u30fc\u30b9\u304b\u3089\ud83e\udd17 Transformers\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059:\n\n```bash\npip install git+https://github.com/huggingface/transformers\n```\n\n\u3053\u306e\u30b3\u30de\u30f3\u30c9\u306f\u6700\u65b0\u306e\u5b89\u5b9a\u7248\u3067\u306f\u306a\u304f\u3001\u958b\u767a\u306b\u304a\u3051\u308b\u6700\u65b0\u306e`main`\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002`main`\u30d0\u30fc\u30b8\u30e7\u30f3\u306f\u6700\u65b0\u306e\u958b\u767a\u72b6\u6cc1\u306b\u5bfe\u5fdc\u3059\u308b\u306e\u306b\u4fbf\u5229\u3067\u3059\u3002\u4f8b\u3048\u3070\u3001\u6700\u5f8c\u306e\u516c\u5f0f\u30ea\u30ea\u30fc\u30b9\u4ee5\u964d\u306b\u30d0\u30b0\u304c\u4fee\u6b63\u3055\u308c\u305f\u304c\u3001\u65b0\u3057\u3044\u30ea\u30ea\u30fc\u30b9\u304c\u307e\u3060\u5c55\u958b\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306a\u3069\u3067\u3059\u3002\u3057\u304b\u3057\u3001\u3053\u308c\u306f`main`\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u5e38\u306b\u5b89\u5b9a\u3057\u3066\u3044\u308b\u3068\u306f\u9650\u3089\u306a\u3044\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\u3002\u79c1\u305f\u3061\u306f`main`\u30d0\u30fc\u30b8\u30e7\u30f3\u306e\u904b\u7528\u3092\u7dad\u6301\u3059\u308b\u3088\u3046\u52aa\u3081\u3001\u307b\u3068\u3093\u3069\u306e\u554f\u984c\u306f\u901a\u5e38\u3001\u6570\u6642\u9593\u304b\u30891\u65e5\u4ee5\u5185\u306b\u89e3\u6c7a\u3055\u308c\u307e\u3059\u3002\u3082\u3057\u554f\u984c\u306b\u906d\u9047\u3057\u305f\u5834\u5408\u306f\u3001\u3088\u308a\u65e9\u304f\u4fee\u6b63\u3067\u304d\u308b\u3088\u3046\u306b[Issue](https://github.com/huggingface/transformers/issues)\u3092\u4f5c\u6210\u3057\u3066\u304f\u3060\u3055\u3044\uff01\n\n\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u3001\ud83e\udd17 Transformers\u304c\u6b63\u3057\u304f\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u78ba\u8a8d\u3057\u307e\u3059:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n```\n\n## \u7de8\u96c6\u53ef\u80fd\u306a\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u3001\u7de8\u96c6\u53ef\u80fd\u306a\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3092\u3057\u307e\u3059:\n\n* \u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u306e`main`\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u4f7f\u3044\u307e\u3059\u3002\n* \ud83e\udd17 Transformers\u306b\u30b3\u30f3\u30c8\u30ea\u30d3\u30e5\u30fc\u30c8\u3057\u3001\u30b3\u30fc\u30c9\u306e\u5909\u66f4\u3092\u30c6\u30b9\u30c8\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067\u30ec\u30dd\u30b8\u30c8\u30ea\u3092\u30af\u30ed\u30fc\u30f3\u3057\u3066\u3001\ud83e\udd17 Transformers\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059:\n\n```bash\ngit clone https://github.com/huggingface/transformers.git\ncd transformers\npip install -e .\n```\n\n\u4e0a\u8a18\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001\u30ec\u30dd\u30b8\u30c8\u30ea\u3092\u30af\u30ed\u30fc\u30f3\u3057\u305f\u30d5\u30a9\u30eb\u30c0\u3068Python\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30d1\u30b9\u3092\u30ea\u30f3\u30af\u3057\u307e\u3059\u3002Python\u306f\u901a\u5e38\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u30d1\u30b9\u306b\u52a0\u3048\u3066\u3001\u3042\u306a\u305f\u304c\u30af\u30ed\u30fc\u30f3\u3057\u305f\u30d5\u30a9\u30eb\u30c0\u306e\u4e2d\u3082\u898b\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\u4f8b\u3048\u3070\u3001Python\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u901a\u5e38\u3001`~/anaconda3/envs/main/lib/python3.7/site-packages/`\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u3001Python\u306f\u30af\u30ed\u30fc\u30f3\u3057\u305f\u30d5\u30a9\u30eb\u30c0\u3082\u691c\u7d22\u3059\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059: `~/transformers/`.\n\n<Tip warning={true}>\n\n\u30e9\u30a4\u30d6\u30e9\u30ea\u30fc\u3092\u4f7f\u3044\u7d9a\u3051\u305f\u3044\u5834\u5408\u306f\u3001transformers\u30d5\u30a9\u30eb\u30c0\u30fc\u3092\u4fdd\u6301\u3057\u3064\u3065\u3051\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n</Tip>\n\n\u3053\u308c\u3067\u3001\u6b21\u306e\u30b3\u30de\u30f3\u30c9\u3067\u7c21\u5358\u306b\u30af\u30ed\u30fc\u30f3\u3092\ud83e\udd17 Transformers\u306e\u6700\u65b0\u7248\u306b\u66f4\u65b0\u3067\u304d\u307e\u3059:\n\n```bash\ncd ~/transformers/\ngit pull\n```\n\nPython\u74b0\u5883\u306f\u6b21\u56de\u306e\u5b9f\u884c\u6642\u306b\ud83e\udd17 Transformers\u306e`main`\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u898b\u3064\u3051\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n## conda\u3067\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n\n`conda-forge`\u306econda\u30c1\u30e3\u30f3\u30cd\u30eb\u304b\u3089\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059:\n\n```bash\nconda install conda-forge::transformers\n```\n\n## \u30ad\u30e3\u30c3\u30b7\u30e5\u306e\u8a2d\u5b9a\n\n\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u306f\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u3001\u30ed\u30fc\u30ab\u30eb\u306b\u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u307e\u3059: `~/.cache/huggingface/hub`. \u3053\u308c\u306f\u30b7\u30a7\u30eb\u74b0\u5883\u5909\u6570`TRANSFORMERS_CACHE`\u3067\u6307\u5b9a\u3055\u308c\u308b\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u3059\u3002Windows\u3067\u306f\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306f`C:\\Users\\username\\.cache\\huggingface\\hub`\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\u7570\u306a\u308b\u30ad\u30e3\u30c3\u30b7\u30e5\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u6307\u5b9a\u3059\u308b\u305f\u3081\u306b\u3001\u4ee5\u4e0b\u306e\u30b7\u30a7\u30eb\u74b0\u5883\u5909\u6570\u3092\u5909\u66f4\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002\u512a\u5148\u5ea6\u306f\u4ee5\u4e0b\u306e\u9806\u756a\u306b\u5bfe\u5fdc\u3057\u307e\u3059:\n\n1. \u30b7\u30a7\u30eb\u74b0\u5883\u5909\u6570 (\u30c7\u30d5\u30a9\u30eb\u30c8): `HUGGINGFACE_HUB_CACHE` \u307e\u305f\u306f `TRANSFORMERS_CACHE`.\n2. \u30b7\u30a7\u30eb\u74b0\u5883\u5909\u6570: `HF_HOME`.\n3. \u30b7\u30a7\u30eb\u74b0\u5883\u5909\u6570: `XDG_CACHE_HOME` + `/huggingface`.\n\n<Tip>\n\n\u3082\u3057\u3001\u4ee5\u524d\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u4f7f\u7528\u3057\u3066\u3044\u305f\u4eba\u3067\u3001`PYTORCH_TRANSFORMERS_CACHE`\u307e\u305f\u306f`PYTORCH_PRETRAINED_BERT_CACHE`\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u305f\u5834\u5408\u3001\u30b7\u30a7\u30eb\u74b0\u5883\u5909\u6570`TRANSFORMERS_CACHE`\u3092\u6307\u5b9a\u3057\u306a\u3044\u9650\u308a\ud83e\udd17 Transformers\u306f\u3053\u308c\u3089\u306e\u30b7\u30a7\u30eb\u74b0\u5883\u5909\u6570\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\n\n</Tip>\n\n## \u30aa\u30d5\u30e9\u30a4\u30f3\u30e2\u30fc\u30c9\n\n\ud83e\udd17 Transformers\u306f\u30ed\u30fc\u30ab\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u307f\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\u30d5\u30a1\u30a4\u30a2\u30a6\u30a9\u30fc\u30eb\u3084\u30aa\u30d5\u30e9\u30a4\u30f3\u306e\u74b0\u5883\u3067\u3082\u52d5\u4f5c\u3055\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u3053\u306e\u52d5\u4f5c\u3092\u6709\u52b9\u306b\u3059\u308b\u305f\u3081\u306b\u306f\u3001\u74b0\u5883\u5909\u6570`HF_HUB_OFFLINE=1`\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\n\n<Tip>\n\n\u74b0\u5883\u5909\u6570`HF_DATASETS_OFFLINE=1`\u3092\u8a2d\u5b9a\u3057\u3001\u30aa\u30d5\u30e9\u30a4\u30f3\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u306b[\ud83e\udd17 Datasets](https://huggingface.co/docs/datasets/)\u3092\u8ffd\u52a0\u3057\u307e\u3059\u3002\n\n</Tip>\n\n\u4f8b\u3048\u3070\u3001\u5916\u90e8\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306b\u5bfe\u3057\u3066\u30d5\u30a1\u30a4\u30a2\u30a6\u30a9\u30fc\u30eb\u3067\u4fdd\u8b77\u3055\u308c\u305f\u901a\u5e38\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u4e0a\u3067\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u5b9f\u884c\u3059\u308b\u5834\u5408\u3001\u901a\u5e38\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30b3\u30de\u30f3\u30c9\u3067\u5b9f\u884c\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059:\n\n```bash\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\n\u30aa\u30d5\u30e9\u30a4\u30f3\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3067\u3053\u306e\u540c\u3058\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u5b9f\u884c\u3057\u307e\u3059:\n\n```bash\nHF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \\\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\n\u3053\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u3001\u30ed\u30fc\u30ab\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u307f\u3092\u691c\u7d22\u3059\u308b\u3053\u3068\u304c\u5206\u304b\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u30cf\u30f3\u30b0\u30a2\u30c3\u30d7\u3057\u305f\u308a\u30bf\u30a4\u30e0\u30a2\u30a6\u30c8\u3092\u5f85\u3063\u305f\u308a\u3059\u308b\u3053\u3068\u306a\u304f\u5b9f\u884c\u3055\u308c\u308b\u306f\u305a\u3067\u3059\u3002\n\n### \u30aa\u30d5\u30e9\u30a4\u30f3\u3067\u4f7f\u7528\u3059\u308b\u305f\u3081\u306b\u30e2\u30c7\u30eb\u3084\u30c8\u30fc\u30af\u30ca\u30a4\u30b6\u30fc\u3092\u53d6\u5f97\u3059\u308b\n\n\u30aa\u30d5\u30e9\u30a4\u30f3\u3067\ud83e\udd17 Transformers\u3092\u4f7f\u7528\u3059\u308b\u3082\u30461\u3064\u306e\u65b9\u6cd5\u306f\u3001\u524d\u3082\u3063\u3066\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304a\u304d\u3001\u30aa\u30d5\u30e9\u30a4\u30f3\u3067\u4f7f\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3068\u304d\u306b\u305d\u306e\u30ed\u30fc\u30ab\u30eb\u30d1\u30b9\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u3053\u308c\u306b\u306f3\u3064\u306e\u65b9\u6cd5\u304c\u3042\u308a\u307e\u3059:\n\n* [Model Hub](https://huggingface.co/models)\u306e\u30e6\u30fc\u30b6\u30fc\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u4e0a\u304b\u3089\u2193\u30a2\u30a4\u30b3\u30f3\u3092\u30af\u30ea\u30c3\u30af\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u65b9\u6cd5\u3002\n\n    ![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)\n\n* [`PreTrainedModel.from_pretrained`]\u304a\u3088\u3073[`PreTrainedModel.save_pretrained`]\u306e\u30ef\u30fc\u30af\u30d5\u30ed\u30fc\u3092\u4f7f\u7528\u3059\u308b\u65b9\u6cd5:\n\n    1. [`PreTrainedModel.from_pretrained`]\u3067\u524d\u3082\u3063\u3066\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059:\n\n    ```py\n    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n    ```\n\n    2. [`PreTrainedModel.save_pretrained`]\u3067\u6307\u5b9a\u3055\u308c\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30d5\u30a1\u30a4\u30eb\u3092\u4fdd\u5b58\u3057\u3066\u304a\u304d\u307e\u3059:\n\n    ```py\n    >>> tokenizer.save_pretrained(\"./your/path/bigscience_t0\")\n    >>> model.save_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n    3. \u30aa\u30d5\u30e9\u30a4\u30f3\u306b\u3042\u308b\u6642\u3001[`PreTrainedModel.from_pretrained`]\u306b\u6307\u5b9a\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u304b\u3089\u30d5\u30a1\u30a4\u30eb\u3092\u30ea\u30ed\u30fc\u30c9\u3057\u307e\u3059:\n\n    ```py\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"./your/path/bigscience_t0\")\n    >>> model = AutoModel.from_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n* \u30d7\u30ed\u30b0\u30e9\u30e0\u7684\u306b[huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub)\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u7528\u3044\u3066\u3001\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u65b9\u6cd5:\n\n    1. \u4eee\u60f3\u74b0\u5883\u306b`huggingface_hub`\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059:\n\n    ```bash\n    python -m pip install huggingface_hub\n    ```\n\n    2. \u6307\u5b9a\u306e\u30d1\u30b9\u306b\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u305f\u3081\u306b\u3001[`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub)\u95a2\u6570\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\u4f8b\u3048\u3070\u3001\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067\u3001[T0](https://huggingface.co/bigscience/T0_3B)\u30e2\u30c7\u30eb\u306e`config.json`\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u306e\u30d1\u30b9\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3067\u304d\u307e\u3059:\n\n    ```py\n    >>> from huggingface_hub import hf_hub_download\n\n    >>> hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./your/path/bigscience_t0\")\n    ```\n\n\u30d5\u30a1\u30a4\u30eb\u304c\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u3001\u30ed\u30fc\u30ab\u30eb\u306b\u30ad\u30e3\u30c3\u30b7\u30e5\u3055\u308c\u305f\u3089\u3001\u305d\u306e\u30ed\u30fc\u30ab\u30eb\u30d1\u30b9\u3092\u6307\u5b9a\u3057\u3066\u30d5\u30a1\u30a4\u30eb\u3092\u30ed\u30fc\u30c9\u3057\u3066\u4f7f\u7528\u3057\u307e\u3059:\n\n```py\n>>> from transformers import AutoConfig\n\n>>> config = AutoConfig.from_pretrained(\"./your/path/bigscience_t0/config.json\")\n```\n\n<Tip>\n\nHub\u306b\u4fdd\u5b58\u3055\u308c\u3066\u3044\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u65b9\u6cd5\u306e\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001[How to download files from the Hub](https://huggingface.co/docs/hub/how-to-downstream)\u30bb\u30af\u30b7\u30e7\u30f3\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n</Tip>\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/docs/source/ja/installation.md"
            },
            {
                "result": {
                    "value": "<!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\u26a0\ufe0f Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n-->\n\n# Installazione\n\nInstalla \ud83e\udd17 Transformers per qualsiasi libreria di deep learning con cui stai lavorando, imposta la tua cache, e opzionalmente configura \ud83e\udd17 Transformers per l'esecuzione offline.\n\n\ud83e\udd17 Transformers \u00e8 testato su Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, e Flax. Segui le istruzioni di installazione seguenti per la libreria di deep learning che stai utilizzando:\n\n* [PyTorch](https://pytorch.org/get-started/locally/) istruzioni di installazione.\n* [TensorFlow 2.0](https://www.tensorflow.org/install/pip) istruzioni di installazione.\n* [Flax](https://flax.readthedocs.io/en/latest/) istruzioni di installazione.\n\n## Installazione con pip\n\nPuoi installare \ud83e\udd17 Transformers in un [ambiente virtuale](https://docs.python.org/3/library/venv.html). Se non sei familiare con gli ambienti virtuali in Python, dai un'occhiata a questa [guida](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). Un ambiente virtuale rende pi\u00f9 semplice la gestione di progetti differenti, evitando problemi di compatibilit\u00e0 tra dipendenze.\n\nInizia creando un ambiente virtuale nella directory del tuo progetto:\n\n```bash\npython -m venv .env\n```\n\nAttiva l'ambiente virtuale:\n\n```bash\nsource .env/bin/activate\n```\n\nOra puoi procedere con l'installazione di \ud83e\udd17 Transformers eseguendo il comando seguente:\n\n```bash\npip install transformers\n```\n\nPer il solo supporto della CPU, puoi installare facilmente \ud83e\udd17 Transformers e una libreria di deep learning in solo una riga. Ad esempio, installiamo \ud83e\udd17 Transformers e PyTorch con:\n\n```bash\npip install transformers[torch]\n```\n\n\ud83e\udd17 Transformers e TensorFlow 2.0:\n\n```bash\npip install transformers[tf-cpu]\n```\n\n\ud83e\udd17 Transformers e Flax:\n\n```bash\npip install transformers[flax]\n```\n\nInfine, verifica se \ud83e\udd17 Transformers \u00e8 stato installato in modo appropriato eseguendo il seguente comando. Questo scaricher\u00e0 un modello pre-allenato:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n```\n\nDopodich\u00e9 stampa l'etichetta e il punteggio:\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n```\n\n## Installazione dalla fonte\n\nInstalla \ud83e\udd17 Transformers dalla fonte con il seguente comando:\n\n```bash\npip install git+https://github.com/huggingface/transformers\n```\n\nQuesto comando installa la versione `main` pi\u00f9 attuale invece dell'ultima versione stabile. Questo \u00e8 utile per stare al passo con gli ultimi sviluppi. Ad esempio, se un bug \u00e8 stato sistemato da quando \u00e8 uscita l'ultima versione ufficiale ma non \u00e8 stata ancora rilasciata una nuova versione. Tuttavia, questo significa che questa versione `main` pu\u00f2 non essere sempre stabile. Ci sforziamo per mantenere la versione `main` operativa, e la maggior parte dei problemi viene risolta in poche ore o in un giorno. Se riscontri un problema, per favore apri una [Issue](https://github.com/huggingface/transformers/issues) cos\u00ec possiamo sistemarlo ancora pi\u00f9 velocemente!\n\nControlla se \ud83e\udd17 Transformers \u00e8 stata installata in modo appropriato con il seguente comando:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n```\n\n## Installazione modificabile\n\nHai bisogno di un'installazione modificabile se vuoi:\n\n* Usare la versione `main` del codice dalla fonte.\n* Contribuire a \ud83e\udd17 Transformers e hai bisogno di testare i cambiamenti nel codice.\n\nClona il repository e installa \ud83e\udd17 Transformers con i seguenti comandi:\n\n```bash\ngit clone https://github.com/huggingface/transformers.git\ncd transformers\npip install -e .\n```\n\nQuesti comandi collegheranno la cartella in cui \u00e8 stato clonato il repository e i path delle librerie Python. Python guarder\u00e0 ora all'interno della cartella clonata, oltre ai normali path delle librerie. Per esempio, se i tuoi pacchetti Python sono installati tipicamente in `~/anaconda3/envs/main/lib/python3.7/site-packages/`, Python cercher\u00e0 anche nella cartella clonata: `~/transformers/`.\n\n<Tip warning={true}>\n\nDevi tenere la cartella `transformers` se vuoi continuare ad utilizzare la libreria.\n\n</Tip>\n\nOra puoi facilmente aggiornare il tuo clone all'ultima versione di \ud83e\udd17 Transformers con il seguente comando:\n\n```bash\ncd ~/transformers/\ngit pull\n```\n\nIl tuo ambiente Python trover\u00e0 la versione `main` di \ud83e\udd17 Transformers alla prossima esecuzione.\n\n## Installazione con conda\n\nInstallazione dal canale conda `conda-forge`:\n\n```bash\nconda install conda-forge::transformers\n```\n\n## Impostazione della cache\n\nI modelli pre-allenati sono scaricati e memorizzati localmente nella cache in: `~/.cache/huggingface/transformers/`. Questa \u00e8 la directory di default data dalla variabile d'ambiente della shell `TRANSFORMERS_CACHE`. Su Windows, la directory di default \u00e8 data da `C:\\Users\\username\\.cache\\huggingface\\transformers`. Puoi cambiare le variabili d'ambiente della shell indicate in seguito, in ordine di priorit\u00e0, per specificare una directory differente per la cache:\n\n1. Variabile d'ambiente della shell (default): `TRANSFORMERS_CACHE`.\n2. Variabile d'ambiente della shell: `HF_HOME` + `transformers/`.\n3. Variabile d'ambiente della shell: `XDG_CACHE_HOME` + `/huggingface/transformers`.\n\n<Tip>\n\n\ud83e\udd17 Transformers utilizzer\u00e0 le variabili d'ambiente della shell `PYTORCH_TRANSFORMERS_CACHE` o `PYTORCH_PRETRAINED_BERT_CACHE` se si proviene da un'iterazione precedente di questa libreria e sono state impostate queste variabili d'ambiente, a meno che non si specifichi la variabile d'ambiente della shell `TRANSFORMERS_CACHE`.\n\n</Tip>\n\n## Modalit\u00e0 Offline\n\n\ud83e\udd17 Transformers pu\u00f2 essere eseguita in un ambiente firewalled o offline utilizzando solo file locali. Imposta la variabile d'ambiente `HF_HUB_OFFLINE=1` per abilitare questo comportamento.\n\n<Tip>\n\nAggiungi [\ud83e\udd17 Datasets](https://huggingface.co/docs/datasets/) al tuo flusso di lavoro offline di training impostando la variabile d'ambiente `HF_DATASETS_OFFLINE=1`.\n\n</Tip>\n\nAd esempio, in genere si esegue un programma su una rete normale, protetta da firewall per le istanze esterne, con il seguente comando:\n\n```bash\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\nEsegui lo stesso programma in un'istanza offline con:\n\n```bash\nHF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \\\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\nLo script viene ora eseguito senza bloccarsi o attendere il timeout, perch\u00e9 sa di dover cercare solo file locali.\n\n### Ottenere modelli e tokenizer per l'uso offline\n\nUn'altra opzione per utilizzare offline \ud83e\udd17 Transformers \u00e8 scaricare i file in anticipo, e poi puntare al loro path locale quando hai la necessit\u00e0 di utilizzarli offline. Ci sono tre modi per fare questo:\n\n* Scarica un file tramite l'interfaccia utente sul [Model Hub](https://huggingface.co/models) premendo sull'icona \u2193.\n\n    ![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)\n\n* Utilizza il flusso [`PreTrainedModel.from_pretrained`] e [`PreTrainedModel.save_pretrained`]:\n\n    1. Scarica i tuoi file in anticipo con [`PreTrainedModel.from_pretrained`]:\n\n    ```py\n    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n    ```\n\n    2. Salva i tuoi file in una directory specificata con [`PreTrainedModel.save_pretrained`]:\n\n    ```py\n    >>> tokenizer.save_pretrained(\"./il/tuo/path/bigscience_t0\")\n    >>> model.save_pretrained(\"./il/tuo/path/bigscience_t0\")\n    ```\n\n    3. Ora quando sei offline, carica i tuoi file con [`PreTrainedModel.from_pretrained`] dalla directory specificata:\n\n    ```py\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"./il/tuo/path/bigscience_t0\")\n    >>> model = AutoModel.from_pretrained(\"./il/tuo/path/bigscience_t0\")\n    ```\n\n* Scarica in maniera programmatica i file con la libreria [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub):\n\n    1. Installa la libreria `huggingface_hub` nel tuo ambiente virtuale:\n\n    ```bash\n    python -m pip install huggingface_hub\n    ```\n\n    2. Utilizza la funzione [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) per scaricare un file in un path specifico. Per esempio, il seguente comando scarica il file `config.json` dal modello [T0](https://huggingface.co/bigscience/T0_3B) nel path che desideri:\n\n    ```py\n    >>> from huggingface_hub import hf_hub_download\n\n    >>> hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./il/tuo/path/bigscience_t0\")\n    ```\n\nUna volta che il tuo file \u00e8 scaricato e salvato in cache localmente, specifica il suo path locale per caricarlo e utilizzarlo:\n\n```py\n>>> from transformers import AutoConfig\n\n>>> config = AutoConfig.from_pretrained(\"./il/tuo/path/bigscience_t0/config.json\")\n```\n\n<Tip>\n\nFai riferimento alla sezione [How to download files from the Hub](https://huggingface.co/docs/hub/how-to-downstream) per avere maggiori dettagli su come scaricare modelli presenti sull Hub.\n\n</Tip>\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/docs/source/it/installation.md"
            },
            {
                "result": {
                    "value": "<!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\u26a0\ufe0f Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n-->\n\n# Guia de Instala\u00e7\u00e3o\n\nNeste guia poder\u00e1 encontrar informa\u00e7\u00f5es para a instala\u00e7\u00e3o do \ud83e\udd17 Transformers para qualquer biblioteca de\nMachine Learning com a qual esteja a trabalhar. Al\u00e9m disso, poder\u00e1 encontrar informa\u00e7\u00f5es sobre como gerar cach\u00eas e\nconfigurar o \ud83e\udd17 Transformers para execu\u00e7\u00e3o em modo offline (opcional).\n\n\ud83e\udd17 Transformers foi testado com Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, e Flax. Para instalar a biblioteca de\ndeep learning com que deseja trabalhar, siga as instru\u00e7\u00f5es correspondentes listadas a seguir:\n\n* [PyTorch](https://pytorch.org/get-started/locally/)\n* [TensorFlow 2.0](https://www.tensorflow.org/install/pip)\n* [Flax](https://flax.readthedocs.io/en/latest/)\n\n## Instala\u00e7\u00e3o pelo Pip\n\n\u00c9 sugerido instalar o \ud83e\udd17 Transformers num [ambiente virtual](https://docs.python.org/3/library/venv.html). Se precisar\nde mais informa\u00e7\u00f5es sobre ambientes virtuais em Python, consulte este [guia](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).\nUm ambiente virtual facilitar\u00e1 a manipula\u00e7\u00e3o e organiza\u00e7\u00e3o de projetos e evita problemas de compatibilidade entre depend\u00eancias.\n\nComece criando um ambiente virtual no diret\u00f3rio do seu projeto:\n\n```bash\npython -m venv .env\n```\n\nE para ativar o ambiente virtual:\n\n```bash\nsource .env/bin/activate\n```\n\nAgora \u00c9 poss\u00edvel instalar o \ud83e\udd17 Transformers com o comando a seguir:\n\n```bash\npip install transformers\n```\n\nSomente para a CPU, \u00e9 poss\u00edvel instalar o \ud83e\udd17 Transformers e a biblioteca de deep learning respectiva apenas numa linha.\n\nPor exemplo, para instalar o \ud83e\udd17 Transformers e o PyTorch, digite:\n\n```bash\npip install transformers[torch]\n```\n\n\ud83e\udd17 Transformers e TensorFlow 2.0:\n\n```bash\npip install transformers[tf-cpu]\n```\n\n\ud83e\udd17 Transformers e Flax:\n\n```bash\npip install transformers[flax]\n```\n\nPor \u00faltimo, verifique se o \ud83e\udd17 Transformers foi instalado com sucesso usando o seguinte comando para baixar um modelo pr\u00e9-treinado:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n```\n\nEm seguida, imprima um r\u00f3tulo e sua pontua\u00e7\u00e3o:\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n```\n\n## Instala\u00e7\u00e3o usando a fonte\n\nPara instalar o \ud83e\udd17 Transformers a partir da fonte use o seguinte comando:\n\n```bash\npip install git+https://github.com/huggingface/transformers\n```\n\nO comando acima instalar\u00e1 a vers\u00e3o `master` mais atual em vez da \u00faltima vers\u00e3o est\u00e1vel. A vers\u00e3o `master` \u00e9 \u00fatil para\nutilizar os \u00faltimos updates contidos em \ud83e\udd17 Transformers. Por exemplo, um erro recente pode ter sido corrigido somente\nap\u00f3s a \u00faltima vers\u00e3o est\u00e1vel, antes que houvesse um novo lan\u00e7amento. No entanto, h\u00e1 a possibilidade que a vers\u00e3o `master` n\u00e3o esteja est\u00e1vel.\nA equipa trata de mant\u00e9r a vers\u00e3o `master` operacional e a maioria dos erros s\u00e3o resolvidos em poucas horas ou dias.\nSe encontrar quaisquer problemas, por favor abra um [Issue](https://github.com/huggingface/transformers/issues) para que o\nmesmo possa ser corrigido o mais r\u00e1pido poss\u00edvel.\n\nVerifique que o \ud83e\udd17 Transformers est\u00e1 instalado corretamente usando o seguinte comando:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n```\n\n## Instala\u00e7\u00e3o edit\u00e1vel\n\nUma instala\u00e7\u00e3o edit\u00e1vel ser\u00e1 necess\u00e1ria caso desejas um dos seguintes:\n* Usar a vers\u00e3o `master` do c\u00f3digo fonte.\n* Contribuir ao \ud83e\udd17 Transformers e precisa testar mudan\u00e7as ao c\u00f3digo.\n\nPara tal, clone o reposit\u00f3rio e instale o \ud83e\udd17 Transformers com os seguintes comandos:\n\n```bash\ngit clone https://github.com/huggingface/transformers.git\ncd transformers\npip install -e .\n```\n\nEstes comandos v\u00e3o ligar o diret\u00f3rio para o qual foi clonado o reposit\u00f3rio ao caminho de bibliotecas do Python.\nO Python agora buscar\u00e1 dentro dos arquivos que foram clonados al\u00e9m dos caminhos normais da biblioteca.\nPor exemplo, se os pacotes do Python se encontram instalados no caminho `~/anaconda3/envs/main/lib/python3.7/site-packages/`,\no Python tamb\u00e9m buscar\u00e1 m\u00f3dulos no diret\u00f3rio onde clonamos o reposit\u00f3rio `~/transformers/`.\n\n<Tip warning={true}>\n\n\u00c9 necess\u00e1rio manter o diret\u00f3rio `transformers` se desejas continuar usando a biblioteca.\n\n</Tip>\n\nAssim, \u00c9 poss\u00edvel atualizar sua c\u00f3pia local para com a \u00faltima vers\u00e3o do \ud83e\udd17 Transformers com o seguinte comando:\n\n```bash\ncd ~/transformers/\ngit pull\n```\n\nO ambiente de Python que foi criado para a instala\u00e7\u00e3o do \ud83e\udd17 Transformers encontrar\u00e1 a vers\u00e3o `master` em execu\u00e7\u00f5es seguintes.\n\n## Instala\u00e7\u00e3o usando o Conda\n\n\u00c9 poss\u00edvel instalar o \ud83e\udd17 Transformers a partir do canal conda `conda-forge` com o seguinte comando:\n\n```bash\nconda install conda-forge::transformers\n```\n\n## Configura\u00e7\u00e3o do Cach\u00ea\n\nOs modelos pr\u00e9-treinados s\u00e3o baixados e armazenados no cach\u00ea local, encontrado em `~/.cache/huggingface/transformers/`.\nEste \u00e9 o diret\u00f3rio padr\u00e3o determinado pela vari\u00e1vel `TRANSFORMERS_CACHE` dentro do shell.\nNo Windows, este diret\u00f3rio pr\u00e9-definido \u00e9 dado por `C:\\Users\\username\\.cache\\huggingface\\transformers`.\n\u00c9 poss\u00edvel mudar as vari\u00e1veis dentro do shell em ordem de prioridade para especificar um diret\u00f3rio de cach\u00ea diferente:\n\n1. Vari\u00e1vel de ambiente do shell (por padr\u00e3o): `TRANSFORMERS_CACHE`.\n2. Vari\u00e1vel de ambiente do shell:`HF_HOME` + `transformers/`.\n3. Vari\u00e1vel de ambiente do shell: `XDG_CACHE_HOME` + `/huggingface/transformers`.\n\n<Tip>\n\n    O \ud83e\udd17 Transformers usar\u00e1 as vari\u00e1veis de ambiente do shell `PYTORCH_TRANSFORMERS_CACHE` ou `PYTORCH_PRETRAINED_BERT_CACHE`\n    se estiver vindo de uma vers\u00e3o anterior da biblioteca que tenha configurado essas vari\u00e1veis de ambiente, a menos que\n    voc\u00ea especifique a vari\u00e1vel de ambiente do shell `TRANSFORMERS_CACHE`.\n\n</Tip>\n\n\n## Modo Offline\n\nO \ud83e\udd17 Transformers tamb\u00e9m pode ser executado num ambiente de firewall ou fora da rede (offline) usando arquivos locais.\nPara tal, configure a vari\u00e1vel de ambiente de modo que `HF_HUB_OFFLINE=1`.\n\n<Tip>\n\nVoc\u00ea pode adicionar o [\ud83e\udd17 Datasets](https://huggingface.co/docs/datasets/) ao pipeline de treinamento offline declarando\n    a vari\u00e1vel de ambiente `HF_DATASETS_OFFLINE=1`.\n\n</Tip>\n\nSegue um exemplo de execu\u00e7\u00e3o do programa numa rede padr\u00e3o com firewall para inst\u00e2ncias externas, usando o seguinte comando:\n\n```bash\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\nExecute esse mesmo programa numa inst\u00e2ncia offline com o seguinte comando:\n\n```bash\nHF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \\\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\nO script agora deve ser executado sem travar ou expirar, pois procurar\u00e1 apenas por arquivos locais.\n\n### Obtendo modelos e tokenizers para uso offline\n\nOutra op\u00e7\u00e3o para usar o \ud83e\udd17 Transformers offline \u00e9 baixar os arquivos antes e depois apontar para o caminho local onde est\u00e3o localizados. Existem tr\u00eas maneiras de fazer isso:\n\n* Baixe um arquivo por meio da interface de usu\u00e1rio do [Model Hub](https://huggingface.co/models) clicando no \u00edcone \u2193.\n\n    ![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)\n\n\n* Use o pipeline do [`PreTrainedModel.from_pretrained`] e [`PreTrainedModel.save_pretrained`]:\n    1. Baixa os arquivos previamente com [`PreTrainedModel.from_pretrained`]:\n\n    ```py\n    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n    ```\n\n\n    2. Salve os arquivos em um diret\u00f3rio espec\u00edfico com [`PreTrainedModel.save_pretrained`]:\n\n    ```py\n    >>> tokenizer.save_pretrained(\"./your/path/bigscience_t0\")\n    >>> model.save_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n    3. Quando estiver offline, acesse os arquivos com [`PreTrainedModel.from_pretrained`] do diret\u00f3rio especificado:\n\n    ```py\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"./your/path/bigscience_t0\")\n    >>> model = AutoModel.from_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n* Baixando arquivos programaticamente com a biblioteca [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub):\n\n    1. Instale a biblioteca [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub) em seu ambiente virtual:\n\n    ```bash\n    python -m pip install huggingface_hub\n    ```\n\n    2. Utiliza a fun\u00e7\u00e3o [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) para baixar um arquivo para um caminho espec\u00edfico. Por exemplo, o comando a seguir baixar\u00e1 o arquivo `config.json` para o modelo [T0](https://huggingface.co/bigscience/T0_3B) no caminho desejado:\n\n    ```py\n    >>> from huggingface_hub import hf_hub_download\n\n    >>> hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./your/path/bigscience_t0\")\n    ```\n\nDepois que o arquivo for baixado e armazenado no cach\u00ea local, especifique seu caminho local para carreg\u00e1-lo e us\u00e1-lo:\n\n```py\n>>> from transformers import AutoConfig\n\n>>> config = AutoConfig.from_pretrained(\"./your/path/bigscience_t0/config.json\")\n```\n\n<Tip>\n\nPara obter mais detalhes sobre como baixar arquivos armazenados no Hub, consulte a se\u00e7\u00e3o [How to download files from the Hub](https://huggingface.co/docs/hub/how-to-downstream).\n\n</Tip>\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/docs/source/pt/installation.md"
            },
            {
                "result": {
                    "value": "<!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\u26a0\ufe0f Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n-->\n\n# \u5b89\u88c5\n\n\u4e3a\u4f60\u6b63\u5728\u4f7f\u7528\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5b89\u88c5 \ud83e\udd17 Transformers\u3001\u8bbe\u7f6e\u7f13\u5b58\uff0c\u5e76\u9009\u62e9\u6027\u914d\u7f6e \ud83e\udd17 Transformers \u4ee5\u79bb\u7ebf\u8fd0\u884c\u3002\n\n\ud83e\udd17 Transformers \u5df2\u5728 Python 3.6+\u3001PyTorch 1.1.0+\u3001TensorFlow 2.0+ \u4ee5\u53ca Flax \u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002\u9488\u5bf9\u4f60\u4f7f\u7528\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u8bf7\u53c2\u7167\u4ee5\u4e0b\u5b89\u88c5\u8bf4\u660e\u8fdb\u884c\u5b89\u88c5\uff1a\n\n* [PyTorch](https://pytorch.org/get-started/locally/) \u5b89\u88c5\u8bf4\u660e\u3002\n* [TensorFlow 2.0](https://www.tensorflow.org/install/pip) \u5b89\u88c5\u8bf4\u660e\u3002\n* [Flax](https://flax.readthedocs.io/en/latest/) \u5b89\u88c5\u8bf4\u660e\u3002\n\n## \u4f7f\u7528 pip \u5b89\u88c5\n\n\u4f60\u5e94\u8be5\u4f7f\u7528 [\u865a\u62df\u73af\u5883](https://docs.python.org/3/library/venv.html) \u5b89\u88c5 \ud83e\udd17 Transformers\u3002\u5982\u679c\u4f60\u4e0d\u719f\u6089 Python \u865a\u62df\u73af\u5883\uff0c\u8bf7\u67e5\u770b\u6b64 [\u6559\u7a0b](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)\u3002\u4f7f\u7528\u865a\u62df\u73af\u5883\uff0c\u4f60\u53ef\u4ee5\u8f7b\u677e\u7ba1\u7406\u4e0d\u540c\u9879\u76ee\uff0c\u907f\u514d\u4e0d\u540c\u4f9d\u8d56\u9879\u4e4b\u95f4\u7684\u517c\u5bb9\u6027\u95ee\u9898\u3002\n\n\u9996\u5148\uff0c\u5728\u9879\u76ee\u76ee\u5f55\u4e2d\u521b\u5efa\u865a\u62df\u73af\u5883\uff1a\n\n```bash\npython -m venv .env\n```\n\n\u5728 Linux \u548c MacOs \u7cfb\u7edf\u4e2d\u6fc0\u6d3b\u865a\u62df\u73af\u5883\uff1a\n\n```bash\nsource .env/bin/activate\n```\n\u5728 Windows \u7cfb\u7edf\u4e2d\u6fc0\u6d3b\u865a\u62df\u73af\u5883\uff1a\n\n```bash\n.env/Scripts/activate\n```\n\n\u73b0\u5728\u4f60\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5 \ud83e\udd17 Transformers\uff1a\n\n```bash\npip install transformers\n```\n\n\u82e5\u4ec5\u9700 CPU \u652f\u6301\uff0c\u53ef\u4ee5\u4f7f\u7528\u5355\u884c\u547d\u4ee4\u65b9\u4fbf\u5730\u5b89\u88c5 \ud83e\udd17 Transformers \u548c\u6df1\u5ea6\u5b66\u4e60\u5e93\u3002\u4f8b\u5982\uff0c\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5 \ud83e\udd17 Transformers \u548c PyTorch\uff1a\n\n```bash\npip install 'transformers[torch]'\n```\n\n\ud83e\udd17 Transformers \u548c TensorFlow 2.0\uff1a\n\n```bash\npip install 'transformers[tf-cpu]'\n```\n\n<Tip warning={true}>\n\nM1 / ARM\u7528\u6237\n\n\u5728\u5b89\u88c5 TensorFlow 2.0 \u524d\uff0c\u4f60\u9700\u8981\u5b89\u88c5\u4ee5\u4e0b\u5e93\uff1a\n```bash\nbrew install cmake\nbrew install pkg-config\n```\n\n</Tip>\n\n\ud83e\udd17 Transformers \u548c Flax:\n\n```bash\npip install 'transformers[flax]'\n```\n\n\u6700\u540e\uff0c\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u68c0\u67e5 \ud83e\udd17 Transformers \u662f\u5426\u5df2\u88ab\u6b63\u786e\u5b89\u88c5\u3002\u8be5\u547d\u4ee4\u5c06\u4e0b\u8f7d\u4e00\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\uff1a\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n```\n\n\u7136\u540e\u6253\u5370\u6807\u7b7e\u4ee5\u53ca\u5206\u6570\uff1a\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n```\n\n## \u6e90\u7801\u5b89\u88c5\n\n\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u4ece\u6e90\u7801\u5b89\u88c5 \ud83e\udd17 Transformers\uff1a\n\n```bash\npip install git+https://github.com/huggingface/transformers\n```\n\n\u6b64\u547d\u4ee4\u4e0b\u8f7d\u7684\u662f\u6700\u65b0\u7684\u524d\u6cbf `main` \u7248\u672c\u800c\u4e0d\u662f\u6700\u65b0\u7684 `stable` \u7248\u672c\u3002`main` \u7248\u672c\u9002\u7528\u4e8e\u8ddf\u6700\u65b0\u5f00\u53d1\u4fdd\u6301\u4e00\u81f4\u3002\u4f8b\u5982\uff0c\u4e0a\u6b21\u6b63\u5f0f\u7248\u53d1\u5e03\u5e26\u6765\u7684 bug \u88ab\u4fee\u590d\u4e86\uff0c\u4f46\u65b0\u7248\u672c\u5c1a\u672a\u88ab\u63a8\u51fa\u3002\u4f46\u662f\uff0c\u8fd9\u4e5f\u8bf4\u660e `main` \u7248\u672c\u5e76\u4e0d\u4e00\u5b9a\u603b\u662f\u7a33\u5b9a\u7684\u3002\u6211\u4eec\u52aa\u529b\u4fdd\u6301 `main` \u7248\u672c\u7684\u53ef\u64cd\u4f5c\u6027\uff0c\u5927\u591a\u6570\u95ee\u9898\u901a\u5e38\u5728\u51e0\u4e2a\u5c0f\u65f6\u6216\u4e00\u5929\u4ee5\u5185\u5c31\u80fd\u88ab\u89e3\u51b3\u3002\u5982\u679c\u4f60\u9047\u5230\u95ee\u9898\uff0c\u8bf7\u63d0\u4e2a [Issue](https://github.com/huggingface/transformers/issues) \u4ee5\u4fbf\u6211\u4eec\u80fd\u66f4\u5feb\u4fee\u590d\u3002\n\n\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u68c0\u67e5 \ud83e\udd17 Transformers \u662f\u5426\u5df2\u88ab\u6b63\u786e\u5b89\u88c5\uff1a\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n```\n\n## \u53ef\u7f16\u8f91\u5b89\u88c5\n\n\u5982\u679c\u4f60\u6709\u4e0b\u5217\u9700\u6c42\uff0c\u9700\u8981\u8fdb\u884c\u53ef\u7f16\u8f91\u5b89\u88c5\uff1a\n\n* \u4f7f\u7528\u6e90\u7801\u7684 `main` \u7248\u672c\u3002\n* \u4e3a \ud83e\udd17 Transformers \u8d21\u732e\u4ee3\u7801\uff0c\u9700\u8981\u6d4b\u8bd5\u4ee3\u7801\u4e2d\u7684\u66f4\u6539\u3002\n\n\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u514b\u9686\u4ed3\u5e93\u5e76\u5b89\u88c5 \ud83e\udd17 Transformers\uff1a\n\n```bash\ngit clone https://github.com/huggingface/transformers.git\ncd transformers\npip install -e .\n```\n\n\u8fd9\u4e9b\u547d\u4ee4\u5c06\u4f1a\u94fe\u63a5\u4f60\u514b\u9686\u7684\u4ed3\u5e93\u4ee5\u53ca\u4f60\u7684 Python \u5e93\u8def\u5f84\u3002\u73b0\u5728\uff0cPython \u4e0d\u4ec5\u4f1a\u5728\u6b63\u5e38\u7684\u5e93\u8def\u5f84\u4e2d\u641c\u7d22\u5e93\uff0c\u4e5f\u4f1a\u5728\u4f60\u514b\u9686\u5230\u7684\u6587\u4ef6\u5939\u4e2d\u8fdb\u884c\u67e5\u627e\u3002\u4f8b\u5982\uff0c\u5982\u679c\u4f60\u7684 Python \u5305\u901a\u5e38\u672c\u5e94\u5b89\u88c5\u5728 `~/anaconda3/envs/main/lib/python3.7/site-packages/` \u76ee\u5f55\u4e2d\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b Python \u4e5f\u4f1a\u641c\u7d22\u4f60\u514b\u9686\u5230\u7684\u6587\u4ef6\u5939\uff1a`~/transformers/`\u3002\n\n<Tip warning={true}>\n\n\u5982\u679c\u4f60\u60f3\u7ee7\u7eed\u4f7f\u7528\u8fd9\u4e2a\u5e93\uff0c\u5fc5\u987b\u4fdd\u7559 `transformers` \u6587\u4ef6\u5939\u3002\n\n</Tip>\n\n\u73b0\u5728\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff0c\u5c06\u4f60\u514b\u9686\u7684 \ud83e\udd17 Transformers \u5e93\u8f7b\u677e\u66f4\u65b0\u81f3\u6700\u65b0\u7248\u672c\uff1a\n\n```bash\ncd ~/transformers/\ngit pull\n```\n\n\u4f60\u7684 Python \u73af\u5883\u5c06\u5728\u4e0b\u6b21\u8fd0\u884c\u65f6\u627e\u5230 `main` \u7248\u672c\u7684 \ud83e\udd17 Transformers\u3002\n\n## \u4f7f\u7528 conda \u5b89\u88c5\n\n\u4ece conda \u7684 `conda-forge` \u9891\u9053\u5b89\u88c5\uff1a\n\n```bash\nconda install conda-forge::transformers\n```\n\n## \u7f13\u5b58\u8bbe\u7f6e\n\n\u9884\u8bad\u7ec3\u6a21\u578b\u4f1a\u88ab\u4e0b\u8f7d\u5e76\u672c\u5730\u7f13\u5b58\u5230 `~/.cache/huggingface/hub`\u3002\u8fd9\u662f\u7531\u73af\u5883\u53d8\u91cf `TRANSFORMERS_CACHE` \u6307\u5b9a\u7684\u9ed8\u8ba4\u76ee\u5f55\u3002\u5728 Windows \u4e0a\uff0c\u9ed8\u8ba4\u76ee\u5f55\u4e3a `C:\\Users\\username\\.cache\\huggingface\\hub`\u3002\u4f60\u53ef\u4ee5\u6309\u7167\u4e0d\u540c\u4f18\u5148\u7ea7\u6539\u53d8\u4e0b\u8ff0\u73af\u5883\u53d8\u91cf\uff0c\u4ee5\u6307\u5b9a\u4e0d\u540c\u7684\u7f13\u5b58\u76ee\u5f55\u3002\n\n1. \u73af\u5883\u53d8\u91cf\uff08\u9ed8\u8ba4\uff09: `HUGGINGFACE_HUB_CACHE` \u6216 `TRANSFORMERS_CACHE`\u3002\n2. \u73af\u5883\u53d8\u91cf `HF_HOME`\u3002\n3. \u73af\u5883\u53d8\u91cf `XDG_CACHE_HOME` + `/huggingface`\u3002\n\n<Tip>\n\n\u9664\u975e\u4f60\u660e\u786e\u6307\u5b9a\u4e86\u73af\u5883\u53d8\u91cf `TRANSFORMERS_CACHE`\uff0c\ud83e\udd17 Transformers \u5c06\u53ef\u80fd\u4f1a\u4f7f\u7528\u8f83\u65e9\u7248\u672c\u8bbe\u7f6e\u7684\u73af\u5883\u53d8\u91cf `PYTORCH_TRANSFORMERS_CACHE` \u6216 `PYTORCH_PRETRAINED_BERT_CACHE`\u3002\n\n</Tip>\n\n## \u79bb\u7ebf\u6a21\u5f0f\n\n\ud83e\udd17 Transformers \u53ef\u4ee5\u4ec5\u4f7f\u7528\u672c\u5730\u6587\u4ef6\u5728\u9632\u706b\u5899\u6216\u79bb\u7ebf\u73af\u5883\u4e2d\u8fd0\u884c\u3002\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf `HF_HUB_OFFLINE=1` \u4ee5\u542f\u7528\u8be5\u884c\u4e3a\u3002\n\n<Tip>\n\n\u901a\u8fc7\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf `HF_DATASETS_OFFLINE=1` \u5c06 [\ud83e\udd17 Datasets](https://huggingface.co/docs/datasets/) \u6dfb\u52a0\u81f3\u4f60\u7684\u79bb\u7ebf\u8bad\u7ec3\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u3002\n\n</Tip>\n\n\u4f8b\u5982\uff0c\u4f60\u901a\u5e38\u4f1a\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u5bf9\u5916\u90e8\u5b9e\u4f8b\u8fdb\u884c\u9632\u706b\u5899\u4fdd\u62a4\u7684\u7684\u666e\u901a\u7f51\u7edc\u4e0a\u8fd0\u884c\u7a0b\u5e8f\uff1a\n\n```bash\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\n\u5728\u79bb\u7ebf\u73af\u5883\u4e2d\u8fd0\u884c\u76f8\u540c\u7684\u7a0b\u5e8f\uff1a\n\n```bash\nHF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \\\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\n\u73b0\u5728\u811a\u672c\u53ef\u4ee5\u5e94\u8be5\u6b63\u5e38\u8fd0\u884c\uff0c\u800c\u65e0\u9700\u6302\u8d77\u6216\u7b49\u5f85\u8d85\u65f6\uff0c\u56e0\u4e3a\u5b83\u77e5\u9053\u53ea\u5e94\u67e5\u627e\u672c\u5730\u6587\u4ef6\u3002\n\n### \u83b7\u53d6\u79bb\u7ebf\u65f6\u4f7f\u7528\u7684\u6a21\u578b\u548c\u5206\u8bcd\u5668\n\n\u53e6\u4e00\u79cd\u79bb\u7ebf\u65f6\u4f7f\u7528 \ud83e\udd17 Transformers \u7684\u65b9\u6cd5\u662f\u9884\u5148\u4e0b\u8f7d\u597d\u6587\u4ef6\uff0c\u7136\u540e\u5728\u9700\u8981\u79bb\u7ebf\u4f7f\u7528\u65f6\u6307\u5411\u5b83\u4eec\u7684\u79bb\u7ebf\u8def\u5f84\u3002\u6709\u4e09\u79cd\u5b9e\u73b0\u7684\u65b9\u6cd5\uff1a\n\n* \u5355\u51fb [Model Hub](https://huggingface.co/models) \u7528\u6237\u754c\u9762\u4e0a\u7684 \u2193 \u56fe\u6807\u4e0b\u8f7d\u6587\u4ef6\u3002\n\n    ![\u4e0b\u8f7d\u56fe\u6807](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)\n\n* \u4f7f\u7528 [`PreTrainedModel.from_pretrained`] \u548c [`PreTrainedModel.save_pretrained`] \u5de5\u4f5c\u6d41\u7a0b\uff1a\n\n    1. \u9884\u5148\u4f7f\u7528 [`PreTrainedModel.from_pretrained`] \u4e0b\u8f7d\u6587\u4ef6\uff1a\n\n    ```py\n    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n    ```\n\n    2. \u4f7f\u7528 [`PreTrainedModel.save_pretrained`] \u5c06\u6587\u4ef6\u4fdd\u5b58\u81f3\u6307\u5b9a\u76ee\u5f55\uff1a\n\n    ```py\n    >>> tokenizer.save_pretrained(\"./your/path/bigscience_t0\")\n    >>> model.save_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n    3. \u73b0\u5728\uff0c\u4f60\u53ef\u4ee5\u5728\u79bb\u7ebf\u65f6\u4ece\u6307\u5b9a\u76ee\u5f55\u4f7f\u7528 [`PreTrainedModel.from_pretrained`] \u91cd\u65b0\u52a0\u8f7d\u4f60\u7684\u6587\u4ef6\uff1a\n\n    ```py\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"./your/path/bigscience_t0\")\n    >>> model = AutoModel.from_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n* \u4f7f\u7528\u4ee3\u7801\u7528 [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub) \u5e93\u4e0b\u8f7d\u6587\u4ef6\uff1a\n\n    1. \u5728\u4f60\u7684\u865a\u62df\u73af\u5883\u4e2d\u5b89\u88c5 `huggingface_hub` \u5e93\uff1a\n\n    ```bash\n    python -m pip install huggingface_hub\n    ```\n\n    2. \u4f7f\u7528 [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) \u51fd\u6570\u5c06\u6587\u4ef6\u4e0b\u8f7d\u5230\u6307\u5b9a\u8def\u5f84\u3002\u4f8b\u5982\uff0c\u4ee5\u4e0b\u547d\u4ee4\u5c06 `config.json` \u6587\u4ef6\u4ece [T0](https://huggingface.co/bigscience/T0_3B) \u6a21\u578b\u4e0b\u8f7d\u81f3\u4f60\u60f3\u8981\u7684\u8def\u5f84\uff1a\n\n    ```py\n    >>> from huggingface_hub import hf_hub_download\n\n    >>> hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./your/path/bigscience_t0\")\n    ```\n\n\u4e0b\u8f7d\u5b8c\u6587\u4ef6\u5e76\u5728\u672c\u5730\u7f13\u5b58\u540e\uff0c\u6307\u5b9a\u5176\u672c\u5730\u8def\u5f84\u4ee5\u52a0\u8f7d\u548c\u4f7f\u7528\u8be5\u6a21\u578b\uff1a\n\n```py\n>>> from transformers import AutoConfig\n\n>>> config = AutoConfig.from_pretrained(\"./your/path/bigscience_t0/config.json\")\n```\n\n<Tip>\n\n\u8bf7\u53c2\u9605 [\u5982\u4f55\u4ece Hub \u4e0b\u8f7d\u6587\u4ef6](https://huggingface.co/docs/hub/how-to-downstream) \u90e8\u5206\uff0c\u83b7\u53d6\u6709\u5173\u4e0b\u8f7d\u5b58\u50a8\u5728 Hub \u4e0a\u6587\u4ef6\u7684\u66f4\u591a\u8be6\u7ec6\u4fe1\u606f\u3002\n\n</Tip>\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/docs/source/zh/installation.md"
            },
            {
                "result": {
                    "value": "<!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\u26a0\ufe0f Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n-->\n\n# Installation\n\nInstallieren Sie \ud83e\udd17 Transformers f\u00fcr die Deep-Learning-Bibliothek, mit der Sie arbeiten, richten Sie Ihren Cache ein und konfigurieren Sie \ud83e\udd17 Transformers optional f\u00fcr den Offline-Betrieb.\n\n\ud83e\udd17 Transformers wurde unter Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, und Flax getestet. Folgen Sie den Installationsanweisungen unten f\u00fcr die von Ihnen verwendete Deep-Learning-Bibliothek:\n\n* [PyTorch](https://pytorch.org/get-started/locally/) installation instructions.\n* [TensorFlow 2.0](https://www.tensorflow.org/install/pip) installation instructions.\n* [Flax](https://flax.readthedocs.io/en/latest/) installation instructions.\n\n## Installation mit pip\n\nSie sollten \ud83e\udd17 Transformers in einer [virtuellen Umgebung](https://docs.python.org/3/library/venv.html) installieren. Wenn Sie mit virtuellen Python-Umgebungen nicht vertraut sind, werfen Sie einen Blick auf diese [Anleitung](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). Eine virtuelle Umgebung macht es einfacher, verschiedene Projekte zu verwalten und Kompatibilit\u00e4tsprobleme zwischen Abh\u00e4ngigkeiten zu vermeiden.\n\nBeginnen wir mit der Erstellung einer virtuellen Umgebung in Ihrem Projektverzeichnis:\n\n\n```bash\npython -m venv .env\n```\n\nAktivieren wir die virtuelle Umgebung. Unter Linux und MacOs:\n\n```bash\nsource .env/bin/activate\n```\nAktivieren wir die virtuelle Umgebung unter Windows\n\n```bash\n.env/Scripts/activate\n```\n\nJetzt k\u00f6nnen wir die \ud83e\udd17 Transformers mit dem folgenden Befehl installieren:\n\n```bash\npip install transformers\n```\n\nBei reiner CPU-Unterst\u00fctzung k\u00f6nnen wir \ud83e\udd17 Transformers und eine Deep-Learning-Bibliothek bequem in einer Zeile installieren. Installieren wir zum Beispiel \ud83e\udd17 Transformers und PyTorch mit:\n\n```bash\npip install transformers[torch]\n```\n\n\ud83e\udd17 Transformers und TensorFlow 2.0:\n\n```bash\npip install transformers[tf-cpu]\n```\n\n\ud83e\udd17 Transformers und Flax:\n\n```bash\npip install transformers[flax]\n```\n\n\u00dcberpr\u00fcfen wir abschlie\u00dfend, ob \ud83e\udd17 Transformers ordnungsgem\u00e4\u00df installiert wurde, indem wir den folgenden Befehl ausf\u00fchren. Es wird ein vortrainiertes Modell heruntergeladen:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n```\n\nDann wird die Kategorie und die Wahrscheinlichkeit ausgegeben:\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n```\n\n## Installation aus dem Code\n\nInstallieren wir \ud83e\udd17 Transformers aus dem Quellcode mit dem folgenden Befehl:\n\n```bash\npip install git+https://github.com/huggingface/transformers\n```\n\nDieser Befehl installiert die aktuelle `main` Version und nicht die neueste `stable` Version. Die `main`-Version ist n\u00fctzlich, um mit den neuesten Entwicklungen Schritt zu halten. Zum Beispiel, wenn ein Fehler seit der letzten offiziellen Version behoben wurde, aber eine neue Version noch nicht ver\u00f6ffentlicht wurde. Das bedeutet jedoch, dass die \"Hauptversion\" nicht immer stabil ist. Wir bem\u00fchen uns, die Hauptversion einsatzbereit zu halten, und die meisten Probleme werden normalerweise innerhalb weniger Stunden oder eines Tages behoben. Wenn Sie auf ein Problem sto\u00dfen, \u00f6ffnen Sie bitte ein [Issue](https://github.com/huggingface/transformers/issues), damit wir es noch schneller beheben k\u00f6nnen!\n\n\u00dcberpr\u00fcfen wir, ob \ud83e\udd17 Transformers richtig installiert wurde, indem Sie den folgenden Befehl ausf\u00fchren:\n\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n```\n\n## Editierbare Installation\n\nSie ben\u00f6tigen eine bearbeitbare Installation, wenn Sie:\n\n* die \"Haupt\"-Version des Quellcodes verwenden m\u00f6chten.\n* Zu \ud83e\udd17 Transformers beitragen und \u00c4nderungen am Code testen wollen.\n\nKlonen Sie das Repository und installieren \ud83e\udd17 Transformers mit den folgenden Befehlen:\n\n```bash\ngit clone https://github.com/huggingface/transformers.git\ncd transformers\npip install -e .\n```\n\nDiese Befehle verkn\u00fcpfen den Ordner, in den Sie das Repository geklont haben, mit den Pfaden Ihrer Python-Bibliotheken. Python wird nun in dem Ordner suchen, in den Sie geklont haben, zus\u00e4tzlich zu den normalen Bibliothekspfaden. Wenn zum Beispiel Ihre Python-Pakete normalerweise in `~/anaconda3/envs/main/lib/python3.7/site-packages/` installiert sind, wird Python auch den Ordner durchsuchen, in den Sie geklont haben: `~/transformers/`.\n\n\n<Tip warning={true}>\n\nSie m\u00fcssen den Ordner `transformers` behalten, wenn Sie die Bibliothek weiter verwenden wollen.\n\n</Tip>\n\nJetzt k\u00f6nnen Sie Ihren Klon mit dem folgenden Befehl ganz einfach auf die neueste Version von \ud83e\udd17 Transformers aktualisieren:\n\n\n```bash\ncd ~/transformers/\ngit pull\n```\n\nIhre Python-Umgebung wird beim n\u00e4chsten Ausf\u00fchren die `main`-Version von \ud83e\udd17 Transformers finden.\n\n## Installation mit conda\n\nInstallation von dem conda Kanal `conda-forge`:\n\n```bash\nconda install conda-forge::transformers\n```\n\n## Cache Einrichtung\n\nVorgefertigte Modelle werden heruntergeladen und lokal zwischengespeichert unter: `~/.cache/huggingface/hub`. Dies ist das Standardverzeichnis, das durch die Shell-Umgebungsvariable \"TRANSFORMERS_CACHE\" vorgegeben ist. Unter Windows wird das Standardverzeichnis durch `C:\\Benutzer\\Benutzername\\.cache\\huggingface\\hub` angegeben. Sie k\u00f6nnen die unten aufgef\u00fchrten Shell-Umgebungsvariablen - in der Reihenfolge ihrer Priorit\u00e4t - \u00e4ndern, um ein anderes Cache-Verzeichnis anzugeben:\n\n1. Shell-Umgebungsvariable (Standard): `HUGGINGFACE_HUB_CACHE` oder `TRANSFORMERS_CACHE`.\n2. Shell-Umgebungsvariable: `HF_HOME`.\n3. Shell-Umgebungsvariable: `XDG_CACHE_HOME` + `/huggingface`.\n\n\n<Tip>\n\nTransformers verwendet die Shell-Umgebungsvariablen `PYTORCH_TRANSFORMERS_CACHE` oder `PYTORCH_PRETRAINED_BERT_CACHE`, wenn Sie von einer fr\u00fcheren Iteration dieser Bibliothek kommen und diese Umgebungsvariablen gesetzt haben, sofern Sie nicht die Shell-Umgebungsvariable `TRANSFORMERS_CACHE` angeben.\n\n</Tip>\n\n## Offline Modus\n\nTransformers ist in der Lage, in einer Firewall- oder Offline-Umgebung zu laufen, indem es nur lokale Dateien verwendet. Setzen Sie die Umgebungsvariable `HF_HUB_OFFLINE=1`, um dieses Verhalten zu aktivieren.\n\n<Tip>\n\nF\u00fcgen sie [\ud83e\udd17 Datasets](https://huggingface.co/docs/datasets/) zu Ihrem Offline-Trainingsworkflow hinzuf\u00fcgen, indem Sie die Umgebungsvariable `HF_DATASETS_OFFLINE=1` setzen.\n\n</Tip>\n\nSo w\u00fcrden Sie beispielsweise ein Programm in einem normalen Netzwerk mit einer Firewall f\u00fcr externe Instanzen mit dem folgenden Befehl ausf\u00fchren:\n\n```bash\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\nF\u00fchren Sie das gleiche Programm in einer Offline-Instanz mit aus:\n\n```bash\nHF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \\\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\nDas Skript sollte nun laufen, ohne sich aufzuh\u00e4ngen oder eine Zeit\u00fcberschreitung abzuwarten, da es wei\u00df, dass es nur nach lokalen Dateien suchen soll.\n\n\n### Abrufen von Modellen und Tokenizern zur Offline-Verwendung\n\nEine andere M\u00f6glichkeit, \ud83e\udd17 Transformers offline zu verwenden, besteht darin, die Dateien im Voraus herunterzuladen und dann auf ihren lokalen Pfad zu verweisen, wenn Sie sie offline verwenden m\u00fcssen. Es gibt drei M\u00f6glichkeiten, dies zu tun:\n\n* Laden Sie eine Datei \u00fcber die Benutzeroberfl\u00e4che des [Model Hub](https://huggingface.co/models) herunter, indem Sie auf das \u2193-Symbol klicken.\n\n    ![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)\n\n* Verwenden Sie den [PreTrainedModel.from_pretrained] und [PreTrainedModel.save_pretrained] Workflow:\n\n    1. Laden Sie Ihre Dateien im Voraus mit [`PreTrainedModel.from_pretrained`] herunter:\n\n    ```py\n    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n    ```\n\n    2. Speichern Sie Ihre Dateien in einem bestimmten Verzeichnis mit [`PreTrainedModel.save_pretrained`]:\n\n    ```py\n    >>> tokenizer.save_pretrained(\"./your/path/bigscience_t0\")\n    >>> model.save_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n    3. Wenn Sie nun offline sind, laden Sie Ihre Dateien mit [`PreTrainedModel.from_pretrained`] aus dem bestimmten Verzeichnis:\n\n    ```py\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"./your/path/bigscience_t0\")\n    >>> model = AutoModel.from_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n* Programmatisches Herunterladen von Dateien mit der [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub) Bibliothek:\n\n    1. Installieren Sie die \"huggingface_hub\"-Bibliothek in Ihrer virtuellen Umgebung:\n\n    ```bash\n    python -m pip install huggingface_hub\n    ```\n\n    2. Verwenden Sie die Funktion [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub), um eine Datei in einen bestimmten Pfad herunterzuladen. Der folgende Befehl l\u00e4dt zum Beispiel die Datei \"config.json\" aus dem Modell [T0](https://huggingface.co/bigscience/T0_3B) in den gew\u00fcnschten Pfad herunter:\n\n    ```py\n    >>> from huggingface_hub import hf_hub_download\n\n    >>> hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./your/path/bigscience_t0\")\n    ```\n\nSobald Ihre Datei heruntergeladen und lokal zwischengespeichert ist, geben Sie den lokalen Pfad an, um sie zu laden und zu verwenden:\n\n```py\n>>> from transformers import AutoConfig\n\n>>> config = AutoConfig.from_pretrained(\"./your/path/bigscience_t0/config.json\")\n```\n\n<Tip>\n\nWeitere Informationen zum Herunterladen von Dateien, die auf dem Hub gespeichert sind, finden Sie im Abschnitt [Wie man Dateien vom Hub herunterl\u00e4dt](https://huggingface.co/docs/hub/how-to-downstream).\n\n</Tip>\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/docs/source/de/installation.md"
            },
            {
                "result": {
                    "value": "<!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\u26a0\ufe0f Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n-->\n\n# \uc124\uce58\ubc29\ubc95[[installation]]\n\n\ud83e\udd17 Transformers\ub97c \uc0ac\uc6a9 \uc911\uc778 \ub525\ub7ec\ub2dd \ub77c\uc774\ube0c\ub7ec\ub9ac\uc5d0 \ub9de\ucdb0 \uc124\uce58\ud558\uace0, \uce90\uc2dc\ub97c \uad6c\uc131\ud558\uac70\ub098 \uc120\ud0dd\uc801\uc73c\ub85c \uc624\ud504\ub77c\uc778\uc5d0\uc11c\ub3c4 \uc2e4\ud589\ud560 \uc218 \uc788\ub3c4\ub85d \ud83e\udd17 Transformers\ub97c \uc124\uc815\ud558\ub294 \ubc29\ubc95\uc744 \ubc30\uc6b0\uaca0\uc2b5\ub2c8\ub2e4.\n\n\ud83e\udd17 Transformers\ub294 Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+ \ubc0f Flax\uc5d0\uc11c \ud14c\uc2a4\ud2b8\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ub525\ub7ec\ub2dd \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc124\uce58\ud558\ub824\uba74 \uc544\ub798 \ub9c1\ud06c\ub41c \uc800\ub9c8\ub2e4\uc758 \uacf5\uc2dd \uc0ac\uc774\ud2b8\ub97c \ucc38\uace0\ud574\uc8fc\uc138\uc694.\n\n* [PyTorch](https://pytorch.org/get-started/locally/) \uc124\uce58\ud558\uae30\n* [TensorFlow 2.0](https://www.tensorflow.org/install/pip) \uc124\uce58\ud558\uae30\n* [Flax](https://flax.readthedocs.io/en/latest/) \uc124\uce58\ud558\uae30\n\n## pip\uc73c\ub85c \uc124\uce58\ud558\uae30[[install-with-pip]]\n\n\ud83e\udd17 Transformers\ub97c [\uac00\uc0c1 \ud658\uacbd](https://docs.python.org/3/library/venv.html)\uc5d0 \uc124\uce58\ud558\ub294 \uac83\uc744 \ucd94\ucc9c\ub4dc\ub9bd\ub2c8\ub2e4. Python \uac00\uc0c1 \ud658\uacbd\uc5d0 \uc775\uc219\ud558\uc9c0 \uc54a\ub2e4\uba74, \uc774 [\uac00\uc774\ub4dc](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)\ub97c \ucc38\uace0\ud558\uc138\uc694. \uac00\uc0c1 \ud658\uacbd\uc744 \uc0ac\uc6a9\ud558\uba74 \uc11c\ub85c \ub2e4\ub978 \ud504\ub85c\uc81d\ud2b8\ub4e4\uc744 \ubcf4\ub2e4 \uc27d\uac8c \uad00\ub9ac\ud560 \uc218 \uc788\uace0, \uc758\uc874\uc131 \uac04\uc758 \ud638\ud658\uc131 \ubb38\uc81c\ub97c \ubc29\uc9c0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uba3c\uc800 \ud504\ub85c\uc81d\ud2b8 \ub514\ub809\ud1a0\ub9ac\uc5d0\uc11c \uac00\uc0c1 \ud658\uacbd\uc744 \ub9cc\ub4e4\uc5b4 \uc90d\ub2c8\ub2e4.\n\n```bash\npython -m venv .env\n```\n\n\uac00\uc0c1 \ud658\uacbd\uc744 \ud65c\uc131\ud654\ud574\uc8fc\uc138\uc694. Linux\ub098 MacOS\uc758 \uacbd\uc6b0:\n\n```bash\nsource .env/bin/activate\n```\nWindows\uc758 \uacbd\uc6b0:\n\n```bash\n.env/Scripts/activate\n```\n\n\uc774\uc81c \ud83e\udd17 Transformers\ub97c \uc124\uce58\ud560 \uc900\ube44\uac00 \ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ub2e4\uc74c \uba85\ub839\uc744 \uc785\ub825\ud574\uc8fc\uc138\uc694.\n\n```bash\npip install transformers\n```\n\nCPU\ub9cc \uc368\ub3c4 \ub41c\ub2e4\uba74, \ud83e\udd17 Transformers\uc640 \ub525\ub7ec\ub2dd \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \ub2e8 1\uc904\ub85c \uc124\uce58\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4 \ud83e\udd17 Transformers\uc640 PyTorch\uc758 \uacbd\uc6b0:\n\n```bash\npip install transformers[torch]\n```\n\n\ud83e\udd17 Transformers\uc640 TensorFlow 2.0\uc758 \uacbd\uc6b0:\n\n```bash\npip install transformers[tf-cpu]\n```\n\n\ud83e\udd17 Transformers\uc640 Flax\uc758 \uacbd\uc6b0:\n\n```bash\npip install transformers[flax]\n```\n\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c \ud83e\udd17 Transformers\uac00 \uc81c\ub300\ub85c \uc124\uce58\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\ud560 \ucc28\ub840\uc785\ub2c8\ub2e4. \uc0ac\uc804\ud6c8\ub828\ub41c \ubaa8\ub378\uc744 \ub2e4\uc6b4\ub85c\ub4dc\ud558\ub294 \ucf54\ub4dc\uc785\ub2c8\ub2e4.\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n```\n\n\ub77c\ubca8\uacfc \uc810\uc218\uac00 \ucd9c\ub825\ub418\uba74 \uc798 \uc124\uce58\ub41c \uac83\uc785\ub2c8\ub2e4.\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n```\n\n## \uc18c\uc2a4\uc5d0\uc11c \uc124\uce58\ud558\uae30[[install-from-source]]\n\n\ud83e\udd17 Transformers\ub97c \uc18c\uc2a4\uc5d0\uc11c \uc124\uce58\ud558\ub824\uba74 \uc544\ub798 \uba85\ub839\uc744 \uc2e4\ud589\ud558\uc138\uc694.\n\n```bash\npip install git+https://github.com/huggingface/transformers\n```\n\n\uc704 \uba85\ub839\uc740 \ucd5c\uc2e0\uc774\uc9c0\ub9cc (\uc548\uc815\uc801\uc778) `stable` \ubc84\uc804\uc774 \uc544\ub2cc \uc2e4\ud5d8\uc131\uc774 \uc9d9\uc740 `main` \ubc84\uc804\uc744 \uc124\uce58\ud569\ub2c8\ub2e4. `main` \ubc84\uc804\uc740 \uac1c\ubc1c \ud604\ud669\uacfc \ubc1c\ub9de\ucd94\ub294\ub370 \uc720\uc6a9\ud569\ub2c8\ub2e4. \uc608\uc2dc\ub85c \ub9c8\uc9c0\ub9c9 \uacf5\uc2dd \ub9b4\ub9ac\uc2a4 \uc774\ud6c4 \ubc1c\uacac\ub41c \ubc84\uadf8\uac00 \ud328\uce58\ub418\uc5c8\uc9c0\ub9cc, \uc0c8 \ub9b4\ub9ac\uc2a4\ub85c \uc544\uc9c1 \ub864\uc544\uc6c3\ub418\uc9c0\ub294 \uc54a\uc740 \uacbd\uc6b0\ub97c \ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ubc14\uafd4 \ub9d0\ud558\uba74 `main` \ubc84\uc804\uc774 \uc548\uc815\uc131\uacfc\ub294 \uac70\ub9ac\uac00 \uc788\ub2e4\ub294 \ub73b\uc774\uae30\ub3c4 \ud569\ub2c8\ub2e4. \uc800\ud76c\ub294 `main` \ubc84\uc804\uc744 \uc0ac\uc6a9\ud558\ub294\ub370 \ubb38\uc81c\uac00 \uc5c6\ub3c4\ub85d \ub178\ub825\ud558\uace0 \uc788\uc73c\uba70, \ub300\ubd80\ubd84\uc758 \ubb38\uc81c\ub294 \ub300\uac1c \uba87 \uc2dc\uac04\uc774\ub098 \ud558\ub8e8 \uc548\uc5d0 \ud574\uacb0\ub429\ub2c8\ub2e4. \ub9cc\uc57d \ubb38\uc81c\uac00 \ubc1c\uc0dd\ud558\uba74 [\uc774\uc288](https://github.com/huggingface/transformers/issues)\ub97c \uc5f4\uc5b4\uc8fc\uc2dc\uba74 \ub354 \ube68\ub9ac \ud574\uacb0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4!\n\n\uc804\uacfc \ub9c8\ucc2c\uac00\uc9c0\ub85c \ud83e\udd17 Transformers\uac00 \uc81c\ub300\ub85c \uc124\uce58\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\ud560 \ucc28\ub840\uc785\ub2c8\ub2e4.\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n```\n\n## \uc218\uc815 \uac00\ub2a5\ud55c \uc124\uce58[[editable-install]]\n\n\uc218\uc815 \uac00\ub2a5\ud55c \uc124\uce58\uac00 \ud544\uc694\ud55c \uacbd\uc6b0\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\n* `main` \ubc84\uc804\uc758 \uc18c\uc2a4 \ucf54\ub4dc\ub97c \uc0ac\uc6a9\ud558\uae30 \uc704\ud574\n* \ud83e\udd17 Transformers\uc5d0 \uae30\uc5ec\ud558\uace0 \uc2f6\uc5b4\uc11c \ucf54\ub4dc\uc758 \ubcc0\uacbd \uc0ac\ud56d\uc744 \ud14c\uc2a4\ud2b8\ud558\uae30 \uc704\ud574\n\n\ub9ac\ud3ec\uc9c0\ud130\ub9ac\ub97c \ubcf5\uc81c\ud558\uace0 \ud83e\udd17 Transformers\ub97c \uc124\uce58\ud558\ub824\uba74 \ub2e4\uc74c \uba85\ub839\uc744 \uc785\ub825\ud574\uc8fc\uc138\uc694.\n\n```bash\ngit clone https://github.com/huggingface/transformers.git\ncd transformers\npip install -e .\n```\n\n\uc704 \uba85\ub839\uc740 \ub9ac\ud3ec\uc9c0\ud130\ub9ac\ub97c \ubcf5\uc81c\ud55c \uc704\uce58\uc758 \ud3f4\ub354\uc640 Python \ub77c\uc774\ube0c\ub7ec\ub9ac\uc758 \uacbd\ub85c\ub97c \uc5f0\uacb0\uc2dc\ud0b5\ub2c8\ub2e4. Python\uc774 \uc77c\ubc18 \ub77c\uc774\ube0c\ub7ec\ub9ac \uacbd\ub85c \uc678\uc5d0 \ubcf5\uc81c\ud55c \ud3f4\ub354 \ub0b4\ubd80\ub97c \ud655\uc778\ud560 \uac83\uc785\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4 Python \ud328\ud0a4\uc9c0\uac00 \uc77c\ubc18\uc801\uc73c\ub85c `~/anaconda3/envs/main/lib/python3.7/site-packages/`\uc5d0 \uc124\uce58\ub418\uc5b4 \uc788\ub294\ub370, \uba85\ub839\uc744 \ubc1b\uc740 Python\uc774 \uc774\uc81c \ubcf5\uc81c\ud55c \ud3f4\ub354\uc778 `~/transformers/`\ub3c4 \uac80\uc0c9\ud558\uac8c \ub429\ub2c8\ub2e4.\n\n<Tip warning={true}>\n\n\ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uacc4\uc18d \uc0ac\uc6a9\ud558\ub824\uba74 `transformers` \ud3f4\ub354\ub97c \uaf2d \uc720\uc9c0\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n</Tip>\n\n\ubcf5\uc81c\ubcf8\uc740 \ucd5c\uc2e0 \ubc84\uc804\uc758 \ud83e\udd17 Transformers\ub85c \uc27d\uac8c \uc5c5\ub370\uc774\ud2b8\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n```bash\ncd ~/transformers/\ngit pull\n```\n\nPython \ud658\uacbd\uc744 \ub2e4\uc2dc \uc2e4\ud589\ud558\uba74 \uc5c5\ub370\uc774\ud2b8\ub41c \ud83e\udd17 Transformers\uc758 `main` \ubc84\uc804\uc744 \ucc3e\uc544\ub0bc \uac83\uc785\ub2c8\ub2e4.\n\n## conda\ub85c \uc124\uce58\ud558\uae30[[install-with-conda]]\n\n`conda-forge` conda \ucc44\ub110\uc5d0\uc11c \uc124\uce58\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n```bash\nconda install conda-forge::transformers\n```\n\n## \uce90\uc2dc \uad6c\uc131\ud558\uae30[[cache-setup]]\n\n\uc0ac\uc804\ud6c8\ub828\ub41c \ubaa8\ub378\uc740 \ub2e4\uc6b4\ub85c\ub4dc\ub41c \ud6c4 \ub85c\uceec \uacbd\ub85c `~/.cache/huggingface/hub`\uc5d0 \uce90\uc2dc\ub429\ub2c8\ub2e4. \uc178 \ud658\uacbd \ubcc0\uc218 `TRANSFORMERS_CACHE`\uc758 \uae30\ubcf8 \ub514\ub809\ud130\ub9ac\uc785\ub2c8\ub2e4. Windows\uc758 \uacbd\uc6b0 \uae30\ubcf8 \ub514\ub809\ud130\ub9ac\ub294 `C:\\Users\\username\\.cache\\huggingface\\hub`\uc785\ub2c8\ub2e4. \uc544\ub798\uc758 \uc178 \ud658\uacbd \ubcc0\uc218\ub97c (\uc6b0\uc120 \uc21c\uc704) \uc21c\uc11c\ub300\ub85c \ubcc0\uacbd\ud558\uc5ec \ub2e4\ub978 \uce90\uc2dc \ub514\ub809\ud1a0\ub9ac\ub97c \uc9c0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n1. \uc178 \ud658\uacbd \ubcc0\uc218 (\uae30\ubcf8): `HUGGINGFACE_HUB_CACHE` \ub610\ub294 `TRANSFORMERS_CACHE`\n2. \uc178 \ud658\uacbd \ubcc0\uc218: `HF_HOME`\n3. \uc178 \ud658\uacbd \ubcc0\uc218: `XDG_CACHE_HOME` + `/huggingface`\n\n<Tip>\n\n\uacfc\uac70 \ud83e\udd17 Transformers\uc5d0\uc11c \uc4f0\uc600\ub358 \uc178 \ud658\uacbd \ubcc0\uc218 `PYTORCH_TRANSFORMERS_CACHE` \ub610\ub294 `PYTORCH_PRETRAINED_BERT_CACHE`\uc774 \uc124\uc815\ub418\uc788\ub2e4\uba74, \uc178 \ud658\uacbd \ubcc0\uc218 `TRANSFORMERS_CACHE`\uc744 \uc9c0\uc815\ud558\uc9c0 \uc54a\ub294 \ud55c \uc6b0\uc120 \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\n\n</Tip>\n\n## \uc624\ud504\ub77c\uc778 \ubaa8\ub4dc[[offline-mode]]\n\n\ud83e\udd17 Transformers\ub97c \ub85c\uceec \ud30c\uc77c\ub9cc \uc0ac\uc6a9\ud558\ub3c4\ub85d \ud574\uc11c \ubc29\ud654\ubcbd \ub610\ub294 \uc624\ud504\ub77c\uc778 \ud658\uacbd\uc5d0\uc11c \uc2e4\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud65c\uc131\ud654\ud558\ub824\uba74 `HF_HUB_OFFLINE=1` \ud658\uacbd \ubcc0\uc218\ub97c \uc124\uc815\ud558\uc138\uc694.\n\n<Tip>\n\n`HF_DATASETS_OFFLINE=1` \ud658\uacbd \ubcc0\uc218\ub97c \uc124\uc815\ud558\uc5ec \uc624\ud504\ub77c\uc778 \ud6c8\ub828 \uacfc\uc815\uc5d0 [\ud83e\udd17 Datasets](https://huggingface.co/docs/datasets/)\uc744 \ucd94\uac00\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n</Tip>\n\n\uc608\ub97c \ub4e4\uc5b4 \uc678\ubd80 \uae30\uae30 \uc0ac\uc774\uc5d0 \ubc29\ud654\ubcbd\uc744 \ub454 \uc77c\ubc18 \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c \ud3c9\uc18c\ucc98\ub7fc \ud504\ub85c\uadf8\ub7a8\uc744 \ub2e4\uc74c\uacfc \uac19\uc774 \uc2e4\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n```bash\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\n\uc624\ud504\ub77c\uc778 \uae30\uae30\uc5d0\uc11c \ub3d9\uc77c\ud55c \ud504\ub85c\uadf8\ub7a8\uc744 \ub2e4\uc74c\uacfc \uac19\uc774 \uc2e4\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n```bash\nHF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \\\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\n\uc774\uc81c \uc2a4\ud06c\ub9bd\ud2b8\ub294 \ub85c\uceec \ud30c\uc77c\uc5d0 \ud55c\ud574\uc11c\ub9cc \uac80\uc0c9\ud560 \uac83\uc774\ubbc0\ub85c, \uc2a4\ud06c\ub9bd\ud2b8\uac00 \uc911\ub2e8\ub418\uac70\ub098 \uc2dc\uac04\uc774 \ucd08\uacfc\ub420 \ub54c\uae4c\uc9c0 \uba48\ucdb0\uc788\uc9c0 \uc54a\uace0 \uc798 \uc2e4\ud589\ub420 \uac83\uc785\ub2c8\ub2e4.\n\n### \uc624\ud504\ub77c\uc778\uc6a9 \ubaa8\ub378 \ubc0f \ud1a0\ud06c\ub098\uc774\uc800 \ub9cc\ub4e4\uc5b4\ub450\uae30[[fetch-models-and-tokenizers-to-use-offline]]\n\nAnother option for using \ud83e\udd17 Transformers offline is to download the files ahead of time, and then point to their local path when you need to use them offline. There are three ways to do this:\n\ud83e\udd17 Transformers\ub97c \uc624\ud504\ub77c\uc778\uc73c\ub85c \uc0ac\uc6a9\ud558\ub294 \ub610 \ub2e4\ub978 \ubc29\ubc95\uc740 \ud30c\uc77c\uc744 \ubbf8\ub9ac \ub2e4\uc6b4\ub85c\ub4dc\ud55c \ub2e4\uc74c, \uc624\ud504\ub77c\uc778\uc77c \ub54c \uc0ac\uc6a9\ud560 \ub85c\uceec \uacbd\ub85c\ub97c \uc9c0\uc815\ud574\ub450\ub294 \uac83\uc785\ub2c8\ub2e4. 3\uac00\uc9c0 \uc911 \ud3b8\ud55c \ubc29\ubc95\uc744 \uace0\ub974\uc138\uc694.\n\n* [Model Hub](https://huggingface.co/models)\uc758 UI\ub97c \ud1b5\ud574 \ud30c\uc77c\uc744 \ub2e4\uc6b4\ub85c\ub4dc\ud558\ub824\uba74 \u2193 \uc544\uc774\ucf58\uc744 \ud074\ub9ad\ud558\uc138\uc694.\n\n    ![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)\n\n* [`PreTrainedModel.from_pretrained`]\uc640 [`PreTrainedModel.save_pretrained`] \uc6cc\ud06c\ud50c\ub85c\ub97c \ud65c\uc6a9\ud558\uc138\uc694.\n\n    1. \ubbf8\ub9ac [`PreTrainedModel.from_pretrained`]\ub85c \ud30c\uc77c\uc744 \ub2e4\uc6b4\ub85c\ub4dc\ud574\ub450\uc138\uc694.\n\n    ```py\n    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n    ```\n\n    2. [`PreTrainedModel.save_pretrained`]\ub85c \uc9c0\uc815\ub41c \uacbd\ub85c\uc5d0 \ud30c\uc77c\uc744 \uc800\uc7a5\ud574\ub450\uc138\uc694.\n\n    ```py\n    >>> tokenizer.save_pretrained(\"./your/path/bigscience_t0\")\n    >>> model.save_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n    3. \uc774\uc81c \uc624\ud504\ub77c\uc778\uc77c \ub54c [`PreTrainedModel.from_pretrained`]\ub85c \uc800\uc7a5\ud574\ub480\ub358 \ud30c\uc77c\uc744 \uc9c0\uc815\ub41c \uacbd\ub85c\uc5d0\uc11c \ub2e4\uc2dc \ubd88\ub7ec\uc624\uc138\uc694.\n\n    ```py\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"./your/path/bigscience_t0\")\n    >>> model = AutoModel.from_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n* [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub) \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \ud65c\uc6a9\ud574\uc11c \ud30c\uc77c\uc744 \ub2e4\uc6b4\ub85c\ub4dc\ud558\uc138\uc694.\n\n    1. \uac00\uc0c1\ud658\uacbd\uc5d0 `huggingface_hub` \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc124\uce58\ud558\uc138\uc694.\n\n    ```bash\n    python -m pip install huggingface_hub\n    ```\n\n    2. [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) \ud568\uc218\ub85c \ud30c\uc77c\uc744 \ud2b9\uc815 \uc704\uce58\uc5d0 \ub2e4\uc6b4\ub85c\ub4dc\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4 \uc544\ub798 \uba85\ub839\uc740 [T0](https://huggingface.co/bigscience/T0_3B) \ubaa8\ub378\uc758 `config.json` \ud30c\uc77c\uc744 \uc9c0\uc815\ub41c \uacbd\ub85c\uc5d0 \ub2e4\uc6b4\ub85c\ub4dc\ud569\ub2c8\ub2e4.\n\n    ```py\n    >>> from huggingface_hub import hf_hub_download\n\n    >>> hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./your/path/bigscience_t0\")\n    ```\n\n\ud30c\uc77c\uc744 \ub2e4\uc6b4\ub85c\ub4dc\ud558\uace0 \ub85c\uceec\uc5d0 \uce90\uc2dc \ud574\ub193\uace0 \ub098\uba74, \ub098\uc911\uc5d0 \ubd88\ub7ec\uc640 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub3c4\ub85d \ub85c\uceec \uacbd\ub85c\ub97c \uc9c0\uc815\ud574\ub450\uc138\uc694.\n\n```py\n>>> from transformers import AutoConfig\n\n>>> config = AutoConfig.from_pretrained(\"./your/path/bigscience_t0/config.json\")\n```\n\n<Tip>\n\nHub\uc5d0 \uc800\uc7a5\ub41c \ud30c\uc77c\uc744 \ub2e4\uc6b4\ub85c\ub4dc\ud558\ub294 \ubc29\ubc95\uc744 \ub354 \uc790\uc138\ud788 \uc54c\uc544\ubcf4\ub824\uba74 [Hub\uc5d0\uc11c \ud30c\uc77c \ub2e4\uc6b4\ub85c\ub4dc\ud558\uae30](https://huggingface.co/docs/hub/how-to-downstream) \uc139\uc158\uc744 \ucc38\uace0\ud574\uc8fc\uc138\uc694.\n\n</Tip>\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/docs/source/ko/installation.md"
            },
            {
                "result": {
                    "value": "<!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n# Installation\n\nInstallez \ud83e\udd17 Transformers pour n'importe quelle librairie d'apprentissage profond avec laquelle vous avez l'habitude de travaillez, configurez votre cache et configurez \ud83e\udd17 Transformers pour un usage hors ligne (facultatif).\n\n\ud83e\udd17 Transformers est test\u00e9 avec Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+ et Flax.\nConsulter les instructions d'installation ci-dessous pour la librairie d'apprentissage profond que vous utilisez:\n\n  * Instructions d'installation pour [PyTorch](https://pytorch.org/get-started/locally/).\n  * Instructions d'installation pour [TensorFlow 2.0](https://www.tensorflow.org/install/pip).\n  * Instructions d'installation pour [Flax](https://flax.readthedocs.io/en/latest/).\n\n## Installation avec pip\n\nVous devriez installer \ud83e\udd17 Transformers dans un [environnement virtuel](https://docs.python.org/3/library/venv.html).\nSi vous n'\u00eates pas \u00e0 l'aise avec les environnements virtuels, consultez ce [guide](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).\nUtiliser un environnement virtuel permet de facilement g\u00e9rer diff\u00e9rents projets et d'\u00e9viter des erreurs de compatibilit\u00e9 entre les diff\u00e9rentes d\u00e9pendances.\n\nCommencez par cr\u00e9er un environnement virtuel dans l'espace de travail de votre projet :\n\n```bash\npython -m venv .env\n```\n\nActivez l'environnement virtuel. Sur Linux ou MacOs :\n\n```bash\nsource .env/bin/activate\n```\n\nActivez l'environnement virtuel sur Windows :\n\n```bash\n.env/Scripts/activate\n```\n\nMaintenant, \ud83e\udd17 Transformers peut \u00eatre install\u00e9 avec la commande suivante :\n\n```bash\npip install transformers\n```\n\nPour une utilisation avec CPU seulement, \ud83e\udd17 Transformers et la librairie d'apprentissage profond de votre choix peuvent \u00eatre install\u00e9s en une seule ligne.\nPar exemple, installez \ud83e\udd17 Transformers et PyTorch avec la commande suivante :\n\n```bash\npip install 'transformers[torch]'\n```\n\n\ud83e\udd17 Transformers et TensorFlow 2.0 :\n\n```bash\npip install 'transformers[tf-cpu]'\n```\n\n<Tip warning={true}>\n\nPour les architectures mac M1 / ARM\n\nVous devez installer les outils suivants avant d'installer TensorFLow 2.0\n\n```bash\nbrew install cmake\nbrew install pkg-config\n```\n\n</Tip>\n\n\ud83e\udd17 Transformers et Flax :\n\n```bash\npip install 'transformers[flax]'\n```\n\nV\u00e9rifiez que \ud83e\udd17 Transformers a bien \u00e9t\u00e9 install\u00e9 avec la commande suivante. La commande va t\u00e9l\u00e9charger un mod\u00e8le pr\u00e9-entra\u00een\u00e9 :\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n```\n\nLe label et score sont ensuite affich\u00e9s :\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n```\n\n## Installation depuis le code source\n\nInstallez \ud83e\udd17 Transformers depuis le code source avec la commande suivante :\n\n```bash\npip install git+https://github.com/huggingface/transformers\n```\n\nCette commande installe la version depuis la branche `main` au lieu de la derni\u00e8re version stable. La version de la branche `main` est utile pour avoir les derniers d\u00e9veloppements. Par exemple, si un bug a \u00e9t\u00e9 r\u00e9solu depuis la derni\u00e8re version stable mais n'a pas encore \u00e9t\u00e9 publi\u00e9 officiellement. Cependant, cela veut aussi dire que la version de la branche `main` n'est pas toujours stable. Nous nous effor\u00e7ons de maintenir la version de la branche `main` op\u00e9rationnelle, et la plupart des probl\u00e8mes sont g\u00e9n\u00e9ralement r\u00e9solus en l'espace de quelques heures ou d'un jour. Si vous recontrez un probl\u00e8me, n'h\u00e9sitez pas \u00e0 cr\u00e9er une [Issue](https://github.com/huggingface/transformers/issues) pour que l'on puisse trouver une solution au plus vite !\n\nV\u00e9rifiez que \ud83e\udd17 Transformers a bien \u00e9t\u00e9 install\u00e9 avec la commande suivante :\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n```\n\n## Installation modifiable\n\nVous aurez besoin d'une installation modifiable si vous le souhaitez :\n\n  * Utiliser la version de la branche `main` du code source.\n  * Contribuer \u00e0 \ud83e\udd17 Transformers et vouler tester vos modifications du code source.\n\nClonez le projet et installez \ud83e\udd17 Transformers avec les commandes suivantes :\n\n```bash\ngit clone https://github.com/huggingface/transformers.git\ncd transformers\npip install -e .\n```\n\nCes commandes cr\u00e9ent des liens entre le dossier o\u00f9 le projet a \u00e9t\u00e9 clon\u00e9 et les chemins de vos librairies Python. Python regardera maintenant dans le dossier que vous avez clon\u00e9 en plus des dossiers o\u00f9 sont install\u00e9es vos autres librairies. Par exemple, si vos librairies Python sont install\u00e9es dans `~/anaconda3/envs/main/lib/python3.7/site-packages/`, Python cherchera aussi dans le dossier o\u00f9 vous avez clon\u00e9 : `~/transformers/`.\n\n<Tip warning={true}>\n\nVous devez garder le dossier `transformers` si vous voulez continuer d'utiliser la librairie.\n\n</Tip>\n\nMaintenant, vous pouvez facilement mettre \u00e0 jour votre clone avec la derni\u00e8re version de \ud83e\udd17 Transformers en utilisant la commande suivante :\n\n```bash\ncd ~/transformers/\ngit pull\n```\n\nVotre environnement Python utilisera la version de la branche `main` lors de la prochaine ex\u00e9cution.\n\n## Installation avec conda\n\nInstallation via le canal `conda-forge` de conda :\n\n```bash\nconda install conda-forge::transformers\n```\n\n## Configuration du cache\n\nLes mod\u00e8les pr\u00e9-entra\u00een\u00e9s sont t\u00e9l\u00e9charg\u00e9s et mis en cache localement dans le dossier suivant : `~/.cache/huggingface/hub`. C'est le dossier par d\u00e9faut donn\u00e9 par la variable d'environnement `TRANSFORMERS_CACHE`. Sur Windows, le dossier par d\u00e9faut est `C:\\Users\\nom_utilisateur\\.cache\\huggingface\\hub`. Vous pouvez modifier les variables d'environnement indiqu\u00e9es ci-dessous - par ordre de priorit\u00e9 - pour sp\u00e9cifier un dossier de cache diff\u00e9rent :\n\n1. Variable d'environnement (par d\u00e9faut) : `HUGGINGFACE_HUB_CACHE` ou `TRANSFORMERS_CACHE`.\n2. Variable d'environnement : `HF_HOME`.\n3. Variable d'environnement : `XDG_CACHE_HOME` + `/huggingface`.\n\n<Tip>\n\n\ud83e\udd17 Transformers utilisera les variables d'environnement `PYTORCH_TRANSFORMERS_CACHE` ou `PYTORCH_PRETRAINED_BERT_CACHE` si vous utilisez une version pr\u00e9c\u00e9dente de cette librairie et avez d\u00e9fini ces variables d'environnement, sauf si vous sp\u00e9cifiez la variable d'environnement `TRANSFORMERS_CACHE`.\n\n</Tip>\n\n## Mode hors ligne\n\n\ud83e\udd17 Transformers peut fonctionner dans un environnement cloisonn\u00e9 ou hors ligne en n'utilisant que des fichiers locaux. D\u00e9finissez la variable d'environnement `HF_HUB_OFFLINE=1` pour activer ce mode.\n\n<Tip>\n\nAjoutez [\ud83e\udd17 Datasets](https://huggingface.co/docs/datasets/) \u00e0 votre processus d'entra\u00eenement hors ligne en d\u00e9finissant la variable d'environnement `HF_DATASETS_OFFLINE=1`.\n\n</Tip>\n\n```bash\nHF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \\\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\nLe script devrait maintenant s'ex\u00e9cuter sans rester en attente ou attendre une expiration, car il n'essaiera pas de t\u00e9l\u00e9charger des mod\u00e8le sur le Hub.\n\nVous pouvez aussi \u00e9viter de t\u00e9l\u00e9charger un mod\u00e8le \u00e0 chaque appel de la fonction [`~PreTrainedModel.from_pretrained`] en utilisant le param\u00e8tre [local_files_only]. Seuls les fichiers locaux sont charg\u00e9s lorsque ce param\u00e8tre est activ\u00e9 (c.-\u00e0-d. `local_files_only=True`) :\n\n```py\nfrom transformers import T5Model\n\nmodel = T5Model.from_pretrained(\"./path/to/local/directory\", local_files_only=True)\n```\n\n### R\u00e9cup\u00e9rer des mod\u00e8les et des tokenizers pour une utilisation hors ligne\n\nUne autre option pour utiliser \ud83e\udd17 Transformers hors ligne est de t\u00e9l\u00e9charger les fichiers \u00e0 l'avance, puis d'utiliser les chemins locaux lorsque vous en avez besoin en mode hors ligne. Il existe trois fa\u00e7ons de faire cela :\n\n  * T\u00e9l\u00e9chargez un fichier via l'interface utilisateur sur le [Model Hub](https://huggingface.co/models) en cliquant sur l'ic\u00f4ne \u2193.\n\n    ![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)\n\n  * Utilisez les fonctions [`PreTrainedModel.from_pretrained`] et [`PreTrainedModel.save_pretrained`] :\n\n    1. T\u00e9l\u00e9chargez vos fichiers \u00e0 l'avance avec [`PreTrainedModel.from_pretrained`]:\n\n    ```py\n    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n    ```\n\n    2. Sauvegardez les fichiers dans un dossier de votre choix avec [`PreTrainedModel.save_pretrained`]:\n\n    ```py\n    >>> tokenizer.save_pretrained(\"./your/path/bigscience_t0\")\n    >>> model.save_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n    3. Maintenant, lorsque vous \u00eates hors ligne, rechargez vos fichiers avec [`PreTrainedModel.from_pretrained`] depuis le dossier o\u00f9 vous les avez sauvegard\u00e9s :\n\n    ```py\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"./your/path/bigscience_t0\")\n    >>> model = AutoModel.from_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n  * T\u00e9l\u00e9chargez des fichiers de mani\u00e8re automatique avec la librairie [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub) :\n\n    1. Installez la librairie `huggingface_hub`  dans votre environnement virtuel :\n\n    ```bash\n    python -m pip install huggingface_hub\n    ```\n\n    2. Utilisez la fonction [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) pour t\u00e9l\u00e9charger un fichier vers un chemin de votre choix.  Par exemple, la commande suivante t\u00e9l\u00e9charge le fichier `config.json` du mod\u00e8le [T0](https://huggingface.co/bigscience/T0_3B) vers le chemin de votre choix :\n\n    ```py\n    >>> from huggingface_hub import hf_hub_download\n\n    >>> hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./your/path/bigscience_t0\")\n    ```\n\nUne fois que votre fichier est t\u00e9l\u00e9charg\u00e9 et cach\u00e9 localement, sp\u00e9cifiez son chemin local pour le charger et l'utiliser :\n\n```py\n>>> from transformers import AutoConfig\n\n>>> config = AutoConfig.from_pretrained(\"./your/path/bigscience_t0/config.json\")\n```\n\n<Tip>\n\nConsultez la section [How to download files from the Hub (Comment t\u00e9l\u00e9charger des fichiers depuis le Hub)](https://huggingface.co/docs/hub/how-to-downstream) pour plus de d\u00e9tails sur le t\u00e9l\u00e9chargement de fichiers stock\u00e9s sur le Hub.\n\n</Tip>\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/docs/source/fr/installation.md"
            },
            {
                "result": {
                    "value": "<!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\u26a0\ufe0f Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n-->\n\n# Instalaci\u00f3n\n\nEn esta gu\u00eda puedes encontrar informaci\u00f3n para instalar \ud83e\udd17 Transformers para cualquier biblioteca de Machine Learning con la que est\u00e9s trabajando. Adem\u00e1s, encontrar\u00e1s informaci\u00f3n sobre c\u00f3mo establecer el cach\u00e9 y c\u00f3mo configurar \ud83e\udd17 Transformers para correrlo de manera offline (opcional).\n\n\ud83e\udd17 Transformers ha sido probada en Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, y Flax. Para instalar la biblioteca de deep learning con la que desees trabajar, sigue las instrucciones correspondientes listadas a continuaci\u00f3n:\n\n* [PyTorch](https://pytorch.org/get-started/locally/)\n* [TensorFlow 2.0](https://www.tensorflow.org/install/pip)\n* [Flax](https://flax.readthedocs.io/en/latest/)\n\n## Instalaci\u00f3n con pip\n\nEs necesario instalar \ud83e\udd17 Transformers en un [entorno virtual](https://docs.python.org/3/library/venv.html). Si necesitas m\u00e1s informaci\u00f3n sobre entornos virtuales de Python, consulta esta [gu\u00eda](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/\n). Un entorno virtual facilita el manejo de proyectos y evita problemas de compatibilidad entre dependencias.\n\nComienza por crear un entorno virtual en el directorio de tu proyecto:\n\n```bash\npython -m venv .env\n```\n\nActiva el entorno virtual:\n\n```bash\nsource .env/bin/activate\n```\n\nAhora puedes instalar \ud83e\udd17 Transformers con el siguiente comando:\n\n```bash\npip install transformers\n```\n\nSolo para CPU, puedes instalar \ud83e\udd17 Transformers y una biblioteca de deep learning con un comando de una sola l\u00ednea.\n\nPor ejemplo, instala \ud83e\udd17 Transformers y Pytorch:\n\n```bash\npip install transformers[torch]\n```\n\n\ud83e\udd17 Transformers y TensorFlow 2.0:\n\n```bash\npip install transformers[tf-cpu]\n```\n\n\ud83e\udd17 Transformers y Flax:\n\n```bash\npip install transformers[flax]\n```\n\nPor \u00faltimo, revisa si \ud83e\udd17 Transformers ha sido instalada exitosamente con el siguiente comando que descarga un modelo pre-entrenado:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n```\nDespu\u00e9s imprime la etiqueta y el puntaje:\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n```\n\n## Instalaci\u00f3n desde la fuente\n\nInstala \ud83e\udd17 Transformers desde la fuente con el siguiente comando:\n\n```bash\npip install git+https://github.com/huggingface/transformers\n```\n\nEl comando de arriba instala la versi\u00f3n `master` m\u00e1s actual en vez de la \u00faltima versi\u00f3n estable. La versi\u00f3n `master` es \u00fatil para obtener los \u00faltimos avances de  \ud83e\udd17 Transformers. Por ejemplo, se puede dar el caso de que un error fue corregido despu\u00e9s de la \u00faltima versi\u00f3n estable pero a\u00fan no se ha liberado un nuevo lanzamiento. Sin embargo, existe la posibilidad de que la versi\u00f3n `master` no sea estable. El equipo trata de mantener la versi\u00f3n `master` operacional y la mayor\u00eda de los errores son resueltos en unas cuantas horas o un d\u00eda. Si encuentras alg\u00fan problema, por favor abre un [Issue](https://github.com/huggingface/transformers/issues) para que pueda ser corregido m\u00e1s r\u00e1pido.\n\nVerifica si \ud83e\udd17 Transformers est\u00e1 instalada apropiadamente con el siguiente comando:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n```\n\n## Instalaci\u00f3n editable\n\nNecesitar\u00e1s una instalaci\u00f3n editable si deseas:\n* Usar la versi\u00f3n `master` del c\u00f3digo fuente.\n* Contribuir a \ud83e\udd17 Transformers y necesitas probar cambios en el c\u00f3digo.\n\nClona el repositorio e instala \ud83e\udd17 Transformers con los siguientes comandos:\n\n```bash\ngit clone https://github.com/huggingface/transformers.git\ncd transformers\npip install -e .\n```\n\n\u00c9stos comandos van a ligar el directorio desde donde clonamos el repositorio al path de las bibliotecas de Python. Python ahora buscar\u00e1 dentro de la carpeta que clonaste adem\u00e1s de los paths normales de la biblioteca. Por ejemplo, si los paquetes de Python se encuentran instalados en `~/anaconda3/envs/main/lib/python3.7/site-packages/`, Python tambi\u00e9n buscar\u00e1 en el directorio desde donde clonamos el repositorio `~/transformers/`.\n\n<Tip warning={true}>\n\nDebes mantener el directorio `transformers` si deseas seguir usando la biblioteca.\n\n</Tip>\n\nPuedes actualizar tu copia local a la \u00faltima versi\u00f3n de \ud83e\udd17 Transformers con el siguiente comando:\n\n```bash\ncd ~/transformers/\ngit pull\n```\n\nEl entorno de Python que creaste para la instalaci\u00f3n de \ud83e\udd17 Transformers encontrar\u00e1 la versi\u00f3n `master` en la siguiente ejecuci\u00f3n.\n\n## Instalaci\u00f3n con conda\n\nPuedes instalar \ud83e\udd17 Transformers desde el canal de conda `conda-forge` con el siguiente comando:\n\n```bash\nconda install conda-forge::transformers\n```\n\n## Configuraci\u00f3n de Cach\u00e9\n\nLos modelos preentrenados se descargan y almacenan en cach\u00e9 localmente en: `~/.cache/huggingface/transformers/`. Este es el directorio predeterminado proporcionado por la variable de entorno de shell `TRANSFORMERS_CACHE`. En Windows, el directorio predeterminado es dado por `C:\\Users\\username\\.cache\\huggingface\\transformers`. Puedes cambiar las variables de entorno de shell que se muestran a continuaci\u00f3n, en orden de prioridad, para especificar un directorio de cach\u00e9 diferente:\n\n1. Variable de entorno del shell (por defecto): `TRANSFORMERS_CACHE`.\n2. Variable de entorno del shell:`HF_HOME` + `transformers/`.\n3. Variable de entorno del shell: `XDG_CACHE_HOME` + `/huggingface/transformers`.\n\n<Tip>\n\n\ud83e\udd17 Transformers usar\u00e1 las variables de entorno de shell `PYTORCH_TRANSFORMERS_CACHE` o `PYTORCH_PRETRAINED_BERT_CACHE` si viene de una iteraci\u00f3n anterior de la biblioteca y ha configurado esas variables de entorno, a menos que especifiques la variable de entorno de shell `TRANSFORMERS_CACHE`.\n\n</Tip>\n\n\n## Modo Offline\n\n\ud83e\udd17 Transformers puede ejecutarse en un entorno con firewall o fuera de l\u00ednea (offline) usando solo archivos locales. Configura la variable de entorno `HF_HUB_OFFLINE=1` para habilitar este comportamiento.\n\n<Tip>\n\nPuedes a\u00f1adir [\ud83e\udd17 Datasets](https://huggingface.co/docs/datasets/) al flujo de entrenamiento offline declarando la variable de entorno  `HF_DATASETS_OFFLINE=1`.\n\n</Tip>\n\nPor ejemplo, normalmente ejecutar\u00edas un programa en una red normal con firewall para instancias externas con el siguiente comando:\n\n```bash\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\nEjecuta este mismo programa en una instancia offline con el siguiente comando:\n\n```bash\nHF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \\\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\nEl script ahora deber\u00eda ejecutarse sin bloquearse ni esperar a que se agote el tiempo de espera porque sabe que solo debe buscar archivos locales.\n\n### Obtener modelos y tokenizers para uso offline\n\nOtra opci\u00f3n para usar \ud83e\udd17 Transformers offline es descargando previamente los archivos y despu\u00e9s apuntar al path local donde se encuentren. Hay tres maneras de hacer esto:\n\n* Descarga un archivo mediante la interfaz de usuario del [Model Hub](https://huggingface.co/models) haciendo click en el \u00edcono \u2193.\n\n    ![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)\n\n\n* Utiliza el flujo de [`PreTrainedModel.from_pretrained`] y [`PreTrainedModel.save_pretrained`]:\n    1. Descarga previamente los archivos con [`PreTrainedModel.from_pretrained`]:\n\n    ```py\n    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n    ```\n\n\n    2. Guarda los archivos en un directorio espec\u00edfico con [`PreTrainedModel.save_pretrained`]:\n\n    ```py\n    >>> tokenizer.save_pretrained(\"./your/path/bigscience_t0\")\n    >>> model.save_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n    3. Cuando te encuentres offline, recarga los archivos con [`PreTrainedModel.from_pretrained`] desde el directorio especificado:\n\n    ```py\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"./your/path/bigscience_t0\")\n    >>> model = AutoModel.from_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n* Descarga de manera program\u00e1tica los archivos con la biblioteca [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub):\n\n    1. Instala la biblioteca [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub) en tu entorno virtual:\n\n    ```bash\n    python -m pip install huggingface_hub\n    ```\n\n    2. Utiliza la funci\u00f3n [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) para descargar un archivo a un path espec\u00edfico. Por ejemplo, el siguiente comando descarga el archivo `config.json` del modelo [T0](https://huggingface.co/bigscience/T0_3B) al path deseado:\n\n    ```py\n    >>> from huggingface_hub import hf_hub_download\n\n    >>> hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./your/path/bigscience_t0\")\n    ```\n\nUna vez que el archivo se descargue y se almacene en cach\u00e9 localmente, especifica tu ruta local para cargarlo y usarlo:\n\n```py\n>>> from transformers import AutoConfig\n\n>>> config = AutoConfig.from_pretrained(\"./your/path/bigscience_t0/config.json\")\n```\n\n<Tip>\n\nPara m\u00e1s detalles sobre c\u00f3mo descargar archivos almacenados en el Hub consulta la secci\u00f3n [How to download files from the Hub](https://huggingface.co/docs/hub/how-to-downstream).\n\n</Tip>\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/docs/source/es/installation.md"
            },
            {
                "result": {
                    "value": "<!---\nCopyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\u26a0\ufe0f Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n-->\n\n# Installation\n\nInstall \ud83e\udd17 Transformers for whichever deep learning library you're working with, setup your cache, and optionally configure \ud83e\udd17 Transformers to run offline.\n\n\ud83e\udd17 Transformers is tested on Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, and Flax. Follow the installation instructions below for the deep learning library you are using:\n\n* [PyTorch](https://pytorch.org/get-started/locally/) installation instructions.\n* [TensorFlow 2.0](https://www.tensorflow.org/install/pip) installation instructions.\n* [Flax](https://flax.readthedocs.io/en/latest/) installation instructions.\n\n## Install with pip\n\nYou should install \ud83e\udd17 Transformers in a [virtual environment](https://docs.python.org/3/library/venv.html). If you're unfamiliar with Python virtual environments, take a look at this [guide](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). A virtual environment makes it easier to manage different projects, and avoid compatibility issues between dependencies.\n\nStart by creating a virtual environment in your project directory:\n\n```bash\npython -m venv .env\n```\n\nActivate the virtual environment. On Linux and MacOs:\n\n```bash\nsource .env/bin/activate\n```\nActivate Virtual environment on Windows\n\n```bash\n.env/Scripts/activate\n```\n\nNow you're ready to install \ud83e\udd17 Transformers with the following command:\n\n```bash\npip install transformers\n```\n\nFor CPU-support only, you can conveniently install \ud83e\udd17 Transformers and a deep learning library in one line. For example, install \ud83e\udd17 Transformers and PyTorch with:\n\n```bash\npip install 'transformers[torch]'\n```\n\n\ud83e\udd17 Transformers and TensorFlow 2.0:\n\n```bash\npip install 'transformers[tf-cpu]'\n```\n\n<Tip warning={true}>\n\nM1 / ARM Users\n\nYou will need to install the following before installing TensorFLow 2.0\n```bash\nbrew install cmake\nbrew install pkg-config\n```\n\n</Tip>\n\n\ud83e\udd17 Transformers and Flax:\n\n```bash\npip install 'transformers[flax]'\n```\n\nFinally, check if \ud83e\udd17 Transformers has been properly installed by running the following command. It will download a pretrained model:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n```\n\nThen print out the label and score:\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n```\n\n## Install from source\n\nInstall \ud83e\udd17 Transformers from source with the following command:\n\n```bash\npip install git+https://github.com/huggingface/transformers\n```\n\nThis command installs the bleeding edge `main` version rather than the latest `stable` version. The `main` version is useful for staying up-to-date with the latest developments. For instance, if a bug has been fixed since the last official release but a new release hasn't been rolled out yet. However, this means the `main` version may not always be stable. We strive to keep the `main` version operational, and most issues are usually resolved within a few hours or a day. If you run into a problem, please open an [Issue](https://github.com/huggingface/transformers/issues) so we can fix it even sooner!\n\nCheck if \ud83e\udd17 Transformers has been properly installed by running the following command:\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n```\n\n## Editable install\n\nYou will need an editable install if you'd like to:\n\n* Use the `main` version of the source code.\n* Contribute to \ud83e\udd17 Transformers and need to test changes in the code.\n\nClone the repository and install \ud83e\udd17 Transformers with the following commands:\n\n```bash\ngit clone https://github.com/huggingface/transformers.git\ncd transformers\npip install -e .\n```\n\nThese commands will link the folder you cloned the repository to and your Python library paths. Python will now look inside the folder you cloned to in addition to the normal library paths. For example, if your Python packages are typically installed in `~/anaconda3/envs/main/lib/python3.7/site-packages/`, Python will also search the folder you cloned to: `~/transformers/`.\n\n<Tip warning={true}>\n\nYou must keep the `transformers` folder if you want to keep using the library.\n\n</Tip>\n\nNow you can easily update your clone to the latest version of \ud83e\udd17 Transformers with the following command:\n\n```bash\ncd ~/transformers/\ngit pull\n```\n\nYour Python environment will find the `main` version of \ud83e\udd17 Transformers on the next run.\n\n## Install with conda\n\nInstall from the conda channel `conda-forge`:\n\n```bash\nconda install conda-forge::transformers\n```\n\n## Cache setup\n\nPretrained models are downloaded and locally cached at: `~/.cache/huggingface/hub`. This is the default directory given by the shell environment variable `TRANSFORMERS_CACHE`. On Windows, the default directory is given by `C:\\Users\\username\\.cache\\huggingface\\hub`. You can change the shell environment variables shown below - in order of priority - to specify a different cache directory:\n\n1. Shell environment variable (default): `HUGGINGFACE_HUB_CACHE` or `TRANSFORMERS_CACHE`.\n2. Shell environment variable: `HF_HOME`.\n3. Shell environment variable: `XDG_CACHE_HOME` + `/huggingface`.\n\n<Tip>\n\n\ud83e\udd17 Transformers will use the shell environment variables `PYTORCH_TRANSFORMERS_CACHE` or `PYTORCH_PRETRAINED_BERT_CACHE` if you are coming from an earlier iteration of this library and have set those environment variables, unless you specify the shell environment variable `TRANSFORMERS_CACHE`.\n\n</Tip>\n\n## Offline mode\n\nRun \ud83e\udd17 Transformers in a firewalled or offline environment with locally cached files by setting the environment variable `HF_HUB_OFFLINE=1`.\n\n<Tip>\n\nAdd [\ud83e\udd17 Datasets](https://huggingface.co/docs/datasets/) to your offline training workflow with the environment variable `HF_DATASETS_OFFLINE=1`.\n\n</Tip>\n\n```bash\nHF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \\\npython examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...\n```\n\nThis script should run without hanging or waiting to timeout because it won't attempt to download the model from the Hub.\n\nYou can also bypass loading a model from the Hub from each [`~PreTrainedModel.from_pretrained`] call with the [`local_files_only`] parameter. When set to `True`, only local files are loaded:\n\n```py\nfrom transformers import T5Model\n\nmodel = T5Model.from_pretrained(\"./path/to/local/directory\", local_files_only=True)\n```\n\n### Fetch models and tokenizers to use offline\n\nAnother option for using \ud83e\udd17 Transformers offline is to download the files ahead of time, and then point to their local path when you need to use them offline. There are three ways to do this:\n\n* Download a file through the user interface on the [Model Hub](https://huggingface.co/models) by clicking on the \u2193 icon.\n\n    ![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)\n\n* Use the [`PreTrainedModel.from_pretrained`] and [`PreTrainedModel.save_pretrained`] workflow:\n\n    1. Download your files ahead of time with [`PreTrainedModel.from_pretrained`]:\n\n    ```py\n    >>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n    >>> model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n    ```\n\n    2. Save your files to a specified directory with [`PreTrainedModel.save_pretrained`]:\n\n    ```py\n    >>> tokenizer.save_pretrained(\"./your/path/bigscience_t0\")\n    >>> model.save_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n    3. Now when you're offline, reload your files with [`PreTrainedModel.from_pretrained`] from the specified directory:\n\n    ```py\n    >>> tokenizer = AutoTokenizer.from_pretrained(\"./your/path/bigscience_t0\")\n    >>> model = AutoModel.from_pretrained(\"./your/path/bigscience_t0\")\n    ```\n\n* Programmatically download files with the [huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub) library:\n\n    1. Install the `huggingface_hub` library in your virtual environment:\n\n    ```bash\n    python -m pip install huggingface_hub\n    ```\n\n    2. Use the [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) function to download a file to a specific path. For example, the following command downloads the `config.json` file from the [T0](https://huggingface.co/bigscience/T0_3B) model to your desired path:\n\n    ```py\n    >>> from huggingface_hub import hf_hub_download\n\n    >>> hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./your/path/bigscience_t0\")\n    ```\n\nOnce your file is downloaded and locally cached, specify it's local path to load and use it:\n\n```py\n>>> from transformers import AutoConfig\n\n>>> config = AutoConfig.from_pretrained(\"./your/path/bigscience_t0/config.json\")\n```\n\n<Tip>\n\nSee the [How to download files from the Hub](https://huggingface.co/docs/hub/how-to-downstream) section for more details on downloading files stored on the Hub.\n\n</Tip>\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/docs/source/en/installation.md"
            },
            {
                "result": {
                    "value": "This repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.11+, and TensorFlow 2.6+.\n\nYou should install \ud83e\udd17 Transformers in a [virtual environment](https://docs.python.org/3/library/venv.html). If you're unfamiliar with Python virtual environments, check out the [user guide](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/).\n\nFirst, create a virtual environment with the version of Python you're going to use and activate it.\n\nThen, you will need to install at least one of Flax, PyTorch, or TensorFlow.\nPlease refer to [TensorFlow installation page](https://www.tensorflow.org/install/), [PyTorch installation page](https://pytorch.org/get-started/locally/#start-locally) and/or [Flax](https://github.com/google/flax#quick-install) and [Jax](https://github.com/google/jax#installation) installation pages regarding the specific installation command for your platform.\n\nWhen one of those backends has been installed, \ud83e\udd17 Transformers can be installed using pip as follows:\n\n```bash\npip install transformers\n```\n\nIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must [install the library from source](https://huggingface.co/docs/transformers/installation#installing-from-source).\n",
                    "type": "Text_excerpt",
                    "original_header": "With pip",
                    "parent_header": [
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/README.md"
            },
            {
                "result": {
                    "value": "\ud83e\udd17 Transformers can be installed using conda as follows:\n\n```shell script\nconda install conda-forge::transformers\n```\n\n> **_NOTE:_** Installing `transformers` from the `huggingface` channel is deprecated.\n\nFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.\n\n> **_NOTE:_**  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in [this issue](https://github.com/huggingface/huggingface_hub/issues/1062).\n",
                    "type": "Text_excerpt",
                    "original_header": "With conda",
                    "parent_header": [
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/huggingface/transformers/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-10-29T13:56:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T09:18:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 57721617
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cuda",
                    "name": "Cuda",
                    "type": "Programming_language",
                    "size": 327721
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 36025
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 30374
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 25815
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 7703
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 4179
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cython",
                    "name": "Cython",
                    "type": "Programming_language",
                    "size": 3635
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jsonnet",
                    "name": "Jsonnet",
                    "type": "Programming_language",
                    "size": 937
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "178": {
        "filename": "leoprover_logic-embedding_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Axiom schemas acting as interaction axioms between different modalities, can simply\nbe added as part of the `$modality` entry (see also [^4]):\n```\ntff(modal_system,logic,\n    $modal == \n      [ $designation == $rigid,\n        $domains == $cumulative,\n        $terms == $local,\n        $modalities == [\n          {$box(#always)} == $modal_system_S4,\n          {$box(#load)} == $modal_system_K,\n          {$box(#shoot)} == $modal_system_K,\n\t\t\t    {$box(#always)} @ (P) => {$box(#load)} @ (P),\n\t\t\t    {$box(#always)} @ (P) => {$box(#shoot)} @ (P) ] ] ).\n``` \n",
                    "original_header": "Modal logic `$modal`: Including interaction axiom schemes"
                },
                "confidence": 0.98852251615911,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/leoprover/logic-embedding/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-01-11T14:11:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-10T16:14:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Scala",
                    "name": "Scala",
                    "type": "Programming_language",
                    "size": 451990
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "OpenEdge ABL",
                    "name": "OpenEdge ABL",
                    "type": "Programming_language",
                    "size": 35530
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 476
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 221
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "179": {
        "filename": "ramonpereira_goal-recognition-ltlf_pltlf-fond_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2020-07-14T17:41:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-10-16T15:05:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "PDDL",
                    "name": "PDDL",
                    "type": "Programming_language",
                    "size": 49117851
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 1496539
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1186919
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1115462
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 305670
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 49458
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 2034
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Common Lisp",
                    "name": "Common Lisp",
                    "type": "Programming_language",
                    "size": 1591
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "180": {
        "filename": "luiscruz_slr-green-ai_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Reproducibility package for the SLR on Green AI\n```bash\nmkdir results\npython -m venv venv #1st time only\nsource venv/bin/activate\npython src/analysis.py\n```\n \n",
                    "original_header": "slr-green-ai"
                },
                "confidence": 0.9999200413921303,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/luiscruz/slr-green-ai/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-12-06T12:34:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-05T04:39:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 17665
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "R",
                    "name": "R",
                    "type": "Programming_language",
                    "size": 259
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "181": {
        "filename": "xtli12_GXU-LIPE_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Our repository is based on the repository [Maniskill2-learn](https://github.com/haosulab/ManiSkill2-Learn)\r\nTo get started, enter the parent directory of where you installed [ManiSkill2](https://github.com/haosulab/ManiSkill2) and clone this repo. Assuming the anaconda environment you installed ManiSkill2 is `mani_skill2`, execute the following commands (**note that the ordering is strict**):\r\n\r\n```\r\ncd {parent_directory_of_ManiSkill2}\r\nconda activate mani_skill2 #(activate the anaconda env where ManiSkill2 is installed)\r\ngit clone https://github.com/haosulab/ManiSkill2-Learn\r\ncd ManiSkill2-Learn\r\nconda install pytorch==1.11.0 torchvision==0.12.0 cudatoolkit=11.3 -c pytorch\r\npip install pytorch3d\r\npip install ninja\r\npip install -e .\r\npip install protobuf==3.19.0\r\n\r\nln -s ../ManiSkill2/data data # link the ManiSkill2 asset directory to ManiSkill2-Learn\r\n# Alternatively, add `export MS2_ASSET_DIR={path_to_maniskill2}/data` to your bashrc file, so that the OS can find the asset directory no matter where you run MS2 envs.\r\n```\r\n\r\nIf you would like to use SparseConvNet to perform 3D manipulation learning, install `torchsparse` and its releated dependencies (the `torchsparse` below is forked from the original repo with bug fix and additional normalization functionalities):\r\n\r\n```\r\nsudo apt-get install libsparsehash-dev # brew install google-sparsehash if you use Mac OS\r\npip install torchsparse@git+https://github.com/lz1oceani/torchsparse.git\r\n```\r",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Getting Started"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/xtli12/GXU-LIPE/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-06-18T02:34:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-02T09:46:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 822329
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cuda",
                    "name": "Cuda",
                    "type": "Programming_language",
                    "size": 12487
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 3137
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "182": {
        "filename": "amrisi_amr-guidelines_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2013-03-23T22:21:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T06:05:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "183": {
        "filename": "spell-system_SPELL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "These instructions were tested with python 3.10.9 on macOS.\n\nCreate a python virtual environment (to avoid installing dependencies in the global environment):\n```\n    python -m venv spell-venv\n```\nEnter the virtual environment:\n```\n    source ./spell-venv/bin/activate\n```\nInstall dependencies:\n```\n    pip install -r requirements.txt\n```\nMake sure that the `robot` tool is available in the `robot` directory (this is required for some tests):\n```\ncd robot\n./get_robot.sh\ncd ..\n```\nCheck that everything works by running the tests:\n```\n    pytest\n```\nRun an example:\n```\n    python spell_cli.py tests/father.owl tests/father-example/P.txt tests/father-example/N.txt\n```\nSee\n```\n    python spell_cli.py --help\n```\nfor some options.\n\nRun the demo webui:\n```\npip install flask\npython -m webui.spell_webui\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Setting up and running SPELL",
                    "parent_header": [
                        "SPELL"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spell-system/SPELL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can find instructions on how to reproduce the benchmarks in [benchmarks.md](benchmarks.md) \n",
                    "original_header": "SPELL"
                },
                "confidence": 0.9580447217577052,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/spell-system/SPELL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-09T12:29:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-10T14:07:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 150631
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 6542
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2519
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "184": {
        "filename": "bio-ontology-research-group_EL2Box_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "185": {
        "filename": "caskcsg_SPCL_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-10-14T05:31:21Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-30T02:15:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 61198
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 12
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "186": {
        "filename": "credl_abcbenchmarking_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2015-10-22T15:14:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2020-04-27T17:40:27Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 58352
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 36500
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "187": {
        "filename": "openai_evals_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "To run evals, you will need to set up and specify your [OpenAI API key](https://platform.openai.com/account/api-keys). After you obtain an API key, specify it using the [`OPENAI_API_KEY` environment variable](https://platform.openai.com/docs/quickstart/step-2-setup-your-api-key). Please be aware of the [costs](https://openai.com/pricing) associated with using the API when running evals. You can also run and create evals using [Weights & Biases](https://wandb.ai/wandb_fc/openai-evals/reports/OpenAI-Evals-Demo-Using-W-B-Prompts-to-Run-Evaluations--Vmlldzo0MTI4ODA3).\n\n**Minimum Required Version: Python 3.9**\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "OpenAI Evals"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/openai/evals/main/README.md"
            },
            {
                "result": {
                    "value": "If you are going to be creating evals, we suggest cloning this repo directly from GitHub and installing the requirements using the following command:\n\n```sh\npip install -e .\n```\n\nUsing `-e`, changes you make to your eval will be reflected immediately without having to reinstall.\n\nOptionally, you can install the formatters for pre-committing with:\n\n```sh\npip install -e .[formatters]\n```\n\nThen run `pre-commit install` to install pre-commit into your git hooks. pre-commit will now run on every commit.\n\nIf you want to manually run all pre-commit hooks on a repository, run `pre-commit run --all-files`. To run individual hooks use `pre-commit run <hook_id>`.\n",
                    "type": "Text_excerpt",
                    "original_header": "Making evals",
                    "parent_header": [
                        "OpenAI Evals",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/openai/evals/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<img width=\"596\" alt=\"https://x.com/gdb/status/1733553161884127435?s=20\" src=\"https://github.com/openai/evals/assets/35577566/ce7840ff-43a8-4d88-bb2f-6b207410333b\">\n \n",
                    "original_header": "OpenAI Evals"
                },
                "confidence": 0.9999831228017161,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openai/evals/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-01-23T20:51:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T09:20:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1650985
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 280354
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 108666
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 33932
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 7022
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 744
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 68
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "188": {
        "filename": "sk5050_HCSSP_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-02-25T05:59:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-02-25T06:00:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 357149
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "189": {
        "filename": "VAN-QIAN_CIKM23-HIEST_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "You can create a new folder \"raw_data\" under the root path and download a dataset from the collection [libcity](https://bigscity-libcity-docs.readthedocs.io/en/latest/tutorial/install_quick_start.html#download-one-dataset) under the new path.\n\nThen simply add the mapping matrix \"XXX.mor.py\" into the folder of a dataset e.g. ,  $ROOT_PATH/raw_data/METR_LA/METR_LA.mor.py. \n\nYou can utilize our proposed mapping matrix or generate one by the provided utils.\n",
                    "type": "Text_excerpt",
                    "original_header": "2. Prepare your dataset",
                    "parent_header": [
                        "Quick Start"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/VAN-QIAN/CIKM23-HIEST/main/README.md"
            },
            {
                "result": {
                    "value": "1. Create a definition file(named HIEST.def) as follows,\n\n```sh\n#Bootstrap is used to specify the agent,where the base image from,here localimage means to build from a local image\nBootstrap: localimage\n## This is something like 'From' in DOCKERFILE to indicate the base image\nFrom: ./pytorch_1.7.1-cuda11.0-cudnn8-devel.sif\n\n# %files can be used to copy files from host into the image\n# like 'COPY' in DOCKERFILE\n# Here we copy the requirements.txt into the image, then we can use it to install the required dependencies.\n%files\n    ./Bigscity-LibCity/requirements.txt /opt\n\n# %post is used to build the new image\n# Usage is same to shell.Here we used pip to install dependencies.\n%post\n    pip install -r /opt/requirements.txt\n    pip install protobuf==3.20.0 #to solve some warning we met\n \n#% environment is used to set env_variables once the image starts\n# These lines are necessary to load cuda\n%environment\n    export PATH=$PATH:/usr/local/cuda-11.0/bin\n    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.0/lib64:/usr/lib/x86_64-linux-gnu\n```\n\n2. Now execute the following command to build the image\n\n```sh\n## still on the root path\nsingularity build HIEST.sif HIEST.def\n```\n\nYou will see the following INFO when building the new image\n\n![image-20230525102417208](./README.assets/image-20230525102417208.png)\n\nIf nothing is wrong after creating SIF file, then you will get the image file **HIEST.sif** on the root path.\n",
                    "type": "Text_excerpt",
                    "original_header": "5.2 Install Requirements",
                    "parent_header": [
                        "Anonymous Github version",
                        "5. Running environment"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/VAN-QIAN/CIKM23-HIEST/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can also search and install the QuickMap services to add the base map. \n",
                    "original_header": "4. The visualization code"
                },
                "confidence": 0.9983970419974472,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/VAN-QIAN/CIKM23-HIEST/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-25T02:36:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-01T03:41:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1563407
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "GLSL",
                    "name": "GLSL",
                    "type": "Programming_language",
                    "size": 9105
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "190": {
        "filename": "SonglinZhai_DNG_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-11-23T14:08:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-14T09:22:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 87177
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "191": {
        "filename": "MasterMilkX_KekeCompetition_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "[Python Version]() (coming in 2023!) \n",
                    "original_header": "Keke AI Competition"
                },
                "confidence": 0.9827178916207736,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/MasterMilkX/KekeCompetition/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-09-23T23:28:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-05T00:44:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 126291
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 15403
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 705
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "192": {
        "filename": "paulorocosta_ai-for-tsp-competition_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-05-06T13:58:55Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-07T15:37:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 55918
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "193": {
        "filename": "yjw1029_DeepQSE_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-10-08T06:28:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-12-30T02:27:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "194": {
        "filename": "rbrandt1_Precise-Benchmarking-of-XAI_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**** Settings ****\r\n\r\n\tSettings are set in main.py.\r\n\r\n\tnum_examples_per_class\t\t\tNumber of examples per class\r\n\tnormalize_explanations\t\t\tNormalize explanations or do not\r\n\tsaveSelectedImages\t\t\tSave one explanation example image per method and class\r\n\tsaveAllImages\t\t\t\tSave all explanations as image\r\n\tresize_Images\t\t\t\tUpscale the above images before saving them.\r\n\tall_xai_methods\t\t\t\tXAI methods to run. Choose from [GradCAM,GradCAMPP,Saliency,DeconvNet, GradientInput, \r\n\t\t\t\t\t\t\t\tGuidedBackprop, IntegratedGradients, SmoothGrad, SquareGrad,VarGrad,Occlusion,Rise,KernelShap,Lime] \r\n\tall_xai_methods\t\t\t\tNames of XAI methods to run. \r\n\tall_xai_metrics\t\t\t\tXAI metrics to run from xplique library. Choose from [Deletion,Insertion, MuFidelity] \r\n\tall_xai_metrics_names \t\t\tNames of the XAI metrics above.\r\n\r\n\r\n**** Run ****\r\n\t\r\n\t--- main program ---\r\n\t\r\n\tTo execute the main program, run\r\n\t\r\n\tpython main.py\r\n\t\r\n\tThe program returns a latex table with average metric scores (table_results_.csv) and a latex table with the average times needed to compute metrics (table_times_.csv). \r\n\tImages are stored in ./paper_images\r\n\t\r\n\t\r\n\t--- Results table aggregation ---\r\n\t\r\n\ttable_results_.csv and table_times_.csv files were obtained by running the main program multiple times. These files are stored in the ./results folder. \r\n\tTo aggregate the results into single tables, run\r\n\t\t\r\n\tgen_paper_tables.py \r\n\t\r\n\twhich is stored in the folder ./results\r\n\r\n\r\n\r\n**** Dependencies ****\r\n\t\r\n\t-- Libraries used in experiments without a gpu available --\r\n\t\r\n\tName                      Version  \t\tLicense\r\n\r\n\tpython                    3.8.1     \t\thttps://docs.python.org/3/license.html\r\n\tkeras                     2.8.0     \t\thttps://github.com/keras-team/keras/blob/master/LICENSE\r\n\ttensorflow                2.8.0\t\t\thttps://github.com/tensorflow/tensorflow/blob/master/LICENSE\r\n\tnumpy                     1.22.2\t\thttps://github.com/numpy/numpy/blob/main/LICENSE.txt\r\n\tpandas                    1.4.1\t\t\thttps://github.com/pandas-dev/pandas/blob/main/LICENSE\r\n\txplique                   0.2.6\t\t\thttps://pythonrepo.com/repo/deel-ai-xplique-python-deep-learning-model-explanation\r\n\tscikit-image              0.19.1\t\thttps://scikit-image.org/docs/stable/license.html\r\n\tscikit-learn              1.0.2\t\t\thttps://scikit-learn.org/stable/\r\n\topencv-python             4.5.5.62\t\thttps://opencv.org/license/\r\n\t\r\n\t\r\n\t-- Libraries used in experiments with a gpu available --\r\n\t\r\n\tName                      Version  \t\tLicense\r\n\t\r\n\tpython                    3.8.12   \t \thttps://docs.python.org/3/license.html\r\n\tkeras                     2.7.0   \t  \thttps://github.com/keras-team/keras/blob/master/LICENSE\r\n\ttensorflow                2.3.0\t\t\thttps://github.com/tensorflow/tensorflow/blob/master/LICENSE\r\n\tnumpy                     1.18.5\t\thttps://github.com/numpy/numpy/blob/main/LICENSE.txt\r\n\tpandas                    1.4.1\t\t\thttps://github.com/pandas-dev/pandas/blob/main/LICENSE\r\n\txplique                   0.3.0\t\t\thttps://pythonrepo.com/repo/deel-ai-xplique-python-deep-learning-model-explanation\r\n\tscikit-image              0.19.2\t\thttps://scikit-image.org/docs/stable/license.html\r\n\tscikit-learn              1.0.2\t\t\thttps://scikit-learn.org/stable/\r\n\topencv-python             4.5.5.62\t\thttps://opencv.org/license/\r\n\t\r\n \n"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/rbrandt1/Precise-Benchmarking-of-XAI/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-08-01T10:40:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-02-24T00:07:11Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 57143
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "195": {
        "filename": "Grey-z_FairRec_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "1. Install the related environment configuration and dependency packages.\n2. Prepare datasets and models to be tested.\n3. Modify the config.json. \n",
                    "original_header": "Instruction"
                },
                "confidence": 0.9999999736827622,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Grey-z/FairRec/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Packages:\n```\ndeepctr==0.9.3\nnumpy==1.18.5\npandas==1.3.2\ntensorflow==2.3.0\n```\n \n",
                    "original_header": "Environment"
                },
                "confidence": 0.9956187074047389,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Grey-z/FairRec/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-11-10T10:48:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-05T11:33:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 49066
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 6401
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 320
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "196": {
        "filename": "morningstarwang_MetaTTE_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We here provide the datasets we adopted in this paper with Google Drive. After downloading the zip file, please extract all the files in data directory to the data folder in this project.\r\n\r\nDownload Link: <a href=\"https://drive.google.com/file/d/1KiiSnx5x6f8B-pkkZEk7QYHIHg7I-zp8/view?usp=sharing\">Download</a>\r\n\r",
                    "type": "Text_excerpt",
                    "original_header": "Data Preparation",
                    "parent_header": [
                        "MetaTTE: a Meta-Learning Based Travel Time Estimation Model for Multi-city Scenarios"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/morningstarwang/MetaTTE/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-02-23T07:00:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-12T11:53:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 85982
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "197": {
        "filename": "ZJLAB-AMMI_LLM4RL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Tensorboard logging is enabled by default for all algorithms. The logger expects that you supply an argument named ```logdir```, containing the root directory you want to store your logfiles \nThe resulting directory tree would look something like this:\n```\nlog/                         # directory with all of the saved models and tensorboard \n\u2514\u2500\u2500 ppo                                 # algorithm name\n    \u2514\u2500\u2500 simpledoorkey                   # environment name\n        \u2514\u2500\u2500 save_name                   # unique save name \n            \u251c\u2500\u2500 acmodel.pt              # actor and critic network for algo\n            \u251c\u2500\u2500 events.out.tfevents     # tensorboard binary file\n            \u2514\u2500\u2500 config.json             # readable hyperparameters for this run\n``` \nRun ```$ tensorboard --logdir=log``` then navigate to BASH4* in your browser\n \n",
                    "original_header": "Logging details"
                },
                "confidence": 0.9805859437498574,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ZJLAB-AMMI/LLM4RL/main/Readme.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<img src=\"img/always.gif\" width=\"300\"/>\n \n",
                    "original_header": "Always baseline:"
                },
                "confidence": 0.9310345324879501,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ZJLAB-AMMI/LLM4RL/main/Readme.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-06-05T09:52:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T13:23:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 81446
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "198": {
        "filename": "OpenBioLink_ITO_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2020-04-20T14:48:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-11T06:30:55Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 33583089
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "199": {
        "filename": "vOptSolver_vOptLib_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2017-09-02T16:02:38Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-25T04:34:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "200": {
        "filename": "lllyasviel_Fooocus_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The Fooocus project, built entirely on the **Stable Diffusion XL** architecture, is now in a state of limited long-term support (LTS) with bug fixes only. As the existing functionalities are considered as nearly free of programmartic issues (Thanks to [mashb1t](https://github.com/mashb1t)'s huge efforts), future updates will focus exclusively on addressing any bugs that may arise. \n\n**There are no current plans to migrate to or incorporate newer model architectures.** However, this may change during time with the development of open-source community. For example, if the community converge to one single dominant method for image generation (which may really happen in half or one years given the current status), Fooocus may also migrate to that exact method.\n\nFor those interested in utilizing newer models such as **Flux**, we recommend exploring alternative platforms such as [WebUI Forge](https://github.com/lllyasviel/stable-diffusion-webui-forge) (also from us), [ComfyUI/SwarmUI](https://github.com/comfyanonymous/ComfyUI). Additionally, several [excellent forks of Fooocus](https://github.com/lllyasviel/Fooocus?tab=readme-ov-file#forks) are available for experimentation.\n\nAgain, recently many fake websites exist on Google when you search \u201cfooocus\u201d. Do **NOT** get Fooocus from those websites \u2013 this page is the only official source of Fooocus. We never have any website like such as \u201cfooocus.com\u201d, \u201cfooocus.net\u201d, \u201cfooocus.co\u201d, \u201cfooocus.ai\u201d, \u201cfooocus.org\u201d, \u201cfooocus.pro\u201d, \u201cfooocus.one\u201d. Those websites are ALL FAKE. **They have ABSOLUTLY no relationship to us. Fooocus is a 100% non-commercial offline open-source software.**\n",
                    "type": "Text_excerpt",
                    "original_header": "Project Status: Limited Long-Term Support (LTS) with Bug Fixes Only"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/lllyasviel/Fooocus/main/readme.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Fooocus is an image generating software (based on [Gradio](https://www.gradio.app/) <a href='https://github.com/gradio-app/gradio'><img src='https://img.shields.io/github/stars/gradio-app/gradio'></a>). \n",
                    "original_header": "Fooocus"
                },
                "confidence": 0.9998056880783789,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/lllyasviel/Fooocus/main/readme.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Below is a quick list using Midjourney's examples: \nBelow is a quick list using LeonardoAI's examples: \n",
                    "original_header": "Features"
                },
                "confidence": 0.9263771010438988,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/lllyasviel/Fooocus/main/readme.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-08-09T18:43:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T09:34:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 2003568
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 57092
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 8224
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1119
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 639
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 632
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "201": {
        "filename": "gyunamister_OPerA_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Please make sure to install the binaries of [Graphviz](https://graphviz.org/) and [Python 3.8.8](https://www.python.org/downloads/release/python-383/) before you proceed. In the following, shell scripts are developed for the zsh, so if you use a different shell, then you need to modify the scripts accordingly.\n\nIn the first shell:\n\n```bash\ngit clone https://github.com/gyunamister/OPerA.git\ncd src/backend/db\ndocker-compose up\n```\n\nIn the second shell:\n\n```bash\nexport OPERA_PATH=<path_to_your_project_root> # the directory where src/ is located\ncd src/backend\n./run_celery.sh\n```\n\nAlternatives to Windows:\n\n```bash\npip install eventlet  \nset REDIS_LOCALHOST_OR_DOCKER=localhost\nset RABBIT_LOCALHOST_OR_DOCKER=localhost\nset RABBITMQ_USER=opera\nset RABBITMQ_PASSWORD=opera92! \ncd src/backend/tasks\ncelery -A tasks worker --loglevel=INFO -P eventlet\n```\n\nIn the third shell:\n\n```bash\nexport OPERA_PATH=<path_to_your_project_root> # the directory where src/ is located\ncd src/backend\n./run_opera.sh\n```\n\nThe default username is admin, and the default password is test123 for logging into the system available at 127.0.0.1/8050.\n",
                    "type": "Text_excerpt",
                    "original_header": "Manual",
                    "parent_header": [
                        "Deployment"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/OPerA/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For automatic and platform-independent deployment, simply execute the following commands:\n```shell script\ngit clone https://github.com/gyunamister/OPerA.git\ncd src/\ndocker-compose up\n```\nAfter installations, the web service is available at *127.0.0.1/8050*. \nThe default username is *admin*, and the default password is *test123* for logging into the system.\nIf you would like the Dash web service to run in debug mode, then change the value of the environment variable **DEBUG_MODE** in the [env file](src/.env) to **true**. \n",
                    "original_header": "Automatic"
                },
                "confidence": 0.9999999998437374,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/gyunamister/OPerA/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-04-21T13:36:52Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-11T11:20:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 350627
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 2188
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2076
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 381
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "202": {
        "filename": "XuanxiangHuang_fmp-experiments_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-02-14T12:53:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-02-14T13:02:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 116442
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "203": {
        "filename": "joyjitchatterjee_ScientometricReview-AI_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2020-09-17T17:23:06Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-11-14T13:29:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 579188
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "204": {
        "filename": "sh0416_clrcmd_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```\nconda create -n clrcmd python=3.8\nconda activate clrcmd\npip install -r requirements.txt\npython setup.py develop\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "1. Prepare Environment",
                    "parent_header": [
                        "Contrastive Learning: Relaxed Contextualized word Mover Distance (CLRCMD)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/sh0416/clrcmd/master/README.md"
            },
            {
                "result": {
                    "value": "```\nbash examples/download_sts.sh\n```\n* `tokenizer.sed`: Tokenizer script used in `download_sts.bash`\n",
                    "type": "Text_excerpt",
                    "original_header": "2-1. Semantic Textual Similarity benchmark (STS12, STS13, STS14, STS15, STS16, STSB, SICKR)",
                    "parent_header": [
                        "Contrastive Learning: Relaxed Contextualized word Mover Distance (CLRCMD)",
                        "2. Prepare dataset"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/sh0416/clrcmd/master/README.md"
            },
            {
                "result": {
                    "value": "```\nbash examples/download_ists.sh\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "2-2. Interpretable Semantic Textual Similarity benchmark (iSTS)",
                    "parent_header": [
                        "Contrastive Learning: Relaxed Contextualized word Mover Distance (CLRCMD)",
                        "2. Prepare dataset"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/sh0416/clrcmd/master/README.md"
            },
            {
                "result": {
                    "value": " * 252th example: from `a closed path` to `a closed path.`\n * 287th example: from `has no gaps` to `[ has no gaps ]`\n * 315th example: from `is in a closed path,` to `[ is in a closed path, ]`\n * 315th example: from `is in a closed path.` to `[ is in a closed path. ]`\n* `STSint.testinput.answers-students.sent1.txt`\n * 287th example: `battery  terminal` to `battery terminal`\n * 308th example: `switch z,  that` to `switch z, that`\n* `STSint.testinput.answers-students.sent2.chunk.txt`\n * 287th example: `are not separated by the gap` to `[ are not separated by the gap ]`\n * 315th example: `are` to `[ are ]`\n * 315th example: `in closed paths` to `[ in closed path ]`\n",
                    "type": "Text_excerpt",
                    "original_header": "2-2-1. Correct wrong input format",
                    "parent_header": [
                        "Contrastive Learning: Relaxed Contextualized word Mover Distance (CLRCMD)",
                        "2. Prepare dataset",
                        "2-2. Interpretable Semantic Textual Similarity benchmark (iSTS)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/sh0416/clrcmd/master/README.md"
            },
            {
                "result": {
                    "value": "```\nbash examples/download_nli.bash\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "2-3. NLI dataset tailored for self-supervised learning (SimCSE-NLI)",
                    "parent_header": [
                        "Contrastive Learning: Relaxed Contextualized word Mover Distance (CLRCMD)",
                        "2. Prepare dataset"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/sh0416/clrcmd/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "# Help message\npython -m examples.run_evaluate_sts -h \n",
                    "original_header": "3-1. Evaluate semantic textual similarity benchmark without any training"
                },
                "confidence": 0.903799281977535,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/sh0416/clrcmd/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-08-17T10:27:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-12-07T07:28:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 1404409
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 52494
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "205": {
        "filename": "JHL-HUST_LDMLP_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "For HGB datasets:\n\n```\nsh download_hgb_datasets.sh\n```\n\nFor experiments on the large dataset ogbn-mag, the dataset will be automatically downloaded from OGB challenge.\n",
                    "type": "Text_excerpt",
                    "original_header": "Data preparation",
                    "parent_header": [
                        "LMSPS"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/JHL-HUST/LDMLP/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-07-15T03:09:11Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-23T06:37:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 248605
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 606
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "206": {
        "filename": "CodingPerson_PEARL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We provide all the data sets (profession data set, hobby data set, and 20News data set) in the folder `data/datasets/`. ",
                    "type": "Text_excerpt",
                    "original_header": "Data sets",
                    "parent_header": [
                        "The Framework PEARL"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/CodingPerson/PEARL/main/README.md"
            },
            {
                "result": {
                    "value": "**Profession** data set(obtained from the authors of [2])  \natribute values: 71; user utterances: 5747   \nused by the previous work: [CHARM](https://aclanthology.org/2020.emnlp-main.434/) [DSCGN](https://dl.acm.org/doi/abs/10.1145/3487553.3524248)   \n\n**Hobby** data set (obtained from the authors of [2])  \natribute values: 149; user utterances: 5787   \nused by the previous work: [CHARM](https://aclanthology.org/2020.emnlp-main.434/) [DSCGN](https://dl.acm.org/doi/abs/10.1145/3487553.3524248)    \n\nNote that we follow the same task setting as previous personal attribute prediction papers[2-4], where attribute values are NOT explicitly mentioned in utterances and the given candidate attribute values are ranked based on the underlying semantics of utterances.\n",
                    "type": "Text_excerpt",
                    "original_header": "Personal attribute prediction task",
                    "parent_header": [
                        "The Framework PEARL",
                        "Data sets"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/CodingPerson/PEARL/main/README.md"
            },
            {
                "result": {
                    "value": "**20News** data set(obtained from [1])   \nclasses: 5; documents: 17871      \nused by the previous work: [X-Class](https://arxiv.org/abs/2010.12794)   \n\nNote that PEARL is tested on the weakly supervised text classification task to verify its universality, flexibility and effectiveness.\n",
                    "type": "Text_excerpt",
                    "original_header": "Weakly supervised text classification task",
                    "parent_header": [
                        "The Framework PEARL",
                        "Data sets"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/CodingPerson/PEARL/main/README.md"
            },
            {
                "result": {
                    "value": "    CUDA_VISIBLE_DEVICES = [gpu_id] python static_representations.py --dataset_name profession\n    CUDA_VISIBLE_DEVICES = [gpu_id] python utterance_word_representations.py --dataset_name profesion\n\nSimilarly, the hobby (resp. 20News) data set can be preprocessed by replacing \"profession\" as \"hobby\" (resp. \"20News\").",
                    "type": "Text_excerpt",
                    "original_header": "Preprocess the profession data set:",
                    "parent_header": [
                        "The Framework PEARL",
                        "Reproduce"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/CodingPerson/PEARL/main/README.md"
            },
            {
                "result": {
                    "value": "    python iterate_frame_profession.py\n\nSimilarly, PEARL can run on the hobby (resp. 20News) data set via the command \"python iterate_frame_hobby.py\" (resp. \"python iterate_frame_20News.py\").\n\n[1] Lang K. Newsweeder. Learning to filter netnews. Machine Learning Proceedings 1995, 331-339.    \n\n[2] Tigunova A, Yates A, Mirza P, et al. CHARM: Inferring personal attributes from conversations. EMNLP'20, 5391-5404.\n\n[3] Liu Y, Chen H, Shen W. Personal Attribute Prediction from Conversations. WWW'2022, 223-227.\n\n[4] Tigunova A, Yates A, Mirza P, et al. Listening between the lines: Learning personal attributes from conversations. WWW'2019, 1818-1828.\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Run PEARL on the profession data set:",
                    "parent_header": [
                        "The Framework PEARL",
                        "Reproduce"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/CodingPerson/PEARL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Computational platform: PyTorch 1.4.0, NVIDIA Geforce GTX 3090 (GPU), Inter i9-10900X (CPU), CUDA Toolkit 10.0 \nDevelopment language: Python 3.6/C++\n       \nLiabraries are listed as follow, which can be installed via the command `pip install -r requirements.txt`.\n```\nnumpy, scipy, tqdm, scikit-learn, sentencepiece=0.1.91, transformers, tensorboardX, nltk, os, sys, collections, itertools, argparse, subprocess, pickle, cudatoolkit=10.0, pytorch==1.4.0\n``` \n",
                    "original_header": "Environment"
                },
                "confidence": 0.9995863106034397,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/CodingPerson/PEARL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-08-13T10:33:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-07T12:49:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 108581
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "207": {
        "filename": "chq1155_A-Survey-on-Generative-Diffusion-Model_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-09-13T10:54:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T07:07:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "208": {
        "filename": "DirectMolecularConfGen_DMCG_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We recommend building a Docker image with the [Dockerfile](Dockerfile).\n\nAfter building and starting the docker, you can run\n\n```shell\ncd /workspace\ngit clone https://github.com/DirectMolecularConfGen/DMCG\ncd DMCG\npip install -e .\n```\n\nYou may possibly need to run `pip install setuptools==59.5.0` if you met problems with the `setuptools` module.\n",
                    "type": "Text_excerpt",
                    "original_header": "Through Docker",
                    "parent_header": [
                        "Direct Molecular Conformation Generation",
                        "Requirements and Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/DirectMolecularConfGen/DMCG/main/README.md"
            },
            {
                "result": {
                    "value": "If you want to develop it locally using conda venv, please refer to Line 27 to Line 36 in [Dockerfile](Dockerfile) to build a virtual conda environment.\n",
                    "type": "Text_excerpt",
                    "original_header": "Through conda venv",
                    "parent_header": [
                        "Direct Molecular Conformation Generation",
                        "Requirements and Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/DirectMolecularConfGen/DMCG/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Download **rdkit_folder.tar.gz** from this [url](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/JNGTDF) and untar this file by `tar -xvf rdkit_folder.tar.gz` \n",
                    "original_header": "Large-scale GEOM-QM9 and GEOM-Drugs data"
                },
                "confidence": 0.9999790170110486,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/DirectMolecularConfGen/DMCG/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```shell\n# Training. We place the unzipped data folder in /workspace/qm9_processed\nbash run_training.sh --dropout 0.1 --use-bn --no-3drot  \\\n    --aux-loss 0.2 --num-layers 6 --lr 2e-4 --batch-size 128 \\\n    --vae-beta-min 0.0001 --vae-beta-max 0.03 --reuse-prior \\\n    --node-attn --data-split confgf --pred-pos-residual \\\n    --dataset-name qm9 --remove-hs --shared-output  \\\n    --ang-lam 0.2 --bond-lam 0.1 --base-path $yourdatapath\n\n# Inference. We recommend using checkpoint_94.pt\npython evaluate.py --dropout 0.1 --use-bn --lr-warmup --use-adamw --train-subset \\\n    --num-layers 6 --eval-from $CKPT --workers 20 --batch-size 128 \\\n    --reuse-prior --node-attn --data-split confgf --dataset-name qm9 --remove-hs \\\n    --shared-output --pred-pos-residual --sample-beta 1.2\n```\n \n",
                    "original_header": "Reproduce small-scale GEOM-QM9"
                },
                "confidence": 0.9718538827037235,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/DirectMolecularConfGen/DMCG/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-01-28T03:50:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-05T01:12:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 123858
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1829
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1548
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "209": {
        "filename": "pokerme7777_HiTSKT_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The requiring environments is as bellow:\n\n- Python 3.6+\n- PyTorch 1.9.0\n- Scikit-learn 0.24.2\n- Numpy 1.19.5\n- Pandas 1.1.5\n- Dask 2021.3.0\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "HiTSKT: A Hierarchical Transformer Model for Session-awared Knowledge Tracing"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/pokerme7777/HiTSKT/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Then, create a new directory ``Dataset`` and put ``ednet.csv`` into this directory.\n```\nmkdir Dataset\n```\nTo preprocess the ``ednet.csv`` file, run the preprocessing script.\n```\npython preprocessing.py --dataset=ednet \n```\n \n",
                    "original_header": "Data and Data Preprocessing"
                },
                "confidence": 0.9654488469908055,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/pokerme7777/HiTSKT/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-09-14T09:12:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-08T07:28:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 144364
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "210": {
        "filename": "NeuralNetworkVerification_Marabou_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "# Installation\n\nMaraboupy is the Python API for Marabou, which is written in C++.\nMarabou and Maraboupy must first be built from source using CMake.\nFirst, clone the Marabou repository:\n```\ngit clone https://github.com/NeuralNetworkVerification/Marabou.git\n```\n\nThe marabou build process uses CMake version 3.2 (or later).\nYou can get CMake [here](https://cmake.org/download/).\n\nBuilding Marabou and Maraboupy also depends on Boost and pybind11, which are\ndownloaded automatically during the build process.\n\nThe python interface was tested only on versions >3.5 and >2.7. The build process prefers python3 but will work if there is only python 2.7 available. (To control the default change the DEFAULT_PYTHON_VERSION variable).  \nBy default, building Marabou also builds the python API, Maraboupy. \nThe BUILD_PYTHON variable controls whether or not the python API is built,\nand the PYTHON_EXECUTABLE variable can control the python executable used to build Maraboupy.\nThis process will produce the binary file and the shared library for the Python \nAPI. \n\nMarabou can be built for Linux, MacOS, or Windows machines.\n\n## Marabou build instructions for Linux or MacOS\n\nTo build build both Marabou and Maraboupy using CMake, run:\n```\ncd path/to/marabou/repo/folder\nmkdir build \ncd build\ncmake .. -DBUILD_PYTHON=ON\ncmake --build .\n```\n\nTo enable multiprocess build change the last command to:\n```\ncmake --build . -j PROC_NUM\n```\nTo compile in debug mode (default is release)\n```\ncmake .. -DCMAKE_BUILD_TYPE=Debug -DBUILD_PYTHON=ON\n```\n\nThe compiled Marabou binary will be in the *build* directory, named _Marabou_.\nIn addition, a shared library will be created and placed in the maraboupy directory, where the\npython sources files are located. Check to see that the MarabouCore shared library is present in the \nmaraboupy directory after building.\n\nAfter building, add the Marabou root directory to your PYTHONPATH environmental variable.\n\n## Build Instructions for Windows using Visual Studio\n\nFirst, install Visual Studio 2017 or later and select the \"Desktop development with C++\" workload. \nEnsure that CMake is installed and added to your PATH.\n\nOpen a command prompt and run:\n```\ncd path\\to\\marabou\\repo\\folder\nmkdir build \ncd build\ncmake .. -G\"Visual Studio 15 2017 Win64\" -DBUILD_PYTHON=ON\ncmake --build . --config Release\n```\nThis process builds Marabou using the generator \"Visual Studio 15 2017 Win64\". \nFor 32-bit machines, omit Win64. Other generators and older versions of Visual Studio can likely be used as well, \nbut only \"Visual Studio 15 2017 Win64\" has been tested.\n\nThe Marabou executable file will be written to the build/Release folder. To build in \nDebug mode, simply run \"cmake --build . --config Debug\", and the executables will be \nwritten to build/Debug.\n\nIn addition, a shared library will be created for the python API, Maraboupy, and placed in either\nmaraboupy/Release or maraboupy/Debug folders, depending on build type. However, Maraboupy needs to have\nthe shared library located in maraboupy alongside the python sources files, so you will need to run either\n```\ncp maraboupy/Release/* maraboupy\n```\nor \n```\ncp maraboupy/Debug/* maraboupy\n```\ndepending on build type in order to copy the shared library to the maraboupy folder.\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/NeuralNetworkVerification/Marabou/master/maraboupy/docs/Setup/0_Installation.md"
            },
            {
                "result": {
                    "value": "The recommended way to install Marabou is via `pip` using the command\n```bash\npip install maraboupy\n```\nwhich will install both the `Marabou` executable on your path and the Python bindings.\nThe Python interface currently supports Python 3.8, 3.9, 3.10 and 3.11.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installing via Pip",
                    "parent_header": [
                        "Marabou",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NeuralNetworkVerification/Marabou/master/README.md"
            },
            {
                "result": {
                    "value": "Marabou can be configured to use the Gurobi optimizer, which can replace the\nin-house LP solver and enable a few additional solving modes.\n\nGurobi requires a license (a free academic license is available), after \ngetting one the software can be downloaded [here](https://www.gurobi.com/downloads/gurobi-optimizer-eula/) \nand [here](https://www.gurobi.com/documentation/9.5/quickstart_linux/software_installation_guid.html#section:Installation) are\ninstallation steps, there is a [compatibility issue](https://support.gurobi.com/hc/en-us/articles/360039093112-C-compilation-on-Linux)\nthat should be addressed.\nA quick installation reference:\n```bash\nexport INSTALL_DIR=/opt\nsudo tar xvfz gurobi9.5.1_linux64.tar.gz -C $INSTALL_DIR\ncd $INSTALL_DIR/gurobi951/linux64/src/build\nsudo make\nsudo cp libgurobi_c++.a ../../lib/\n```\nNext, set the following environment variables (e.g., by adding the following to the `.bashrc` and invoke `source .bashrc`): \n```bash\nexport GUROBI_HOME=\"/opt/gurobi951/linux64\"\nexport PATH=\"${PATH}:${GUROBI_HOME}/bin\"\nexport LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:${GUROBI_HOME}/lib\"\nexport GRB_LICENSE_FILE=/path/to/license.lic\n```\n\nAfter Gurobi is set up, follow the same build instruction of Marabou in the beginning, \nexcept that you need  to run the following command instead of `cmake ../`:\n```bash\ncmake ../ -DENABLE_GUROBI=ON\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Compile Marabou with the Gurobi optimizer (optional)",
                    "parent_header": [
                        "Marabou",
                        "Installation",
                        "Building from source"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NeuralNetworkVerification/Marabou/master/README.md"
            },
            {
                "result": {
                    "value": "The `cmake ../` command can take other options, for example:\n\n- Compile without the Python binding:\n```bash\ncmake ../ -DBUILD_PYTHON=OFF\n```\n- Compile in debug mode (default is release):\n```bash\ncmake ../ -DCMAKE_BUILD_TYPE=Debug\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Other CMake options",
                    "parent_header": [
                        "Marabou",
                        "Installation",
                        "Building from source"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NeuralNetworkVerification/Marabou/master/README.md"
            },
            {
                "result": {
                    "value": "To run tests we use [ctest](https://cmake.org/cmake/help/v3.15/manual/ctest.1.html).\nThe tests have labels according to level (unit/system/regress0/regress1...), and the code they are testing (engine/common etc...).  \nFor example to run all unit tests execute in the build directory:\n```bash\nctest -L unit\n```\nOn every build we run the unit tests, and on every pull request we run unit,\nsystem, regress0 and regress1.\n\nAnother option to build and run all of the tests is: \n```bash\ncd path/to/marabou/repo/folder\nmkdir build \ncd build\ncmake ..\nmake check -j PROC_NUM\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Testing",
                    "parent_header": [
                        "Marabou",
                        "Installation",
                        "Building from source"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NeuralNetworkVerification/Marabou/master/README.md"
            },
            {
                "result": {
                    "value": "We no longer provide Windows support. Instructions to build an old version of Marabou\nfor Windows can be found [here](https://github.com/NeuralNetworkVerification/Marabou/tree/0fc1d10ff0e1859cf32abe54eb22f3ec0fec59f6?tab=readme-ov-file#build-instructions-for-windows-using-visual-studio).\n",
                    "type": "Text_excerpt",
                    "original_header": "Build Instructions for Windows using Visual Studio",
                    "parent_header": [
                        "Marabou",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NeuralNetworkVerification/Marabou/master/README.md"
            },
            {
                "result": {
                    "value": "1. Install `pre-commit` which manages the pre-commit hooks and use it to install the hooks, e.g.\n```bash\npip install pre-commit\npre-commit install\n```\nThis guarantees automatic formatting of your C++ code whenever you commit.\n",
                    "type": "Text_excerpt",
                    "original_header": "Setting up your development environment",
                    "parent_header": [
                        "Marabou",
                        "Developing Marabou"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NeuralNetworkVerification/Marabou/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-03-09T21:40:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-14T01:33:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 3855201
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 350250
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 48260
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Perl",
                    "name": "Perl",
                    "type": "Programming_language",
                    "size": 34739
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 25625
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 21416
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 5768
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 3158
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JetBrains MPS",
                    "name": "JetBrains MPS",
                    "type": "Programming_language",
                    "size": 2449
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 2049
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 930
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "211": {
        "filename": "kracr_ontoseer_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "\r\nIn this section we will discuss how one can download OntoSeer.\r\n\r\n<a name=\"code\"></a>\r\n\r",
                    "type": "Text_excerpt",
                    "original_header": "3.Installation Guide",
                    "parent_header": [
                        "Table of Contents"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/kracr/ontoseer/master/README.md"
            },
            {
                "result": {
                    "value": "\r\n1. Get a copy of the example code:\r\n\r\n     git clone https://github.com/kracr/ontoseer\r\n    \r\n2. Change into the OntoSeer directory.\r\n\r\n3. Type mvn clean package.  On build completion, the \"target\" directory will contain a OntoSeer-${version}.jar file.\r\n\r\n4. Copy the JAR file from the target directory to the \"plugins\" folder.\r\n\r\n\t4.1.1 Click on the \"plugins\" folder subdirectory of your Protege distribution (for linux/windows).\r\n \t![OntoSeer_jar_plugin](https://github.com/kracr/ontoseer/blob/master/Images/Onto4.png)\r\n\r\n \t4.1.2 Click on the \"plugins\" folder after \"Show Package Contents\" option in right click option on Protege application (for mac).\r\n \t![OntoSeer_jar_plugin](https://github.com/kracr/ontoseer/blob/master/Images/ontoseer_mac_folder.png)\r\n\r\n \t4.2 Copy OntoSeer.jar in the plugin folder.\r\n \t![OntoSeer_jar_plugin_folder](https://github.com/kracr/ontoseer/blob/master/Images/plugin_folder.png)\r\n\r\n5. Restart Protege.\r\n\r\n6. Go to about Section of Protege and check whether the plugin has been correctly installed or not .It will be shown in the window.\r\n\r\n![OntoSeer_jar_plugin_About](https://github.com/kracr/ontoseer/blob/master/Images/about_protedge.png)\r\n\r\n7. Click on Windows. Click on Tabs .Click on OntoSeer Tab.This window will appear.\r\n\r\n![OntoSeer_jar_plugin_Actual_Tab](https://github.com/kracr/ontoseer/blob/master/Images/ontoseer_window_help.png)\r\n\r\n<a name=\"exe\"></a>\r\n\r",
                    "type": "Text_excerpt",
                    "original_header": "Installation Steps:",
                    "parent_header": [
                        "Table of Contents",
                        "3.1 Using Source Code"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/kracr/ontoseer/master/README.md"
            },
            {
                "result": {
                    "value": " \r\n This section discusses how OntoSeer can be used  along with Protege to get various recommendations.\r\n  1. Click On OntoSeer tab button.\r\n This window will be shown.\r\n \r\n ![Plugin Window](https://github.com/kracr/ontoseer/blob/master/Images/ontoseer_view.png)\r\n \r\n \r\n ## 4.1 ODP Recommendation\r\n 1. Click On ODP recommendation  button. Two classes must be present for getting ODP recommendation.\r\n This window will be shown.\r\n \r\n ![OntoSeer ODP](https://github.com/kracr/ontoseer/blob/master/Images/odp.png)\r\n \r\n2. Enter description of the ontology that one is trying to make .Alternatively domain\r\nname,name of class and properties one want to make or can additively provide with the competency\r\nquestions.One can provide additional comments also. But one have to make sure that they are actually\r\nmaking at least two classes to get recommendation. But the\r\nrecommendation will get better if one provide answer to as many questions as one can.\r\n\r\n\r\n \r\n3. Get Recommendation. The recommendation is based on the data that we have scraped from 223\r\nODPs that we collected from http://ontologydesignpatterns.org/wiki/Community:ListPatterns\r\n\r\n ![OntoSeer_jar_ODP_reco_show](https://github.com/kracr/ontoseer/blob/master/Images/odp_college.png)\r\n \r\n  <a name=\"Vocab\"></a>\r\n \r\n ## 4.2 Vocab and Alternate Name Recommendation\r\n \r\n 1. One should start buliding classes and properties in Protege .For example:-\r\n  ![OntoSeer_jar_Vocab](https://github.com/kracr/ontoseer/blob/master/Images/vocab.png)\r\n 2. Click on VocabRecommendation button.\r\n 3. Select the class or property for which you want the recommendations.Recommendations will be provided based on query results from LOV,Bioportal and our indexed files.\r\n 4.Get the recommendations.\r\n ![OntoSeer_jar_Vocab_reco_show](https://github.com/kracr/ontoseer/blob/master/Images/vocab_name.png)\r\n\r\n \r\n  <a name=\"Naming\"></a>\r\n  \r\n ## 4.3 Naming Convention Recommendation \r\n \r\n 1. One should start buliding classes and properties in Protege .For example:-\r\n \r\n   \r\n 2. Click on the NamingRecommendation button.\r\n\r\n![OntoSeer_jar_Name](https://github.com/kracr/ontoseer/blob/master/Images/class_naming.png)\r\n\r\n 3. Select the class or property for which you want the recommendations.\r\n \r\n 4. Get the class recommendations.\r\n \r\n ![OntoSeer_jar_Name_reco_show](https://github.com/kracr/ontoseer/blob/master/Images/class_naming_name.png)\r\n \r\n 5. Get the property recommendations.\r\n \r\n ![OntoSeer_jar_Name_reco_show](https://github.com/kracr/ontoseer/blob/master/Images/property_naming_name.png)\r\n\r\n <a name=\"Axiom\"></a>\r\n \r\n ## 4.4 Axiom Recommendation \r\n1. Start building the ontologies .\r\n\r\n  \r\n2. Click on Axiom Recommendation button .\r\n\r\n\r\n  ![OntoSeer_jar_Name](https://github.com/kracr/ontoseer/blob/master/Images/axiom.png)\r\n  \r\n3. Select the class or property for which you want the recommendations.\r\n\r\n\r\n4. Get the recommendations.\r\n\r\n![Axiom Recommendation](https://github.com/kracr/ontoseer/blob/master/Images/axiom_name.png)\r\n\r\n\r\n<a name=\"class\"></a>\r\n ## 4.5 Class Hierarchy Validation\r\n \r\n Class hierarch validation actually validates the correctness of a subclass hierarchy based on properties like rigidity, identitiy and unity of the classes.\r\n1. Click on Class Hierarchy Validation button .\r\n  ![OntoSeer_jar_Name](https://github.com/kracr/ontoseer/blob/master/Images/class_heirarchy.png)\r\n\r\n2. Answer the questions in (Y/N) format. Answer to all the questions are mandatory to velidate the hierarchy.\r\n\r\n3. Validate the Hierarchy\r\n![Class Hierarchy](https://github.com/kracr/ontoseer/blob/master/Images/class_heirarchy_name.png)\r\n\r\n<a name=\"future\"></a>\r",
                    "type": "Text_excerpt",
                    "original_header": "4.User Manual",
                    "parent_header": [
                        "Table of Contents"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/kracr/ontoseer/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\r\n1. User should have Protege installed in the machine. Version should be >5.0.0.\r\n\r\n \tIf one is not having protege or protege5.0.0 or higher installed they can download latest version of protege from https://protege.stanford.edu/products.php based on machine\u2019s operating system:\r\n\t\r\n\r\n2. JRE should be installed in user machine and version should be  >1.8.\r\n   To check for java version one can type java -version in terminal.The following will be the output. \r\n   \r\n   ![java-versioncheck](https://github.com/kracr/ontoseer/blob/master/Images/Onto1.png)\r\n\r\n<a name=\"InstallationGuide\"></a>\r\n\r \n",
                    "original_header": "2.Prerequisites"
                },
                "confidence": 0.9999999999744773,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/kracr/ontoseer/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "1. A brief demo of OntoSeer can be found in the link: https://youtu.be/iNQOJGZkZKQ\r\n\r\n2. A brief presentation of OntoSeer is available at: https://www.youtube.com/watch?v=8WrgaHixkww&t=0s\r\n\r\n<a name=\"google\"></a>\r \n",
                    "original_header": "7.Demo Video of OntoSeer"
                },
                "confidence": 0.9533056422895777,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/kracr/ontoseer/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-09-05T10:26:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-02-20T11:34:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 146242
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 20425
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 176
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "212": {
        "filename": "tae898_explicit-memory_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-09-28T10:49:11Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-21T15:09:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "213": {
        "filename": "bscheibel_dmma-e_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Requirements: \nOS: Fedora 36\nPython: version 3.10\nPython packages:\n    pandas==1.4.3\n    numpy==1.22.0\n    scikit-learn==1.1.1\n    scikit-multiflow==0.5.3\n    pm4py==2.2.26\n    matplotlib==3.5.2  \n\nThese packages can be installed using pip. \nTo start the script in terminal: python dmma-e.py. Per default, all synthetic datasets are started subsequently. \n",
                    "original_header": "dmma-e"
                },
                "confidence": 0.9866622692271513,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/bscheibel/dmma-e/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-11-27T06:24:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-06T08:20:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 14666
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "214": {
        "filename": "avani17101_go-nba_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "215": {
        "filename": "shuwen-liu-ox_LogInfer_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The original dataset of FB15K237 can be found at the folder FB_ori, which contains three files:\n- positive training set: FB_ori/train.txt  \n- positive validation set: FB_ori/validation.txt  \n- positive test set: FB_ori/test.txt \nThe original dataset of WN18RR can be found at the folder WN_ori, which contains three files:\n- positive training set: WN_ori/train.txt  \n- positive validation set: WN_ori/validation.txt  \n- positive test set: WN_ori/test.txt \n- train.txt    --------positive training set\n- valid.txt    --------positive validation set\n- test.txt    --------positive training set\n- candidate_entities.txt    --------Entities for generating negative examples using relevance-based random sampling\n- candidate_relations.txt    --------Relations for generating negative examples using relevance-based random sampling\n- train_neg_Z.txt    --------Negative training set\n- valid_neg_Z.txt    --------Negative validation set\n- test_neg_Z.txt    --------Negative test set \n2. System Requirement\n- Python 3.6.9\n- numpy\n- random\n- [RDFox](https://www.cs.ox.ac.uk/isg/tools/RDFox/2014/AAAI/) \n- train.txt    --------positive training set\n- valid.txt    --------positive validation set\n- test.txt    --------positive test set\n- candidate_entities.txt    ---------entities for generating negative examples using relevance-based random sampling\n- candidate_relations.txt   ---------relations for generating negative examples using relevance-based random sampling:     \n- train_neg_rb.txt\n- valid_neg_rb.txt\n- test_neg_rb.txt \nThis will result in 3 files in the folder benchmarks/BENCHMARK_NAME/:\n- train_neg_pa.txt\n- valid_neg_pa.txt\n- test_neg_pa.txt \n\nThen, run the following command to search for the assignments for the body of the rules \\mathcal{R}^-: \nThis will result in 3 files in the folder benchmarks/BENCHMARK_NAME/:\n- train_neg_qg.txt\n- valid_neg_qg.txt\n- test_neg_qg.txt \nThis will result in 3 files in the folder benchmarks/BENCHMARK_NAME/:\n- train_neg_rc.txt\n- valid_neg_rc.txt\n- test_neg_rc.txt \n",
                    "original_header": "LogInfer"
                },
                "confidence": 0.9746296075550298,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/shuwen-liu-ox/LogInfer/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-03-14T18:44:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-06-15T06:18:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 62370
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "216": {
        "filename": "KanghoonYoon_hetsgg-torch_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "``` python  \n\nconda create -n hetsgg python=3.7.7\n\nconda activate hetsgg\n\nconda install -y ipython scipy h5py\n\npip install ninja yacs cython matplotlib tqdm opencv-python overrides gpustat gitpython ipdb graphviz tensorboardx termcolor scikit-learn==0.23.1\n\nconda install pytorch==1.7.0 torchvision==0.8.0 cudatoolkit=11.0 -c pytorch\n\npip install torch-scatter==2.0.7 torch-sparse==0.6.9 -f https://data.pyg.org/whl/torch-1.7.0+cu110.html\n\npip install torch-sparse -f https://data.pyg.org/whl/torch-1.7.0+cu110.html\n\npip install torch-geometric\n\ngit clone https://github.com/cocodataset/cocoapi.git\ncd cocoapi/PythonAPI\npython setup.py build_ext install\n\ncd ..\n\ngit clone https://github.com/NVIDIA/apex.git\ncd apex\npip install -v --disable-pip-version-check --no-cache-dir ./\n\ncd ..\n\npython setup.py build develop\n\n```  \n",
                    "type": "Text_excerpt",
                    "original_header": "Package Install",
                    "parent_header": [
                        "Unbiased Heterogeneous Scene Graph Generation with Relation-aware Message Passing Network"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/KanghoonYoon/hetsgg-torch/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<p align=\"center\">   \n    <a href=\"https://pytorch.org/\" alt=\"PyTorch\">\n      <img src=\"https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?e&logo=PyTorch&logoColor=white\" /></a>\n    <a href=\"https://aaai.org/Conferences/AAAI-23/\" alt=\"Conference\">\n        <img src=\"https://img.shields.io/badge/AAAI'23-brightgreen\" /></a>\n</p> \n",
                    "original_header": "Unbiased Heterogeneous Scene Graph Generation with Relation-aware Message Passing Network"
                },
                "confidence": 0.9999999989513526,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/KanghoonYoon/hetsgg-torch/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You should change the value of **model_config** in shell/\\*.sh files to *relHetSGGp_vg*.\n```python  \nexport model_config=\"relHetSGGp_vg\"\n``` \n \n",
                    "original_header": "HetSGG++"
                },
                "confidence": 0.9204479368919318,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/KanghoonYoon/hetsgg-torch/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-07-21T07:20:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-21T01:58:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 898648
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cuda",
                    "name": "Cuda",
                    "type": "Programming_language",
                    "size": 116876
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 18715
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 9857
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 7128
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "217": {
        "filename": "baharslmn_pbn-epsilon-tuning_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-05-10T13:35:18Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-05-10T14:31:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 57563319
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 62757
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "218": {
        "filename": "BUPT-ANTlab_PEPCRL-MVP_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-10-24T10:30:18Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-01T06:53:55Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 54050
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "219": {
        "filename": "bprovanbessell_SATfeatPy_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Current command line usage, from project root directory.\nThis will print a dictionary of the features. Abbreviations can be found in (see [features](documentation/features.md)). [TO DO].\n```\npython generate_features.py path/to/cnf_file.cnf\n``` \n**Dependencies**\n- Python 3.8  \n- NetworkX 2.6.3  \n- community 1.0.0 \n- powerlaw 1.5  \n- sklearn 1.0.2  \n- scipy 1.7.3   \nA binary for ubcsat is included in the ubcsat folder, however you may have to compile and add this yourself for full functionality.\nPlease clone and compile [ubcsat](https://github.com/dtompkins/ubcsat/tree/beta), and put the resulting binary in the ubcsat folder, if the current binary does not work. We found the beta branch to be stable.\n \n",
                    "original_header": "SAT-features"
                },
                "confidence": 0.9806039212951472,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/bprovanbessell/SATfeatPy/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-12-08T13:00:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-30T10:26:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 473831
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 114456
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "220": {
        "filename": "HumanBehaviourChangeProject_semantic-prediction_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-03-23T09:53:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-04-21T21:11:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 120663
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "R",
                    "name": "R",
                    "type": "Programming_language",
                    "size": 42216
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "221": {
        "filename": "kakaobrain_pororo_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "# \uc124\uce58 \uac00\uc774\ub4dc\n\n\ubcf8 \ubb38\uc11c\uc5d0\uc11c\ub294 Pororo \uc124\uce58\ub97c \uc704\ud574 \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\uc5d0 \ub300\ud55c \uc124\uba85\uacfc \uc124\uce58 \ubc29\ubc95\uc744 \ub2e4\ub8f9\ub2c8\ub2e4.\n\n<br>\n\n## \uacf5\ud1b5 \ubaa8\ub4c8\n\n- Pororo \uc0ac\uc6a9\uc744 \uc704\ud574 \uacf5\ud1b5\uc801\uc73c\ub85c \uc124\uce58\ub418\uc5b4\uc57c \ud560 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n- \ud574\ub2f9 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub4e4\uc740 `pip install` \uba85\ub839\uc5b4\ub97c \ud1b5\ud574 Pororo\uac00 \uc124\uce58\ub420 \ub54c \uacf5\ud1b5\uc801\uc73c\ub85c \uc124\uce58\ub418\ubbc0\ub85c, \ucd94\uac00\uc801\uc778 \uc870\uce58\ub97c \ucde8\ud574\uc8fc\uc9c0 \uc54a\uc73c\uc154\ub3c4 \ub429\ub2c8\ub2e4.\n\n```python\nrequirements = [\n    \"torch==1.6.0\",\n    \"torchvision==0.7.0\",\n    \"pillow>=4.1.1\",\n    \"fairseq>=0.10.2\",\n    \"transformers>=4.0.0\",\n    \"sentence_transformers>=0.4.1.2\",\n    \"nltk>=3.5\",\n    \"word2word\",\n    \"wget\",\n    \"joblib\",\n    \"lxml\",\n    \"g2p_en\",\n    \"whoosh\",\n    \"marisa-trie\",\n    \"kss\",\n    'dataclasses; python_version<\"3.7\"',\n]\n```\n\n<br>\n\n## \ud55c\uad6d\uc5b4\n\n- \ud55c\uad6d\uc5b4\uc758 \ud2b9\uc815 \ud0dc\uc2a4\ud06c\ub97c \uc218\ud589\ud558\uae30 \uc704\ud574\uc11c\ub294 \ucd94\uac00\uc801\uc778 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc124\uce58\ud560 \ud544\uc694\uac00 \uc788\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n- `python-mecab-ko`\ub294 **\ud55c\uad6d\uc5b4 Tokenization, PoS Tagging, Dependency Parsing** \ub4f1 \uc5ec\ub7ec \ud0dc\uc2a4\ud06c\uc758 \uc218\ud589\uc744 \uc704\ud574 \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\uc785\ub2c8\ub2e4.\n\n```console\npip install python-mecab-ko==1.0.9\n```\n\n- `kollocate`\ub294 **\ud55c\uad6d\uc5b4 Collocation** \ud0dc\uc2a4\ud06c\uc758 \uc218\ud589\uc744 \uc704\ud574 \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\uc785\ub2c8\ub2e4.\n\n```console\npip install kollocate\n```\n\n- `koparadigm`\ub294 **\ud55c\uad6d\uc5b4 Morphological Inflection** \ud0dc\uc2a4\ud06c\uc758 \uc218\ud589\uc744 \uc704\ud574 \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\uc785\ub2c8\ub2e4.\n\n```console\npip install koparadigm\n```\n\n- `g2pk`\ub294 **\ud55c\uad6d\uc5b4 Grapheme-to-Phoneme** \ud0dc\uc2a4\ud06c\uc758 \uc218\ud589\uc744 \uc704\ud574 \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\uc785\ub2c8\ub2e4.\n\n```console\npip install g2pk\n```\n\n<br>\n\n## \uc77c\ubcf8\uc5b4\n\n- \uc77c\ubcf8\uc5b4\uc758 \ud2b9\uc815 \ud0dc\uc2a4\ud06c\ub97c \uc218\ud589\ud558\uae30 \uc704\ud574\uc11c\ub294 \ucd94\uac00\uc801\uc778 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc124\uce58\ud560 \ud544\uc694\uac00 \uc788\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n- `fugashi`\uc640 `ipadic`\uc740 **\uc77c\ubcf8\uc5b4 RoBERTa** \ubaa8\ub378\uc758 \ud1a0\ud06c\ub098\uc774\uc988\uc640 **\uc77c\ubcf8\uc5b4 PoS Tagging**\uc744 \uc704\ud574 \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\uc785\ub2c8\ub2e4.\n\n```console\npip install fugashi ipadic\n```\n\n- `romkan`\uc740 **\uc77c\ubcf8\uc5b4 Grapheme-to-Phoneme** \ud0dc\uc2a4\ud06c\uc758 \uc218\ud589\uc744 \uc704\ud574 \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\uc785\ub2c8\ub2e4.\n\n```console\npip install romkan\n```\n\n<br>\n\n## \uc911\uad6d\uc5b4\n\n- \uc911\uad6d\uc5b4\uc758 \ud2b9\uc815 \ud0dc\uc2a4\ud06c\ub97c \uc218\ud589\ud558\uae30 \uc704\ud574\uc11c\ub294 \ucd94\uac00\uc801\uc778 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc124\uce58\ud560 \ud544\uc694\uac00 \uc788\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n- `g2pM`\uc740 **\uc911\uad6d\uc5b4 Grapheme-to-Phoneme** \ud0dc\uc2a4\ud06c\uc758 \uc218\ud589\uc744 \uc704\ud574 \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\uc785\ub2c8\ub2e4.\n\n```console\npip install g2pM\n```\n\n- `jieba`\ub294 **\uc911\uad6d\uc5b4 PoS Tagging** \ud0dc\uc2a4\ud06c\uc758 \uc218\ud589\uc744 \uc704\ud574 \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac\uc785\ub2c8\ub2e4.\n\n```console\npip install jieba\n```\n\n<br>\n\n## \uae30\ud0c0\n\n### Linux \uc9c0\uc6d0 \ud0dc\uc2a4\ud06c\n\n- Automatic Speech Recognition\n- Speech Translation\n- Optical Character Recognition\n- Image Captioning\n\n<br>\n\n### Automatic Speech Recognition\n  \n- \uc74c\uc131\uc778\uc2dd \ubaa8\ub4c8\uc744 \ud65c\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 [wav2letter](https://github.com/facebookresearch/wav2letter) \uc124\uce58\uac00 \ud544\uc694\ud569\ub2c8\ub2e4. \ub808\ud3ec\uc9c0\ud1a0\ub9ac\uc758 `asr-install.sh`\ub97c \uc2e4\ud589\ud568\uc73c\ub85c\uc368 `wav2letter` \uc124\uce58\uac00 \uac00\ub2a5\ud569\ub2c8\ub2e4.\n- Wav2letter\ub97c \uc815\uc0c1\uc801\uc73c\ub85c \uc124\uce58\ud558\uae30 \uc704\ud574\uc11c\ub294 CUDA \uc124\uce58\uac00 \uc120\ud589\ub418\uc5b4\uc57c \ud569\ub2c8\ub2e4.\n\n```console\nbash asr-install.sh\n```\n\n<br>\n  \n### Speech Synthesis\n\n- **\uc74c\uc131\ud569\uc131** \ubaa8\ub4c8\uc744 \ud65c\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 \uc544\ub798 \ubaa8\ub4c8\ub4e4\uc744 \ucd94\uac00\ub85c \uc124\uce58\ud574\uc8fc\uc154\uc57c \ud569\ub2c8\ub2e4.\n\n```\nrequirements = [\n    \"editdistance==0.5.3\",\n    \"epitran==1.2\",\n    \"fastdtw==0.3.4\",\n    \"future\",\n    \"jieba==0.42.1\",\n    \"librosa==0.7.0\",\n    \"phonemizer==2.1\",\n    \"Pillow==7.1.0\",\n    \"pinyin==0.4.0\",\n    \"scipy\",\n    \"SoundFile==0.10.2\",\n    \"numba==0.48\",\n    \"ko_pron\",\n]\n```\n  \n<br>\n  \n\n### Optical Character Recognition\n\n- OCR \ubaa8\ub4c8\uc744 \ud65c\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 \uc544\ub798 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub4e4\uc744 \uc124\uce58\ud574\uc8fc\uc154\uc57c \ud569\ub2c8\ub2e4.\n\n```console\napt-get install -y libgl1-mesa-glx\n```\n\n```console\npip install opencv-python scikit-image\n```\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/kakaobrain/pororo/master/INSTALL.ko.md"
            },
            {
                "result": {
                    "value": "# Installation Guide\n\nThis document deals with how to install libraries required for Pororo installation.\n\n<br>\n\n## Common modules\n\n- The libraries that should be installed in common for the use of Pororo are:\n    - These libraries are installed when Pororo is installed through the `pip install` command, so you do not have to take additional action\n\n```python\nrequirements = [\n    \"torch==1.6.0\",\n    \"torchvision==0.7.0\",\n    \"pillow>=4.1.1\",\n    \"fairseq>=0.10.2\",\n    \"transformers>=4.0.0\",\n    \"sentence_transformers>=0.4.1.2\",\n    \"nltk>=3.5\",\n    \"word2word\",\n    \"wget\",\n    \"joblib\",\n    \"lxml\",\n    \"g2p_en\",\n    \"whoosh\",\n    \"marisa-trie\",\n    \"kss\",\n    'dataclasses; python_version<\"3.7\"',\n]\n```\n\n<br>\n\n## Korean\n\n- You may need to install additional libraries to perform specific tasks in Korean.\n\n- `python-mecab-ko` is a library needed for the **Korean Tokenization, PoS Tagging, Dependency Parsing, etc.**\n\n```console\npip install python-mecab-ko==1.0.9\n```\n\n- `kollocate` is a library needed for the **Korean Collocation** task.\n\n```console\npip install kollocate\n```\n\n- `koparadigm` is a library needed for the **Korean Morphological Inflection** task.\n\n```console\npip install koparadigm\n```\n\n- `g2pk` is a library needed for the **Korean Grapheme-to-Phoneme** task.\n\n```console\npip install g2pk\n```\n\n<br>\n\n## Japanese\n\n- You may need to install additional libraries to perform specific tasks in Japanese.\n\n- `fugashi` and `ipadic` are the libraries needed for the **Japanese RoBERTa** model and the **Japanese PoS Tagging**.\n\n```console\npip install fugashi ipadic\n```\n\n- `romkan` is a library needed for the **Japanese Grapheme-to-Phoneme** task.\n\n```console\npip install romkan\n```\n\n<br>\n\n## Chinese\n\n- You may need to install additional libraries to perform specific tasks in Chinese.\n\n- `g2pM` is a library needed for the **Chinese Grapheme-to-Phoneme** task.\n\n```console\npip install g2pM\n```\n\n- `jieba` is a library needed for the **Chinese PoS Tagging** task.\n\n```console\npip install jieba\n```\n\n<br>\n\n## Etc.\n\n### Linux Supported Tasks\n\n- Automatic Speech Recognition\n- Speech Translation\n- Optical Character Recognition\n- Image Captioning\n\n<br>\n\n### Automatic Speech Recognition\n  \n- To utilize the **Automatic Speech Recognition** module, [wav2letter](https://github.com/facebookresearch/wav2letter) is required. `asr-install.sh` can be used for installation of th `wav2letter`\n- Note! CUDA must be pre-installed for installation of the wav2letter.\n  \n```console\nbash asr-install.sh\n```\n\n<br>\n  \n### Speech Synthesis\n\n- To utilize the **Speech Synthesis** module, you need to install additional modules below.\n\n```\nrequirements = [\n    \"editdistance==0.5.3\",\n    \"epitran==1.2\",\n    \"fastdtw==0.3.4\",\n    \"future\",\n    \"jieba==0.42.1\",\n    \"librosa==0.7.0\",\n    \"phonemizer==2.1\",\n    \"Pillow==7.1.0\",\n    \"pinyin==0.4.0\",\n    \"scipy\",\n    \"SoundFile==0.10.2\",\n    \"numba==0.48\",\n    \"ko_pron\",\n]\n```\n  \n<br>\n  \n### Optical Character Recognition\n\n- To utilize the **OCR** module, you need to install the following libraries\n\n```console\napt-get install -y libgl1-mesa-glx\n```\n\n```console\npip install opencv-python scikit-image\n```\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/kakaobrain/pororo/master/INSTALL.md"
            },
            {
                "result": {
                    "value": "---\nname: Install issue\nabout: Issue about installation\nlabels: 'install'\n---\n\n## Environment\n\n- OS :\n- Python version :\n- Misc. :\n\n<br>\n\n## FAQ\n\n- [Windows Support (fairseq)](https://github.com/kakaobrain/pororo/issues/15#issuecomment-772417976)\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/kakaobrain/pororo/master/.github/ISSUE_TEMPLATE/install.md"
            },
            {
                "result": {
                    "value": "- `pororo` is based on `torch=1.6(cuda 10.1)` and `python>=3.6`\n\n- You can install a package through the command below:\n\n```console\npip install pororo\n```\n\n- Or you can install it **locally**:\n\n```console\ngit clone https://github.com/kakaobrain/pororo.git\ncd pororo\npip install -e .\n```\n\n- For library installation for specific tasks other than the **common modules**, please refer to [INSTALL.md](INSTALL.md)\n\n- For the utilization of **Automatic Speech Recognition**, [_wav2letter_](https://github.com/facebookresearch/wav2letter) should be installed separately. For the installation, please run the [asr-install.sh](asr-install.sh)\n\n```console\nbash asr-install.sh\n```\n\n- For the utilization of **Speech Synthesis**, please run the [tts-install.sh](tts-install.sh)\n\n```console\nbash tts-install.sh\n```\n\n- **Speech Synthesis** samples can be found [here](https://pororo-tts.github.io/)\n\n<br>\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "PORORO: Platform Of neuRal mOdels for natuRal language prOcessing"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/kakaobrain/pororo/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<p align=\"center\">\n  <a href=\"https://github.com/kakaobrain/pororo/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/kakaobrain/pororo.svg\" /></a>\n  <a href=\"https://github.com/kakaobrain/pororo/blob/master/LICENSE\"><img alt=\"Apache 2.0\" src=\"https://img.shields.io/badge/license-Apache%202.0-blue.svg\" /></a>\n  <a href=\"https://kakaobrain.github.io/pororo/\"><img alt=\"Docs\" src=\"https://img.shields.io/badge/docs-passing-success.svg\" /></a>\n  <a href=\"https://github.com/kakaobrain/pororo/issues\"><img alt=\"Issues\" src=\"https://img.shields.io/github/issues/kakaobrain/pororo\" /></a>\n</p> \n",
                    "original_header": "PORORO: Platform Of neuRal mOdels for natuRal language prOcessing"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/kakaobrain/pororo/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-01-28T05:37:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-12T20:45:14Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 835454
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2237
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1682
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 233
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "222": {
        "filename": "zxd-octopus_VRICR_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We run all experiments and tune hyperparameters on a RTX3090 with 24GB memory, you can adjust `train_batch_size` and `test_batch_size` according to your GPU, and then the optimization hyperparameters also need to be tuned.\r\n```\r\nsh script/redial/redial_rec_pretrain.sh\r\nsh script/redial/redial_rec_finetune.sh # remember to change --task_ID_for_pretrain and --last_ckpt_path_for_pretrain\r\nsh script/redial/redial_conv.sh\r\n\r\nsh script/tgredial/train/redial_rec_pretrain.sh\r\nsh script/tgredial/tgredial_rec_finetune.sh # remember to change --task_ID_for_pretrain and --last_ckpt_path_for_pretrain\r\nsh script/tgredial/tgredial_conv.sh \r\n```\r\n\r\nYou can also test the model has been saved by us.\r\nBASH2*\r\n\r\n\r\n\r \n",
                    "original_header": "Quick-Start"
                },
                "confidence": 0.9999999999980105,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/zxd-octopus/VRICR/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-08-10T10:10:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-08T15:41:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 157174
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1497
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "223": {
        "filename": "amidos2006_Mario-AI-Framework_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<p align=\"center\">\n<a href=\"#features\">Features</a> &mdash; <a href=\"#use\">How To Use</a> &mdash; <a href=\"#papers\">Related Papers</a> &mdash; <a href=\"#missing\">Missing Features</a> &mdash; <a href=\"#copyrights\">Copyrights</a>\n</p>\n<p align=\"center\">\n<img width=\"300\" height=\"300\" alt=\"Robin Baumgarten A* agent\" src=\"https://raw.githubusercontent.com/amidos2006/Mario-AI-Framework/master/img/frameworkAD.gif\">\n</p>\n<p align=\"center\">\n  <b>Current Framework Version: 0.8.0</b>\n</p> \n"
                },
                "confidence": 0.9940815128217478,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/amidos2006/Mario-AI-Framework/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-04-10T14:39:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T15:30:26Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 396741
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "224": {
        "filename": "a-burigana_delphic_asp_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We made the installation of *DELPHIC* easy by using the *Conda* package management system. If you don't have *Conda* installed in your machine, please follow this [guide](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html).\n\nTo install *DELPHIC*, move to the *DELPHIC* directory in your terminal and simply run the following command:\n\n```bash\nconda env create -f delphic.yml\n```\n\nThis will take care of everything. All dependencies needed for the installation are specified in the YAML file `delphic.yml`. Before running *DELPHIC*, you only need to activate its Conda environment with the following command:\n\n```bash\nconda activate delphic\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "DELPHIC"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/a-burigana/delphic_asp/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-03-10T09:23:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-03-16T09:50:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 19706
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "225": {
        "filename": "NVlabs_GroupViT_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "* Python 3.7\n* PyTorch 1.8\n* webdataset 0.1.103\n* mmsegmentation 0.18.0\n* timm 0.4.12\n\nInstructions:\n\n```shell\nconda create -n groupvit python=3.7 -y\nconda activate groupvit\nconda install pytorch==1.8.0 torchvision==0.9.0 cudatoolkit=11.1 -c pytorch -c conda-forge\npip install mmcv-full==1.3.14 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html\npip install mmsegmentation==0.18.0\npip install webdataset==0.1.103\npip install timm==0.4.12\ngit clone https://github.com/NVIDIA/apex\ncd && apex && pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\npip install opencv-python==4.4.0.46 termcolor==1.1.0 diffdist einops omegaconf\npip install nltk ftfy regex tqdm\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Environmental Setup",
                    "parent_header": [
                        "GroupViT: Semantic Segmentation Emerges from Text Supervision"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NVlabs/GroupViT/main/README.md"
            },
            {
                "result": {
                    "value": "During training, we use [webdataset](https://webdataset.github.io/webdataset/) for scalable data loading.\nTo convert image text pairs into the webdataset format, we use the [img2dataset](https://github.com/rom1504/img2dataset) tool to download and preprocess the dataset.\n\nFor inference, we use [mmsegmentation](https://github.com/open-mmlab/mmsegmentation) for semantic segmentation testing, evaluation and visualization on Pascal VOC, Pascal Context and COCO datasets.\n\nThe overall file structure is as follows:\n\n```shell\nGroupViT\n\u251c\u2500\u2500 local_data\n\u2502   \u251c\u2500\u2500 gcc3m_shards\n\u2502   \u2502   \u251c\u2500\u2500 gcc-train-000000.tar\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2502   \u251c\u2500\u2500 gcc-train-000436.tar\n\u2502   \u251c\u2500\u2500 gcc12m_shards\n\u2502   \u2502   \u251c\u2500\u2500 gcc-conceptual-12m-000000.tar\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2502   \u251c\u2500\u2500 gcc-conceptual-12m-001943.tar\n\u2502   \u251c\u2500\u2500 yfcc14m_shards\n\u2502   \u2502   \u251c\u2500\u2500 yfcc14m-000000.tar\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2502   \u251c\u2500\u2500 yfcc14m-001888.tar\n\u2502   \u251c\u2500\u2500 redcap12m_shards\n\u2502   \u2502   \u251c\u2500\u2500 redcap12m-000000.tar\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2502   \u251c\u2500\u2500 redcap12m-001211.tar\n\u2502   \u251c\u2500\u2500 imagenet_shards\n\u2502   \u2502   \u251c\u2500\u2500 imagenet-val-000000.tar\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2502   \u251c\u2500\u2500 imagenet-val-000049.tar\n\u2502   \u251c\u2500\u2500 VOCdevkit\n\u2502   \u2502   \u251c\u2500\u2500 VOC2012\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 JPEGImages\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 SegmentationClass\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ImageSets\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Segmentation\n\u2502   \u2502   \u251c\u2500\u2500 VOC2010\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 JPEGImages\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 SegmentationClassContext\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ImageSets\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 SegmentationContext\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 train.txt\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 val.txt\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 trainval_merged.json\n\u2502   \u2502   \u251c\u2500\u2500 VOCaug\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 dataset\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cls\n\u2502   \u251c\u2500\u2500 coco\n\u2502   \u2502   \u251c\u2500\u2500 images\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 train2017\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 val2017\n\u2502   \u2502   \u251c\u2500\u2500 annotations\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 train2017\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 val2017\n```\n\nThe instructions for preparing each dataset are as follows.\n",
                    "type": "Text_excerpt",
                    "original_header": "Data Preparation",
                    "parent_header": [
                        "GroupViT: Semantic Segmentation Emerges from Text Supervision"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NVlabs/GroupViT/main/README.md"
            },
            {
                "result": {
                    "value": "Please download the training split annotation file from [Conceptual Caption 12M](https://ai.google.com/research/ConceptualCaptions/download) and name it as `gcc3m.tsv`.\n\nThen run `img2dataset` to download the image text pairs and save them in the webdataset format.\n```\nsed -i '1s/^/caption\\turl\\n/' gcc3m.tsv\nimg2dataset --url_list gcc3m.tsv --input_format \"tsv\" \\\n            --url_col \"url\" --caption_col \"caption\" --output_format webdataset\\\n            --output_folder local_data/gcc3m_shards\n            --processes_count 16 --thread_count 64\n            --image_size 512 --resize_mode keep_ratio --resize_only_if_bigger True \\\n            --enable_wandb True --save_metadata False --oom_shard_count 6\nrename -d 's/^/gcc-train-/' local_data/gcc3m_shards/*\n```\nPlease refer to [img2dataset CC3M tutorial](https://github.com/rom1504/img2dataset/blob/main/dataset_examples/cc3m.md) for more details.\n",
                    "type": "Text_excerpt",
                    "original_header": "GCC3M",
                    "parent_header": [
                        "GroupViT: Semantic Segmentation Emerges from Text Supervision",
                        "Data Preparation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NVlabs/GroupViT/main/README.md"
            },
            {
                "result": {
                    "value": "Please download the annotation file from [Conceptual Caption 12M](https://github.com/google-research-datasets/conceptual-12m) and name it as `gcc12m.tsv`.\n\nThen run `img2dataset` to download the image text pairs and save them in the webdataset format.\n```\nsed -i '1s/^/caption\\turl\\n/' gcc12m.tsv\nimg2dataset --url_list gcc12m.tsv --input_format \"tsv\" \\\n            --url_col \"url\" --caption_col \"caption\" --output_format webdataset\\\n            --output_folder local_data/gcc12m_shards \\\n            --processes_count 16 --thread_count 64\n            --image_size 512 --resize_mode keep_ratio --resize_only_if_bigger True \\\n            --enable_wandb True --save_metadata False --oom_shard_count 6\nrename -d 's/^/gcc-conceptual-12m-/' local_data/gcc12m_shards/*\n```\nPlease refer to [img2dataset CC12M tutorial](https://github.com/rom1504/img2dataset/blob/main/dataset_examples/cc12m.md) for more details.\n",
                    "type": "Text_excerpt",
                    "original_header": "GCC12M",
                    "parent_header": [
                        "GroupViT: Semantic Segmentation Emerges from Text Supervision",
                        "Data Preparation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NVlabs/GroupViT/main/README.md"
            },
            {
                "result": {
                    "value": "Please follow the [CLIP Data Preparation](https://github.com/openai/CLIP/blob/main/data/yfcc100m.md) instructions to download the YFCC14M subset.\n```\nwget https://openaipublic.azureedge.net/clip/data/yfcc100m_subset_data.tsv.bz2\nbunzip2 yfcc100m_subset_data.tsv.bz2\n```\n\nThen run the preprocessing script to create the subset sql db and annotation tsv files. This may take a while.\n```\npython convert_dataset/create_subset.py --input-dir . --output-dir . --subset yfcc100m_subset_data.tsv\n```\nThis script will create two files: an SQLite db called `yfcc100m_dataset.sql` and an annotation tsv file called `yfcc14m_dataset.tsv`.\n\nThen follow the [YFCC100M Download Instruction](https://gitlab.com/jfolz/yfcc100m/-/tree/master) to download the dataset and its metadata file.\n```\npip install git+https://gitlab.com/jfolz/yfcc100m.git\nmkdir -p yfcc100m_meta\npython -m yfcc100m.convert_metadata . -o yfcc100m_meta --skip_verification\nmkdir -p yfcc100m_zip\npython -m yfcc100m.download yfcc100m_meta -o yfcc100m_zip\n```\n\nFinally convert the dataset into the webdataset format.\n```\npython convert_dataset/convert_yfcc14m.py --root yfcc100m_zip --info yfcc14m_dataset.tsv --shards yfcc14m_shards\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "YFCC14M",
                    "parent_header": [
                        "GroupViT: Semantic Segmentation Emerges from Text Supervision",
                        "Data Preparation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NVlabs/GroupViT/main/README.md"
            },
            {
                "result": {
                    "value": "Please download the annotation file from [RedCaps](https://redcaps.xyz/).\n```\nwget https://www.dropbox.com/s/cqtdpsl4hewlli1/redcaps_v1.0_annotations.zip?dl=1\nunzip redcaps_v1.0_annotations.zip\n```\n\nThen run the preprocessing script and `img2dataset` to download the image text pairs and save them in the webdataset format.\n```\npython convert_dataset/process_redcaps.py annotations redcaps12m_meta/redcaps12m.parquet --num-split 16\nimg2dataset --url_list ~/data/redcaps12m/ --input_format \"parquet\" \\\n            --url_col \"URL\" --caption_col \"TEXT\" --output_format webdataset \\\n            --output_folder local_data/recaps12m_shards\n            --processes_count 16 --thread_count 64\n            --image_size 512 --resize_mode keep_ratio --resize_only_if_bigger True \\\n            --enable_wandb True --save_metadata False --oom_shard_count 6\nrename -d 's/^/redcap12m-/' local_data/recaps12m_shards/*\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "RedCaps12M",
                    "parent_header": [
                        "GroupViT: Semantic Segmentation Emerges from Text Supervision",
                        "Data Preparation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NVlabs/GroupViT/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-03-16T23:10:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-16T07:00:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 183630
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1450
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "226": {
        "filename": "eugenevinitsky_sequential_social_dilemma_games_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "To install the SSD environments:",
                    "type": "Text_excerpt",
                    "original_header": "Setup instructions"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/eugenevinitsky/sequential_social_dilemma_games/master/README.md"
            },
            {
                "result": {
                    "value": "```bash",
                    "type": "Text_excerpt",
                    "original_header": "Anaconda/miniconda",
                    "parent_header": [
                        "Setup instructions"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/eugenevinitsky/sequential_social_dilemma_games/master/README.md"
            },
            {
                "result": {
                    "value": "```bash\ngit clone -b master https://github.com/eugenevinitsky/sequential_social_dilemma_games\ncd sequential_social_dilemma_games\nconda create -n ssd python==3.8.10 # Create a conda virtual environment\n# Patch ray due to https://github.com/ray-project/ray/issues/7946\n# And https://github.com/ray-project/ray/pull/8491\n. conda_uint8_patch.sh\n```\n###\n```bash\ngit clone -b master https://github.com/eugenevinitsky/sequential_social_dilemma_games\ncd sequential_social_dilemma_games\npython3 -m venv venv # Create a Python virtual environment\n. venv/bin/activate\npip3 install --upgrade pip setuptools wheel\npython3 setup.py develop\npip3 install -r requirements.txt\n# Patch ray due to https://github.com/ray-project/ray/issues/7946\n# And https://github.com/ray-project/ray/pull/8491\n. venv_uint8_patch.sh\n```\n\nTo install sb3|rllib|all requirements for learning:\n```bash\npip3 install social-dilemmas[sb3|rllib|all]\n```\n\nIf using RLlib:\n```\n\n```\n\nAfter the setup, you can run experiments like so:\n- To train with default parameters (baseline model cleanup with 2 agents):\n```bash\npython3 run_scripts/train.py\n```\n\n- To train the MOA with 5 agents:\n```bash\npython3 run_scripts/train.py --model moa --num_agents 5\n```\n\nMany more options are available which can be found in [default_args.py](config/default_args.py). A collection of preconfigured training scripts can be found in [run_scripts](run_scripts). \n\nNote that the RLlib initialization time can be rather high (up to 5 minutes) the more agents you use, and the more complex your used model is.\n\n- To train using [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3) and parameter shared PPO:\n```bash\npython3 run_scripts/sb3_train.py --env harvest --num_agents 5\n```\n\n- To train using [MARL-Baselines3](https://github.com/Rohan138/marl-baselines3) and independent PPO:\n```bash\npython3 run_scripts/sb3_independent.py --env harvest --num_agents 5\n```\n\n- To train using [MARL-Baselines3](https://github.com/Rohan138/marl-baselines3) and independent PPO with inequity aversion:\n```bash\npython3 run_scripts/sb3_independent.py --env harvest --num_agents 5 --inequity-averse-reward=True --alpha=5.0 --beta=0.05\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "",
                    "parent_header": [
                        "Setup instructions"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/eugenevinitsky/sequential_social_dilemma_games/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "If you run into any cuda errors, make sure you've got a [compatible set](https://www.tensorflow.org/install/source#tested_build_configurations) of cuda/cudnn/tensorflow versions installed. However, beware of the following:\n>The compatibility table given in the tensorflow site does not contain specific minor versions for cuda and cuDNN. However, if the specific versions are not met, there will be an error when you try to use tensorflow. [source](https://stackoverflow.com/a/53727997)\n \n",
                    "original_header": "CUDA, cuDNN and tensorflow-gpu"
                },
                "confidence": 0.9999999999879492,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/eugenevinitsky/sequential_social_dilemma_games/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Every environment that subclasses MapEnv probably needs to implement the following methods:\n```python\nclass NewMapEnv(MapEnv):\n    ...\n    \n    def custom_reset(self):\n        \"\"\"Reset custom elements of the map. For example, spawn apples\"\"\"\n        pass\n\n    def custom_action(self, agent, action):\n        \"\"\"Execute any custom, non-move actions that may be defined, like fire or clean\"\"\"\n        pass\n\n    def custom_map_update(self):\n        \"\"\"Custom map updates that don't have to do with agent actions\"\"\"\n        pass\n\n    def setup_agents(self):\n        \"\"\"Construct all the agents for the environment\"\"\"\n        raise NotImplementedError\n```\n \n",
                    "original_header": "Constructing new environments"
                },
                "confidence": 0.9999744055643418,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/eugenevinitsky/sequential_social_dilemma_games/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-11-30T21:26:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-18T04:36:21Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 322025
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 9864
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1121
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "227": {
        "filename": "JHL-HUST_BandHS_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-01-16T09:46:55Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-02-12T14:43:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 88080
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 53838
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 216
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "228": {
        "filename": "ML-KULeuven_LearnSDD_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "1. From the sdd package, copy the sdd library (libsdd.so) to lib/ \n2. Make sure that the c libraries can be found by adding lib/ to the ld library path\n    ```\n    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:lib/\n    ```\n    \n3. Learn a model for the NLTCS dataset and store the output in the directory nltcs output/: \nFor more information about the commands, use the following commands:\n```\njava -jar LearnSDD.jar\njava -jar LearnSDD.jar learn\njava -jar LearnSDD.jar infer\n```\n \n",
                    "original_header": "Quickstart"
                },
                "confidence": 0.9796800357338955,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ML-KULeuven/LearnSDD/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For learning, an output directory needs to be provided. In this directory the\nfollowing files and directories will appear: \n",
                    "original_header": "Output Directory"
                },
                "confidence": 0.9264673117287783,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ML-KULeuven/LearnSDD/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-03-07T18:37:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2021-07-01T08:43:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 109846
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 83192
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "229": {
        "filename": "yuehu9_DSAB-Detecting-Socially-Abnormal-Drving-Behaviors_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The code was written in Python 3.8.12. The main packages required are\npandas                        1.4.1;\ntorch                         1.11.0;\ntorch-cluster                 1.6.0;\ntorch-geometric               2.0.4;\ntorch-scatter                 2.0.9;\ntorch-sparse                  0.6.13;\ntorch-spline-conv             1.2.1;\ntorchvision                   0.12.0;\nscikit-learn                  1.1.1;\n\nThe complete list of packages are in the `requirements.txt`\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "DSAB-Detecting Socially Abnormal Highway Driving Behaviors via Recurrent Graph Attention Networks"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/yuehu9/DSAB-Detecting-Socially-Abnormal-Drving-Behaviors/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n```bash\nsh scripts/preprocessing.sh\n``` \n",
                    "original_header": "Using the code"
                },
                "confidence": 0.9957373705808414,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/yuehu9/DSAB-Detecting-Socially-Abnormal-Drving-Behaviors/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-10-25T19:05:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-14T12:49:26Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 57764
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1168
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "230": {
        "filename": "LemonQC_KG2Text_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-10-25T06:48:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-26T02:26:20Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 184221
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Perl",
                    "name": "Perl",
                    "type": "Programming_language",
                    "size": 25257
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Emacs Lisp",
                    "name": "Emacs Lisp",
                    "type": "Programming_language",
                    "size": 17034
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Smalltalk",
                    "name": "Smalltalk",
                    "type": "Programming_language",
                    "size": 1892
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Ruby",
                    "name": "Ruby",
                    "type": "Programming_language",
                    "size": 1649
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "NewLisp",
                    "name": "NewLisp",
                    "type": "Programming_language",
                    "size": 1582
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 835
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Slash",
                    "name": "Slash",
                    "type": "Programming_language",
                    "size": 278
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "SystemVerilog",
                    "name": "SystemVerilog",
                    "type": "Programming_language",
                    "size": 184
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "231": {
        "filename": "aig-upf_pgp-landmarks_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "In order to reproduce SoCS 2022 experiments simply run:\n```shell\n./scripts/socs22_experiments.sh\n``` \nThis script consists of the following commands which should succeed (given the paper settings):\n```shell\n./scripts/compile_all.sh\n./scripts/synthesis_generators.sh\n./scripts/synthesis_experiments.sh\n./scripts/synthesis_combined_pgp_landmarks_h1.sh\n./scripts/synthesis_combined_bfs_h5_h1.sh\n./scripts/validation_generators.sh\n./scripts/validation_experiments.sh\n```\n \n",
                    "original_header": "Reproducing SoCS 2022 Experiments"
                },
                "confidence": 0.9849320819191159,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/aig-upf/pgp-landmarks/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-05-08T15:39:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-29T15:11:18Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 189063
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 89763
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 19469
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "232": {
        "filename": "Ethan-Yys_DBPMaN_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-10-13T14:55:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-06T02:17:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 146678
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 13763
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "233": {
        "filename": "alpha-asp_Alpha_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Alpha uses the [Gradle build automation system](https://gradle.org). Executing\n```bash\n$ ./gradlew build\n```\n \nwill automatically fetch all dependencies (declared in [`build.gradle.kts`](build.gradle.kts)) and compile the project. \nArtifacts generated will be placed in the `build/` subfolder of the respective module. Most notably you'll find files ready for distribution at\n`alpha-cli-app/build/distributions/`. They contain archives which in turn contain a `bin/` directory with scripts to run Alpha on Linux\nand Windows. \nIf you want to generate a JAR file to be run standalone, execute\n```bash\n$ ./gradlew alpha-cli-app:bundledJar\n```\n \nand pick up `alpha-cli-app/build/libs/alpha-cli-app-${version}-bundled.jar`.\n \n",
                    "original_header": "Building"
                },
                "confidence": 0.9966347152624924,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/alpha-asp/Alpha/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2016-07-08T10:52:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-10T17:50:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 1661304
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Classic ASP",
                    "name": "Classic ASP",
                    "type": "Programming_language",
                    "size": 19876
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "ANTLR",
                    "name": "ANTLR",
                    "type": "Programming_language",
                    "size": 5509
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 78
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "234": {
        "filename": "snudatalab_Acorn_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-03-17T01:15:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-03-17T01:39:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 35870
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "235": {
        "filename": "wencolani_IterE_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2019-03-21T13:58:11Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-05T20:43:26Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 88173
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "236": {
        "filename": "Otamio_KGA_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "This is the repo for the submission *Augmenting Knowledge Graphs for Better Link Prediction*. This repo is structured as follows:\n1. `augment`. This directory contains the code to run the literal graph augmentation for the input graph. All input are tab-separated files. `augment_lp.py` is used to produce graph for link prediction, and `augment_np.py` is used to produce graph for numeric prediction.\n   1. To augment the dataset with link prediction, make sure the directory `data/{dataset}` contains at least four files:\n      1. `train.txt`: The training entity triples.\n      2. `valid.txt`: The validation entity triples.\n      3. `test.txt`: The testing entity triples.\n      4. `numerical_literals.txt`: The literal triples.\n      5. Once you get the above files, augment the graph with `python augment/augment_lp.py --dataset {dataset} --bins {bins}`.\n   2. To augment the dataset with numericaprediction, make sure the directory `data/{dataset}` contains at least four files:\n      1. `train_kge`: The entity triples.\n      2. `train_100`: The training literal triples.\n      3. `dev`: The validation literal triples.\n      4. `test`: The test literal triples.\n      5. Once you get the above files, augment the graph with `python augment/augment_np.py --dataset {dataset} --bins {bins}`.\n2. `pbg`. This directory contains the code to run Darpa Wikidata using PyTorch-BigGraph. To run the code, we recommend installing PyTorch-BigGraph as documented in https://github.com/facebookresearch/PyTorch-BigGraph, and Faiss as documented in https://github.com/facebookresearch/faiss.\n3. `rotate`. This directory contains the code to run TransE and RotatE with negative sampling. To run the code, we recommend installing the environment documented in https://github.com/DeepGraphLearning/KnowledgeGraphEmbedding.\n4. `tucker`. This directory contains the code to run DistMult, ComplEx, ConvE, and TuckER with k-N sampling. To run the code, we recommend installing the environment documented in https://github.com/ibalazevic/TuckER.\n5. `data`. This directory is the default location to store the input graphs. The data for this project can be located at: https://drive.google.com/drive/folders/14XtfAsfchsS-gPUZ1_YtP1X3bFiCaOS6?usp=sharing. \n6. `out`. This directory is the default location to store output logs.\n7. `numeric`. This directory is the default location to store numeric prediction logs. Since augmenting the graph for either link prediction and numeric prediction will produce different data, we recommend using directory `data` to store the augmented graph for link prediction, and directory `numeric` to store the augmented graph for numeric prediction. \n",
                    "original_header": "KGA: Knowledge Graph Augmentation"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Otamio/KGA/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-01-05T07:41:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-28T20:53:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 144711
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "237": {
        "filename": "jalaliamin_ResearchCode_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-06-18T17:58:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-10T13:09:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 4674650
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "238": {
        "filename": "thomasnguyen92_MIMIC-IV-ICD-data-processing_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Our directory has the following structure:\n```\nmimicdata\n\u2514\u2500\u2500\u2500physionet.org/\n|   |files/\n\u2514\u2500\u2500\u2500mimic4_icd9/\n|   |   ALL_CODES.csv\n|   |   ALL_CODES_filtered.csv\n|   |   disch_9_full.csv\n|   |   disch_9_filtered.csv\n|   |   notes_labeled.csv\n|   |   *_hadm_ids.csv (already in repo)\n\u2514\u2500\u2500\u2500mimic4_icd10/\n|   |   ALL_CODES.csv\n|   |   ALL_CODES_filtered.csv\n|   |   disch_10_full.csv\n|   |   disch_10_filtered.csv\n|   |   notes_labeled.csv\n|   |   *_hadm_ids.csv (already in repo)\n```\nThe MIMIC-IV files can be obtained from [this website](https://physionet.org/content/mimiciv/2.2/). You can download it to the directory `mimicdata/physionet.org` \nNow, make sure your python path includes the base directory of this repository. Then, in Jupyter Notebook, run all cells (in the menu, click Cell -> Run All) in `notebooks/dataproc_mimic_IV_exploration_icd9.ipynb` and `notebooks/dataproc_mimic_IV_exploration_icd10.ipynb`. These will take some time.\n \n",
                    "original_header": "Data processing"
                },
                "confidence": 0.9881618357112621,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/thomasnguyen92/MIMIC-IV-ICD-data-processing/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-04-10T06:13:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-13T15:58:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 145434
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 48170
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "239": {
        "filename": "aoluming_IDKG_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "please download the MM-IMDB 2.0 dataset in the following link:https://drive.google.com/file/d/1fmU3ZKM3ieTDeTAeyK1uT9sFVvaGplIp/view?usp=sharing\nand change the path in IDKG/processor/dataset.py \nWe have train the Open KG in advance and download it in :https://drive.google.com/file/d/1-yszovzxKTXi1284HUuJz-sNjs1dFfZQ/view?usp=sharing. Also you need to change the kgparam_path in the dataset.py. \nFor training the code:\nsh run_imdbclip.sh \n"
                },
                "confidence": 0.9444001681681705,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/aoluming/IDKG/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-07-27T08:19:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-17T01:59:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 112856
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 614
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "240": {
        "filename": "Derposoft_plot__2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "241": {
        "filename": "alviano_xasp_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "After cloning the repository, install dependencies:\n```bash\n$ poetry install\n$ poetry shell\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/alviano/xasp/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "OSes: \n- CentOS 7\n- Debian sid\n- MacOS Big Sur Version 11.6\n- Ubuntu 20.04.5 LTS \nBrowsers:\n- Chrome\n- Firefox   \n- Safari \n",
                    "original_header": "Tested Environments"
                },
                "confidence": 0.9674492684201175,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/alviano/xasp/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-11-29T07:36:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-19T07:33:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 87715
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "242": {
        "filename": "Trusted-AI_AIF360_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "``` r\ninstall.packages(\"aif360\")\n```\n\nFor more details regarding the R setup, please refer to instructions [here](aif360/aif360-r/README.md).\n",
                    "type": "Text_excerpt",
                    "original_header": "R",
                    "parent_header": [
                        "AI Fairness 360 (AIF360)",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Trusted-AI/AIF360/main/README.md"
            },
            {
                "result": {
                    "value": "Supported Python Configurations:\n\n| OS      | Python version |\n| ------- | -------------- |\n| macOS   | 3.8 \u2013 3.11     |\n| Ubuntu  | 3.8 \u2013 3.11     |\n| Windows | 3.8 \u2013 3.11     |\n",
                    "type": "Text_excerpt",
                    "original_header": "Python",
                    "parent_header": [
                        "AI Fairness 360 (AIF360)",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Trusted-AI/AIF360/main/README.md"
            },
            {
                "result": {
                    "value": "AIF360 requires specific versions of many Python packages which may conflict\nwith other projects on your system. A virtual environment manager is strongly\nrecommended to ensure dependencies may be installed safely. If you have trouble\ninstalling AIF360, try this first.\n",
                    "type": "Text_excerpt",
                    "original_header": "(Optional) Create a virtual environment",
                    "parent_header": [
                        "AI Fairness 360 (AIF360)",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Trusted-AI/AIF360/main/README.md"
            },
            {
                "result": {
                    "value": "Conda is recommended for all configurations though Virtualenv is generally\ninterchangeable for our purposes. [Miniconda](https://conda.io/miniconda.html)\nis sufficient (see [the difference between Anaconda and\nMiniconda](https://conda.io/docs/user-guide/install/download.html#anaconda-or-miniconda)\nif you are curious) if you do not already have conda installed.\n\nThen, to create a new Python 3.11 environment, run:\n\n```bash\nconda create --name aif360 python=3.11\nconda activate aif360\n```\n\nThe shell should now look like `(aif360) $`. To deactivate the environment, run:\n\n```bash\n(aif360)$ conda deactivate\n```\n\nThe prompt will return to `$ `.\n",
                    "type": "Text_excerpt",
                    "original_header": "Conda",
                    "parent_header": [
                        "AI Fairness 360 (AIF360)",
                        "Setup",
                        "(Optional) Create a virtual environment"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Trusted-AI/AIF360/main/README.md"
            },
            {
                "result": {
                    "value": "To install the latest stable version from PyPI, run:\n\n```bash\npip install aif360\n```\n\nNote: Some algorithms require additional dependencies (although the metrics will\nall work out-of-the-box). To install with certain algorithm dependencies\nincluded, run, e.g.:\n\n```bash\npip install 'aif360[LFR,OptimPreproc]'\n```\n\nor, for complete functionality, run:\n\n```bash\npip install 'aif360[all]'\n```\n\nThe options for available extras are: `OptimPreproc, LFR, AdversarialDebiasing,\nDisparateImpactRemover, LIME, ART, Reductions, FairAdapt, inFairness,\nLawSchoolGPA, notebooks, tests, docs, all`\n\nIf you encounter any errors, try the [Troubleshooting](#troubleshooting) steps.\n",
                    "type": "Text_excerpt",
                    "original_header": "Install with `pip`",
                    "parent_header": [
                        "AI Fairness 360 (AIF360)",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Trusted-AI/AIF360/main/README.md"
            },
            {
                "result": {
                    "value": "Clone the latest version of this repository:\n\n```bash\ngit clone https://github.com/Trusted-AI/AIF360\n```\n\nIf you'd like to run the examples, download the datasets now and place them in\ntheir respective folders as described in\n[aif360/data/README.md](aif360/data/README.md).\n\nThen, navigate to the root directory of the project and run:\n\n```bash\npip install --editable '.[all]'\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Manual installation",
                    "parent_header": [
                        "AI Fairness 360 (AIF360)",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Trusted-AI/AIF360/main/README.md"
            },
            {
                "result": {
                    "value": "If you encounter any errors during the installation process, look for your\nissue here and try the solutions.\n",
                    "type": "Text_excerpt",
                    "original_header": "Troubleshooting",
                    "parent_header": [
                        "AI Fairness 360 (AIF360)",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Trusted-AI/AIF360/main/README.md"
            },
            {
                "result": {
                    "value": "See the [Install TensorFlow with pip](https://www.tensorflow.org/install/pip)\npage for detailed instructions.\n\nNote: we require `'tensorflow >= 1.13.1'`.\n\nOnce tensorflow is installed, try re-running:\n\n```bash\npip install 'aif360[AdversarialDebiasing]'\n```\n\nTensorFlow is only required for use with the\n`aif360.algorithms.inprocessing.AdversarialDebiasing` class.\n",
                    "type": "Text_excerpt",
                    "original_header": "TensorFlow",
                    "parent_header": [
                        "AI Fairness 360 (AIF360)",
                        "Setup",
                        "Troubleshooting"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Trusted-AI/AIF360/main/README.md"
            },
            {
                "result": {
                    "value": "On MacOS, you may first have to install the Xcode Command Line Tools if you\nnever have previously:\n\n```sh\nxcode-select --install\n```\n\nOn Windows, you may need to download the [Microsoft C++ Build Tools for Visual\nStudio 2019](https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&rel=16).\nSee the [CVXPY Install](https://www.cvxpy.org/install/index.html#mac-os-x-windows-and-linux)\npage for up-to-date instructions.\n\nThen, try reinstalling via:\n\n```bash\npip install 'aif360[OptimPreproc]'\n```\n\nCVXPY is only required for use with the\n`aif360.algorithms.preprocessing.OptimPreproc` class.\n",
                    "type": "Text_excerpt",
                    "original_header": "CVXPY",
                    "parent_header": [
                        "AI Fairness 360 (AIF360)",
                        "Setup",
                        "Troubleshooting"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Trusted-AI/AIF360/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The `examples` directory contains a diverse collection of jupyter notebooks\nthat use AI Fairness 360 in various ways. Both tutorials and demos illustrate\nworking code using AIF360. Tutorials provide additional discussion that walks\nthe user through the various steps of the notebook. See the details about\n[tutorials and demos here](examples/README.md)\n \n",
                    "original_header": "Using AIF360"
                },
                "confidence": 0.9743039954477047,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Trusted-AI/AIF360/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-08-22T20:47:15Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T00:47:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1055074
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "R",
                    "name": "R",
                    "type": "Programming_language",
                    "size": 40282
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 11155
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 190
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "243": {
        "filename": "AlessandroGianola_SMT-based-Data-Aware-Processes-Verification_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-08-29T13:49:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-09-03T15:34:38Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "244": {
        "filename": "giacomo97cnr_Rule-based-ODD_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-02-15T08:54:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-02-15T09:58:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "MATLAB",
                    "name": "MATLAB",
                    "type": "Programming_language",
                    "size": 10303
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "245": {
        "filename": "khalil-research_ARGA-AAAI23_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-11-30T22:05:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-17T23:40:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 117974
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "246": {
        "filename": "Kayal-Sampath_detecting-signs-of-depression-from-social-media-postings_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-02-04T03:09:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T10:50:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "247": {
        "filename": "janikbenzin_ocpd_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "248": {
        "filename": "pellierd_HDDL2-1_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-05-17T08:40:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-13T11:24:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 128623
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "249": {
        "filename": "bowen-xu_SeL-NAL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To compile the C++ code, run the commands as the following\n```\ngit submodule update --init --recursive\nmkdir build\ncd build\ncmake ..\nmake\n```\nThere would be two target folders, `./narsese` and `./SequentialGroup`, which are also two python modules.\n \n",
                    "original_header": "Compilation"
                },
                "confidence": 0.9999999999771774,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/bowen-xu/SeL-NAL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-10-05T19:00:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-13T18:49:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 778357
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 68124
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 30402
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 3835
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "250": {
        "filename": "YODA-Lab_Simple-Incentives-For-Ridesharing_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-03-05T07:04:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-03T18:32:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 191691
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "251": {
        "filename": "anrep_HousE_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-01-20T07:52:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-17T08:16:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 44390
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 3017
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "252": {
        "filename": "jayetri_DrugEHRQA-A-Question-Answering-Dataset-on-Structured-and-Unstructured-Electronic-Health-Records_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "d.In order to generate the selected multimodal answer, run the script generate_multimodal_dataset.py using the following commands:  \nStep 1) Firstly, download the 'ADE and Medication EXtraction Challenge' dataset from the n2c2 repository. Also download the MIMIC-III database from https://physionet.org/. \nStep5)\nIn order to generate the selected multimodal answer, run the script generate_multimodal_dataset.py using the following commands:  \n",
                    "original_header": "DrugEHRQA-A-Question-Answering-Dataset-on-Structured-and-Unstructured-Electronic-Health-Records"
                },
                "confidence": 0.9579935207590577,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/jayetri/DrugEHRQA-A-Question-Answering-Dataset-on-Structured-and-Unstructured-Electronic-Health-Records/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-09-03T21:47:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-24T07:33:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 174788
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "253": {
        "filename": "yuanmu97_infi_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "InFi has been tested on Python 3.7, TensorFlow 2.4, and MindSpore 1.5.\n\nYou need to install at least one of TensorFlow or MindSpore.\n\nIf you'd like to play with jupyter notebook examples, you need to install Jupyter-Lab.\n\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/yuanmu97/infi/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-01-27T02:19:20Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T09:05:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 34167
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "254": {
        "filename": "Jfortin1_ComBatHarmonization_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "|                | R | Python | Matlab |\n|----------------|---|--------|--------|\n| Parametric adjustments     | x | x      | x      |\n| Non-parametric adjustments | x | x      | x      |\n| Empirical Bayes   | x |   x     | x      |\n| No empirical Bayes   | x |    x    |       |\n| Mean adjustment only | x |    x    |        |\n| Reference batch | x |    x    |        |\n| Can handle missing values | x |        |        | \n",
                    "original_header": "Current implemented features"
                },
                "confidence": 0.9205230527447097,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Jfortin1/ComBatHarmonization/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-03-23T14:15:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-15T09:18:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "R",
                    "name": "R",
                    "type": "Programming_language",
                    "size": 18487
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 11475
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "MATLAB",
                    "name": "MATLAB",
                    "type": "Programming_language",
                    "size": 6730
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "255": {
        "filename": "ZesenChen_multi-label-dataset_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2018-02-28T12:00:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-08T13:50:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "256": {
        "filename": "creapar_crowdscore_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-12-09T13:30:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-02-20T10:03:18Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 92121
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "257": {
        "filename": "sisl_CPOMDPExperiments_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Runtime warnings are expected. If installation errors occur from trying to install the frozen manifest, you can try direct package installation:\n\n1. Deleting the `Manifest.toml` file\n\n2. From the `Project.toml` file, remove the lines for the four packages under development\n\n3. Run `julia --project=. install.jl`\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation bugs",
                    "parent_header": [
                        "CPOMDPExperiments"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/sisl/CPOMDPExperiments/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Using Julia 1.6 \nTo install, in a Julia REPL: \n1. Activate the local environment with `] activate .`  \n2. Develop the constrained solver packages with `include(\"develop.jl\")` \n3. Install remaining dependencies from the Manifest using `] instantiate` \nTo run experiments in the installed environment, include an experiment file `julia --project=. [filepath]`. Experiment files are \n",
                    "original_header": "CPOMDPExperiments"
                },
                "confidence": 0.974656603622921,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/sisl/CPOMDPExperiments/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-10-20T02:58:26Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-10-25T13:04:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Julia",
                    "name": "Julia",
                    "type": "Programming_language",
                    "size": 215107
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "258": {
        "filename": "Arthur-Heng_Spoiler-Detection_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "`conda env create -f environment.yml` would generate a conda environment called `spoiler` that should be able to run the code.\n \n",
                    "original_header": "Environment"
                },
                "confidence": 0.9999677776389295,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Arthur-Heng/Spoiler-Detection/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-04-21T12:09:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-02-11T00:24:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 27530
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "259": {
        "filename": "sgzZ123_GRE_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-02-08T08:36:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-17T16:40:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "260": {
        "filename": "PneuC_OPARL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "### This is an archived version without doc and missing some features. The repository has been move to https://github.com/SUSTechGameAI/OPARL\n \n"
                },
                "confidence": 0.9941872305303452,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/PneuC/OPARL/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-05-31T08:29:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-07-25T14:57:52Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 131888
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 3614
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "261": {
        "filename": "that-recsys-lab_scruf_d_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Note: require Python 3.9 or earlier due to functions in the Whalrus package.\n \n",
                    "original_header": "SCRUF-D"
                },
                "confidence": 0.994789768874586,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/that-recsys-lab/scruf_d/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "A SCRUF experiment is configured using a TOML file with following section. See example below.\n \n",
                    "original_header": "Configuration"
                },
                "confidence": 0.9812448902298382,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/that-recsys-lab/scruf_d/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-01-14T19:01:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-07-09T04:25:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 304344
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 195958
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "262": {
        "filename": "facebookresearch_fbai-speech_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-04-05T23:08:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-02-13T16:00:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 10731
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "263": {
        "filename": "arama-Foundation_Gymnasium-Robotics_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "---\nfirstpage:\nlastpage:\n---\n\n## Installation\n\nTo install the Gymnasium-Robotics environments use `pip install gymnasium-robotics`\n\nThese environments also require the MuJoCo engine from Deepmind to be installed. Instructions to install the physics engine can be found at the [MuJoCo website](https://mujoco.org/) and the [MuJoCo Github repository](https://github.com/deepmind/mujoco).  \n\nNote that the latest environment versions use the latest mujoco python bindings maintained by the MuJoCo team. If you wish to use the old versions of the environments that depend on [mujoco-py](https://github.com/openai/mujoco-py), please install this library with `pip install gymnasium-robotics[mujoco-py]`\n\nWe support and test for Python 3.8, 3.9, 3.10 and 3.11 on Linux and macOS. We will accept PRs related to Windows, but do not officially support it.\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/Farama-Foundation/Gymnasium-Robotics/main/docs/content/installation.md"
            },
            {
                "result": {
                    "value": "To install the Gymnasium-Robotics environments use `pip install gymnasium-robotics`\n\nThese environments also require the MuJoCo engine from Deepmind to be installed. Instructions to install the physics engine can be found at the [MuJoCo website](https://mujoco.org/) and the [MuJoCo Github repository](https://github.com/deepmind/mujoco).  \n\nNote that the latest environment versions use the latest mujoco python bindings maintained by the MuJoCo team. If you wish to use the old versions of the environments that depend on [mujoco-py](https://github.com/openai/mujoco-py), please install this library with `pip install gymnasium-robotics[mujoco-py]`\n\nWe support and test for Python 3.8, 3.9, 3.10 and 3.11 on Linux and macOS. We will accept PRs related to Windows, but do not officially support it.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Farama-Foundation/Gymnasium-Robotics/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "`Gymnasium-Robotics` includes the following groups of environments: \n",
                    "original_header": "Environments"
                },
                "confidence": 0.9005627689593626,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Farama-Foundation/Gymnasium-Robotics/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The following example demonstrates how the exposed reward, terminated, and truncated functions\ncan be used to re-compute the values with substituted goals. The info dictionary can be used to store\nadditional information that may be necessary to re-compute the reward, but that is independent of the\ngoal, e.g. state derived from the simulation.\n```python\nimport gymnasium as gym\n\nenv = gym.make(\"FetchReach-v3\")\nenv.reset()\nobs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n\n# The following always has to hold:\nassert reward == env.compute_reward(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\nassert truncated == env.compute_truncated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\nassert terminated == env.compute_terminated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\n\n# However goals can also be substituted:\nsubstitute_goal = obs[\"achieved_goal\"].copy()\nsubstitute_reward = env.compute_reward(obs[\"achieved_goal\"], substitute_goal, info)\nsubstitute_terminated = env.compute_terminated(obs[\"achieved_goal\"], substitute_goal, info)\nsubstitute_truncated = env.compute_truncated(obs[\"achieved_goal\"], substitute_goal, info)\n```\n \n",
                    "original_header": "Multi-goal API"
                },
                "confidence": 0.999986429190583,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Farama-Foundation/Gymnasium-Robotics/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-10-25T18:10:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T00:04:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 733987
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1072
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 484
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "264": {
        "filename": "bytekid_cocomot_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Complete log files for the road fine, hospital billing, and sepsis data sets are\navailable:\n  * M. de Leoni, F. Mannhardt: Road traffic fine management process\n    https://doi.org/10.4121/uuid:270fd440-1057-4fb9-89a9-b699b47990f5\n  * F. Mannhardt: Hospital Billing - Event Log\n    https://doi.org/10.4121/uuid:76c46b83-c930-4798-a1c9-4be94dfeb741\n  * F. Mannhardt: Sepsis Cases - Event Log\n    https://doi.org/10.4121/uuid:915d2bfb-7e84-49ad-a286-dc35f063a460\n",
                    "type": "Text_excerpt",
                    "original_header": "Data sets",
                    "parent_header": [
                        "CoCoMoT",
                        "Data and Experiments"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/bytekid/cocomot/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-03-19T14:15:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-12T18:18:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 209338
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "265": {
        "filename": "logpai_deep-loglizer_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```bash\ngit clone https://github.com/logpai/deep-loglizer.git\ncd deep-loglizer\npip install -r requirements.txt\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Install",
                    "parent_header": [
                        "Deep-loglizer"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/logpai/deep-loglizer/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-07-23T23:05:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-13T20:52:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 59564
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2875
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "266": {
        "filename": "ckindermann_iswc-2022_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-07-26T20:47:38Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-07-28T15:17:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 227294
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "267": {
        "filename": "for-ai_goodtriever_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Run the following to create the environment. Packages will be installed as well.\n```bash\nconda env create -f environment.yml\nconda activate model_safety\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "Model Safety with Retrieval-Augmented Language Models"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/for-ai/goodtriever/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-11-10T15:05:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-30T19:31:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 56408439
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 192403
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 554
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "268": {
        "filename": "xufangzhi_TaCo_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-07-22T03:32:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-11T08:55:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 306374
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 900
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "269": {
        "filename": "Farama-Foundation_Minigrid_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "# Installation\n\nTo install `minigrid`, the easiest way is to use `pip`:\n\n```bash\npip install minigrid\n```\n\nHowever, if you would like to build on top of `minigrid`, you would need to install it from source. To do this, first clone the repository:\n\n```bash\ngit clone https://github.com/Farama-Foundation/Minigrid.git\n```\n\nThen, install the package:\n\n```bash\ncd Minigrid\npython3 -m pip install .\n```\n\nIf you want to install the package in [development mode](https://setuptools.pypa.io/en/latest/userguide/development_mode.html), use the following command instead:\n\n```bash\npython3 -m pip install -e .\n```\n\nAn installation in development mode (i.e., an editable install) is useful if you want to modify the source code of `minigrid` and have your changes take effect immediately.",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/Farama-Foundation/Minigrid/master/docs/content/installation.md"
            },
            {
                "result": {
                    "value": "To install the Minigrid library use `pip install minigrid`.\n\nWe support Python 3.7, 3.8, 3.9, 3.10 and 3.11 on Linux and macOS. We will accept PRs related to Windows, but do not officially support it.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Farama-Foundation/Minigrid/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-12-13T16:22:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T11:55:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 522278
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 484
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 470
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "270": {
        "filename": "mahdiabolghasemi_IEEE-predict_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "271": {
        "filename": "yunchengwang_GreenKGC_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**Requirements** \n     pip install -r requirements.txt \n     source best_config.sh \n",
                    "original_header": "GreenKGC: A Lightweight Knowledge Graph Completion Method"
                },
                "confidence": 0.9692478515787729,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/yunchengwang/GreenKGC/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-22T05:01:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-01T09:19:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 27765
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 838
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "272": {
        "filename": "ykazakov_ore-2015-competition-framework_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "In order to make a reasoner runnable for the framework, the following\nsteps are necessary:\n\n1.  Create a new folder in the \u2019data/reasoners/\u2019 directory, named by the\n    reasoner/the reasoner configuration (e.g., \u2019elk-linux\u2019).\n\n2.  Specify the settings for the new reasoner in the \u2019reasoner.dat\u2019 file\n    within the reasoner\u2019s directory (e.g.,\n    \u2019data/reasoners/elk-linux/reasoner.dat\u2019).\n\n    -   This can simply be archived by copying an existing reasoner\n        configuration file (e.g.,\n        \u2019data/reasoners/hermit-linux/reasoner.dat\u2019) and modify some of\n        the values (e.g., \u2019OutputPathName\u2019 to \u2019elk-linux\u2019,\n        \u2019ReasonerName\u2019 to \u2019ELK\u2019, \u2019ProfileSupport\u2019 to \u2019EL\u2019, and\n        \u2019DatatypeSupport\u2019 to \u2019FALSE\u2019). Also see comments in the existing\n        configuration files (e.g.,\n        \u2019data/reasoners/hermit-linux/reasoner.dat\u2019).\n\n3.  Create a starter/wrapper script (e.g., \u2019execReasoner.sh\u2019) in the\n    reasoner folder that triggers the reasoner (also see ORE 2014\n    Specification).\n\n    -   The wrapper script must be referenced in the reasoner\n        configuration file (\u2019reasoner.dat\u2019) by the \u2019StarterScript\u2019\n        setting, (e.g., \u2019./execReasoner.sh\u2019).\n\n    -   The wrapper script is executed by the evaluation framework,\n        i.e., it must be executable (e.g., apply \u2019chmod a+x\n        execReasoner.sh\u2019).\n\n    -   For OWL API-based reasoners, the wrapper script can directly\n        execute the OREv2ReasonerWrapper (\u2019OREv2ReasonerWrapper.jar\u2019),\n        which already implements the input and output specifications for\n        the ORE 2014 Competition. Note, the OREv2ReasonerWrapper\n        requires as first argument the corresponding OWLReasonerFactory\n        class (e.g., \u2019org.semanticweb.elk.owlapi.ElkReasonerFactory\u2019)\n        that has to be loaded with the Java Reflection API in order to\n        create the OWLReasoner from the factory. Also note that the\n        OREv2ReasonerWrapper may have to be recompiled such that all\n        libraries of the reasoner are in the Classpath of the\n        \u2019OREv2ReasonerWrapper.jar\u2019 file. The OREv2ReasonerWrapper can be\n        build by the Ant script \u2019build-wrapper-v2.xml\u2019 (the libs of the\n        reasoner must be copied into the \u2019lib\u2019 directory).\n\n4.  The execution of the reasoner can be tested by calling a\n    corresponding starter script for a reasoning task with the reasoner\n    folder as first argument (for example,\n    \u2019scripts/test-classification.sh elk-linux\u2019).\n\n    -   If the reasoner configuration file is not named \u2019reasoner.dat\u2019\n        within the reasoner folder, then the path to this file must be\n        used as first argument.\n\n    -   Optionally, the evaluation configuration file can be listed as\n        second argument.\n\n5.  The reasoner folder (or the path to the reasoner configuration file)\n    can then also be specified in the competition files.\n\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Reasoner Set-up Instructions"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ykazakov/ore-2015-competition-framework/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "-   The ORE 2014 Live Competition Queries package, available at\n    <https://zenodo.org/record/11133>, contains the queries and\n    configuration files for the ORE 2014 Live Competition. \n",
                    "original_header": "ORE Live Competition"
                },
                "confidence": 0.9716570385684251,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ykazakov/ore-2015-competition-framework/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "-   The competition server has to be started, e.g., by executing the\n    script \u2019scripts/competition-server-ore2014.sh\u2019. \n",
                    "original_header": "Parallel Execution"
                },
                "confidence": 0.9766790828021267,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ykazakov/ore-2015-competition-framework/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The \u2019FileOrderFile\u2019s used in \u2019scripts/create-ore2014-queries.sh\u2019 script\ncorrespond to the \u2019fileorder.txt\u2019 files from the ORE 2014 Dataset (e.g.,\nthe \u2019ore2014-classification-dl-fileorder.txt\u2019 corresponds to\n\u2019dataset/pure\\_dl/classification/fileorder.txt\u2019). \n",
                    "original_header": "Query Generation"
                },
                "confidence": 0.9995421690963953,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ykazakov/ore-2015-competition-framework/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2015-06-03T20:45:06Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2015-07-28T22:34:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Web Ontology Language",
                    "name": "Web Ontology Language",
                    "type": "Programming_language",
                    "size": 2747008
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 754436
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 57269
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 50067
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 33813
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 8069
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 1312
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "273": {
        "filename": "DanCunnington_NSIL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "This repository is associated with the [paper](https://arxiv.org/abs/2205.12735) \"Neuro-Symbolic Learning of Answer Set Programs from Raw Data\", published at IJCAI 2023. A recorded presentation is [available](https://www.youtube.com/watch?v=wUYoiH8Aie8). Please consider [citing](#citation) if it is useful in your work. The technical appendix forming our supplementary material is available [here](./TechnicalAppendix.pdf).\n",
                    "type": "Text_excerpt",
                    "original_header": "NSIL: Neuro-Symbolic Learning of Answer Set Programs from Raw Data"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/DanCunnington/NSIL/main/README.md"
            },
            {
                "result": {
                    "value": "If running on an intel machine, the recommended approach is using [Docker](#docker-installation). For Apple Silicon users, Docker can be used by adding the `--platform linux/amd64` flag to the build and run commands, however, the performance hit is significant. It is recommended to install [natively](#native-unix-installation).\n",
                    "type": "Text_excerpt",
                    "original_header": "Intel x86 vs. Apple Silicon (Mac M1/M2)",
                    "parent_header": [
                        "NSIL: Neuro-Symbolic Learning of Answer Set Programs from Raw Data"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/DanCunnington/NSIL/main/README.md"
            },
            {
                "result": {
                    "value": "A docker container is provided for easy setup and installation so the only additional software required is a container runtime such as [Docker Desktop](https://www.docker.com/products/docker-desktop/), [Podman](https://podman.io/), or [minikube](https://minikube.sigs.k8s.io/docs/tutorials/docker_desktop_replacement/).\n",
                    "type": "Text_excerpt",
                    "original_header": "Docker installation",
                    "parent_header": [
                        "NSIL: Neuro-Symbolic Learning of Answer Set Programs from Raw Data"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/DanCunnington/NSIL/main/README.md"
            },
            {
                "result": {
                    "value": "The following commands assume the `docker` command is available on your system. If using a different container run-time, please replace accordingly. From the root directory:\n\n1. `docker build -t nsil:ijcai_2023 .`\n2. `docker run -d -p 8000:8000 -p 9990:9990 --name nsil_ijcai_2023 nsil:ijcai_2023`\n3. Open [http://localhost:8000](http://localhost:8000) in your web browser to launch a markdown viewer containing detailed documentation that explains how to reproduce the experiment results.\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "NSIL: Neuro-Symbolic Learning of Answer Set Programs from Raw Data",
                        "Docker installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/DanCunnington/NSIL/main/README.md"
            },
            {
                "result": {
                    "value": "```\nexit\ndocker stop nsil_ijcai_2023\ndocker rm nsil_ijcai_2023\ndocker rmi nsil:ijcai_2023\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Stopping the container and removing files",
                    "parent_header": [
                        "NSIL: Neuro-Symbolic Learning of Answer Set Programs from Raw Data",
                        "Docker installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/DanCunnington/NSIL/main/README.md"
            },
            {
                "result": {
                    "value": "1. Create python environment and install dependencies\n```bash\nvirtualenv nsil_p3\nsource nsil_p3/bin/activate\npip install -r requirements.txt\n```\n\n2. Download image data\n```bash\nchmod +x ./download_data.sh\n./download_data.sh\n```\n\n3. Create a setup script with the following contents:\n```bash\nBASE_PATH=/path/to/NSIL\nexport PYTHONPATH=$BASE_PATH\ncd $BASE_PATH/examples/$1\n```\nand replace the value of `BASE_PATH` accordingly. Save this file to `paper_experiments/ijcai_2023/scripts/setup.sh` and ensure it has execute permissions. If you also want to run the NeurASP and FF-NSL baseline experiments, save a copy to `paper_experiments/ijcai_2023/scripts/naive_baselines/setup.sh`, again ensuring executable permissions.\n\n4. Move ILASP and FastLAS binaries to the root directory. We provide apple silicon and intel ubuntu linux binaries, copy accordingly.\n```bash\nmv LAS_binaries/ILASP_apple_silicon ILASP\nmv LAS_binaries/FastLAS_apple_silicon FastLAS\n```\n\n5. Set the python path to the root directory\n```bash\nexport PYTHONPATH=/path/to/NSIL\n```\n\n6. To view documentation:\n```bash\ncd paper_experiments/ijcai_2023/\nchmod +x ./start_web_servers.sh\n./start_web_servers.sh\n```\n\n7. To run experiments:\n```bash\ncd paper_experiments/ijcai_2023/scripts\nfind . -type f -exec chmod +x {} \\;\n./run_arithmetic_repeats.sh -p 100 -s 0 -m 5 # For example - see documentation for more commands.\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "NSIL: Neuro-Symbolic Learning of Answer Set Programs from Raw Data",
                        "Native Unix Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/DanCunnington/NSIL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-06T09:39:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-06T11:24:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 1800475
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 61697
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 15849
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1518
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "274": {
        "filename": "Yubin-Liu_Hybrid-Q-Learning-Network-Approach-for-MPLP_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-10-30T13:35:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-21T01:36:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 47200
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "275": {
        "filename": "Pointerformer_Pointerformer_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "`python eval.py val_data_path=./data/tsp100_test_concorde.txt load_checkpoint_path=./result_ckpt/model100.ckpt` \n`python eval.py val_data_path=./data/partner_100.txt load_checkpoint_path=./result_ckpt/model100.ckpt real_data=true` \n",
                    "original_header": "Evaluate"
                },
                "confidence": 0.9764586410426341,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Pointerformer/Pointerformer/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-02-11T09:57:15Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-11T15:06:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 63428
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "276": {
        "filename": "joonleesky_train-procgen-pytorch_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Use `train.py` to train the agent in procgen environment. It has the following arguments:\n- `--exp_name`: ID to designate your expriment.s\n- `--env_name`: Name of the Procgen environment.\n- `--start_level`: Start level for for environment.\n- `--num_levels`: Number of training levels for environment.\n- `--distribution_mode`: Mode of your environ\n- `--param_name`: Configurations name for your training. By default, the training loads hyperparameters from `config.yml/procgen/param_name`.\n- `--num_timesteps`: Number of total timesteps to train your agent. \n",
                    "original_header": "Train"
                },
                "confidence": 0.9683696233434457,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/joonleesky/train-procgen-pytorch/master/Readme.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-08-14T08:21:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-09T12:53:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 32473
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "277": {
        "filename": "tinkoff-ai_CORL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "| **Task-Name**      |BC|10% BC|TD3+BC|AWAC|CQL|IQL|ReBRAC|SAC-N|EDAC|DT|\n|--------------------|------------|--------|--------|--------|-----|-----|------|-------|------|----|\n|pen-human-v1|71.03 \u00b1 6.26|26.99 \u00b1 9.60|-3.88 \u00b1 0.21|81.12 \u00b1 13.47|13.71 \u00b1 16.98|78.49 \u00b1 8.21|103.16 \u00b1 8.49|6.86 \u00b1 5.93|5.07 \u00b1 6.16|67.68 \u00b1 5.48|\n|pen-cloned-v1|51.92 \u00b1 15.15|46.67 \u00b1 14.25|5.13 \u00b1 5.28|89.56 \u00b1 15.57|1.04 \u00b1 6.62|83.42 \u00b1 8.19|102.79 \u00b1 7.84|31.35 \u00b1 2.14|12.02 \u00b1 1.75|64.43 \u00b1 1.43|\n|pen-expert-v1|109.65 \u00b1 7.28|114.96 \u00b1 2.96|122.53 \u00b1 21.27|160.37 \u00b1 1.21|-1.41 \u00b1 2.34|128.05 \u00b1 9.21|152.16 \u00b1 6.33|87.11 \u00b1 48.95|-1.55 \u00b1 0.81|116.38 \u00b1 1.27|\n|door-human-v1|2.34 \u00b1 4.00|-0.13 \u00b1 0.07|-0.33 \u00b1 0.01|4.60 \u00b1 1.90|5.53 \u00b1 1.31|3.26 \u00b1 1.83|-0.10 \u00b1 0.01|-0.38 \u00b1 0.00|-0.12 \u00b1 0.13|4.44 \u00b1 0.87|\n|door-cloned-v1|-0.09 \u00b1 0.03|0.29 \u00b1 0.59|-0.34 \u00b1 0.01|0.93 \u00b1 1.66|-0.33 \u00b1 0.01|3.07 \u00b1 1.75|0.06 \u00b1 0.05|-0.33 \u00b1 0.00|2.66 \u00b1 2.31|7.64 \u00b1 3.26|\n|door-expert-v1|105.35 \u00b1 0.09|104.04 \u00b1 1.46|-0.33 \u00b1 0.01|104.85 \u00b1 0.24|-0.32 \u00b1 0.02|106.65 \u00b1 0.25|106.37 \u00b1 0.29|-0.33 \u00b1 0.00|106.29 \u00b1 1.73|104.87 \u00b1 0.39|\n|hammer-human-v1|3.03 \u00b1 3.39|-0.19 \u00b1 0.02|1.02 \u00b1 0.24|3.37 \u00b1 1.93|0.14 \u00b1 0.11|1.79 \u00b1 0.80|0.24 \u00b1 0.24|0.24 \u00b1 0.00|0.28 \u00b1 0.18|1.28 \u00b1 0.15|\n|hammer-cloned-v1|0.55 \u00b1 0.16|0.12 \u00b1 0.08|0.25 \u00b1 0.01|0.21 \u00b1 0.24|0.30 \u00b1 0.01|1.50 \u00b1 0.69|5.00 \u00b1 3.75|0.14 \u00b1 0.09|0.19 \u00b1 0.07|1.82 \u00b1 0.55|\n|hammer-expert-v1|126.78 \u00b1 0.64|121.75 \u00b1 7.67|3.11 \u00b1 0.03|127.06 \u00b1 0.29|0.26 \u00b1 0.01|128.68 \u00b1 0.33|133.62 \u00b1 0.27|25.13 \u00b1 43.25|28.52 \u00b1 49.00|117.45 \u00b1 6.65|\n|relocate-human-v1|0.04 \u00b1 0.03|-0.14 \u00b1 0.08|-0.29 \u00b1 0.01|0.05 \u00b1 0.03|0.06 \u00b1 0.03|0.12 \u00b1 0.04|0.16 \u00b1 0.30|-0.31 \u00b1 0.01|-0.17 \u00b1 0.17|0.05 \u00b1 0.01|\n|relocate-cloned-v1|-0.06 \u00b1 0.01|-0.00 \u00b1 0.02|-0.30 \u00b1 0.01|-0.04 \u00b1 0.04|-0.29 \u00b1 0.01|0.04 \u00b1 0.01|1.66 \u00b1 2.59|-0.01 \u00b1 0.10|0.17 \u00b1 0.35|0.16 \u00b1 0.09|\n|relocate-expert-v1|107.58 \u00b1 1.20|97.90 \u00b1 5.21|-1.73 \u00b1 0.96|108.87 \u00b1 0.85|-0.30 \u00b1 0.02|106.11 \u00b1 4.02|107.52 \u00b1 2.28|-0.36 \u00b1 0.00|71.94 \u00b1 18.37|104.28 \u00b1 0.42|\n|                    |            |        |        |     |     |      |       |      |    |  |\n| **adroit average**        | 48.18|42.69|10.40|56.75|1.53|53.43|59.39|12.43|18.78|49.21|\n \n",
                    "original_header": "Adroit"
                },
                "confidence": 0.9224797817599657,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/tinkoff-ai/CORL/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "| **Task-Name**             |AWAC|CQL|IQL|SPOT|Cal-QL|\n|---------------------------|------------|--------|--------|-----|-----|\n|antmaze-umaze-v2|0.04 \u00b1 0.01|0.02 \u00b1 0.00|0.07 \u00b1 0.00|0.02 \u00b1 0.00|0.01 \u00b1 0.00|\n|antmaze-umaze-diverse-v2|0.88 \u00b1 0.01|0.09 \u00b1 0.01|0.43 \u00b1 0.11|0.22 \u00b1 0.07|0.05 \u00b1 0.01|\n|antmaze-medium-play-v2|1.00 \u00b1 0.00|0.08 \u00b1 0.01|0.09 \u00b1 0.01|0.06 \u00b1 0.00|0.04 \u00b1 0.01|\n|antmaze-medium-diverse-v2|1.00 \u00b1 0.00|0.08 \u00b1 0.00|0.10 \u00b1 0.01|0.05 \u00b1 0.01|0.04 \u00b1 0.01|\n|antmaze-large-play-v2|1.00 \u00b1 0.00|0.21 \u00b1 0.02|0.34 \u00b1 0.05|0.29 \u00b1 0.07|0.13 \u00b1 0.02|\n|antmaze-large-diverse-v2|1.00 \u00b1 0.00|0.21 \u00b1 0.03|0.41 \u00b1 0.03|0.23 \u00b1 0.08|0.13 \u00b1 0.02|\n|                           |            |        |        |     |     |      |       |      |    |\n| **antmaze average**       |0.82|0.11|0.24|0.15|0.07|\n|                           |            |        |        |     |     |      |       |      |    |\n|pen-cloned-v1|0.46 \u00b1 0.02|0.97 \u00b1 0.00|0.37 \u00b1 0.01|0.58 \u00b1 0.02|0.98 \u00b1 0.01|\n|door-cloned-v1|1.00 \u00b1 0.00|1.00 \u00b1 0.00|0.83 \u00b1 0.03|0.99 \u00b1 0.01|1.00 \u00b1 0.00|\n|hammer-cloned-v1|1.00 \u00b1 0.00|1.00 \u00b1 0.00|0.65 \u00b1 0.10|0.98 \u00b1 0.01|1.00 \u00b1 0.00|\n|relocate-cloned-v1|1.00 \u00b1 0.00|1.00 \u00b1 0.00|1.00 \u00b1 0.00|1.00 \u00b1 0.00|1.00 \u00b1 0.00|\n|                           |            |        |        |     |     |      |       |      |    |\n| **adroit average**        |0.86|0.99|0.71|0.89|0.99|\n \n",
                    "original_header": "Regrets"
                },
                "confidence": 0.9985268464852538,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/tinkoff-ai/CORL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-09-23T08:43:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T08:12:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 474166
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1093
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "278": {
        "filename": "itsaugat_sf_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "279": {
        "filename": "itayhubara_BinaryNet-pytorch_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The code is based on https://github.com/eladhoffer/convNet.pytorch\nPlease install torch and torchvision by following the instructions at: http://pytorch.org/\nTo run resnet18 for cifar10 dataset use: python main_binary.py --model resnet_binary --save resnet18_binary --dataset cifar10\n \n",
                    "original_header": "BNN.pytorch"
                },
                "confidence": 0.9999999996575752,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/itayhubara/BinaryNet.pytorch/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-12-20T02:11:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-12T02:41:11Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 75133
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "280": {
        "filename": "deepmind_pushworld_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-01-24T16:36:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-13T10:04:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 153286
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 139212
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 23461
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 8158
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 7095
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 3003
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 229
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "281": {
        "filename": "ndangtt_portfolio-based-analysis_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-05-14T07:29:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-06-25T12:56:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 35175
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 1518
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1119
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "282": {
        "filename": "GuanSuns_ASGRL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**Note**: The code has been refactored for better readability. If you encounter any problem, feel free to email lguan9@asu.edu or submit an issue on Github.  \n",
                    "original_header": "Official python implementation of the ASGRL in the ICML 2022 paper: <a href=\"https://arxiv.org/abs/2202.02886\">Leveraging Approximate Symbolic Models for Reinforcement Learning via Skill Diversity</a>"
                },
                "confidence": 0.9782553383825965,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/GuanSuns/ASGRL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-06-13T00:41:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T00:57:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 164140
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "283": {
        "filename": "Michael-Beukman_PCGNN_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The main structure of the code is (hopefully) somewhat understandable.\nFirst of all, to run any python file in here, use `./run.sh path/to/python/file` instead of using `python` directly, because otherwise modules are not recognised.  \nFinally, the following commands should work on [wsl](https://docs.microsoft.com/en-us/windows/wsl/install) or Linux, but probably not on Windows (without some tweaking). \n",
                    "original_header": "General structure"
                },
                "confidence": 0.9957652818933049,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Michael-Beukman/PCGNN/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To have a go at generating levels, then you can use the functions provided in `src/main/main.py`. Specifically you can call this (remember to be in the `src` directory before running these commands):\n```\n./run.sh main/main.py --method noveltyneat --game mario --command generate --width 114 --height 14\n``` \n",
                    "original_header": "Generate Levels."
                },
                "confidence": 0.9975195510726433,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Michael-Beukman/PCGNN/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can also play the (Mario) levels, or let an agent play them. After generating a level using the above, you can play it by using:\n```\n./run.sh main/main.py --game mario --command play-human --filename test_level.txt\n```\nOr you can let an A* agent play it using\n```\n./run.sh main/main.py --game mario --command play-agent --filename test_level.txt\n```\n \n",
                    "original_header": "Playing Levels"
                },
                "confidence": 0.9999757118833946,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Michael-Beukman/PCGNN/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You need to run the following three scripts, in order, and before you start the next one, all the jobs from the previous one must have finished. \nNote, timing results probably will differ, and for fairness, we recommend using a machine with at least 8 cores, as we do usually run multiple seeds in parallel. Do not continue on to the next step before all runs in the current one have finished.\nFirst of all, `cd src/pipelines`\n1. `./reproduce_full.sh`    -> Runs the DirectGA & NoveltyNEAT experiments.\n2. `./analyse_all.sh`       -> Reruns the metric calculations on the above, and saves it to a easy to work with format\n3. `./finalise_analysis.sh` -> Uses the above results to create figures and tables. \nThe analysis runs (steps 2 and 3.) should automatically use the latest results.\nIf you want to change this, then before going from one step to the next, you will need to manually update the location of the `.p` files, e.g. between step 1. and 2., you need to update \n- `src/analysis/proper_experiments/v200/for_mario_generation_1.py`, \n- `src/analysis/proper_experiments/v100/for_maze_1.py`, \n- `src/analysis/proper_experiments/v100/analyse_104.py`\n- `src/analysis/proper_experiments/v200/analyse_206.py`.  \nLikewise, between step 2. and 3., you need to update (only if you don't want to analyse the latest runs.)\n- `src/analysis/proper_experiments/v400/analyse_all_statistical_tests.py` and \n- `src/analysis/proper_experiments/v400/analyse_all_metrics_properly.py`. \nFor the PCGRL inference, there are two steps to do, specifically:\n1. Run `infer_pcgrl.py`\n2. Then run the analysis scripts again, specifically `analyse_all.sh` and `finalise_analysis.sh` (noting to change the PCGRL filepaths in `for_mario_generation_1.py` and `for_maze_1.py`) \n",
                    "original_header": "Reproducing"
                },
                "confidence": 0.9964938507922627,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Michael-Beukman/PCGNN/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- https://github.com/MattChanTK/gym-maze\n- https://www.samyzaf.com/ML/rl/qmaze.html \n",
                    "original_header": "Some ideas from here"
                },
                "confidence": 0.999998508478161,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Michael-Beukman/PCGNN/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-10-17T06:44:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-24T10:11:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 576553
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 34208
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 24921
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "284": {
        "filename": "anonymous902109_iters_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "\r\n```shell\r\nconda create -n irs python=3.7  \r\nconda activate irs  \r\npip install -r requirements.txt  \r\n```\r\n\r",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Interactive Reward Shaping"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/anonymous902109/iters/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-12-28T11:53:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-10-29T18:08:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 75500
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "285": {
        "filename": "fivosts_BenchPress_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "# Installation\n\n## TLDR\n\n`git clone` and `cd` into the repository and run:\n\n```\n$: mkdir build; cd build\n$: cmake ..\n$: make -j\n$: cd ..\n$: ./benchpress --help\n```\n\n## More info\n\n### Prerequisites [Optional]\n\nTo install __BenchPress__ you need to have `cmake>=3.14` installed, and a few other standard apt packages. Inspect `requirements.apt` file to see what is required. Either `apt install` the listed packages or execute the script with sudo rights to install them. This step is optional.\n\n### Python\n\n__BenchPress__ uses `3.6<=python.version<=3.8`. `python3.8` is recommended. You may also use `python3.9` but pip will struggle to find older package versions. You will have to manually bump package versions in `requirements.pip`.\n\n### Building BenchPress\n\nBuild makefiles:\n\n```\n$: cmake -S <path_to_src_root> -B <path_to_build_root> <-Dcmake_flag1, -Dcmake_flag2, ...>\n```\nFor most of __BenchPress's__ functionalities (e.g. training and sampling the model), no cmake flags are required. The following build flags are supported:\n\n- `-DLOCAL=<path>[Default: \"\"]`: All output binaries and libraries will be compiled under `<build_root>/local/`. Override this flag if you want to specify a custom output path (e.g. in the case of high-bandwidth partitions of clusters).\n- `-DBOOST_FROM_SOURCE=ON/OF[Default: OFF]`: Set `ON` if you with boost library to be compiled from source into the build directory. __BenchPress__ does not use boost, however if you want to extend it to C++ synthesis and want boost header files to be visible by the language model, you can use this flag.\n- `-DPROTOC_FROM_SOURCE=ON/OFF[Default: OFF]`: __BenchPress__ uses protobuf messages to read/write specifications about the model, corpuses, sampler and other things. To compiler protobufs `protoc` is needed. If you cannot install it globally, this flag will install it from source within the build directory.\n- `-DBUILD_CLDRIVE=ON/OFF[Default: OFF]`: Set `ON` to build `cldrive`, a driver for OpenCL kernels. `cldrive` is required if one desires to execute kernels using __BenchPress's__ cli. Details: https://github.com/ChrisCummins/cldrive\n- `-DBUILD_CSMITH=ON/OFF[Default: OFF]`: Builds `csmith` fuzzer and adds it to environment.\n- `-DBUILD_CLSMITH=ON/OFF[Default: OFF]`: Builds `clsmith` fuzzer (`csmith` variation for OpenCL) and adds it to environment.\n- `-DBUILD_MUTEC=ON/OFF[Default: OFF]`: Builds `mutec` source code mutator and adds it to __BenchPress's__ environment. Details: https://github.com/chao-peng/mutec\n- `-DBUILD_SRCIROR=ON/OFF[Default: OFF]`: Builds `srciror` text-level and IR mutator and adds it to the environment. Details: https://github.com/TestingResearchIllinois/srciror\n\nAfter you specify the build environment, `cd` into your build directory and:\n```\n$: make -j\n```\nThis will produce all libraries and binaries sandboxed in the build directory. At the root of the source directory an executable script `benchpress` will be built:\n```\n$: ./benchpress --help\n```\nwill list all available execution flags for the application.\n\n### Platforms\n\n\u26a0\ufe0f __BenchPress__ only supports Linux-based systems. While it can be installed on Windows or MacOS, it has not been attempted and tested, therefore not guaranteed to work.\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/fivosts/BenchPress/master/INSTALL.md"
            },
            {
                "result": {
                    "value": "See `INSTALL.md` for instructions.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/fivosts/BenchPress/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "If you have trained __BenchPress__ and ran a sampler to any downstream task you want to evaluate, you can use the codebase's evaluators. The evaluators usually take a list of database groups and perform operations/analysis/plotting on them. Evaluators are described in protobuf files (see examples in `model_zoo/evaluation/`). To run an evaluator run\n```\n$: export BENCHPRESS_BINARY=deeplearning/benchpress/experiments/evaluators.py\n$: ./benchpress --evaluator_config <path/to/your/evaluator.pbxt>\n```\n \n",
                    "original_header": "Evaluate the code"
                },
                "confidence": 0.9877906792312424,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/fivosts/BenchPress/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "__BenchPress__ provides modules to scrape source code from Github and store it into databases. Language specifications are set through protobuf files. See `model_zoo/github` for examples. For example\n```\n./benchpress --config model_zoo/github/bq_C_db.pbtxt\n```\nto scrape C repositories from BigQuery.\n \n",
                    "original_header": "Github and BigQuery mining"
                },
                "confidence": 0.999204141005247,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/fivosts/BenchPress/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-04-11T19:01:11Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-04T01:59:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 2004391
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 1880609
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 117557
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 51102
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 26930
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 23251
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Pawn",
                    "name": "Pawn",
                    "type": "Programming_language",
                    "size": 20085
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 14611
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 8622
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Pascal",
                    "name": "Pascal",
                    "type": "Programming_language",
                    "size": 976
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 448
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "NASL",
                    "name": "NASL",
                    "type": "Programming_language",
                    "size": 390
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "POV-Ray SDL",
                    "name": "POV-Ray SDL",
                    "type": "Programming_language",
                    "size": 80
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "286": {
        "filename": "alibaba_AliceMind_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-05-21T13:04:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-18T12:49:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 9282417
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 107828
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cuda",
                    "name": "Cuda",
                    "type": "Programming_language",
                    "size": 36414
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 20507
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 20142
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cython",
                    "name": "Cython",
                    "type": "Programming_language",
                    "size": 8858
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Lua",
                    "name": "Lua",
                    "type": "Programming_language",
                    "size": 4210
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 769
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 607
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "287": {
        "filename": "aseembits93_attainable-utility-preservation_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "1. Using Python 2.7 as the interpreter, acquire the libraries in `requirements.txt`.\n2. Clone using `--recursive` to snag the `pycolab` submodule:\n`git clone --recursive https://github.com/alexander-turner/attainable-utility-preservation.git`.\n3. Run `python -m experiments.charts` or `python -m experiments.ablation`, tweaking the code to include the desired environments. \n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Attainable Utility Preservation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/aseembits93/attainable-utility-preservation/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-08-03T23:14:06Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-01-11T03:08:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 224420
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "288": {
        "filename": "facebookresearch_esm_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Bulk download instructions available at a seperate README [here](scripts/atlas/README.md). \n",
                    "original_header": "ESM Metagenomic Atlas <a name=\"atlas\"></a>"
                },
                "confidence": 0.9959407974802024,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/facebookresearch/esm/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Then, follow the remaining instructions in the tutorial. You can also run the tutorial in a [colab notebook](https://colab.research.google.com/github/facebookresearch/esm/blob/main/examples/sup_variant_prediction.ipynb). \n",
                    "original_header": "Supervised variant prediction - training a classifier on the embeddings"
                },
                "confidence": 0.996687159166806,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/facebookresearch/esm/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "| Shorthand | `esm.pretrained.`           | #layers | #params | Dataset | Embedding Dim |  Model URL (automatically downloaded to `~/.cache/torch/hub/checkpoints`) |\n|-----------|---------------------|---------|-------------|---------|---------------|-----------------------------------------------------------------------|\n| ESM-2     | `esm2_t48_15B_UR50D`         | 48           | 15B         | UR50/D 2021_04                           | 5120 |  https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t48_15B_UR50D.pt          |\n|           | `esm2_t36_3B_UR50D`          | 36           | 3B          | UR50/D 2021_04                           | 2560 |  https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t36_3B_UR50D.pt           |\n|           | `esm2_t33_650M_UR50D`        | 33           | 650M        | UR50/D 2021_04                           | 1280 |  https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt         |\n|           | `esm2_t30_150M_UR50D`        | 30           | 150M        | UR50/D 2021_04                           | 640  |  https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t30_150M_UR50D.pt         |\n|           | `esm2_t12_35M_UR50D`         | 12           | 35M         | UR50/D 2021_04                           | 480  |  https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t12_35M_UR50D.pt          |\n|           | `esm2_t6_8M_UR50D`           | 6            | 8M          | UR50/D 2021_04                           | 320  |  https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt            |\n| ESMFold   | `esmfold_v1`                 | 48 (+36)     | 690M (+3B)  | UR50/D 2021_04                           | -    |  https://dl.fbaipublicfiles.com/fair-esm/models/esmfold_3B_v1.pt               |\n|           | `esmfold_v0`                 | 48 (+36)     | 690M (+3B)  | UR50/D 2021_04                           | -    |  https://dl.fbaipublicfiles.com/fair-esm/models/esmfold_3B_v0.pt               |\n|           | `esmfold_structure_module_only_*`              | 0 (+various) | various     | UR50/D 2021_04                           | -    |  https://dl.fbaipublicfiles.com/fair-esm/models/esmfold_structure_module_only_*                  |\n| ESM-IF1   | `esm_if1_gvp4_t16_142M_UR50` | 20           | 124M        | CATH 4.3 + predicted structures for UR50 | 512  | https://dl.fbaipublicfiles.com/fair-esm/models/esm_if1_gvp4_t16_142M_UR50.pt   |\n| ESM-1v    | `esm1v_t33_650M_UR90S_[1-5]` | 33           | 650M        | UR90/S 2020_03                           | 1280 | https://dl.fbaipublicfiles.com/fair-esm/models/esm1v_t33_650M_UR90S_1.pt       |\n| ESM-MSA-1b| `esm_msa1b_t12_100M_UR50S`   | 12           | 100M        | UR50/S + MSA 2018_03                     | 768  | https://dl.fbaipublicfiles.com/fair-esm/models/esm_msa1b_t12_100M_UR50S.pt     |\n| ESM-MSA-1 | `esm_msa1_t12_100M_UR50S`    | 12           | 100M        | UR50/S + MSA 2018_03                     | 768  | https://dl.fbaipublicfiles.com/fair-esm/models/esm_msa1_t12_100M_UR50S.pt      |\n| ESM-1b    | `esm1b_t33_650M_UR50S`       | 33           | 650M        | UR50/S 2018_03                           | 1280 | https://dl.fbaipublicfiles.com/fair-esm/models/esm1b_t33_650M_UR50S.pt         |\n| ESM-1     | `esm1_t34_670M_UR50S`        | 34           | 670M        | UR50/S 2018_03                           | 1280 |  https://dl.fbaipublicfiles.com/fair-esm/models/esm1_t34_670M_UR50S.pt         |\n|           | `esm1_t34_670M_UR50D`        | 34           | 670M        | UR50/D 2018_03                           | 1280 |  https://dl.fbaipublicfiles.com/fair-esm/models/esm1_t34_670M_UR50D.pt         |\n|           | `esm1_t34_670M_UR100`        | 34           | 670M        | UR100 2018_03                            | 1280 |  https://dl.fbaipublicfiles.com/fair-esm/models/esm1_t34_670M_UR100.pt         |\n|           | `esm1_t12_85M_UR50S`         | 12           | 85M         | UR50/S 2018_03                           | 768  |  https://dl.fbaipublicfiles.com/fair-esm/models/esm1_t12_85M_UR50S.pt          |\n|           | `esm1_t6_43M_UR50S`          | 6            | 43M         | UR50/S 2018_03                           | 768  |  https://dl.fbaipublicfiles.com/fair-esm/models/esm1_t6_43M_UR50S.pt           | \n",
                    "original_header": "Pre-trained Models <a name=\"available-models\"></a>"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/facebookresearch/esm/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "| Name   | Description                                                                   | URL                                                                   |\n|--------|-------------------------------------------------------------------------------|-----------------------------------------------------------------------|\n| splits | train/valid splits                                                            | https://dl.fbaipublicfiles.com/fair-esm/structural-data/splits.tar.gz |\n| pkl    | pkl objects containing sequence, SSP labels, distance map, and 3d coordinates | https://dl.fbaipublicfiles.com/fair-esm/structural-data/pkl.tar.gz    |\n| msas   | a3m files containing MSA for each domain                                      | https://dl.fbaipublicfiles.com/fair-esm/structural-data/msas.tar.gz   |\n \n",
                    "original_header": "ESM Structural Split Dataset <a name=\"available-esmssd\"></a>"
                },
                "confidence": 0.9764201692891541,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/facebookresearch/esm/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-08-31T17:41:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T06:23:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 268893
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2256
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "289": {
        "filename": "wonderren_public_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "290": {
        "filename": "edgeslab_sRCD_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "  ```conda env create -f conda_venv_rcd.yml```\n\t\t\n  It will create a conda venv named \"rcd\" which will contain all the required packages. You need to activate the venv before using it:\n  \n  ```source activate rcd```\n  \n  ",
                    "type": "Text_excerpt",
                    "original_header": "Installations",
                    "parent_header": [
                        "Relational Causal Discovery with $\\sigma$-separation (sRCD)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/edgeslab/sRCD/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-08-22T22:11:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-19T17:00:20Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 669149
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 179309
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "PLpgSQL",
                    "name": "PLpgSQL",
                    "type": "Programming_language",
                    "size": 100155
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "291": {
        "filename": "QueensGambit_CrazyAra_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Binaries and models are available for the following chess variants:\n*   [Crazyhouse](https://lichess.org/variant/crazyhouse)\n*   [Chess](https://en.wikipedia.org/wiki/Chess)\n \n",
                    "original_header": "Variants"
                },
                "confidence": 0.9820631533236492,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/QueensGambit/CrazyAra/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Instructions can be found in the [wiki](https://github.com/QueensGambit/CrazyAra/wiki/Build-instructions).\n \n",
                    "original_header": "Compilation"
                },
                "confidence": 0.9104837983885322,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/QueensGambit/CrazyAra/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-09-09T16:07:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T16:35:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 1099450
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1031363
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 753
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "292": {
        "filename": "DiseaseOntology_-HumanDiseaseOntology_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "293": {
        "filename": "khalil-research_leo_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The `code/cpp` folder contains the code for BDD Manager, which is based on the implementation of [1] available at https://www.andrew.cmu.edu/user/vanhoeve/mdd/. Once the binary is successfully built, run the code in `code/python/leo` package for executing different phases of LEO. \n \n",
                    "original_header": "Repository structure"
                },
                "confidence": 0.9210451291986269,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/khalil-research/leo/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Once everything is set execute `make`. If it ran correctly then there should be a binary named `multiobj` created in this folder. Copy this binary to `resources/bin`.\n \n",
                    "original_header": "Building the C++ code"
                },
                "confidence": 0.9993586615316822,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/khalil-research/leo/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-11-10T17:43:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-19T20:52:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 168257
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 160496
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 1744
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "294": {
        "filename": "DuarteMRAlves_yolov5-grpc_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-03-09T15:32:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-11-11T05:30:21Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 16829
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 4640
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 720
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 180
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "295": {
        "filename": "RingBDStack_SR-MARL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Build the Dockerfile using<br>\n```python\ncd docker\nbash build.sh\n```\nSet up StarCraft II and SMAC:<br>\n```python\nbash install_sc2.sh\n```\nThis will download SC2 into the 3rdparty folder and copy the maps necessary to run over.<br>",
                    "type": "Text_excerpt",
                    "original_header": "Installation instructions",
                    "parent_header": [
                        "Effective and Stable Role-based Multi-Agent Collaboration by Structural Information Principles.<br>"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/RingBDStack/SR-MARL/main/readme.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-11-22T08:47:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-28T08:35:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 356302
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1796
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 958
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "296": {
        "filename": "melanibe_failure_detection_benchmark_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Just replace the config name by one of the above config names and follow the steps from the above section (note that config name argument is expected to be the relative path to the configs folder). \n \n",
                    "original_header": "Configurations to reproduce all plots in the paper"
                },
                "confidence": 0.9999924507497612,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/melanibe/failure_detection_benchmark/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-05-26T17:35:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-04T17:08:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 933665
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 148314
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "297": {
        "filename": "jzf2101_alphatology_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```bash\n# generates jobs in jobs/[job-name].sh\nmkdir times\n./pipelines/icml2020.sh\n\n# download results (I moved this into a bashscript for myself)\n# $1 == jobname.\nrsync --progress [USER]@[REMOTE]:[PATH_TO_PROJECT]/results/$1/\\* results/$1\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "setup jobs (assumes slurm)",
                    "parent_header": [
                        "alphatology"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/jzf2101/alphatology/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-10-16T06:09:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-05T21:30:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 199510
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 647
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "298": {
        "filename": "tae898_room-env_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-04-04T16:21:38Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-23T15:26:14Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "299": {
        "filename": "opendilab_DI-engine_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "You can simply install DI-engine from PyPI with the following command:\n\n```bash\npip install DI-engine\n```\n\nIf you use Anaconda or Miniconda, you can install DI-engine from conda-forge through the following command:\n\n```bash\nconda install -c opendilab di-engine\n```\n\nFor more information about installation, you can refer to [installation](https://di-engine-docs.readthedocs.io/en/latest/01_quickstart/installation.html).\n\nAnd our dockerhub repo can be found [here](https://hub.docker.com/repository/docker/opendilab/ding)\uff0cwe prepare `base image` and `env image` with common RL environments.\n\n<details close>\n<summary>(Click for Details)</summary>\n\n- base: opendilab/ding:nightly\n- rpc: opendilab/ding:nightly-rpc\n- atari: opendilab/ding:nightly-atari\n- mujoco: opendilab/ding:nightly-mujoco\n- dmc: opendilab/ding:nightly-dmc2gym\n- metaworld: opendilab/ding:nightly-metaworld\n- smac: opendilab/ding:nightly-smac\n- grf: opendilab/ding:nightly-grf\n- cityflow: opendilab/ding:nightly-cityflow\n- evogym: opendilab/ding:nightly-evogym\n- d4rl: opendilab/ding:nightly-d4rl\n\n</details>\n\nThe detailed documentation are hosted on [doc](https://di-engine-docs.readthedocs.io/en/latest/) | [\u4e2d\u6587\u6587\u6863](https://di-engine-docs.readthedocs.io/zh_CN/latest/).\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/opendilab/DI-engine/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n| No. |                                                              Algorithm                                                              |                                                                                     Label                                                                                     |                                                                                                                                   Doc and Implementation                                                                                                                                   |                                      Runnable Demo                                      |\n| :-: | :---------------------------------------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------: |\n|  1  |                             [DQN](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)                             |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |             [DQN doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/dqn.html)<br>[DQN\u4e2d\u6587\u6587\u6863](https://di-engine-docs.readthedocs.io/zh_CN/latest/12_policies/dqn_zh.html)<br>[policy/dqn](https://github.com/opendilab/DI-engine/blob/main/ding/policy/dqn.py)             |     python3 -u cartpole_dqn_main.py / ding -m serial -c cartpole_dqn_config.py -s 0     |\n|  2  |                                             [C51](https://arxiv.org/pdf/1707.06887.pdf)                                             |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |                                                            [C51 doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/c51.html)<br>[policy/c51](https://github.com/opendilab/DI-engine/blob/main/ding/policy/c51.py)                                                            |                      ding -m serial -c cartpole_c51_config.py -s 0                      |\n|  3  |                                            [QRDQN](https://arxiv.org/pdf/1710.10044.pdf)                                            |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |                                                        [QRDQN doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/qrdqn.html)<br>[policy/qrdqn](https://github.com/opendilab/DI-engine/blob/main/ding/policy/qrdqn.py)                                                        |                     ding -m serial -c cartpole_qrdqn_config.py -s 0                     |\n|  4  |                                             [IQN](https://arxiv.org/pdf/1806.06923.pdf)                                             |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |                                                            [IQN doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/iqn.html)<br>[policy/iqn](https://github.com/opendilab/DI-engine/blob/main/ding/policy/iqn.py)                                                            |                      ding -m serial -c cartpole_iqn_config.py -s 0                      |\n|  5  |                                             [FQF](https://arxiv.org/pdf/1911.02140.pdf)                                             |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |                                                            [FQF doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/fqf.html)<br>[policy/fqf](https://github.com/opendilab/DI-engine/blob/main/ding/policy/fqf.py)                                                            |                      ding -m serial -c cartpole_fqf_config.py -s 0                      |\n|  6  |                                           [Rainbow](https://arxiv.org/pdf/1710.02298.pdf)                                           |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |                                                    [Rainbow doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/rainbow.html)<br>[policy/rainbow](https://github.com/opendilab/DI-engine/blob/main/ding/policy/rainbow.py)                                                    |                    ding -m serial -c cartpole_rainbow_config.py -s 0                    |\n|  7  |                                             [SQL](https://arxiv.org/pdf/1702.08165.pdf)                                             |                          ![discrete](https://img.shields.io/badge/-discrete-brightgreen)![continuous](https://img.shields.io/badge/-continous-green)                          |                                                            [SQL doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/sql.html)<br>[policy/sql](https://github.com/opendilab/DI-engine/blob/main/ding/policy/sql.py)                                                            |                      ding -m serial -c cartpole_sql_config.py -s 0                      |\n|  8  |                                         [R2D2](https://openreview.net/forum?id=r1lyTjAqYX)                                         |                            ![dist](https://img.shields.io/badge/-distributed-blue)![discrete](https://img.shields.io/badge/-discrete-brightgreen)                            |                                                          [R2D2 doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/r2d2.html)<br>[policy/r2d2](https://github.com/opendilab/DI-engine/blob/main/ding/policy/r2d2.py)                                                          |                      ding -m serial -c cartpole_r2d2_config.py -s 0                      |\n|  9  |                   [PG](https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf)                   |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |                                                             [PG doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/a2c.html)<br>[policy/pg](https://github.com/opendilab/DI-engine/blob/main/ding/policy/pg.py)                                                             |                       ding -m serial -c cartpole_pg_config.py -s 0                       |\n| 10 |                                            [PromptPG](https://arxiv.org/abs/2209.14610)                                            |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |                                                                                               [policy/prompt_pg](https://github.com/opendilab/DI-engine/blob/main/ding/policy/prompt_pg.py)                                                                                               |                   ding -m serial_onpolicy -c tabmwp_pg_config.py -s 0                   |\n| 11 |                                             [A2C](https://arxiv.org/pdf/1602.01783.pdf)                                             |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |                                                            [A2C doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/a2c.html)<br>[policy/a2c](https://github.com/opendilab/DI-engine/blob/main/ding/policy/a2c.py)                                                            |                      ding -m serial -c cartpole_a2c_config.py -s 0                      |\n| 12 |                        [PPO](https://arxiv.org/abs/1707.06347)/[MAPPO](https://arxiv.org/pdf/2103.01955.pdf)                        | ![discrete](https://img.shields.io/badge/-discrete-brightgreen)![continuous](https://img.shields.io/badge/-continous-green)![MARL](https://img.shields.io/badge/-MARL-yellow) |                                                            [PPO doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/ppo.html)<br>[policy/ppo](https://github.com/opendilab/DI-engine/blob/main/ding/policy/ppo.py)                                                            | python3 -u cartpole_ppo_main.py / ding -m serial_onpolicy -c cartpole_ppo_config.py -s 0 |\n| 13 |                                             [PPG](https://arxiv.org/pdf/2009.04416.pdf)                                             |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |                                                            [PPG doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/ppg.html)<br>[policy/ppg](https://github.com/opendilab/DI-engine/blob/main/ding/policy/ppg.py)                                                            |                             python3 -u cartpole_ppg_main.py                             |\n| 14 |                                            [ACER](https://arxiv.org/pdf/1611.01224.pdf)                                            |                          ![discrete](https://img.shields.io/badge/-discrete-brightgreen)![continuous](https://img.shields.io/badge/-continous-green)                          |                                                          [ACER doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/acer.html)<br>[policy/acer](https://github.com/opendilab/DI-engine/blob/main/ding/policy/acer.py)                                                          |                      ding -m serial -c cartpole_acer_config.py -s 0                      |\n| 15 |                                             [IMPALA](https://arxiv.org/abs/1802.01561)                                             |                            ![dist](https://img.shields.io/badge/-distributed-blue)![discrete](https://img.shields.io/badge/-discrete-brightgreen)                            |                                                      [IMPALA doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/impala.html)<br>[policy/impala](https://github.com/opendilab/DI-engine/blob/main/ding/policy/impala.py)                                                      |                     ding -m serial -c cartpole_impala_config.py -s 0                     |\n| 16 |                     [DDPG](https://arxiv.org/pdf/1509.02971.pdf)/[PADDPG](https://arxiv.org/pdf/1511.04143.pdf)                     |                             ![continuous](https://img.shields.io/badge/-continous-green)![hybrid](https://img.shields.io/badge/-hybrid-darkgreen)                             |                                                          [DDPG doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/ddpg.html)<br>[policy/ddpg](https://github.com/opendilab/DI-engine/blob/main/ding/policy/ddpg.py)                                                          |                      ding -m serial -c pendulum_ddpg_config.py -s 0                      |\n| 17 |                                             [TD3](https://arxiv.org/pdf/1802.09477.pdf)                                             |                             ![continuous](https://img.shields.io/badge/-continous-green)![hybrid](https://img.shields.io/badge/-hybrid-darkgreen)                             |                                                            [TD3 doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/td3.html)<br>[policy/td3](https://github.com/opendilab/DI-engine/blob/main/ding/policy/td3.py)                                                            |     python3 -u pendulum_td3_main.py / ding -m serial -c pendulum_td3_config.py -s 0     |\n| 18 |                                            [D4PG](https://arxiv.org/pdf/1804.08617.pdf)                                            |                                                         ![continuous](https://img.shields.io/badge/-continous-green)                                                         |                                                          [D4PG doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/d4pg.html)<br>[policy/d4pg](https://github.com/opendilab/DI-engine/blob/main/ding/policy/d4pg.py)                                                          |                            python3 -u pendulum_d4pg_config.py                            |\n| 19 |                                           [SAC](https://arxiv.org/abs/1801.01290)/[MASAC]                                           | ![discrete](https://img.shields.io/badge/-discrete-brightgreen)![continuous](https://img.shields.io/badge/-continous-green)![MARL](https://img.shields.io/badge/-MARL-yellow) |                                                            [SAC doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/sac.html)<br>[policy/sac](https://github.com/opendilab/DI-engine/blob/main/ding/policy/sac.py)                                                            |                      ding -m serial -c pendulum_sac_config.py -s 0                      |\n| 20 |                                            [PDQN](https://arxiv.org/pdf/1810.06394.pdf)                                            |                                                           ![hybrid](https://img.shields.io/badge/-hybrid-darkgreen)                                                           |                                                                                                    [policy/pdqn](https://github.com/opendilab/DI-engine/blob/main/ding/policy/pdqn.py)                                                                                                    |                     ding -m serial -c gym_hybrid_pdqn_config.py -s 0                     |\n| 21 |                                            [MPDQN](https://arxiv.org/pdf/1905.04388.pdf)                                            |                                                           ![hybrid](https://img.shields.io/badge/-hybrid-darkgreen)                                                           |                                                                                                    [policy/pdqn](https://github.com/opendilab/DI-engine/blob/main/ding/policy/pdqn.py)                                                                                                    |                    ding -m serial -c gym_hybrid_mpdqn_config.py -s 0                    |\n| 22 |                                            [HPPO](https://arxiv.org/pdf/1903.01344.pdf)                                            |                                                           ![hybrid](https://img.shields.io/badge/-hybrid-darkgreen)                                                           |                                                                                                     [policy/ppo](https://github.com/opendilab/DI-engine/blob/main/ding/policy/ppo.py)                                                                                                     |                ding -m serial_onpolicy -c gym_hybrid_hppo_config.py -s 0                |\n| 23 |                                             [BDQ](https://arxiv.org/pdf/1711.08946.pdf)                                             |                                                           ![hybrid](https://img.shields.io/badge/-hybrid-darkgreen)                                                           |                                                                                                     [policy/bdq](https://github.com/opendilab/DI-engine/blob/main/ding/policy/dqn.py)                                                                                                     |                             python3 -u hopper_bdq_config.py                             |\n| 24 |                                              [MDQN](https://arxiv.org/abs/2007.14430)                                              |                                                        ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                        |                                                                                                    [policy/mdqn](https://github.com/opendilab/DI-engine/blob/main/ding/policy/mdqn.py)                                                                                                    |                            python3 -u asterix_mdqn_config.py                            |\n| 25 |                                            [QMIX](https://arxiv.org/pdf/1803.11485.pdf)                                            |                                                              ![MARL](https://img.shields.io/badge/-MARL-yellow)                                                              |                                                          [QMIX doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/qmix.html)<br>[policy/qmix](https://github.com/opendilab/DI-engine/blob/main/ding/policy/qmix.py)                                                          |                     ding -m serial -c smac_3s5z_qmix_config.py -s 0                     |\n| 26 |                                            [COMA](https://arxiv.org/pdf/1705.08926.pdf)                                            |                                                              ![MARL](https://img.shields.io/badge/-MARL-yellow)                                                              |                                                          [COMA doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/coma.html)<br>[policy/coma](https://github.com/opendilab/DI-engine/blob/main/ding/policy/coma.py)                                                          |                     ding -m serial -c smac_3s5z_coma_config.py -s 0                     |\n| 27 |                                              [QTran](https://arxiv.org/abs/1905.05408)                                              |                                                              ![MARL](https://img.shields.io/badge/-MARL-yellow)                                                              |                                                                                                   [policy/qtran](https://github.com/opendilab/DI-engine/blob/main/ding/policy/qtran.py)                                                                                                   |                     ding -m serial -c smac_3s5z_qtran_config.py -s 0                     |\n| 28 |                                              [WQMIX](https://arxiv.org/abs/2006.10800)                                              |                                                              ![MARL](https://img.shields.io/badge/-MARL-yellow)                                                              |                                                        [WQMIX doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/wqmix.html)<br>[policy/wqmix](https://github.com/opendilab/DI-engine/blob/main/ding/policy/wqmix.py)                                                        |                     ding -m serial -c smac_3s5z_wqmix_config.py -s 0                     |\n| 29 |                                           [CollaQ](https://arxiv.org/pdf/2010.08531.pdf)                                           |                                                              ![MARL](https://img.shields.io/badge/-MARL-yellow)                                                              |                                                      [CollaQ doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/collaq.html)<br>[policy/collaq](https://github.com/opendilab/DI-engine/blob/main/ding/policy/collaq.py)                                                      |                    ding -m serial -c smac_3s5z_collaq_config.py -s 0                    |\n| 30 |                                           [MADDPG](https://arxiv.org/pdf/1706.02275.pdf)                                           |                                                              ![MARL](https://img.shields.io/badge/-MARL-yellow)                                                              |                                                         [MADDPG doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/ddpg.html)<br>[policy/ddpg](https://github.com/opendilab/DI-engine/blob/main/ding/policy/ddpg.py)                                                         |                ding -m serial -c ptz_simple_spread_maddpg_config.py -s 0                |\n| 31 |                                            [GAIL](https://arxiv.org/pdf/1606.03476.pdf)                                            |                                                                ![IL](https://img.shields.io/badge/-IL-purple)                                                                |                                               [GAIL doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/gail.html)<br>[reward_model/gail](https://github.com/opendilab/DI-engine/blob/main/ding/reward_model/gail_irl_model.py)                                               |                 ding -m serial_gail -c cartpole_dqn_gail_config.py -s 0                 |\n| 32 |                                            [SQIL](https://arxiv.org/pdf/1905.11108.pdf)                                            |                                                                ![IL](https://img.shields.io/badge/-IL-purple)                                                                |                                                    [SQIL doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/sqil.html)<br>[entry/sqil](https://github.com/opendilab/DI-engine/blob/main/ding/entry/serial_entry_sqil.py)                                                    |                   ding -m serial_sqil -c cartpole_sqil_config.py -s 0                   |\n| 33 |                                            [DQFD](https://arxiv.org/pdf/1704.03732.pdf)                                            |                                                                ![IL](https://img.shields.io/badge/-IL-purple)                                                                |                                                          [DQFD doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/dqfd.html)<br>[policy/dqfd](https://github.com/opendilab/DI-engine/blob/main/ding/policy/dqfd.py)                                                          |                   ding -m serial_dqfd -c cartpole_dqfd_config.py -s 0                   |\n| 34 |                                            [R2D3](https://arxiv.org/pdf/1909.01387.pdf)                                            |                                                                ![IL](https://img.shields.io/badge/-IL-purple)                                                                |       [R2D3 doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/r2d3.html)<br>[R2D3\u4e2d\u6587\u6587\u6863](https://di-engine-docs.readthedocs.io/zh_CN/latest/12_policies/r2d3_zh.html)<br>[policy/r2d3](https://di-engine-docs.readthedocs.io/zh_CN/latest/12_policies/r2d3_zh.html)       |                        python3 -u pong_r2d3_r2d2expert_config.py                        |\n| 35 |                                    [Guided Cost Learning](https://arxiv.org/pdf/1603.00448.pdf)                                    |                                                                ![IL](https://img.shields.io/badge/-IL-purple)                                                                |                      [Guided Cost Learning\u4e2d\u6587\u6587\u6863](https://di-engine-docs.readthedocs.io/zh_CN/latest/12_policies/guided_cost_zh.html)<br>[reward_model/guided_cost](https://github.com/opendilab/DI-engine/blob/main/ding/reward_model/guided_cost_reward_model.py)                      |                            python3 lunarlander_gcl_config.py                            |\n| 36 |                                              [TREX](https://arxiv.org/abs/1904.06387)                                              |                                                                ![IL](https://img.shields.io/badge/-IL-purple)                                                                |                                             [TREX doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/trex.html)<br>[reward_model/trex](https://github.com/opendilab/DI-engine/blob/main/ding/reward_model/trex_reward_model.py)                                             |                               python3 mujoco_trex_main.py                               |\n| 37 |                               [Implicit Behavorial Cloning](https://implicitbc.github.io/) (DFO+MCMC)                               |                                                                ![IL](https://img.shields.io/badge/-IL-purple)                                                                |                                                  [policy/ibc](https://github.com/opendilab/DI-engine/blob/main/ding/policy/ibc.py) <br> [model/template/ebm](https://github.com/opendilab/DI-engine/blob/main/ding/model/template/ebm.py)                                                  |              python3 d4rl_ibc_main.py -s 0 -c pen_human_ibc_mcmc_config.py              |\n| 38 |                                             [BCO](https://arxiv.org/pdf/1805.01954.pdf)                                             |                                                                ![IL](https://img.shields.io/badge/-IL-purple)                                                                |                                                                                                [entry/bco](https://github.com/opendilab/DI-engine/blob/main/ding/entry/serial_entry_bco.py)                                                                                                |                            python3 -u cartpole_bco_config.py                            |\n| 39 |                                             [HER](https://arxiv.org/pdf/1707.01495.pdf)                                             |                                                           ![exp](https://img.shields.io/badge/-exploration-orange)                                                           |                                               [HER doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/her.html)<br>[reward_model/her](https://github.com/opendilab/DI-engine/blob/main/ding/reward_model/her_reward_model.py)                                               |                              python3 -u bitflip_her_dqn.py                              |\n| 40 |                                               [RND](https://arxiv.org/abs/1810.12894)                                               |                                                           ![exp](https://img.shields.io/badge/-exploration-orange)                                                           |                                               [RND doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/rnd.html)<br>[reward_model/rnd](https://github.com/opendilab/DI-engine/blob/main/ding/reward_model/rnd_reward_model.py)                                               |                         python3 -u cartpole_rnd_onppo_config.py                         |\n| 41 |                                             [ICM](https://arxiv.org/pdf/1705.05363.pdf)                                             |                                                           ![exp](https://img.shields.io/badge/-exploration-orange)                                                           | [ICM doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/icm.html)<br>[ICM\u4e2d\u6587\u6587\u6863](https://di-engine-docs.readthedocs.io/zh_CN/latest/12_policies/icm_zh.html)<br>[reward_model/icm](https://github.com/opendilab/DI-engine/blob/main/ding/reward_model/icm_reward_model.py) |                          python3 -u cartpole_ppo_icm_config.py                          |\n| 42 |                                             [CQL](https://arxiv.org/pdf/2006.04779.pdf)                                             |                                                         ![offline](https://img.shields.io/badge/-offlineRL-darkblue)                                                         |                                                            [CQL doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/cql.html)<br>[policy/cql](https://github.com/opendilab/DI-engine/blob/main/ding/policy/cql.py)                                                            |                               python3 -u d4rl_cql_main.py                               |\n| 43 |                                            [TD3BC](https://arxiv.org/pdf/2106.06860.pdf)                                            |                                                         ![offline](https://img.shields.io/badge/-offlineRL-darkblue)                                                         |                                                      [TD3BC doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/td3_bc.html)<br>[policy/td3_bc](https://github.com/opendilab/DI-engine/blob/main/ding/policy/td3_bc.py)                                                      |                              python3 -u d4rl_td3_bc_main.py                              |\n| 44 |                                    [Decision Transformer](https://arxiv.org/pdf/2106.01345.pdf)                                    |                                                         ![offline](https://img.shields.io/badge/-offlineRL-darkblue)                                                         |                                                                                                      [policy/dt](https://github.com/opendilab/DI-engine/blob/main/ding/policy/dt.py)                                                                                                      |                               python3 -u d4rl_dt_mujoco.py                               |\n| 45 |                                            [EDAC](https://arxiv.org/pdf/2110.01548.pdf)                                            |                                                         ![offline](https://img.shields.io/badge/-offlineRL-darkblue)                                                         |                                                          [EDAC doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/edac.html)<br>[policy/edac](https://github.com/opendilab/DI-engine/blob/main/ding/policy/edac.py)                                                          |                               python3 -u d4rl_edac_main.py                               |\n| 46 |                                            [QGPO](https://arxiv.org/pdf/2304.12824.pdf)                                            |                                                         ![offline](https://img.shields.io/badge/-offlineRL-darkblue)                                                         |                                                          [QGPO doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/qgpo.html)<br>[policy/qgpo](https://github.com/opendilab/DI-engine/blob/main/ding/policy/qgpo.py)                                                          |                             python3 -u ding/example/qgpo.py                             |\n| 47 |   MBSAC([SAC](https://arxiv.org/abs/1801.01290)+[MVE](https://arxiv.org/abs/1803.00101)+[SVG](https://arxiv.org/abs/1510.09142))   |                           ![continuous](https://img.shields.io/badge/-continous-green)![mbrl](https://img.shields.io/badge/-ModelBasedRL-lightblue)                           |                                                                                          [policy/mbpolicy/mbsac](https://github.com/opendilab/DI-engine/blob/main/ding/policy/mbpolicy/mbsac.py)                                                                                          |   python3 -u pendulum_mbsac_mbpo_config.py \\ python3 -u pendulum_mbsac_ddppo_config.py   |\n| 48 | STEVESAC([SAC](https://arxiv.org/abs/1801.01290)+[STEVE](https://arxiv.org/abs/1807.01675)+[SVG](https://arxiv.org/abs/1510.09142)) |                           ![continuous](https://img.shields.io/badge/-continous-green)![mbrl](https://img.shields.io/badge/-ModelBasedRL-lightblue)                           |                                                                                          [policy/mbpolicy/mbsac](https://github.com/opendilab/DI-engine/blob/main/ding/policy/mbpolicy/mbsac.py)                                                                                          |                       python3 -u pendulum_stevesac_mbpo_config.py                       |\n| 49 |                                            [MBPO](https://arxiv.org/pdf/1906.08253.pdf)                                            |                                                         ![mbrl](https://img.shields.io/badge/-ModelBasedRL-lightblue)                                                         |                                                     [MBPO doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/mbpo.html)<br>[world_model/mbpo](https://github.com/opendilab/DI-engine/blob/main/ding/world_model/mbpo.py)                                                     |                          python3 -u pendulum_sac_mbpo_config.py                          |\n| 50 |                                        [DDPPO](https://openreview.net/forum?id=rzvOQrnclO0)                                        |                                                         ![mbrl](https://img.shields.io/badge/-ModelBasedRL-lightblue)                                                         |                                                                                              [world_model/ddppo](https://github.com/opendilab/DI-engine/blob/main/ding/world_model/ddppo.py)                                                                                              |                        python3 -u pendulum_mbsac_ddppo_config.py                        |\n| 51 |                                          [DreamerV3](https://arxiv.org/pdf/2301.04104.pdf)                                          |                                                         ![mbrl](https://img.shields.io/badge/-ModelBasedRL-lightblue)                                                         |                                                                                          [world_model/dreamerv3](https://github.com/opendilab/DI-engine/blob/main/ding/world_model/dreamerv3.py)                                                                                          |                      python3 -u cartpole_balance_dreamer_config.py                      |\n| 52 |                                             [PER](https://arxiv.org/pdf/1511.05952.pdf)                                             |                                                            ![other](https://img.shields.io/badge/-other-lightgrey)                                                            |                                                                                   [worker/replay_buffer](https://github.com/opendilab/DI-engine/blob/main/ding/worker/replay_buffer/advanced_buffer.py)                                                                                   |                                      `rainbow demo`                                      |\n| 53 |                                             [GAE](https://arxiv.org/pdf/1506.02438.pdf)                                             |                                                            ![other](https://img.shields.io/badge/-other-lightgrey)                                                            |                                                                                                   [rl_utils/gae](https://github.com/opendilab/DI-engine/blob/main/ding/rl_utils/gae.py)                                                                                                   |                                        `ppo demo`                                        |\n| 54 |                                           [ST-DIM](https://arxiv.org/pdf/1906.08226.pdf)                                           |                                                            ![other](https://img.shields.io/badge/-other-lightgrey)                                                            |                                                                              [torch_utils/loss/contrastive_loss](https://github.com/opendilab/DI-engine/blob/main/ding/torch_utils/loss/contrastive_loss.py)                                                                              |                   ding -m serial -c cartpole_dqn_stdim_config.py -s 0                   |\n| 55 |                                             [PLR](https://arxiv.org/pdf/2010.03934.pdf)                                             |                                                            ![other](https://img.shields.io/badge/-other-lightgrey)                                                            |                                       [PLR doc](https://di-engine-docs.readthedocs.io/en/latest/12_policies/plr.html)<br>[data/level_replay/level_sampler](https://github.com/opendilab/DI-engine/blob/main/ding/data/level_replay/level_sampler.py)                                       |                          python3 -u bigfish_plr_config.py -s 0                          |\n| 56 |                                           [PCGrad](https://arxiv.org/pdf/2001.06782.pdf)                                           |                                                            ![other](https://img.shields.io/badge/-other-lightgrey)                                                            |                                                                             [torch_utils/optimizer_helper/PCGrad](https://github.com/opendilab/DI-engine/blob/main/ding/data/torch_utils/optimizer_helper.py)                                                                             |                        python3 -u multi_mnist_pcgrad_main.py -s 0                        | \n",
                    "original_header": "Algorithm Versatility"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/opendilab/DI-engine/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "| No |                                          Environment                                          |                                                                                                                   Label                                                                                                                   |                                             Visualization                                             |                                                                                                                                     Code and Doc Links                                                                                                                                     |\n| :-: | :--------------------------------------------------------------------------------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\n| 1 |               [Atari](https://github.com/openai/gym/tree/master/gym/envs/atari)               |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                                  ![original](./dizoo/atari/atari.gif)                                  |               [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/atari/envs) <br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/atari.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/atari_zh.html)               |\n| 2 |        [box2d/bipedalwalker](https://github.com/openai/gym/tree/master/gym/envs/box2d)        |                                                                                       ![continuous](https://img.shields.io/badge/-continous-green)                                                                                       |                         ![original](./dizoo/box2d/bipedalwalker/original.gif)                         | [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/box2d/bipedalwalker/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/bipedalwalker.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/bipedalwalker_zh.html) |\n| 3 |         [box2d/lunarlander](https://github.com/openai/gym/tree/master/gym/envs/box2d)         |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                         ![original](./dizoo/box2d/lunarlander/lunarlander.gif)                         |    [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/box2d/lunarlander/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/lunarlander.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/lunarlander_zh.html)    |\n| 4 | [classic_control/cartpole](https://github.com/openai/gym/tree/master/gym/envs/classic_control) |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                       ![original](./dizoo/classic_control/cartpole/cartpole.gif)                       |   [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/classic_control/cartpole/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/cartpole.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/cartpole_zh.html)   |\n| 5 | [classic_control/pendulum](https://github.com/openai/gym/tree/master/gym/envs/classic_control) |                                                                                       ![continuous](https://img.shields.io/badge/-continous-green)                                                                                       |                       ![original](./dizoo/classic_control/pendulum/pendulum.gif)                       |   [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/classic_control/pendulum/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/pendulum.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/pendulum_zh.html)   |\n| 6 |                [competitive_rl](https://github.com/cuhkrlcourse/competitive-rl)                |                                                         ![discrete](https://img.shields.io/badge/-discrete-brightgreen) ![selfplay](https://img.shields.io/badge/-selfplay-blue)                                                         |                         ![original](./dizoo/competitive_rl/competitive_rl.gif)                         |                                                     [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo.classic_control)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/en/latest/13_envs/competitive_rl_zh.html)                                                     |\n| 7 |                    [gfootball](https://github.com/google-research/football)                    |                          ![discrete](https://img.shields.io/badge/-discrete-brightgreen)![sparse](https://img.shields.io/badge/-sparse%20reward-orange)![selfplay](https://img.shields.io/badge/-selfplay-blue)                          |                              ![original](./dizoo/gfootball/gfootball.gif)                              |           [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo.gfootball/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/gfootball.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/en/latest/13_envs/gfootball_zh.html)           |\n| 8 |                      [minigrid](https://github.com/maximecb/gym-minigrid)                      |                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)![sparse](https://img.shields.io/badge/-sparse%20reward-orange)                                                      |                               ![original](./dizoo/minigrid/minigrid.gif)                               |             [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/minigrid/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/minigrid.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/en/latest/13_envs/minigrid_zh.html)             |\n| 9 |              [MuJoCo](https://github.com/openai/gym/tree/master/gym/envs/mujoco)              |                                                                                       ![continuous](https://img.shields.io/badge/-continous-green)                                                                                       |                                 ![original](./dizoo/mujoco/mujoco.gif)                                 |                [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/majoco/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/mujoco.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/en/latest/13_envs/mujoco_zh.html)                |\n| 10 |                 [PettingZoo](https://github.com/Farama-Foundation/PettingZoo)                 |                              ![discrete](https://img.shields.io/badge/-discrete-brightgreen) ![continuous](https://img.shields.io/badge/-continous-green) ![marl](https://img.shields.io/badge/-MARL-yellow)                              |                   ![original](./dizoo/petting_zoo/petting_zoo_mpe_simple_spread.gif)                   |        [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/petting_zoo/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/pettingzoo.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/pettingzoo_zh.html)        |\n| 11 |               [overcooked](https://github.com/HumanCompatibleAI/overcooked-demo)               |                                                            ![discrete](https://img.shields.io/badge/-discrete-brightgreen) ![marl](https://img.shields.io/badge/-MARL-yellow)                                                            |                             ![original](./dizoo/overcooked/overcooked.gif)                             |                                                       [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/overcooded/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/overcooked.html)                                                       |\n| 12 |                          [procgen](https://github.com/openai/procgen)                          |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                                ![original](./dizoo/procgen/coinrun.gif)                                |               [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/procgen)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/procgen.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/procgen_zh.html)               |\n| 13 |                      [pybullet](https://github.com/benelot/pybullet-gym)                      |                                                                                       ![continuous](https://img.shields.io/badge/-continous-green)                                                                                       |                               ![original](./dizoo/pybullet/pybullet.gif)                               |                                                        [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/pybullet/envs)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/pybullet_zh.html)                                                        |\n| 14 |                            [smac](https://github.com/oxwhirl/smac)                            | ![discrete](https://img.shields.io/badge/-discrete-brightgreen) ![marl](https://img.shields.io/badge/-MARL-yellow)![selfplay](https://img.shields.io/badge/-selfplay-blue)![sparse](https://img.shields.io/badge/-sparse%20reward-orange) |                                   ![original](./dizoo/smac/smac.gif)                                   |                 [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/smac/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/smac.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/smac_zh.html)                 |\n| 15 |                         [d4rl](https://github.com/rail-berkeley/d4rl)                         |                                                                                       ![offline](https://img.shields.io/badge/-offlineRL-darkblue)                                                                                       |                                      ![ori](dizoo/d4rl/d4rl.gif)                                      |                                                              [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/d4rl)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/d4rl_zh.html)                                                              |\n| 16 |                                          league_demo                                          |                                                         ![discrete](https://img.shields.io/badge/-discrete-brightgreen) ![selfplay](https://img.shields.io/badge/-selfplay-blue)                                                         |                            ![original](./dizoo/league_demo/league_demo.png)                            |                                                                                                    [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/league_demo/envs)                                                                                                    |\n| 17 |                                          pomdp atari                                          |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                                                                                                        |                                                                                                       [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/pomdp/envs)                                                                                                       |\n| 18 |                          [bsuite](https://github.com/deepmind/bsuite)                          |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                                 ![original](./dizoo/bsuite/bsuite.png)                                 |             [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/bsuite/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs//bsuite.html) <br> [\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/bsuite_zh.html)             |\n| 19 |                             [ImageNet](https://www.image-net.org/)                             |                                                                                             ![IL](https://img.shields.io/badge/-IL/SL-purple)                                                                                             |                         ![original](./dizoo/image_classification/imagenet.png)                         |                                                    [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/image_classification)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/image_cls_zh.html)                                                    |\n| 20 |                 [slime_volleyball](https://github.com/hardmaru/slimevolleygym)                 |                                                          ![discrete](https://img.shields.io/badge/-discrete-brightgreen)![selfplay](https://img.shields.io/badge/-selfplay-blue)                                                          |                              ![ori](dizoo/slime_volley/slime_volley.gif)                              |    [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/slime_volley)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/slime_volleyball.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/slime_volleyball_zh.html)    |\n| 21 |                    [gym_hybrid](https://github.com/thomashirtz/gym-hybrid)                    |                                                                                         ![hybrid](https://img.shields.io/badge/-hybrid-darkgreen)                                                                                         |                                 ![ori](dizoo/gym_hybrid/moving_v0.gif)                                 |           [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/gym_hybrid)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/gym_hybrid.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/gym_hybrid_zh.html)           |\n| 22 |                       [GoBigger](https://github.com/opendilab/GoBigger)                       |                                    ![hybrid](https://img.shields.io/badge/-hybrid-darkgreen)![marl](https://img.shields.io/badge/-MARL-yellow)![selfplay](https://img.shields.io/badge/-selfplay-blue)                                    |                                 ![ori](./dizoo/gobigger_overview.gif)                                 |                                [dizoo link](https://github.com/opendilab/GoBigger-Challenge-2021/tree/main/di_baseline)<br>[env tutorial](https://gobigger.readthedocs.io/en/latest/index.html)<br>[\u73af\u5883\u6307\u5357](https://gobigger.readthedocs.io/zh_CN/latest/)                                |\n| 23 |                       [gym_soccer](https://github.com/openai/gym-soccer)                       |                                                                                         ![hybrid](https://img.shields.io/badge/-hybrid-darkgreen)                                                                                         |                              ![ori](dizoo/gym_soccer/half_offensive.gif)                              |                                                        [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/gym_soccer)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/gym_soccer_zh.html)                                                        |\n| 24 |           [multiagent_mujoco](https://github.com/schroederdewitt/multiagent_mujoco)           |                                                              ![continuous](https://img.shields.io/badge/-continous-green) ![marl](https://img.shields.io/badge/-MARL-yellow)                                                              |                                 ![original](./dizoo/mujoco/mujoco.gif)                                 |                                                    [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/multiagent_mujoco/envs)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/mujoco_zh.html)                                                    |\n| 25 |                                            bitflip                                            |                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen) ![sparse](https://img.shields.io/badge/-sparse%20reward-orange)                                                      |                                ![original](./dizoo/bitflip/bitflip.gif)                                |                                                         [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/bitflip/envs)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/bitflip_zh.html)                                                         |\n| 26 |                      [sokoban](https://github.com/mpSchrader/gym-sokoban)                      |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      | ![Game 2](https://github.com/mpSchrader/gym-sokoban/raw/default/docs/Animations/solved_4.gif?raw=true) |             [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/sokoban/envs)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/sokoban.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/sokoban_zh.html)             |\n| 27 |                   [gym_anytrading](https://github.com/AminHP/gym-anytrading)                   |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                         ![original](./dizoo/gym_anytrading/envs/position.png)                         |                                                [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/gym_anytrading) <br> [env tutorial](https://github.com/opendilab/DI-engine/blob/main/dizoo/gym_anytrading/envs/README.md)                                                |\n| 28 |                   [mario](https://github.com/Kautenja/gym-super-mario-bros)                   |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                                  ![original](./dizoo/mario/mario.gif)                                  |  [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/mario) <br> [env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/gym_super_mario_bros.html) <br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/gym_super_mario_bros_zh.html)  |\n| 29 |                       [dmc2gym](https://github.com/denisyarats/dmc2gym)                       |                                                                                       ![continuous](https://img.shields.io/badge/-continous-green)                                                                                       |                            ![original](./dizoo/dmc2gym/dmc2gym_cheetah.png)                            |               [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/dmc2gym)<br>[env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/dmc2gym.html)<br>[\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/dmc2gym_zh.html)               |\n| 30 |                        [evogym](https://github.com/EvolutionGym/evogym)                        |                                                                                       ![continuous](https://img.shields.io/badge/-continous-green)                                                                                       |                                 ![original](./dizoo/evogym/evogym.gif)                                 |            [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/evogym/envs) <br> [env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/evogym.html) <br> [\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/Evogym_zh.html)            |\n| 31 |             [gym-pybullet-drones](https://github.com/utiasDSL/gym-pybullet-drones)             |                                                                                       ![continuous](https://img.shields.io/badge/-continous-green)                                                                                       |                    ![original](./dizoo/gym_pybullet_drones/gym_pybullet_drones.gif)                    |                                                                                          [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/gym_pybullet_drones/envs)<br>\u73af\u5883\u6307\u5357                                                                                          |\n| 32 |                 [beergame](https://github.com/OptMLGroup/DeepBeerInventory-RL)                 |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                               ![original](./dizoo/beergame/beergame.png)                               |                                                                                               [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/beergame/envs)<br>\u73af\u5883\u6307\u5357                                                                                               |\n| 33 | [classic_control/acrobot](https://github.com/openai/gym/tree/master/gym/envs/classic_control) |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                        ![original](./dizoo/classic_control/acrobot/acrobot.gif)                        |                                                [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/classic_control/acrobot/envs)<br> [\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/acrobot_zh.html)                                                |\n| 34 |   [box2d/car_racing](https://github.com/openai/gym/blob/master/gym/envs/box2d/car_racing.py)   |                                                     ![discrete](https://img.shields.io/badge/-discrete-brightgreen) <br> ![continuous](https://img.shields.io/badge/-continous-green)                                                     |                          ![original](./dizoo/box2d/carracing/car_racing.gif)                          |                                                                                            [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/box2d/carracing/envs)<br>\u73af\u5883\u6307\u5357                                                                                            |\n| 35 |                     [metadrive](https://github.com/metadriverse/metadrive)                     |                                                                                       ![continuous](https://img.shields.io/badge/-continous-green)                                                                                       |                            ![original](./dizoo/metadrive/metadrive_env.gif)                            |                                                       [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/metadrive/env)<br> [\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/metadrive_zh.html)                                                       |\n| 36 |  [cliffwalking](https://github.com/openai/gym/blob/master/gym/envs/toy_text/cliffwalking.py)  |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                          ![original](./dizoo/cliffwalking/cliff_walking.gif)                          |                                                                                    [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/cliffwalking/envs)<br> env tutorial <br> \u73af\u5883\u6307\u5357                                                                                    |\n| 37 |                       [tabmwp](https://promptpg.github.io/explore.html)                       |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                                ![original](./dizoo/tabmwp/tabmwp.jpeg)                                |                                                                                         [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/tabmwp) <br> env tutorial <br> \u73af\u5883\u6307\u5357                                                                                         |\n| 38 |            [frozen_lake](https://gymnasium.farama.org/environments/toy_text/frozen_lake)      |                                                                                      ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                      |                                ![original](./dizoo/frozen_lake/FrozenLake.gif)                        |                                                                                         [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/frozen_lake) <br> env tutorial <br> \u73af\u5883\u6307\u5357                                                                                         |\n| 39 | [ising_model](https://github.com/mlii/mfrl/tree/master/examples/ising_model)                  |                            ![discrete](https://img.shields.io/badge/-discrete-brightgreen) ![marl](https://img.shields.io/badge/-MARL-yellow)                                                                                             |                                ![original](./dizoo/ising_env/ising_env.gif)                           | [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/ising_env) <br> env tutorial <br> [\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh_CN/latest/13_envs/ising_model_zh.html) |\n| 40 | [taxi](https://www.gymlibrary.dev/environments/toy_text/taxi/)                  |                            ![discrete](https://img.shields.io/badge/-discrete-brightgreen)                                                                                 |                                ![original](./dizoo/taxi/Taxi-v3_episode_0.gif)                           | [dizoo link](https://github.com/opendilab/DI-engine/tree/main/dizoo/taxi/envs) <br> [env tutorial](https://di-engine-docs.readthedocs.io/en/latest/13_envs/taxi.html) <br> [\u73af\u5883\u6307\u5357](https://di-engine-docs.readthedocs.io/zh-cn/latest/13_envs/taxi_zh.html) | \n![offline](https://img.shields.io/badge/-offlineRL-darkblue) means offline RL environment \n",
                    "original_header": "Environment Versatility"
                },
                "confidence": 0.9317488587890966,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/opendilab/DI-engine/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "  <img src=https://github.com/opendilab/DI-engine/blob/main/assets/wechat.jpeg width=35% />\n- Contact our email (opendilab@pjlab.org.cn)\n- Contributes to our future plan [Roadmap](https://github.com/opendilab/DI-engine/issues/548) \n",
                    "original_header": "Feedback and Contribution"
                },
                "confidence": 0.9943287859922587,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/opendilab/DI-engine/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-07-04T07:11:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T09:58:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 8019574
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 8592
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 1610
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "300": {
        "filename": "Fantasy-Shaw_H-STFormer_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Intel or AMD x86_64-arch, 8 CPU cores or more; \n80GB RAM (128GB recommended); \n",
                    "original_header": "Recommended Hardware Env"
                },
                "confidence": 0.9529491486671718,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Fantasy-Shaw/H-STFormer/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-08-01T02:36:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-30T10:37:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 230767
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "301": {
        "filename": "tatsu-lab_stanford_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "302": {
        "filename": "salesforce_ICLRec_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We provide the trained models on Beauty, Sports_and_Games, Toys_and_Games, and Yelp datasets in `./src/output` folder. You can directly evaluate the trained models on test set by running:\n```\npython main.py --data_name <Data_name> --model_idx 1 --do_eval\n```\n \n",
                    "original_header": "Evaluate Model"
                },
                "confidence": 0.9174564702514456,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/salesforce/ICLRec/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To train ICLRec on a specific dataset, change to the `src` folder and run following command: \n```\nbash scripts/run_<data_name>.sh\n```\n \n",
                    "original_header": "Train Model"
                },
                "confidence": 0.9998875621424722,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/salesforce/ICLRec/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-02-25T12:15:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-05T13:14:27Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 90892
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1267
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "303": {
        "filename": "ilog-ecnu_EvoRRP_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```shell\nconda env create -f environment.yml\nconda activate evorrp\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Evolutionary Retrosynthetic Route Planning"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ilog-ecnu/EvoRRP/main/README.md"
            },
            {
                "result": {
                    "value": "Use your own single-step retrosynthetic model to repalce `from single_step.infer import SingleInference` in file `algorithm/CUSOP.py`.\n",
                    "type": "Text_excerpt",
                    "original_header": "Prepare Single-step Model",
                    "parent_header": [
                        "Evolutionary Retrosynthetic Route Planning"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ilog-ecnu/EvoRRP/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```shell\ngit clone https://github.com/ilog-ecnu/EvoRRP\ncd EvoRRP\n```\n \n",
                    "original_header": "Quickstart"
                },
                "confidence": 0.9999998769152971,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ilog-ecnu/EvoRRP/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-08-15T03:54:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-06T01:18:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 23866
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "304": {
        "filename": "filipcano_intentional-autonomous-agents_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Requirements\n  - Python 3\n  - pip install docker\n  - Prism Model Checker\n\nWe use the prism model checker for path simulation. To install it, follow the instructions instructions given by the [website](https://www.prismmodelchecker.org/download.php).\nNext, write the path to the Prism executable found in the bin directory into the `config.txt` file.\n\nFor Prism to work, it may be necessary to install the Java JDK if it is not already available. Whether Prism is working can be verified by running the `prism` executable found in the bin directory.\n\nTo answer the model checking queries we use a modified version of [TEMPEST](https://www.tempest-synthesis.org), which in turn is a fork of the [STORM](https://www.stormchecker.org/) model checker via [docker](https://www.docker.com/).\nYou can download the docker container with\n\n```\ndocker pull lposch/tempest-devel-traces\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Analyzing Intentional Behavior in Autonomous Agents Under Uncertainty"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/filipcano/intentional-autonomous-agents/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-19T07:18:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-07-12T08:24:15Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 173172
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Raku",
                    "name": "Raku",
                    "type": "Programming_language",
                    "size": 96216
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 41155
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "305": {
        "filename": "openjournals_joss-reviews_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "If you're looking for more information about the JOSS project you might like to take a look at the JOSS website: http://joss.theoj.org/about . Alternatively, if you're looking for the open source application that powers JOSS then head over here: https://github.com/openjournals/joss\n \n",
                    "original_header": "Reviews for the Journal of Open Source Software"
                },
                "confidence": 0.982312079736234,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/openjournals/joss-reviews/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2016-02-23T05:02:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T20:41:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "306": {
        "filename": "reissnda_AutomataConformance_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2020-04-08T05:04:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-01-30T09:01:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 6261080
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 2788393
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 23016
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "307": {
        "filename": "Ericonaldo_ILSwiss_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "[News!] We have tested the environment in Python 3.10 and PyTorch 2.0 with other packages in new versions. You can install the new environment from `requirement2.yaml`. Notice that new versions of `gym` and `gymnasium` are not consistent yet. \n",
                    "original_header": "ILSwiss"
                },
                "confidence": 0.9999481511809083,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Ericonaldo/ILSwiss/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- Soft-Actor-Critic (SAC)\n- Soft-Actor-Critic (SAC) (Auto Learning Alpha version)\n- Soft-Actor-Critic-Auto-Encoder (SAC-AE)\n- TD3\n- DDPG\n- PPO\n- HER (Goal-Condtioned RL, with SAC or TD3)\n- GCSL (Goal-Condtioned RL)\n- Model-Based Policy Optimization (MBPO, https://github.com/jannerm/mbpo)\n- Reinforcement Learning with Augmented Data (RAD-SAC, https://github.com/MishaLaskin/rad)\n- Contrastive Unsupervised Representation Learning (CURL-SAC, https://github.com/MishaLaskin/curl/)\n \n",
                    "original_header": "Implemented RL algorithms:"
                },
                "confidence": 0.99996254798442,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Ericonaldo/ILSwiss/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-07-27T14:43:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-23T14:22:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 615218
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 2439
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "308": {
        "filename": "Hope-Rita_PatCLS_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-07-28T01:43:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-30T14:06:52Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 73970
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "309": {
        "filename": "jhudsy_numerical_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "310": {
        "filename": "feiwangyuzhou_TernaryCL_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-10-08T13:53:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-11-12T08:16:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 57552
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "311": {
        "filename": "gemcollector_RL-ViGen_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "# Installation\n\nClone the RL-ViGen repo:\n```\ngit clone https://github.com/gemcollector/RL-ViGen.git\ncd RL-ViGen/\n```\n\nCreate a conda environment:\n```\nconda create -n rl-vigen python=3.8\n```\nRun the installation script:\n```\nbash setup/install_rlvigen.sh\n```\n\nIn addition, the following resources are required:\n- CARLA: We apply CARLA 0.9.10 which is a stable version in RL-ViGen. The CARLA 0.9.10 should be downloaded first, and place it to the `./third_party` folder:\n    ```\n    wget https://carla-releases.s3.eu-west-3.amazonaws.com/Linux/CARLA_0.9.10.tar.gz\n    ```\n- Robosuite: we have employed the `1.4.0` version of [Robosuite](https://github.com/ARISE-Initiative/robosuite/), concurrently utilizing [mujoco](https://github.com/deepmind/mujoco) version `2.3.0` as the underlying simulator engine. We have incorporated all the relevant components associated with Robosuite in the first creating conda step.\n\n - DM-Control:  Our DM-Control also contains [mujoco_menagerie\n](https://github.com/deepmind/mujoco_menagerie) as the basic component. We have incorporated all the relevant components associated with DM-Control in the first creating conda step.\n\nTo use the Habitat, you need to set up a separate conda environment:\n```\nconda create -n vigen-habitat python=3.8 cmake=3.14.0 -y \n```\n```\nbash setup/install_vigen-habitat.sh\n```\n\n\n1. We are using Gibson scene datasets for our experiment. You can find instructions for downloading the dataset [here](https://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md#gibson-and-3dscenegraph-datasets).\n\n2. Next we need the episode dataset for the experiments. You can get the training and validation dataset from [here](https://dl.fbaipublicfiles.com/habitat/data/datasets/pointnav/gibson/v1/pointnav_gibson_v1.zip) and place it in the ./data folder under the path : `data/datasets/pointnav/gibson/v1/`.\n\n\n## Installation all in one\n\nWe provide a script to install all the dependencies and resources required for RL-ViGen. You can run the following command to install:\n\n```\nbash setup/install_all.sh\n```\nIf you are employing this method of installation, please modify all the  `train` and `eval` scripts, ensuring that the parameter `task` is set to `task@_global_`. Here is an example:\n\n```\nCUDA_VISIBLE_DEVICES=0  python train.py \\\n\t\t\t\t\t\tenv=${env} \\\n\t\t\t\t\t\ttask@_global_=${task_name}\n```\n\n\n## Installation with Docker\n```\ndocker pull cititude/rl-vigen:1.0\n```",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/gemcollector/RL-ViGen/master/INSTALLATION.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n<p align=\"center\">\n  <br />\n  <a href=\"./MODEL_CARD.md\"><img alt=\"Model Card\" src=\"https://img.shields.io/badge/benchmark-RLViGen-green.svg\" /></a>\n  <a href=\"./LICENSE\"><img alt=\"MIT License\" src=\"https://img.shields.io/badge/license-MIT-red.svg\" /></a>\n  <a href=\"Python 3.8\"><img alt=\"Python 3.8\" src=\"https://img.shields.io/badge/python-3.8-blue.svg\" /></a>\n  <a href=\"https://github.com/psf/black\"><img alt=\"Code style: white\" src=\"https://img.shields.io/badge/mujoco-2.3.0-white.svg\" /></a>\n</p> \n[comment]: <> (  <img width=\"19.5%\" src=\"https://imgur.com/O5Va3NY.gif\">) \n[comment]: <> (  <img width=\"19.5%\" src=\"https://imgur.com/PCOR9Mm.gif\">) \n[comment]: <> (  <img width=\"19.5%\" src=\"https://imgur.com/H0ab6tz.gif\">) \n[comment]: <> (  <img width=\"19.5%\" src=\"https://imgur.com/sDGgRos.gif\">) \n[comment]: <> (  <img width=\"19.5%\" src=\"https://imgur.com/gj3qo1X.gif\">) \n[comment]: <> (  <img width=\"19.5%\" src=\"https://imgur.com/FFzRwFt.gif\">) \n[comment]: <> (  <img width=\"19.5%\" src=\"https://imgur.com/W5BKyRL.gif\">) \n[comment]: <> (  <img width=\"19.5%\" src=\"https://imgur.com/qwOGfRQ.gif\">) \n[comment]: <> (  <img width=\"19.5%\" src=\"https://imgur.com/Uubf00R.gif\">)\n </p> \n[comment]: <> (  <img src=\"https://i.imgur.com/SemY10G.png\" width=\"100%\"/>) \n[comment]: <> (  <img width=\"100%\" src=\"https://imgur.com/mrS4fFA.png\">) \n[comment]: <> (  <img width=\"100%\" src=\"https://imgur.com/pPd1ks6.png\">) \n",
                    "original_header": "RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization"
                },
                "confidence": 0.9775582173320901,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/gemcollector/RL-ViGen/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To install our benchmark, please follow the instructions in [INSTALLATION.md](INSTALLATION.md). \n",
                    "original_header": "Intallation"
                },
                "confidence": 0.9984976488316626,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/gemcollector/RL-ViGen/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The algorithms will use the [Places](http://places2.csail.mit.edu/download.html) dataset for data augmentation, which can be downloaded by running\n```\nwget http://data.csail.mit.edu/places/places365/places365standard_easyformat.tar\n```\nAfter downloading and extracting the data, add your dataset directory to the datasets list in `cfgs/aug_config.cfg`.\n \n",
                    "original_header": "Extra Datasets"
                },
                "confidence": 0.9965333245605155,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/gemcollector/RL-ViGen/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```\ncd RL-ViGen/\nbash scripts/train.sh\n``` \n",
                    "original_header": "Habitat, Robosuite, Locomotion"
                },
                "confidence": 0.9989576238612908,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/gemcollector/RL-ViGen/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```\ncd RL-ViGen/\nbash scripts/carlatrain.sh\n```\n \n",
                    "original_header": "CARLA"
                },
                "confidence": 0.9985125942132199,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/gemcollector/RL-ViGen/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For evaluation, you should change `model_dir` to your own saved model folder first. Regarding  `Robosuite` , `Habitat`, and `CARLA`, we can run the evaluation code as follow:\n```\ncd RL-ViGen/\nbash scripts/eval.sh \n```\nYou should change the `env`, `task_name`, `test_agent` for different evaluation in the `eval.sh`. \nFor `DM-Control`, we can run the evaluation code as follow:\n```\ncd RL-ViGen/\nbash scripts/locoeval.sh\n``` \n",
                    "original_header": "Evaluation"
                },
                "confidence": 0.9973152975787883,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/gemcollector/RL-ViGen/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-22T12:07:11Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T13:46:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 3779543
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 136624
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 11112
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "312": {
        "filename": "Gentopia-AI_Gentopia_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "# Installation\nPlease follow the instructions below to set up Gentopia and GentPool on your system.\nWe recommend using a virtual environment.\n```bash\nconda create --name gentenv python=3.10\nconda activate gentenv\n```\n\n## Install Gentopia from PyPI\nTo install the basic framework, \n```bash\npip install gentopia\n```\nAdditionally, if you want to use open LLMs like `llama` on huggingface, together with 8-bit/4-bit quantization tricks, install with \n```bash\npip install gentopia[huggingface]\n```\nNOTE:  We are still in early development (gentopia `v0.x.x` is considered early access), you may want to frequently \n```bash\npip install --upgrade gentopia\n```\n\n## Install Gentopia from source\nAlternatively, if you are a true hacker who modifies the source code frequently, we recommend installing from source.\n```bash\ngit clone git@github.com:Gentopia-AI/Gentopia.git\ncd Gentopia\npip install -e .\n```\n\n## Install GentPool\nWe recommend using GentPool as a space to build your agent because you can easily call other public agents for interaction, \nand access our unique benchmark eval to test your agent.\n```bash\ngit clone git@github.com:Gentopia-AI/GentPool.git\n```\nCreate a .env file under GentPool (ignored by git) and put your API Keys inside. They will be registered as environmental variables at run time.\n```bash\ncd GentPool\ntouch .env\necho \"OPENAI_API_KEY=<your_openai_api_key>\" >> .env\necho \"WOLFRAM_ALPHA_APPID=<your_wolfram_alpha_api_key>\" >> .env\n```\n... and so on if you plan to use other service keys.\n\n## Download public GentBench data\n\nGentBench is our unique benchmark eval for agents. It tests a wide range of agent capability beyond vanilla LLMs.\nSee [here]() for more details.\n\nGentBench is half-public and half-private (both will be updated and expanded). \nYou have full access to the public data for testing, fine-tuning or so, but private benchmark will only be used to evaluate agents registered in GentPool.\nThis prevents overfitting and gives you a sense of generalizability.\nTo download the public benchmark, make sure you've installed [Git-LFS](https://git-lfs.com/) and GentPool, then\n```bash\ncd GentPool\ngit lfs fetch --all\ngit lfs pull\n```\nThen you will see downloaded tasks under `GentPool/benchmark/`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/Gentopia-AI/Gentopia/main/docs/installation.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<img width=\"1140\" alt=\"image\" src=\"https://github.com/Gentopia-AI/Gentopia/assets/65674752/8cb8ec87-6e50-44d5-aedc-c4994e9a8aa2\"> \n",
                    "original_header": "Gentopia"
                },
                "confidence": 0.9948067761446041,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Gentopia-AI/Gentopia/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-29T22:35:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-13T15:56:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 359543
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 769
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 636
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 212
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "313": {
        "filename": "ejcgt_attention-target-detection_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Please adjust the dataset path accordingly in config.py. \n",
                    "original_header": "Dataset"
                },
                "confidence": 0.9477826841165965,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ejcgt/attention-target-detection/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-03-03T06:56:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T03:04:20Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 129051
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 374
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "314": {
        "filename": "alibaba_tgin_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We have processed the raw data and upload it to the `electronics/` fold. You can use it directly.\n\nAlso, you can get the data from the amazon website and process it using the script:\n\n```\nsh prepare_data.sh\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "1. interaction data",
                    "parent_header": [
                        "TGIN",
                        "Prepare data"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/alibaba/tgin/main/README.md"
            },
            {
                "result": {
                    "value": "You can use the processed triangles data directly, and just skip this step.\n\n```\npython script/gen_wnd_edges.py\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "2. co-occurrence graph",
                    "parent_header": [
                        "TGIN",
                        "Prepare data"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/alibaba/tgin/main/README.md"
            },
            {
                "result": {
                    "value": "We have extracted and selected the triangles of both amazon(books) and amazon(electronics) datasets. You can <a href=\"https://drive.google.com/drive/folders/1gj7aHFjRLVPwmhvK-o1waJKj3Xme7GVM\" target=\"_blank\">download</a> and put it into the `triangle_data/` folder.\n\nNext, the triangle indexes should be transformed into the input format of the TGIN model.\n```\npython process_tridata.py\n```\n\nAlso, you can refer to the MapReduce source code in \n`triangle_mapreduce.zip` folder to generate triangle indexes.\n\n\n",
                    "type": "Text_excerpt",
                    "original_header": "3. triangle extraction and selection",
                    "parent_header": [
                        "TGIN",
                        "Prepare data"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/alibaba/tgin/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The code has been tested running under Python 2.7.18, with the following packages installed (along with their dependencies): \n",
                    "original_header": "Required packages"
                },
                "confidence": 0.9986126660883272,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/alibaba/tgin/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- cPickle == 1.17\n- numpy == 1.16.6\n- keras == 2.0.8\n- tensorflow-gpu == 1.5.0\n### \n \n"
                },
                "confidence": 0.9984790416408297,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/alibaba/tgin/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-05-25T12:59:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-22T03:40:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 178422
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 544
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "315": {
        "filename": "zjukg_NeuralKG_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n<p align=\"center\">\n    <a href=\"https://github.com/zjukg/NeuralKG/tree/main\"> <img src=\"pics/neuralkg2.png\" height=\"100\"/></a>\n    <a href=\"https://github.com/zjukg/NeuralKG/tree/ind\"> <img src=\"pics/neuralkg-ind2.png\" height=\"100\"/></a>\n<p>\n<p align=\"center\">  \n    <a href=\"http://neuralkg.zjukg.cn/\">\n        <img alt=\"Website\" src=\"https://img.shields.io/badge/website-online-orange\">\n    </a>\n    <a href=\"https://pypi.org/project/neuralkg/\">\n        <img alt=\"Pypi\" src=\"https://img.shields.io/pypi/v/neuralkg\">\n    </a>\n    <a href=\"https://github.com/zjukg/NeuralKG/blob/main/LICENSE\">\n        <img alt=\"Pypi\" src=\"https://img.shields.io/badge/license-Apache--2.0-yellowgreen\">\n    </a>\n    \n    <a href=\"https://zjukg.github.io/NeuralKG/index.html\">\n        <img alt=\"Documentation\" src=\"https://img.shields.io/badge/Doc-online-blue\">\n    </a>\n</p> \n## Installation \n+  Install PyTorch\n```\npip install torch==1.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n```\n+ Install DGL\nBASH4* \n+ From Source\n```bash\ngit clone https://github.com/zjukg/NeuralKG.git\ncd NeuralKG\npython setup.py install\n```\n## Training\nBASH7*\n \n# Notebook Guide \n\n\ud83d\ude03We use colab to provide some notebooks to help users use our library. \n# Detailed Documentation\nhttps://zjukg.github.io/NeuralKG/neuralkg.html \n"
                },
                "confidence": 0.9805314966772575,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/zjukg/NeuralKG/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-01-17T06:09:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-16T17:31:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 349709
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 37021
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "316": {
        "filename": "TheFebrin_Polygonal-Map-Generation-for-Games_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```python\nclass Corner:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n        self.touches = []\n        self.protrudes = []\n        self.adjacent = []\n        self.terrain_type = TerrainType.LAND\n        self.height = 0\n        self.downslope = None\n        self.river = 0\n        self.moisture = 0\n``` \n```python\nclass Edge:\n    def __init__(self, center1, center2, corner1, corner2):\n        self.d0 = center1\n        self.d1 = center2\n        self.v0 = corner1\n        self.v1 = corner2\n        self.river = 0\n``` \n",
                    "original_header": "Map representation"
                },
                "confidence": 0.9997266531570056,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/TheFebrin/Polygonal-Map-Generation-for-Games/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* Python - version 3.7.3\n* numpy\n* scipy\n* shapely\n* matplotlib\n* plotly\n \n",
                    "original_header": "Libraries"
                },
                "confidence": 0.9997015280158635,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/TheFebrin/Polygonal-Map-Generation-for-Games/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-01-23T18:12:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-14T14:53:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 8270628
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 41917
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "317": {
        "filename": "forestagostinelli_DeepCubeA_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "For required python packages, please see requirements.txt.\nYou should be able to install these packages with pip or conda\n\nPython version used: 3.7.2\n\nIMPORTANT! Before running anything, please execute: `source setup.sh` in the DeepCubeA directory to add the current \ndirectory to your python path.\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/forestagostinelli/DeepCubeA/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "This is the code for [DeepCubeA](https://cse.sc.edu/~foresta/assets/files/SolvingTheRubiksCubeWithDeepReinforcementLearningAndSearch_Final.pdf) for python3 and PyTorch.\nThe original python2, tensorflow code can be found on [CodeOcean](https://codeocean.com/capsule/5723040/tree/v1). \nYou can also adapt this code to use DeepCubeA to solve new problems that you might be working on. \n",
                    "original_header": "DeepCubeA"
                },
                "confidence": 0.9702497912981377,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/forestagostinelli/DeepCubeA/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "`cd cpp/` \n",
                    "original_header": "Compiling C++ for A* Search"
                },
                "confidence": 0.9089214582713104,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/forestagostinelli/DeepCubeA/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-02-23T03:30:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T13:04:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 121455
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 30574
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 5208
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 349
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 256
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "318": {
        "filename": "aig-upf_tarski_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "\n# Installing Tarski\n\n## Software Requirements\nTarski is mostly developed in Python, and requires a working Python>=3.6 installation.\nWe strongly recommend installing Tarski within a Python\n[virtual environment](https://docs.python.org/3/tutorial/venv.html).\nThe installation instructions below will install for you any additional\nrequired dependencies.\n\n\n## Installation Instructions\n\nYou can install the latest Tarski release with:\n\n    pip install tarski\n\nIf instead you want to use the latest code available on the Github repository, \nyou can install with:\n    \n    pip install -U git+https://github.com/aig-upf/tarski.git\n\n\n## Installing Tarski in Development Mode\nIf developing Tarski, we recommend cloning from the Github repository and doing\na development installation (the`-e` flag for `pip`):\n    \n    git clone https://github.com/aig-upf/tarski\n    cd tarski\n    pip install -e .\n\nThis will install the project in \"editable mode\", meaning that any modification\nto the files is immediately reflected in the _installed_ library.\n\n## Installing Extras (Experimental)\nTarski allows the _optional_ installation of certain extras that will allow you\nto run certain non-essential functionalities of the library. For instance,\nthe `tarski.rddl` experimental package allows you to interact with the\n[PyRDDL package](https://github.com/thiagopbueno/pyrddl) for parsing of RDDL\nprobabilistic planning problems. To use this optional package, you'd need to \n`pip install` with the `pyrddl` \"extra\", as in: \n\n    pip install tarski[rddl]\n\nWe strongly recommend to use these extras only if you know what you're doing.\nCurrent extras include:\n\n* `arithmetic`: Enables use of Tarski for dealing with numeric planning problems, algebraic matrix sorts, etc.\n               Installs `scipy` and `numpy` python packages.\n* `rddl`: Enables dealing with RDDL probabilistic problems. Installs `pyrddl` python package.",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/aig-upf/tarski/master/docs/installation.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**Testing**: Most tests can be run by executing `pytest` on the root directory.\nAlternatively, they can be run through `tox`, for which several testing environments [are defined](tox.ini).\n \n",
                    "original_header": "What is Tarski"
                },
                "confidence": 0.9976372557457542,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/aig-upf/tarski/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-01-09T12:34:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-04T08:25:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1112384
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 152006
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "ANTLR",
                    "name": "ANTLR",
                    "type": "Programming_language",
                    "size": 14515
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 5355
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Smarty",
                    "name": "Smarty",
                    "type": "Programming_language",
                    "size": 1508
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "319": {
        "filename": "alanxuji_DeLaLA_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-10-26T14:53:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-11T09:37:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 65875
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "320": {
        "filename": "kavitawagh_RLProject_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "321": {
        "filename": "RobinLu1209_Geometer_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-12-17T07:04:49Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-16T07:00:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 40504
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "322": {
        "filename": "sanda-avram_ROST-source-code_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-11-21T19:20:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-03-13T06:11:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 19432
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 18954
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 8444
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 3126
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "323": {
        "filename": "stacs-cp_AutoIG_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-05-06T13:15:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-12T16:29:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 114639
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 14101
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "R",
                    "name": "R",
                    "type": "Programming_language",
                    "size": 4294
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "324": {
        "filename": "yuanmu97_MLink_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Create a virtual environment and install python packages using pip:\n```bash\nconda create --name mlink python=3.9\nconda activate mlink\npip install tensorflow-federated\n# tensorflow_federated-0.50.0, 2023/3/1\n```\n\nTo run jupyter notebooks:\n```bash\npip install ipykernel\nipython kernel install --user --name=mlink\njupyter-lab\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "MLink"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/yuanmu97/MLink/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-02-11T07:47:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-03T08:43:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 56923
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 45055
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "325": {
        "filename": "ScriptsOfTribute_ScriptsOfTribute-Core_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-09-19T10:12:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-10T15:56:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C#",
                    "name": "C#",
                    "type": "Programming_language",
                    "size": 579066
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 121414
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 84085
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 15387
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2764
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 1564
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Gnuplot",
                    "name": "Gnuplot",
                    "type": "Programming_language",
                    "size": 691
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 228
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "326": {
        "filename": "bdy9527_SDCN_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://github.com/461054993/SDCN/blob/master/SDCN.pdf\n \n",
                    "original_header": "Paper"
                },
                "confidence": 0.9990698525682603,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/bdy9527/SDCN/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "graph: \u94fe\u63a5:https://pan.baidu.com/s/1MEWr1KyrtBQndVNy8_y2Lw  \u5bc6\u7801:opc1 \ndata: \u94fe\u63a5:https://pan.baidu.com/s/1kqoWlElbWazJyrTdv1sHNg  \u5bc6\u7801:1gd4 \n",
                    "original_header": "Dataset"
                },
                "confidence": 0.9530775254672481,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/bdy9527/SDCN/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-02-12T09:24:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-17T01:55:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 18903
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "327": {
        "filename": "potassco_plasp_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```sh\nplasp <command> [<option>...] [<input file>...]\n``` \n`plasp help` shows a list of all commands provided by `plasp`.\nTo list all available options of a command, call `plasp <command> --help` or `plasp help <command>`. \n",
                    "original_header": "Provided Tools"
                },
                "confidence": 0.9750961609147503,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/potassco/plasp/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2016-05-20T13:25:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-04T14:43:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 535128
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 9732
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "328": {
        "filename": "tufts-ai-robotics-group_Automaton-guided-CL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The requirements are listed in the file: requirements.txt \nTo install: `pip install -r requirements.txt` \nTo test AGCL-sequence on MC, run:\n`$ python MC/AGCL-sequence/main.py` \n",
                    "original_header": "Automaton-Guided-CL"
                },
                "confidence": 0.9677128609459852,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/tufts-ai-robotics-group/Automaton-guided-CL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-03-16T03:33:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-30T11:28:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 577071
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "329": {
        "filename": "zhiweihu1103_ET-TET_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-10-08T05:20:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-15T12:54:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 37977
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "330": {
        "filename": "ryoryon66_TAAM_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "First, please intall graphviz on your computer.([doc](https://pygraphviz.github.io/documentation/stable/install.html))\nWe have confirmed that drawing is possible with version 5.0.1.\n\n```\nsudo apt-get install graphviz graphviz-dev # ubuntu\n```\n\nThen, run the following commands.\nWe used python 3.10.0.\n\n```\npython -m venv venv # Python 3.10.0 or later version of that is required.\nsource  venv/bin/activate\npip install -r requirements.txt\n```\n\nThe following commands can be executed to check if it works properly.\n\n```\npytest\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "TAAM, a mathematical argumentation model implemented in Python"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            },
            {
                "result": {
                    "value": "TAAM implemented in ./model_src/ is briefly explained here to show how to use it.\n\n",
                    "type": "Text_excerpt",
                    "original_header": "manual",
                    "parent_header": [
                        "TAAM, a mathematical argumentation model implemented in Python"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            },
            {
                "result": {
                    "value": "\n\nTAAM is implemented in the `TAAMModel` class, which consists of a typed graph, a complete Boolean algebra, and interpretation, each of which must be initialized in the following manner. After initializing each of them, use the constructor of `TAAMModel` to generate a model.\n",
                    "type": "Text_excerpt",
                    "original_header": "Initialization of TAAM(`TAAMModel`)",
                    "parent_header": [
                        "TAAM, a mathematical argumentation model implemented in Python",
                        "manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            },
            {
                "result": {
                    "value": "Initialize a typed graph using the constructor of the `TypedGraph` class.A typed graph is automatically generated such that well-formedness is satisfied; to check whether or not well-informedness is satisfied, the `is_well_formed` method can be used.\n\n```\nArgs:\n    Aord_size (int, optional): the number of elements in Aord_size(Aord = {\"0\",\"1\",... }). Defaults to 6.\n    Themes_size (int, optional):the number of Themes (Themes = {\"t0\",\"t1\",...}). Defaults to 10.\n    num_pnode (int, optional): the number of pnodes. Defaults to 5.\n    num_onode (int, optional): the number of onodes. Defaults to 3.\n    num_edge (int, optional): the number of edges. Defaults to 10.\n    limit_num_given_themes (int, optional): Maximum number of themes given to vertices and edges. Defaults to 3.\n```\n\n```\n>>> typed_graph = TypedGraph(Aord_size=2,Themes_size=2,num_pnode=1,num_onode=1,num_edge=1,limit_num_given_themes=2)\n>>> print(typed_graph)\nDiGraph with 2 nodes and 1 edges\nAord:['0', '1']\nThemes:['t0', 't1']\n```\nSee implementation for details.\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Initialization of Typed Graphs(`TypedGraph`)",
                    "parent_header": [
                        "TAAM, a mathematical argumentation model implemented in Python",
                        "manual",
                        "Initialization of TAAM(`TAAMModel`)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            },
            {
                "result": {
                    "value": "Initialize a boolean algebra using the constructor of the `BooleanAlgebra` class.\n```\nArgs:\n    num_propvar (int, optional): the number of propositional variables in the boolean Algebra. Defaults to 3.\n```\n\nIt is recommended that the number of propositional variables be no more than 3, as the program may take considerably longer time to execute.\n\n```\n>>> D = BooleanAlgebra(num_propvar=2)\n>>> print(D)\n[A0, A1]\n```\n\nSee implementation for details.\n\n\n\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Initialization of boolean algebra (`BooleanAlgebra`)",
                    "parent_header": [
                        "TAAM, a mathematical argumentation model implemented in Python",
                        "manual",
                        "Initialization of TAAM(`TAAMModel`)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            },
            {
                "result": {
                    "value": "Initialize an interpretation using the constructor of the `Interpretation` class with an initialized typed graph and  a boolean algebra.\n\n```\nArgs:\n    typed_graph (TypedGraph): typed graph\n    D (BooleanAlgebra): boolean algebra\n    limit_image_size (int, optional): the maximum number of \n                                      elements in the output of Interpretation. \n                                      Defaults to 5.\n```\n\n```\n>>> I = Interpretation(typed_graph,D)\n>>> print(I)\n{((), '0'): [A0 & A1,\n             (A0 & A1) | (A0 & ~A1),\n             (A0 & A1) | (A0 & ~A1) | (~A0 & ~A1),\n             (A0 & A1) | (A0 & ~A1) | (A1 & ~A0) | (~A0 & ~A1)],\n ((), '1'): [(A0 & A1) | (A0 & ~A1)],\n<snip>\n (('t0', 't1'), 'omega'): [(A0 & A1) | (A0 & ~A1),\n                           False,\n                           (A0 & A1) | (A0 & ~A1) | (~A0 & ~A1),\n                           (A0 & A1) | (~A0 & ~A1),\n                           (A0 & A1) | (A0 & ~A1) | (A1 & ~A0)],\n<snip>\n (('t1',), 't1.c'): []}\n\n```\n\n\nSee implementation for details.\n\n\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Initialization of interpretations(`Interpretation`)",
                    "parent_header": [
                        "TAAM, a mathematical argumentation model implemented in Python",
                        "manual",
                        "Initialization of TAAM(`TAAMModel`)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            },
            {
                "result": {
                    "value": "After initializing the model, use the  `meet_{constraint name}` methods.\nTrue(False) is returned if the model is (un)satisfied.\n\n",
                    "type": "Text_excerpt",
                    "original_header": "How to check if constraints are satisfied",
                    "parent_header": [
                        "TAAM, a mathematical argumentation model implemented in Python",
                        "manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            },
            {
                "result": {
                    "value": "Use save_model and load_model (static method) implemented in `TAAMModel`.\n\n```python=\nmodel = TAAMModel()\nmodel.save(\"save location\")\nmodel.load(\"path_to_dill_file\")\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Saving and Loading models",
                    "parent_header": [
                        "TAAM, a mathematical argumentation model implemented in Python",
                        "manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            },
            {
                "result": {
                    "value": "You can visualize the model by using `visualize` methods.\n\nAn example is below.\n\n```python\nmodel = TAAMModel()\n\nmodel.typed_graph.visualize(title=\"example1\")\n\nmodel.D.visualize(title=\"example2\")\n\n# description can be used to add more information about the model.\nmodel.visualize(\n    description = f\"{model.typed_graph}\\n I:{model.I}\",\n    title=\"example3\"\n)\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Visualization of the model",
                    "parent_header": [
                        "TAAM, a mathematical argumentation model implemented in Python",
                        "manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "See the source code or the csv files below for details.(branch data1) \n",
                    "original_header": "Without bit pattern representation."
                },
                "confidence": 0.9357996086390499,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "See the source code or the csv files below for details.(branch data2) \n",
                    "original_header": "With bit pattern representaion."
                },
                "confidence": 0.9357996086390499,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ryoryon66/TAAM/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-11-09T08:08:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-01-20T14:26:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 2888898
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 121131
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "331": {
        "filename": "kevinzakka_x-magical_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "**x-magical** requires Python 3.8 or higher. We recommend using an [Anaconda](https://docs.anaconda.com/anaconda/install/) environment for installation. You can create one with the following:\n\n```bash\nconda create -n xmagical python=3.8\nconda activate xmagical\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "x-magical"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/kevinzakka/x-magical/main/README.md"
            },
            {
                "result": {
                    "value": "```bash\npip install x-magical\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installing PyPI release",
                    "parent_header": [
                        "x-magical",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/kevinzakka/x-magical/main/README.md"
            },
            {
                "result": {
                    "value": "Clone the repository and install in editable mode:\n\n```bash\ngit clone https://github.com/kevinzakka/x-magical.git\ncd x-magical\npip install -r requirements.txt\npip install -e .\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installing from source",
                    "parent_header": [
                        "x-magical",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/kevinzakka/x-magical/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-03-13T04:49:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-06T23:32:16Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 111247
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 617
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "332": {
        "filename": "CamDavidsonPilon_lifetimes_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```bash\npip install lifetimes\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/CamDavidsonPilon/lifetimes/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2014-12-29T02:47:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-17T00:18:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 249448
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 680
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "333": {
        "filename": "maximecb_gym-minigrid_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "# Installation\n\nTo install `minigrid`, the easiest way is to use `pip`:\n\n```bash\npip install minigrid\n```\n\nHowever, if you would like to build on top of `minigrid`, you would need to install it from source. To do this, first clone the repository:\n\n```bash\ngit clone https://github.com/Farama-Foundation/Minigrid.git\n```\n\nThen, install the package:\n\n```bash\ncd Minigrid\npython3 -m pip install .\n```\n\nIf you want to install the package in [development mode](https://setuptools.pypa.io/en/latest/userguide/development_mode.html), use the following command instead:\n\n```bash\npython3 -m pip install -e .\n```\n\nAn installation in development mode (i.e., an editable install) is useful if you want to modify the source code of `minigrid` and have your changes take effect immediately.",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/maximecb/gym-minigrid/master/docs/content/installation.md"
            },
            {
                "result": {
                    "value": "To install the Minigrid library use `pip install minigrid`.\n\nWe support Python 3.7, 3.8, 3.9, 3.10 and 3.11 on Linux and macOS. We will accept PRs related to Windows, but do not officially support it.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/maximecb/gym-minigrid/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-12-13T16:22:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T11:55:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 522278
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 484
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 470
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "334": {
        "filename": "navdeepkumar12_rmdp_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-09-01T06:56:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-06-23T04:55:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 17936
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "335": {
        "filename": "potassco_clingo-dl_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "# Table of Contents\n\n- [Installation using conda](#installation-using-conda)\n- [Installation using pip](#installation-using-pip)\n- [Requirements](#requirements)\n- [Build, Install, and Test](#build-install-and-test)\n  - [Build Options](#build-options)\n\n# Installation using conda\n\nThe latest clingo-dl release is available using the conda-forge channel:\n\n    conda install -c conda-forge clingo-dl\n\nFurthermore, releases and development versions can also be installed from the `potassco` and `potassco/label/dev` channels.\n\n# Installation using pip\n\nFor the latest release use:\n\n    pip install --upgrade clingo-dl\n\nor the latest development version:\n\n    pip install --upgrade --extra-index-url https://test.pypi.org/simple/ clingo-dl\n\n# Requirements\n\n- a C++17 conforming compiler\n  - *at least* [gcc] version 7.0\n  - *at least* [clang] version 4.0\n  - *at least* msvc++ 14.11 ([vs][Visual Studio] 2017 15.3)\n  - other compilers might work\n- the [cmake] build system\n  - at least version 3.16 is recommended\n  - at least version 3.1 is *required*\n- the [clingo] ASP solver\n  - *at least* version 5.5\n- optionally, the [python] programming language\n  - *at least* version 3.6\n\n# Build, Install, and Test\n\nTo build clingo-dl in its default configurations in release mode, run\n\n    cmake -H<SOURCE_DIR> -B<BUILD_DIR> -DCMAKE_BUILD_TYPE=Release\n    cmake --build <BUILD_DIR>\n\nThe resulting binaries and shared libraries will be in `<BUILD_DIR>/bin` and are ready to use.\n\nTo install all binaries and development files under cmake's install prefix (see the [build options](#build-options)), run\n\n    cmake --build <BUILD_DIR> --target install\n\n## Build Options\n\nThe most important options to control the build are\n\n- Variable `CMAKE_BUILD_TYPE` should be set to `Release`. (Default: unset)\n- Variable `CMAKE_INSTALL_PREFIX` controls where to install clingo-dl. (Default: `/usr/local/bin`)\n\nCmake's `-L` option can be used to get an overview over the variables that can be set for building clingo-dl.\nTo get clingo-dl specific options, run\n\n    cmake -H<SOURCE_DIR> -B<BUILD_DIR> -DCMAKE_BUILD_TYPE=Release -LH\n\nor, to also print important cmake specific configuration variables, run\n\n    cmake -H<SOURCE_DIR> -B<BUILD_DIR> -DCMAKE_BUILD_TYPE=Release -LAH\n\nOptions and variables can be passed to cmake on the command line using `-D<VARIABLE>=<VALUE>`\nor by editing `<BUILD_DIR>/CMakeCache.txt` after running cmake.\n\n[gcc]: https://gcc.gnu.org/\n[clang]: http://clang.llvm.org/\n[msvc]: https://www.visualstudio.com/\n[clingo]: https://github.com/potassco/clingo/\n[cmake]: https://www.cmake.org/\n[python]: https://www.python.org/\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/potassco/clingo-dl/master/INSTALL.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "  - [**Downloading source and binary releases**][download]\n  - [**Installation and software requirements**](INSTALL.md)\n  - [Changes between releases](CHANGES.md)\n  - [Potassco clingo-dl page][home] \n",
                    "original_header": "Clingo-dl: A grounder and solver for solving ASP modulo Difference Constraints"
                },
                "confidence": 0.9951029185784661,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/potassco/clingo-dl/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2016-11-07T11:26:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-12T17:09:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 217994
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 68172
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 21544
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 11481
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 6774
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 1119
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "336": {
        "filename": "henrygilbert22_phd_chatgpt_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "337": {
        "filename": "medicalvalues-public_mvrdf2vec_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "338": {
        "filename": "teshnizi_OptiMUS_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```bash\npip install -r requirements.txt\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "First install the requirement:",
                    "parent_header": [
                        "**OptiMUS**: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models",
                        "Running the code"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/teshnizi/OptiMUS/main/README.md"
            },
            {
                "result": {
                    "value": "```bash\ngrbgetkey YOUR_LICENSE\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Install gurobi and your license (for gurobi installation, please refer to the official website):",
                    "parent_header": [
                        "**OptiMUS**: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models",
                        "Running the code"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/teshnizi/OptiMUS/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-10-05T18:53:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T01:43:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 97021
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "339": {
        "filename": "egg-west_Stratega_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-07-17T13:37:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-03-17T10:51:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 1229967
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 32900
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 10909
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 4907
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "GLSL",
                    "name": "GLSL",
                    "type": "Programming_language",
                    "size": 794
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "340": {
        "filename": "pnnl_expert_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "This package can be installed locally as a static install using:\n\n``python setup.py install``\n\nor alternatively as a development install (incorporating updates when changes are made to files) using:\n\n``python setup.py develop``\n\n\n\nIf installed as a static install, the package must be reinstalled to incorporate updates.\n\n\nIf installed as a development install, changes to the files will be updated dynamically in the package without running subsequent installation commands.\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Install and Use",
                    "parent_header": [
                        "EXPERT"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/pnnl/expert/master/README.md"
            },
            {
                "result": {
                    "value": "To use the SPERT model for the local content graph:\n\n1. Clone the SPERT repo: https://github.com/lavis-nlp/spert\n2. Download the data and models:\n```\nbash ./scripts/fetch_datasets.sh\nbash ./scripts/fetch_models.sh\n```\n3. Point the local graph construction to the location of the SPERT repo:\n```\ngraph = lcg.localContentGraph(text=text,\n                              spert_path='/path/to/spert/')\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "SPERT Model",
                    "parent_header": [
                        "EXPERT",
                        "Install and Use",
                        "External Install Depencies"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/pnnl/expert/master/README.md"
            },
            {
                "result": {
                    "value": "Install GROBID using instructions here:\n[https://grobid.readthedocs.io/en/latest/Install-Grobid/](https://grobid.readthedocs.io/en/latest/Install-Grobid/).\n\nRun GROBID:\n```\njava -jar grobid-core/build/libs/grobid-core-0.6.2-onejar.jar -gH grobid-home -dIn /path/to/pdf/files/ -dOut /path/to/output/directory/  -exe processFullText -ignoreAssets\n```\n\nExamples for parsing the resulting XML files can be found in the GROBID Parsing Example notebook.\n\n\n<hr>\n\n\n",
                    "type": "Text_excerpt",
                    "original_header": "PDF parsing",
                    "parent_header": [
                        "EXPERT",
                        "Install and Use",
                        "External Install Depencies"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/pnnl/expert/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-07-23T20:45:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-21T03:17:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 745218
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 16804
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "341": {
        "filename": "ftaglino_SemanticRelatednessInRDFGraph_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2017-03-02T14:32:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2020-07-24T07:30:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 416083
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "342": {
        "filename": "Dtradke_Teams_IPD_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The code is run by: python3 main.py\n \n",
                    "original_header": "Teams_IPD"
                },
                "confidence": 0.9014495858729799,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Dtradke/Teams_IPD/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-05-02T19:43:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-09-20T03:41:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 70294
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "343": {
        "filename": "wulongfeng_CaliRare_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-02-02T14:36:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-10T08:02:52Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 58420
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 110
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "344": {
        "filename": "aig-upf_best-first-generalized-planning_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-07-20T11:05:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2021-07-29T09:35:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 110466
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 53351
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 17973
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "345": {
        "filename": "google-research_vision_transformer_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Make sure you have `Python>=3.10` installed on your machine.\n\nInstall JAX and python dependencies by running:\n\n```\n# If using GPU:\npip install -r vit_jax/requirements.txt\n\n# If using TPU:\npip install -r vit_jax/requirements-tpu.txt\n```\n\nFor newer versions of [JAX](https://github.com/google/jax), follow the instructions\nprovided in the corresponding repository linked here. Note that installation\ninstructions for CPU, GPU and TPU differs slightly.\n\nInstall [Flaxformer](https://github.com/google/flaxformer), follow the instructions\nprovided in the corresponding repository linked here.\n\nFor more details refer to the section [Running on cloud](#running-on-cloud)\nbelow.\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Vision Transformer and MLP-Mixer Architectures"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/google-research/vision_transformer/main/README.md"
            },
            {
                "result": {
                    "value": "And then fetch the repository and the install dependencies (including `jaxlib`\nwith TPU support) as usual:\n\n```bash\ngit clone --depth=1 --branch=master https://github.com/google-research/vision_transformer\ncd vision_transformer\n\n# optional: install virtualenv\npip3 install virtualenv\npython3 -m virtualenv env\n. env/bin/activate\n```\n\nIf you're connected to a VM with GPUs attached, install JAX and other dependencies with the following\ncommand:\n\n```bash\npip install -r vit_jax/requirements.txt\n```\n\nIf you're connected to a VM with TPUs attached, install JAX and other dependencies with the following\ncommand:\n\n```bash\npip install -r vit_jax/requirements-tpu.txt\n```\n\nInstall [Flaxformer](https://github.com/google/flaxformer), follow the instructions\nprovided in the corresponding repository linked here.\n\nFor both GPUs and TPUs, Check that JAX can connect to attached accelerators with the command:\n```bash\npython -c 'import jax; print(jax.devices())'\n```\n\nAnd finally execute one of the commands mentioned in the section\n[fine-tuning a model](#fine-tuning-a-model).\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup VM",
                    "parent_header": [
                        "Vision Transformer and MLP-Mixer Architectures",
                        "Running on cloud"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/google-research/vision_transformer/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n[`timm`]: https://github.com/rwightman/pytorch-image-models\n[sayakpaul/collections/vision_transformer]: https://tfhub.dev/sayakpaul/collections/vision_transformer\n[Sayak Paul]: https://github.com/sayakpaul \n",
                    "original_header": "Colab"
                },
                "confidence": 0.9999994778781711,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/vision_transformer/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For example for fine-tuning a ViT-B/16 (pre-trained on imagenet21k) on CIFAR10\n(note how we specify `b16,cifar10` as arguments to the config, and how we\ninstruct the code to access the models directly from a GCS bucket instead of\nfirst downloading them into the local directory):\n```bash\npython -m vit_jax.main --workdir=/tmp/vit-$(date +%s) \\\n    --config=$(pwd)/vit_jax/configs/vit.py:b16,cifar10 \\\n    --config.pretrained_dir='gs://vit_models/imagenet21k'\n```\nIn order to fine-tune a Mixer-B/16 (pre-trained on imagenet21k) on CIFAR10:\n```bash\npython -m vit_jax.main --workdir=/tmp/vit-$(date +%s) \\\n    --config=$(pwd)/vit_jax/configs/mixer_base16_cifar10.py \\\n    --config.pretrained_dir='gs://mixer_models/imagenet21k'\n```\nThe \"How to train your ViT? ...\" paper added >50k checkpoints that you can\nfine-tune with the [`configs/augreg.py`] config. When you only specify the model\nname (the `config.name` value from [`configs/model.py`]), then the best i21k\ncheckpoint by upstream validation accuracy (\"recommended\" checkpoint, see\nsection 4.5 of the paper) is chosen. To make up your mind which model you want\nto use, have a look at Figure 3 in the paper. It's also possible to choose a\ndifferent checkpoint (see Colab [`vit_jax_augreg.ipynb`]) and then specify the\nvalue from the `filename` or `adapt_filename` column, which correspond to the\nfilenames without `.npz` from the [`gs://vit_models/augreg`] directory.\n```bash\npython -m vit_jax.main --workdir=/tmp/vit-$(date +%s) \\\n    --config=$(pwd)/vit_jax/configs/augreg.py:R_Ti_16 \\\n    --config.dataset=oxford_iiit_pet \\\n    --config.base_lr=0.01\n```\n \nCurrently, the code will automatically download CIFAR-10 and CIFAR-100 datasets.\nOther public or custom datasets can be easily integrated, using [tensorflow\ndatasets library](https://github.com/tensorflow/datasets/). Note that you will\nalso need to update `vit_jax/input_pipeline.py` to specify some parameters about\nany added dataset. \nTo see a detailed list of all available flags, run `python3 -m vit_jax.train\n--help`. \n- Different models require different amount of memory. Available memory also\n  depends on the accelerator configuration (both type and count). If you\n  encounter an out-of-memory error you can increase the value of\n  `--config.accum_steps=8` -- alternatively, you could also decrease the\n  `--config.batch=512` (and decrease `--config.base_lr` accordingly).\n- The host keeps a shuffle buffer in memory. If you encounter a host OOM (as\n  opposed to an accelerator OOM), you can decrease the default\n  `--config.shuffle_buffer=50000`. \n",
                    "original_header": "Fine-tuning a model"
                },
                "confidence": 0.9994999793209893,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/vision_transformer/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We provide a variety of ViT models in different GCS buckets. The models can be\ndownloaded with e.g.:\n```\nwget https://storage.googleapis.com/vit_models/imagenet21k/ViT-B_16.npz\n```\n \n",
                    "original_header": "Available ViT models"
                },
                "confidence": 0.984647946321693,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/vision_transformer/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For installation follow [the same steps](#installation) as above.\n \n",
                    "original_header": "MLP-Mixer"
                },
                "confidence": 0.9693587137165897,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/vision_transformer/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://console.cloud.google.com/storage/mixer_models/ \nNote that these models are also available directly from TF-Hub:\n[sayakpaul/collections/mlp-mixer] (external contribution by [Sayak\nPaul]). \n",
                    "original_header": "Available Mixer models"
                },
                "confidence": 0.943407897301066,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/vision_transformer/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n[GSAM]: https://arxiv.org/abs/2203.08065\n[SAM]: https://arxiv.org/abs/2010.01412\n[AugReg]: https://arxiv.org/abs/2106.10270 \n[`vit_jax/configs/models.py`]: https://github.com/google-research/vision_transformer/blob/main/vit_jax/configs/models.py\n[`model_cards/lit.md`]: https://github.com/google-research/vision_transformer/blob/main/model_cards/lit.md \n[`gs://vit_models/imagenet21k`]: https://console.cloud.google.com/storage/browser/vit_models/imagenet21k/\n[`gs://vit_models/imagenet21k+imagenet2012`]: https://console.cloud.google.com/storage/browser/vit_models/imagenet21k+imagenet2012/\n[`gs://vit_models/augreg`]: https://console.cloud.google.com/storage/browser/vit_models/augreg/\n[`gs://vit_models/sam`]: https://console.cloud.google.com/storage/browser/vit_models/sam/\n[`gs://mixer_models/sam`]: https://console.cloud.google.com/storage/mixer_models/sam/\n[`gs://vit_models/gsam`]: https://console.cloud.google.com/storage/browser/vit_models/gsam/\n[`gs://mixer_models/gsam`]: https://console.cloud.google.com/storage/mixer_models/gsam/\n \n",
                    "original_header": "Disclaimers"
                },
                "confidence": 0.9990599087097273,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google-research/vision_transformer/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-10-21T12:35:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T08:58:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 2702144
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 117118
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "346": {
        "filename": "Zaiwen_ModelCorrection_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-09-10T07:08:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-08-22T00:06:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 7523394
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 4521615
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 2031827
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Julia",
                    "name": "Julia",
                    "type": "Programming_language",
                    "size": 1340270
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 953830
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 158403
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 108915
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Less",
                    "name": "Less",
                    "type": "Programming_language",
                    "size": 19818
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "GAP",
                    "name": "GAP",
                    "type": "Programming_language",
                    "size": 6334
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2305
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 831
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Ruby",
                    "name": "Ruby",
                    "type": "Programming_language",
                    "size": 537
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 189
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "347": {
        "filename": "thuiar_MIntRec_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-09-09T09:47:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-08T11:17:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 219925
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "348": {
        "filename": "aiwc_test__2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "349": {
        "filename": "rballester_yodo_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-06-15T19:32:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-15T18:44:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 139243
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 7639
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "350": {
        "filename": "gyunamister_impacta_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "*IMPACTA* is an interactive tool implementing digital twins of organizations supporting impact analysis of changes in Process-Aware Information Systems (PAIS). \n",
                    "type": "Text_excerpt",
                    "original_header": "Tool manual - IMPACTA"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "We first need to design DT-IMs based on event data and user inputs. \n",
                    "type": "Text_excerpt",
                    "original_header": "1. **Designing Digital Twin Interface Models (DT-IMs)**",
                    "parent_header": [
                        "User Manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- Input: OCEL, guards, valves, activity variants\n- output: Digitalt Twin Interface Model (DT-IM)\n",
                    "type": "Text_excerpt",
                    "original_header": "1.1. Input and output (see Appendix for details)",
                    "parent_header": [
                        "User Manual",
                        "1. **Designing Digital Twin Interface Models (DT-IMs)**"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- Go to **Home**. As shown below, 1) Import OCEL JSON and 2) Preview the data and parse it.\n    \n    ![Untitled](resources/Untitled.png)\n    \n- Go to **Design**. As shown below, 1) discover an OCPN, 2) upload valves, 3) upload guards, and 4) upload activity variants, and 5) connect to the target information system. You can see the discovered OCPN, uploaded valves, uploaded guards, and uploaded activity variants in the same page.\n    \n    ![Untitled](resources/Untitled%201.png)\n    \n- As shown below, 1) apply valves, 2) apply guards, and 3) apply activity variants to enhance the discovered OCPN and produce an DT-IM.\n    \n    ![Untitled](resources/Untitled%202.png)\n    \n",
                    "type": "Text_excerpt",
                    "original_header": "1.2. How to",
                    "parent_header": [
                        "User Manual",
                        "1. **Designing Digital Twin Interface Models (DT-IMs)**"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "Next, we enhance the DT-IM discovered in the previous step to the target information system by synchronizing current configurations (hence updating control views) and importing streaming event data (hence updating operational views).\n",
                    "type": "Text_excerpt",
                    "original_header": "2. Synchronizing to the target information system and updating control/operational views of DT-IM.",
                    "parent_header": [
                        "User Manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- Input:\n    - user inputs\n    - DT-IM\n- Output\n    - DT-IM enhanced with up-to-date control/operational views\n",
                    "type": "Text_excerpt",
                    "original_header": "2.1. Input and Output",
                    "parent_header": [
                        "User Manual",
                        "2. Synchronizing to the target information system and updating control/operational views of DT-IM."
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- Go to **Dashboard & Impact Analysis** and click Sync To Information System to synchronize the DT-IM with the target information system. The synchronization is based on the connection to the target system done in the previous step.\n- Go to Control-View, and you can see the current configuration, i.e., 1) current valve settings and 2) activity variant settings with 3) the DT-IM.\n    \n    ![Untitled](resources/Untitled%203.png)\n    \n- Go to Operational-View, and you can see the current operational states, i.e., 1) marking, 2) object value mapping, and 3) diagnostics as below. By clicking a place, you can see the marking of the place. The diagnostics are provided by selecting the analysis period and types of diagnostics.\n    \n    ![Untitled](resources/Untitled%204.png)\n    \n    ![Untitled](resources/Untitled%205.png)\n    \n",
                    "type": "Text_excerpt",
                    "original_header": "2.2. How to",
                    "parent_header": [
                        "User Manual",
                        "2. Synchronizing to the target information system and updating control/operational views of DT-IM."
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "To analyze the impact of changes incurred by actions, we design actions. An action consists of 1) changes in valves and 2) changes activity variants.\n",
                    "type": "Text_excerpt",
                    "original_header": "3. Defining Actions",
                    "parent_header": [
                        "User Manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- Input\n    - User inputs\n    - DT-IM\n- Output\n    - Action defined over DT-IM (Python Object)\n",
                    "type": "Text_excerpt",
                    "original_header": "3.1. Input and Output",
                    "parent_header": [
                        "User Manual",
                        "3. Defining Actions"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- Go to Action Definition. As shown below, 1) specify action name, 2) define valve changes by adjusting knots, and 3) define activity variant changes by choosing activity variants.\n    \n    ![Untitled](resources/Untitled%206.png)\n    \n",
                    "type": "Text_excerpt",
                    "original_header": "3.2. How to",
                    "parent_header": [
                        "User Manual",
                        "3. Defining Actions"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- Input\n    - User inputs\n    - DT-IM\n- Output\n    - Action Instance defined over DT-IM (Python Object)\n",
                    "type": "Text_excerpt",
                    "original_header": "4.1. Input and Output",
                    "parent_header": [
                        "User Manual",
                        "4. Designing Action Instances"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- Go to **Dashboard & Impact Analysis**. As shown below, 1) select an action, 2) specify the start and end time of executing the action, and 3) add an action instance. The timeline shows the overview of defined action instances.\n    \n    ![Untitled](resources/Untitled%207.png)\n    \n",
                    "type": "Text_excerpt",
                    "original_header": "4.2. How to",
                    "parent_header": [
                        "User Manual",
                        "4. Designing Action Instances"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "At the start time of the action instance, we analyze pre-action impacts with multiple impact measures. At the end time of the action instance, we analyze post-action impacts with multiple impact measures. \n\nThe impact analysis aims to analyze the impact of the action instance by continuously evaluating the streaming event data from the target information system. To ease the introduction of its functionality, we use the simulation of the target information system that we can flexibly control, i.e., start it and forward it whenever we want to evaluate an action instance.\n",
                    "type": "Text_excerpt",
                    "original_header": "5. Impact Analysis",
                    "parent_header": [
                        "User Manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- Input\n    - Streaming event data\n    - DT-IM\n- Output\n    - pre/post-action impact scores\n",
                    "type": "Text_excerpt",
                    "original_header": "5.1. Input and Output",
                    "parent_header": [
                        "User Manual",
                        "5. Impact Analysis"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- As shown below, specify 1) the simulation step size (i.e., how much time of the reality each step will represent) and 2) the number of simulation steps (i.e., how many simulation steps we will use) Afterward, you can control the simulation by 3) starting the simulation of the target information system and 4) moving forward each step.\n    \n    ![Untitled](resources/Untitled%208.png)\n    \n- As shown below, 1) the vertical line in the timeline represents the progress of the simulation.  Once an action instance has been effective, we can 2) click the action instance in the timeline to see the pre-action impact scores as below. Moreover, by clicking the green box, we can analyze the impacted entities. Once an action instance is finished, we can click the action instance in the timeline to see the post-action impact scores as below.\n    \n    ![Untitled](resources/Untitled%209.png)\n    \n",
                    "type": "Text_excerpt",
                    "original_header": "5.2. How to",
                    "parent_header": [
                        "User Manual",
                        "5. Impact Analysis"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "For automatic and platform-independent deployment, simply execute the following commands:\n```shell script\ngit clone https://github.com/gyunamister/impacta.git\ncd src/\ndocker-compose up\n```\nAfter installations, the web service is available at *127.0.0.1/8050*. \nThe default username is *admin*, and the default password is *test123* for logging into the system.\nIf you would like the Dash web service to run in debug mode, then change the value of the environment variable **DEBUG_MODE** in the [env file](src/.env) to **true**.\n\nExample logs are available at [examples](example-files/).\n",
                    "type": "Text_excerpt",
                    "original_header": "Automatic",
                    "parent_header": [
                        "User Manual",
                        "Deployment"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "Please make sure to install the binaries of [Graphviz](https://graphviz.org/) and [Python 3.8.3](https://www.python.org/downloads/release/python-383/) before you proceed. In the following, shell scripts are developed for the zsh, so if you use a different shell, then you need to modify the scripts accordingly.\n\nIn the first shell:\n\n```bash\ngit clone https://github.com/gyunamister/impacta.git\ngit clone https://github.com/gyunamister/ocpa.git\ncd impacta/src/backend/db\ndocker-compose up\n```\n\nIn the second shell:\n\n```bash\nexport DTWEEN_PATH=<path_to_your_impacta_root> # impacta/\nexport OCPA_PATH=<path_to_your_ocpa_root> # ocpa/\ncd impacta/src/backend\nchmod +x ./run_celery.sh\n./run_celery.sh\n```\n\nAlternatives to Windows:\n\n```bash\npip install eventlet  \nset REDIS_LOCALHOST_OR_DOCKER=localhost\nset RABBIT_LOCALHOST_OR_DOCKER=localhost\nset RABBITMQ_USER=dtween\nset RABBITMQ_PASSWORD=dtween92! \ncd src/server/backend/tasks\ncelery -A tasks worker --loglevel=INFO -P eventlet\n```\n\nIn the third shell:\n\n```bash\nexport DTWEEN_PATH=<path_to_your_impacta_root> # impacta/\nexport OCPA_PATH=<path_to_your_ocpa_root> # ocpa/\ncd impacta/src/backend\nchmod +x ./run_dtween.sh\n./run_dtween.sh\n```\n\nThe default username is admin, and the default password is test123 for logging into the system available at 127.0.0.1/8050.\n\n### Automatic\n\nTBD\n",
                    "type": "Text_excerpt",
                    "original_header": "Manual",
                    "parent_header": [
                        "User Manual",
                        "Deployment"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "To facilitate the test of the tool, we provide an experimental environment with an information system supporting a Purchase-To-Pay(P2P) process.\n",
                    "type": "Text_excerpt",
                    "original_header": "Target information system",
                    "parent_header": [
                        "User Manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            },
            {
                "result": {
                    "value": "- OCEL: [standard OCEL format](http://ocel-standard.org/)\n    - Example:\n        \n        ```json\n        {\n            \"ocel:global-event\": {\n                \"ocel:activity\": \"__INVALID__\"\n            },\n            \"ocel:global-object\": {\n                \"ocel:type\": \"__INVALID__\"\n            },\n            \"ocel:global-log\": {\n                \"ocel:attribute-names\": [\n                    \"type\",\n                    \"price\"\n                ],\n                \"ocel:object-types\": [\n                    \"order\",\n                    \"item\",\n                    \"route\"\n                ],\n                \"ocel:version\": \"1.0\",\n                \"ocel:ordering\": \"timestamp\"\n            },\n            \"ocel:events\": {\n                \"1c8428e6-3ad8-44f0-b0a6-76027ddd6fe6\": {\n                    \"ocel:activity\": \"place_order\",\n                    \"ocel:timestamp\": \"2021-06-01 17:54:02\",\n                    \"ocel:omap\": [\n                        \"o0\",\n                        \"i0a\",\n                        \"i0b\"\n                    ],\n                    \"ocel:vmap\": {\n                        \"resource\": \"po_machine\"\n                    }\n                },\n        \t\t\t\t...\n        \t\t},\n        \t\t\"ocel:objects\": {\n                \"o0\": {\n                    \"ocel:type\": \"order\",\n                    \"ocel:ovmap\": {\n                        \"price\": 231\n                    }\n                },\n        \t\t\t\t...\n        \t\t}\n        }\n        ```\n        \n- guards: JSON-based format\n    - Example\n    \n    ```json\n    {\n        \"guards\": [\n            {\n                \"transition\": \"Create Purchase Requisition\",\n                \"guard\": \"[Material.planned_delivery_days >= {min_planned_delivery_days}]\"\n            },\n            {\n                \"transition\": \"Create Purchase Order\",\n                \"guard\": \"[Material.net_price - Material.effective_price <= {max_price_diff}, Material.quantity >= {min_order_quantity}]\"\n            },\n            ...\n        ]\n    }\n    ```\n    \n- valves: JSON-based format\n    - Example\n    \n    ```json\n    {\n        \"valves\": {\n            \"min_planned_delivery_days\": {\n                \"r_min\": 0,\n                \"r_max\": 100,\n                \"default\": 5\n            },\n            \"max_price_diff\": {\n                \"r_min\": 100,\n                \"r_max\": 1000,\n                \"default\": 200\n            },\n            \"min_order_quantity\": {\n                \"r_min\": 0,\n                \"r_max\": 100,\n                \"default\": 5\n            },\n    \t\t\t\t...\n        }\n    }\n    ```\n    \n- Output:\n    - Digital Twin Interface Model: Python object\n- system information: JSON-based format\n    - Example\n        \n        ```json\n        {\n            \"dir-event-stream\": \"<path-to-event-stream>\",\n            \"dir-system-config\": \"<path-to-system-configuration>\"\n        }\n        ```\n        \n        The event stream must be in OCEL: [standard OCEL format](http://ocel-standard.org/). The system configuration is JSON-based format.\n",
                    "type": "Text_excerpt",
                    "original_header": "Appendix 1: Input and Output",
                    "parent_header": [
                        "User Manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/impacta/impact-analysis/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-01-04T14:54:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-01-08T08:51:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 601182
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 2155
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2080
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 54
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "351": {
        "filename": "yanneta_learning_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "352": {
        "filename": "whitemech_planning-for-past-temporal-goals_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "- from PyPI: \n\n```\npip install plan4past\n```\n\n- from source (`main` branch): \n\n```\npip install git+https://github.com/whitemech/Plan4Past.git\n```\n\nor, clone the repository and install:\n\n```\ngit clone https://github.com/whitemech/Plan4Past.git\ncd Plan4Past\npip install .\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/whitemech/planning-for-past-temporal-goals/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- To use Apptainer:\n```\napptainer build plan4past.sif plan4past.def\n\n# to launch the tool:\n./plan4past.sif -d examples/pddl/domain.pddl -p examples/pddl/p-0.pddl -g \"ontable_c & O(on_b_a)\"\n``` \n",
                    "original_header": "Docker &amp; Apptainer images"
                },
                "confidence": 0.923568791942435,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/whitemech/planning-for-past-temporal-goals/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "If you want to contribute, set up your development environment as follows: \n- Intall [Poetry](https://python-poetry.org)\n- Clone the repository: `git clone https://github.com/whitemech/Plan4Past.git && cd Plan4Past`\n- Install the dependencies: `poetry shell && poetry install`\n \n",
                    "original_header": "Development"
                },
                "confidence": 0.9997029580168644,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/whitemech/planning-for-past-temporal-goals/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To build the docs: `mkdocs build` \n",
                    "original_header": "Docs"
                },
                "confidence": 0.9919383757396745,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/whitemech/planning-for-past-temporal-goals/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-11-02T10:41:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-19T16:27:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 234586
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 3324
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1841
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "353": {
        "filename": "yunshengtian_DGEMO_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "If you are interested in trying DGEMO for your own problems, here are the necessary steps:\n\n- First, to define your custom problem, here is a basic template assuming you put this file as `problems/myproblem.py`.  Here in `__init__()`, we set 3 design variables (`n_var`), 2 objectives (`n_obj`), 0 constraints (`n_constr`), the lower bound of the design variables as 0 (`xl`) and upper bound as 1 (`xu`). Next, the objective evaluation function is defined as `_evaluate_F()`, where the argument `x` is a batch of design variables. As a simple example, we define the first objective as the first design variable, and the second objective as the second design variable subtracting the third design variable. \n\n```python\nimport numpy as np\nfrom .problem import Problem\n\nclass MyProblem(Problem):\n  \n  \tdef __init__(self):\n      \tsuper().__init__(n_var=3, n_obj=2, n_constr=0, xl=0, xu=1)\n        \n    def _evaluate_F(self, x):\n      \tx1, x2, x3 = x[:, 0], x[:, 1], x[:, 2]\n        f1 = x1\n        f2 = x2 - x3\n        return np.column_stack([f1, f2])\n```\n\n- Add the following line to `problems/__init__.py`:\n\n```python\nfrom problems.myproblem import MyProblem\n```\n\n- Append a tuple `('myproblem', MyProblem)` to the `problems` variable in `get_problem_options()` in `problems/common.py` such that our problem is callable from command line arguments.\n- To run optimization on the custom problem, run `main.py` with `--problem myproblem` and other necessary arguments.\n\nFor more examples of predefined optimization problems, please refer to `problems/`.\n",
                    "type": "Text_excerpt",
                    "original_header": "Custom Problem Setup",
                    "parent_header": [
                        "Diversity-Guided Efficient Multi-Objective Optimization (DGEMO)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/yunshengtian/DGEMO/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<img src=\"https://github.com/yunshengtian/DGEMO/blob/master/assets/spaces_readme.png?raw=true\" width=\"500\"> \n",
                    "original_header": "Diversity-Guided Efficient Multi-Objective Optimization (DGEMO)"
                },
                "confidence": 0.9943167573484024,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/yunshengtian/DGEMO/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To reproduce this result, run the following command:\n```\npython scripts/run.py --algo nsga2 parego moead-ego tsemo usemo-ei dgemo --problem zdt1 zdt2 zdt3 dtlz1 dtlz2 dtlz3 dtlz4 dtlz5 dtlz6 oka1 oka2 vlmop2 vlmop3 re1 re2 re3 re4 re5 re6 re7 --batch-size 10 --n-iter 20 --n-seed 10\n```\n \nTo visualize this figure, run the following command:\n```\npython visualization/visualize_hv_all.py\n```\n \n",
                    "original_header": "Performance"
                },
                "confidence": 0.9801557242478773,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/yunshengtian/DGEMO/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Note if you don't specify `--problem` or `--algo` arguments, it will automatically find all the problems or algorithms you have in the result folder.\n \n",
                    "original_header": "Visualization"
                },
                "confidence": 0.9967686567734241,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/yunshengtian/DGEMO/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-06-28T04:00:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-15T13:48:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 186512
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "354": {
        "filename": "mcinnes_umap_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "UMAP depends upon ``scikit-learn``, and thus ``scikit-learn``'s dependencies\nsuch as ``numpy`` and ``scipy``. UMAP adds a requirement for ``numba`` for\nperformance reasons. The original version used Cython, but the improved code\nclarity, simplicity and performance of Numba made the transition necessary.\n\nRequirements:\n\n* Python 3.6 or greater\n* numpy\n* scipy\n* scikit-learn\n* numba\n* tqdm\n* `pynndescent <https://github.com/lmcinnes/pynndescent>`_\n\nRecommended packages:\n\n* For plotting\n   * matplotlib\n   * datashader\n   * holoviews\n* for Parametric UMAP\n   * tensorflow > 2.0.0\n\n**Install Options**\n\nConda install, via the excellent work of the conda-forge team:\n\n.. code:: bash\n\n    conda install -c conda-forge umap-learn\n\nThe conda-forge packages are available for Linux, OS X, and Windows 64 bit.\n\nPyPI install, presuming you have numba and sklearn and all its requirements\n(numpy and scipy) installed:\n\n.. code:: bash\n\n    pip install umap-learn\n\nIf you wish to use the plotting functionality you can use\n\n.. code:: bash\n\n    pip install umap-learn[plot]\n\nto install all the plotting dependencies.\n\nIf you wish to use Parametric UMAP, you need to install Tensorflow, which can be\ninstalled either using the instructions at https://www.tensorflow.org/install\n(recommended) or using\n\n.. code:: bash\n\n    pip install umap-learn[parametric_umap]\n\nfor a CPU-only version of Tensorflow.\n\nIf you're on an x86 processor, you can also optionally install `tbb`, which will\nprovide additional CPU optimizations:\n\n.. code:: bash\n\n    pip install umap-learn[tbb]\n\nIf pip is having difficulties pulling the dependencies then we'd suggest installing\nthe dependencies manually using anaconda followed by pulling umap from pip:\n\n.. code:: bash\n\n    conda install numpy scipy\n    conda install scikit-learn\n    conda install numba\n    pip install umap-learn\n\nFor a manual install get this package:\n\n.. code:: bash\n\n    wget https://github.com/lmcinnes/umap/archive/master.zip\n    unzip master.zip\n    rm master.zip\n    cd umap-master\n\nOptionally, install the requirements through Conda:\n\n.. code:: bash\n\n    conda install scikit-learn numba\n\nThen install the package\n\n.. code:: bash\n\n    python -m pip install -e .\n\n---------------",
                    "type": "Text_excerpt",
                    "original_header": "Installing"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/lmcinnes/umap/master/README.rst"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Second, UMAP scales well in embedding dimension\u2014it isn't just for\nvisualisation! You can use UMAP as a general purpose dimension reduction\ntechnique as a preliminary step to other machine learning tasks. With a\nlittle care it partners well with the `hdbscan\n<https://github.com/scikit-learn-contrib/hdbscan>`_ clustering library (for\nmore details please see `Using UMAP for Clustering\n<https://umap-learn.readthedocs.io/en/latest/clustering.html>`_). \n",
                    "original_header": "Benefits of UMAP"
                },
                "confidence": 0.9999800377695582,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/lmcinnes/umap/master/README.rst"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "This functionality is built upon the densMAP `implementation <https://github.com/hhcho/densvis>`_ provided by the developers\nof densMAP, who also contributed to integrating densMAP into the umap package. \nSee `the documentation <https://umap-learn.readthedocs.io/en/0.5dev/densmap_demo.html>`_ for more details. \n",
                    "original_header": "densMAP"
                },
                "confidence": 0.9966028413004736,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/lmcinnes/umap/master/README.rst"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": ".. |pypi_version| image:: https://img.shields.io/pypi/v/umap-learn.svg\n.. _pypi_version: https://pypi.python.org/pypi/umap-learn/ \n.. |pypi_downloads| image:: https://pepy.tech/badge/umap-learn/month\n.. _pypi_downloads: https://pepy.tech/project/umap-learn \n.. |conda_version| image:: https://anaconda.org/conda-forge/umap-learn/badges/version.svg\n.. _conda_version: https://anaconda.org/conda-forge/umap-learn \n.. |conda_downloads| image:: https://anaconda.org/conda-forge/umap-learn/badges/downloads.svg\n.. _conda_downloads: https://anaconda.org/conda-forge/umap-learn \n.. |License| image:: https://img.shields.io/pypi/l/umap-learn.svg\n.. _License: https://github.com/lmcinnes/umap/blob/master/LICENSE.txt \n.. |build_status| image:: https://dev.azure.com/TutteInstitute/build-pipelines/_apis/build/status/lmcinnes.umap?branchName=master\n.. _build_status: https://dev.azure.com/TutteInstitute/build-pipelines/_build/latest?definitionId=2&branchName=master \n.. |Coverage| image:: https://coveralls.io/repos/github/lmcinnes/umap/badge.svg\n.. _Coverage: https://coveralls.io/github/lmcinnes/umap \n.. |Docs| image:: https://readthedocs.org/projects/umap-learn/badge/?version=latest\n.. _Docs: https://umap-learn.readthedocs.io/en/latest/?badge=latest \n"
                },
                "confidence": 0.9974492623874617,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/lmcinnes/umap/master/README.rst"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-07-02T01:11:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T15:53:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 8535093
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 3613
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 690
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 428
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "355": {
        "filename": "fastai_imagenette_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2019-03-06T01:58:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T11:31:38Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 20171
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "356": {
        "filename": "maximecb_gym-miniworld_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "# Installation\n\nTo install `miniworld`, the easiest way is to use `pip`:\n\n```bash\npip install miniworld\n```\n\nHowever, if you would like to build on top of `miniworld`, you would need to install it from source. To do this, first clone the repository:\n\n```bash\ngit clone https://github.com/Farama-Foundation/Miniworld.git\n```\n\nThen, install the package:\n\n```bash\ncd Miniworld\npython3 -m pip install .\n```\n\nIf you want to install the package in [development mode](https://setuptools.pypa.io/en/latest/userguide/development_mode.html), use the following command instead:\n\n```bash\npython3 -m pip install -e .\n```\n\nAn installation in development mode (i.e., an editable install) is useful if you want to modify the source code of `miniworld` and have your changes take effect immediately.",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/maximecb/gym-miniworld/master/docs/content/installation.md"
            },
            {
                "result": {
                    "value": "Requirements:\n- Python 3.7+\n- Gymnasium\n- NumPy\n- Pyglet (OpenGL 3D graphics)\n- GPU for 3D graphics acceleration (optional)\n\nYou can install it from `PyPI` using:\n\n```console\npython3 -m pip install miniworld\n```\n\nYou can also install from source:\n\n```console\ngit clone https://github.com/Farama-Foundation/Miniworld.git\ncd Miniworld\npython3 -m pip install -e .\n```\n\nIf you run into any problems, please take a look at the [troubleshooting guide](docs/troubleshooting.md).\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/maximecb/gym-miniworld/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-08-28T03:12:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-07T16:00:14Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 159313
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 721
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 484
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "357": {
        "filename": "jeroenmiddelhuis_LearningResourceAllocation_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Alternatively, you can use the `requirements.txt` file to install the appropriate libraries. \n",
                    "original_header": "LearningResourceAllocation"
                },
                "confidence": 0.9999998995804923,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/jeroenmiddelhuis/LearningResourceAllocation/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-02-03T14:28:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-15T18:14:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 3707582
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 132932
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "358": {
        "filename": "j-easy_easy-rules_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "As of December 2020, Easy Rules is in maintenance mode. This means only bug fixes will be addressed from now on.\nVersion 4.1.x is the only supported version. Please consider upgrading to this version at your earliest convenience.\n \n",
                    "original_header": "Project status"
                },
                "confidence": 0.902645934334321,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/j-easy/easy-rules/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You are welcome to contribute to the project with pull requests on GitHub.\nPlease note that Easy Rules is in [maintenance mode](https://github.com/j-easy/easy-rules#project-status),\nwhich means only pull requests for bug fixes will be considered. \nIf you believe you found a bug or have any question, please use the [issue tracker](https://github.com/j-easy/easy-rules/issues).\n \n",
                    "original_header": "Contribution"
                },
                "confidence": 0.9974222558951196,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/j-easy/easy-rules/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* [Apache Nifi](https://nifi.apache.org) (see [Nifi EasyRules Bundle](https://github.com/apache/nifi/tree/rel/nifi-1.12.1/nifi-nar-bundles/nifi-easyrules-bundle))\n* [Open Remote](https://openremote.io) (see [build.gradle](https://github.com/openremote/openremote/blob/v1.0.4/model/build.gradle#L27))\n* [Open Smart Register Platform](http://smartregister.org) (see [build.gradle](https://github.com/OpenSRP/opensrp-client-anc/blob/v1.5.0/opensrp-anc/build.gradle#L196))\n* [Toad Edge by Quest](https://support.quest.com/fr-fr/technical-documents/toad-edge/2.1/user-guide/14)\n* [Extreme Networks](https://cloud.kapostcontent.net/pub/c4c24aae-b82d-44e4-8d86-01c235e4b40f/open-source-declaration-for-extr-xmc-8-dot-5)\n \n",
                    "original_header": "Who is using Easy Rules?"
                },
                "confidence": 0.9363169767313002,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/j-easy/easy-rules/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2013-03-10T14:38:26Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T07:38:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 436511
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "359": {
        "filename": "echalmers_modulated_td_error_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Preprint version available at https://doi.org/10.48550/arXiv.2205.09729\n \n",
                    "original_header": "modulated_td_error"
                },
                "confidence": 0.9184991954536311,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/echalmers/modulated_td_error/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-07-10T16:23:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-07-10T16:27:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 21258
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "360": {
        "filename": "ryangpeixu_pg3_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For any questions or issues with the code, please email ryanyang@mit.edu and tslvr@mit.edu. \nInstructions for running (tested on OS X and Ubuntu 18.04):\n* Use Python 3.6 or higher.\n* Download Python dependencies: `pip install -r requirements.txt`. \n",
                    "original_header": "PG3: Policy-Guided Planning for Generalized Policy Generation"
                },
                "confidence": 0.9768898793106053,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ryangpeixu/pg3/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-04-21T21:32:21Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-07T23:42:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 84698
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 715
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "361": {
        "filename": "wiio12_LEGO-Prover_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "LEGO-Prover is only tested under Python 3.11.4, but with high possibility compatible with lower Python versions. We have tested the LEGO-Prover under Ubuntu 18.04. You need to follow the instructions bellow to install LEGO-Prover.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/wiio12/LEGO-Prover/master/README.md"
            },
            {
                "result": {
                    "value": "You could begin with cloning the project to local directory\n```shell\ngit clone https://github.com/wiio12/LEGO-Prover.git\ncd LEGO-Prover\npip install -e .\npip install protobuf==3.20.3\n```\n**Noet:** the pip might give error about incompatible versions for `protobuf` and `grpcio-tools`, but it works fine (at lease for me).\n",
                    "type": "Text_excerpt",
                    "original_header": "Python Install",
                    "parent_header": [
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/wiio12/LEGO-Prover/master/README.md"
            },
            {
                "result": {
                    "value": "[PISA](https://github.com/albertqjiang/Portal-to-ISAbelle) (Portal to ISAbelle) is a REPL wrapper for Isabelle theorem prover. LEGO-Prover utilize PISA to communicate with Isabelle theorem prover and verify the formal code. You should follow the instruction bellow to install PISA and Isabelle. **This process might be struggling**\n\n1. **Scala configuration**\n   \n    Install SDKMAN\n    ```shell\n    cd ~\n    curl -s \"https://get.sdkman.io\" | bash\n    source .bashrc\n    ```\n    \n    Install JAVA 11 and sbt\n    ```shell\n    sdk install java 11.0.11-open\n    sdk install sbt\n    ```\n\n2. **Configure Isabelle**\n    ```shell\n    wget https://isabelle.in.tum.de/website-Isabelle2022/dist/Isabelle2022_linux.tar.gz\n    tar -xzf Isabelle2022_linux.tar.gz\n    export PATH=\"$PATH:$HOME/Isabelle2022/bin/\"\n    ```\n    Try\n    ```shell\n    isabelle \n    ```\n    to makes ure isabelle is properly installed.\n\n3. **Update submodules**\n\n    Go back to the repo directory and update PISA submodule\n    ```shell\n    cd LEGO-Prover\n    git submodule init\n    git submodule update\n    ```\n",
                    "type": "Text_excerpt",
                    "original_header": "PISA Install",
                    "parent_header": [
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/wiio12/LEGO-Prover/master/README.md"
            },
            {
                "result": {
                    "value": "This project require OpenAI API Keys to properly query the OpenAI LLMs. LEGO-Prover requires two types of models: standard GPT models (i.e. gpt-4, gpt-3.5-turbo) and embedding models (i.e. text-embedding-ada-002). Please make sure the API key provided have access to these models.\n\nPlease place your OpenAI API keys in the `openai_keys.py` file, formatted as follows:\n```python\nGPT_35_POOL = [\n    (\"sk-xxx\", \"org-xxx\"),\n    (\"sk-xxx\", None),      # if no organization id is required\n]\n\nGPT_4_POOL = [\n    (\"sk-xxx\", \"org-xxx\"),\n]\n```\nYou could leave one of the pool empty if you only have GPT-4 keys or GPT-3.5 keys.\n",
                    "type": "Text_excerpt",
                    "original_header": "OpenAI API Keys",
                    "parent_header": [
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/wiio12/LEGO-Prover/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-10-09T04:23:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-16T08:37:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 105635
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Isabelle",
                    "name": "Isabelle",
                    "type": "Programming_language",
                    "size": 17185
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "362": {
        "filename": "janikbenzin_contect_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The manual deployment is recommended for developers and service providers of the framework. \nPlease make sure to install the binaries of [Graphviz](https://graphviz.org) and [Python 3.8.8](https://www.python.org/downloads/release/python-388/) (s.t. *python3* will invoke this interpreter's binary) before you proceed.\nIn the following, shell scripts are developed for the zsh, so if you use a different shell, then you need to modify the scripts accordingly.\n\n```shell script\ngit clone https://gitlab.com/janikbenzin/contect.git\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Manual",
                    "parent_header": [
                        "Contect",
                        "Deployment"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/janikbenzin/contect/master/README.md"
            },
            {
                "result": {
                    "value": "In PyCharm, please configure a Python 3.8.8 interpreter with a venv in the project root and open the *requirements.txt* in the root directory.\nSelect PyCharm's option to install the dependencies in the *requirements.txt*.\nThen, proceed as follows: \nNavigate to *Preferences > Project Interpreter > Show All > Show paths for the selected interpreter*\nHere, the paths *<path_to_dir_of_git_project_root>/src/server* and *<path_to_dir_of_git_project_root>/src/evaluation*\nshould be included. \nNow, navigate to *Run > Edit Configurations... > Add New Configuration > Python*\nIn the corresponding *Configuration > Script paths* insert **<path_to_dir_of_git_project_root>/src/server/backend/index.py** here.\nThen, in the section *Environment Variables* add variables **REDIS_LOCALHOST_OR_DOCKER** and **LOCALHOST_OR_DOCKER** with the value **localhost** and **CONTECT_PATH** with the value **<path_to_your_project_root>**. \nIf you would like Dash to run in debug mode, then additionally add variable **DEBUG_MODE** with the value **true**. \nPress the *Apply* button, then *Ok*. \nNow, proceed with a shell in PyCharm:\n\n```shell script\ncd src/server/backend/db\ndocker-compose up\n```\nIf you work on a *Unix* based system, run the following commands in a new shell:\n\n```shell script\ncd src/server/backend\nexport CONTECT_PATH=<path_to_your_project_root> # the directory where src/ is located\nchmod +x ./run_celery.sh\n./run_celery.sh\n```\nNow, you can locally deploy the web service using PyCharm's *Run* of your newly specified *Run Configuration*\nor debug it using the *Debug* of the same configuration.\nThe default username is *admin*, and the default password is *test123* for logging into the system available at *127.0.0.1/8050*.\n\nIf you use a *Windows* machine, then the following commands are recommended in a shell of PyCharm:\n```shell script\npip install eventlet  \nset REDIS_LOCALHOST_OR_DOCKER=localhost\nset RABBIT_LOCALHOST_OR_DOCKER=localhost\nset RABBITMQ_USER=contect\nset RABBITMQ_PASSWORD=contect191! \ncd src/server/backend/tasks\ncelery -A tasks worker --loglevel=INFO -P eventlet\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "PyCharm",
                    "parent_header": [
                        "Contect",
                        "Deployment",
                        "Manual"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/janikbenzin/contect/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For automatic and platform-independent deployment, simply execute the following commands:\n```shell script\ngit clone https://gitlab.com/janikbenzin/contect.git\ncd src/server\ndocker-compose up\n```\nThe web service is now available at *127.0.0.1/8050*. \nThe default username is *admin*, and the default password is *test123* for logging into the system.\nIf you would like the Dash web service to run in debug mode, then change the value of the environment variable **DEBUG_MODE** in the [env file](src/server/.env) to **true**.\n \n",
                    "original_header": "Automatic"
                },
                "confidence": 0.9999999997655777,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/janikbenzin/contect/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-04-18T11:30:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-02-21T16:27:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 752010
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2072
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1699
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "363": {
        "filename": "EngyNasr_MSE-Benchmark_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The second part of the MSE benchmark is the manual reference alignment, which are the expected result from the test cases\u2019 alignment. They are compared to the result of the ontology matchers. For every test case, a manual reference alignment is created.\n\n- Singulars and plurals are equivalently matched (e.g. water = waters).\n- Only classes correspondances are included (No properties or individuals alignment).\n\n\n***1st Test Case:***\n\nIncludes all possible types of logical relations (correspondences) between ontologies\u2019 classes, subclass (\u2286) , superclass (\u2287) and equivalence (=).\n        \n***2nd Test Case:***\n\nInclude only the equivalence (=) logical relation (correspondences) between the ontologies\u2019 classes.\n    \n***3rd Test Case:***\n\nInclude only the equivalence (=) logical relation (correspondences) between the ontologies\u2019 classes.\n\n<a name=\"backgroundknowledgeontologies\"/>  \n",
                    "type": "Text_excerpt",
                    "original_header": "Manual Reference Alignments",
                    "parent_header": [
                        "MSE Benchmark Description"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/EngyNasr/MSE-Benchmark/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-07-24T11:03:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-10-10T12:56:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "364": {
        "filename": "sisl_BetaZero-jl_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "To install the BetaZero solver, run:\n\n```julia\nusing Pkg\npkg\"add https://github.com/sisl/BetaZero.jl\"\n```\n\n(**Optional**) To install the supporting example POMDP models (e.g., `LightDark` and `MinEx`), the `RemoteJobs` package, and the `ParticleBeliefs` wrapper, run:\n```julia\nusing BetaZero\ninstall_extras()\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "BetaZero.jl"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/sisl/BetaZero.jl/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-01-24T20:44:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-13T16:52:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Julia",
                    "name": "Julia",
                    "type": "Programming_language",
                    "size": 400292
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 10700
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "365": {
        "filename": "ckohlschm_detecting-surprising-instances_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "**Requirements**\n\nThe Tool requires the following python packages:\n\n- [pm4py](https://pm4py.fit.fraunhofer.de/)\n- [numpy](https://numpy.org/)\n- [pandas](https://pandas.pydata.org/)\n- [scikit-learn](https://scikit-learn.org/)\n- [networkx](https://networkx.org/)\n- [matplotlib](https://matplotlib.org/)\n- [cdt](https://github.com/FenTechSolutions/CausalDiscoveryToolbox/) (for causal structure discovery)\n- [dowhy](https://github.com/py-why/dowhy/) (for causal effect estimation)\n\nYou can install the python dependencies using:\n\n```\npip install -r requirements.txt\n```\n\nIn addition, you need an [R](https://r-project.org/) installation for the cdt package and the following R libraries:\n- pcalg\n- kpcalg\n- bnlearn\n- sparsebn\n- SID\n- CAM\n- D2C\n- RCIT\n\nFor more information about the R installation and the additional libraries, check the [cdt documentation](https://github.com/FenTechSolutions/CausalDiscoveryToolbox)\n\n**Run the application**\n\nAfter installing the required dependencies, you can run the application using one of the following commands: \n\n*Run an evaluation*:\n```\nsrc > py main.py\n```\n\n*Run the frontend*:\n```\nfrontend > py manage.py runserver 0.0.0.0:<port>\n```\n\nYou can then access the application via localhost:<port> in your browser.\n\n*Run the application using the Docker image*:\n```\ndocker run -p 33333:33333 ghcr.io/ckohlschm/detecting-surprising-instances:1.1.0\n```\n\nYou can then access the application via localhost:33333 in your browser.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Interactive Tool for Process Improvement Opportunity Detection and Causal Modeling"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ckohlschm/detecting-surprising-instances/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-07-14T14:02:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-09-02T10:53:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 523443
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 282258
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 212515
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "SCSS",
                    "name": "SCSS",
                    "type": "Programming_language",
                    "size": 148706
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 13644
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 578
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 67
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "366": {
        "filename": "oogle_jax_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "(installation)=\n# Installation\n\n<!--* freshness: { reviewed: '2024-06-18' } *-->\n\nUsing JAX requires installing two packages: `jax`, which is pure Python and\ncross-platform, and `jaxlib` which contains compiled binaries, and requires\ndifferent builds for different operating systems and accelerators.\n\n**TL;DR** For most users, a typical JAX installation may look something like this:\n\n* **CPU-only (Linux/macOS/Windows)**\n  ```\n  pip install -U jax\n  ```\n* **GPU (NVIDIA, CUDA 12)**\n  ```\n  pip install -U \"jax[cuda12]\"\n  ```\n\n* **TPU (Google Cloud TPU VM)**\n  ```\n  pip install -U \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n  ```\n\n(install-supported-platforms)=\n## Supported platforms\n\nThe table below shows all supported platforms and installation options. Check if your setup is supported; and if it says _\"yes\"_ or _\"experimental\"_, then click on the corresponding link to learn how to install JAX in greater detail.\n\n|                  | Linux, x86_64                        | Linux, aarch64      | macOS, Intel x86_64, AMD GPU   | macOS, Apple Silicon, ARM-based       | Windows, x86_64         | Windows WSL2, x86_64           |\n|------------------|---------------------------------------|--------------------------------|----------------------------------------|----------------------------------------|-------------------------|-----------------------------------------|\n| CPU              | {ref}`yes <install-cpu>`              | {ref}`yes <install-cpu>`        | {ref}`yes <install-cpu>`| {ref}`yes <install-cpu>`| {ref}`yes <install-cpu>` | {ref}`yes <install-cpu>`|\n| NVIDIA GPU       | {ref}`yes <install-nvidia-gpu>`       | {ref}`yes <install-nvidia-gpu>` | no | n/a | no | {ref}`experimental <install-nvidia-gpu>` |\n| Google Cloud TPU | {ref}`yes <install-google-tpu>`       | n/a | n/a | n/a | n/a | n/a |\n| AMD GPU          | {ref}`experimental <install-amd-gpu>` | no | no | n/a | no | no |\n| Apple GPU    | n/a                                   | no | {ref}`experimental <install-apple-gpu>` | {ref}`experimental <install-apple-gpu>` | n/a |  n/a |\n\n\n(install-cpu)=\n## CPU\n\n### pip installation: CPU\n\nCurrently, the JAX team releases `jaxlib` wheels for the following\noperating systems and architectures:\n\n- Linux, x86_64\n- Linux, aarch64\n- macOS, Intel\n- macOS, Apple ARM-based\n- Windows, x86_64 (*experimental*)\n\nTo install a CPU-only version of JAX, which might be useful for doing local\ndevelopment on a laptop, you can run:\n\n```bash\npip install --upgrade pip\npip install --upgrade jax\n```\n\nOn Windows, you may also need to install the\n[Microsoft Visual Studio 2019 Redistributable](https://learn.microsoft.com/en-US/cpp/windows/latest-supported-vc-redist?view=msvc-170#visual-studio-2015-2017-2019-and-2022)\nif it is not already installed on your machine.\n\nOther operating systems and architectures require building from source. Trying\nto pip install on other operating systems and architectures may lead to `jaxlib`\nnot being installed alongside `jax`, although `jax` may successfully install\n(but fail at runtime).\n\n\n(install-nvidia-gpu)=\n## NVIDIA GPU\n\nJAX supports NVIDIA GPUs that have SM version 5.2 (Maxwell) or newer.\nNote that Kepler-series GPUs are no longer supported by JAX since\nNVIDIA has dropped support for Kepler GPUs in its software.\n\nYou must first install the NVIDIA driver. You're\nrecommended to install the newest driver available from NVIDIA, but the driver\nversion must be >= 525.60.13 for CUDA 12 on Linux.\n\nIf you need to use a newer CUDA toolkit with an older driver, for example\non a cluster where you cannot update the NVIDIA driver easily, you may be\nable to use the\n[CUDA forward compatibility packages](https://docs.nvidia.com/deploy/cuda-compatibility/)\nthat NVIDIA provides for this purpose.\n\n### pip installation: NVIDIA GPU (CUDA, installed via pip, easier)\n\nThere are two ways to install JAX with NVIDIA GPU support:\n\n- Using NVIDIA CUDA and cuDNN installed from pip wheels\n- Using a self-installed CUDA/cuDNN\n\nThe JAX team strongly recommends installing CUDA and cuDNN using the pip wheels,\nsince it is much easier!\n\nNVIDIA has released CUDA pip packages only for x86_64 and aarch64; on other\nplatforms you must use a local installation of CUDA.\n\n```bash\npip install --upgrade pip\n\n# NVIDIA CUDA 12 installation\n# Note: wheels only available on linux.\npip install --upgrade \"jax[cuda12]\"\n```\n\nIf JAX detects the wrong version of the NVIDIA CUDA libraries, there are several things\nyou need to check:\n\n* Make sure that `LD_LIBRARY_PATH` is not set, since `LD_LIBRARY_PATH` can\n  override the NVIDIA CUDA libraries.\n* Make sure that the NVIDIA CUDA libraries installed are those requested by JAX.\n  Rerunning the installation command above should work.\n\n### pip installation: NVIDIA GPU (CUDA, installed locally, harder)\n\nIf you prefer to use a preinstalled copy of NVIDIA CUDA, you must first\ninstall NVIDIA [CUDA](https://developer.nvidia.com/cuda-downloads) and\n[cuDNN](https://developer.nvidia.com/CUDNN).\n\nJAX provides pre-built CUDA-compatible wheels for **Linux x86_64 and Linux aarch64 only**. Other\ncombinations of operating system and architecture are possible, but require\nbuilding from source (refer to {ref}`building-from-source` to learn more}.\n\nYou should use an NVIDIA driver version that is at least as new as your\n[NVIDIA CUDA toolkit's corresponding driver version](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#cuda-major-component-versions__table-cuda-toolkit-driver-versions).\nIf you need to use a newer CUDA toolkit with an older driver, for example\non a cluster where you cannot update the NVIDIA driver easily, you may be\nable to use the\n[CUDA forward compatibility packages](https://docs.nvidia.com/deploy/cuda-compatibility/)\nthat NVIDIA provides for this purpose.\n\nJAX currently ships one CUDA wheel variant:\n\n| Built with | Compatible with    |\n|------------|--------------------|\n| CUDA 12.3  | CUDA >=12.1        |\n| CUDNN 9.1  | CUDNN >=9.1, <10.0 |\n| NCCL 2.19  | NCCL >=2.18        |\n\nJAX checks the versions of your libraries, and will report an error if they are\nnot sufficiently new.\nSetting the `JAX_SKIP_CUDA_CONSTRAINTS_CHECK` environment variable will disable\nthe check, but using older versions of CUDA may lead to errors, or incorrect\nresults.\n\nNCCL is an optional dependency, required only if you are performing multi-GPU\ncomputations.\n\nTo install, run:\n\n```bash\npip install --upgrade pip\n\n# Installs the wheel compatible with NVIDIA CUDA 12 and cuDNN 9.0 or newer.\n# Note: wheels only available on linux.\npip install --upgrade \"jax[cuda12_local]\"\n```\n\n**These `pip` installations do not work with Windows, and may fail silently; refer to the table\n[above](#supported-platforms).**\n\nYou can find your CUDA version with the command:\n\n```bash\nnvcc --version\n```\n\nJAX uses `LD_LIBRARY_PATH` to find CUDA libraries and `PATH` to find binaries\n(`ptxas`, `nvlink`). Please make sure that these paths point to the correct CUDA\ninstallation.\n\nJAX requires libdevice10.bc, which typically comes from the cuda-nvvm package.\nMake sure that it is present in your CUDA installation.\n\nPlease let the JAX team know on [the GitHub issue tracker](https://github.com/google/jax/issues)\nif you run into any errors or problems with the pre-built wheels.\n\n(docker-containers-nvidia-gpu)=\n### NVIDIA GPU Docker containers\n\nNVIDIA provides the [JAX\nToolbox](https://github.com/NVIDIA/JAX-Toolbox) containers, which are\nbleeding edge containers containing nightly releases of jax and some\nmodels/frameworks.\n\n(install-google-tpu)=\n## Google Cloud TPU\n\n### pip installation: Google Cloud TPU\n\nJAX provides pre-built wheels for\n[Google Cloud TPU](https://cloud.google.com/tpu/docs/users-guide-tpu-vm).\nTo install JAX along with appropriate versions of `jaxlib` and `libtpu`, you can run\nthe following in your cloud TPU VM:\n\n```bash\npip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n```\n\nFor users of Colab (https://colab.research.google.com/), be sure you are\nusing *TPU v2* and not the older, deprecated TPU runtime.\n\n(install-apple-gpu)=\n## Apple Silicon GPU (ARM-based)\n\n### pip installation: Apple ARM-based Silicon GPUs\n\nApple provides an experimental Metal plugin for Apple ARM-based GPU hardware. For details,\nrefer to\n[Apple's JAX on Metal documentation](https://developer.apple.com/metal/jax/).\n\n**Note:** There are several caveats with the Metal plugin:\n\n* The Metal plugin is new and experimental and has a number of\n  [known issues](https://github.com/google/jax/issues?q=is%3Aissue+is%3Aopen+label%3A%22Apple+GPU+%28Metal%29+plugin%22).\n  Please report any issues on the JAX issue tracker.\n* The Metal plugin currently requires very specific versions of `jax` and\n  `jaxlib`. This restriction will be relaxed over time as the plugin API\n  matures.\n\n(install-amd-gpu)=\n## AMD GPU\n\nJAX has experimental ROCm support. There are two ways to install JAX:\n\n* Use [AMD's Docker container](https://hub.docker.com/r/rocm/jax); or\n* Build from source (refer to {ref}`building-from-source` \u2014 a section called _Additional notes for building a ROCM `jaxlib` for AMD GPUs_).\n\n## Conda (community-supported)\n\n### Conda installation\n\nThere is a community-supported Conda build of `jax`. To install it using `conda`,\nsimply run:\n\n```bash\nconda install jax -c conda-forge\n```\n\nTo install it on a machine with an NVIDIA GPU, run:\n\n```bash\nconda install jaxlib=*=*cuda* jax cuda-nvcc -c conda-forge -c nvidia\n```\n\nNote the `cudatoolkit` distributed by `conda-forge` is missing `ptxas`, which\nJAX requires. You must therefore either install the `cuda-nvcc` package from\nthe `nvidia` channel, or install CUDA on your machine separately so that `ptxas`\nis in your path. The channel order above is important (`conda-forge` before\n`nvidia`).\n\nIf you would like to override which release of CUDA is used by JAX, or to\ninstall the CUDA build on a machine without GPUs, follow the instructions in the\n[Tips & tricks](https://conda-forge.org/docs/user/tipsandtricks.html#installing-cuda-enabled-packages-like-tensorflow-and-pytorch)\nsection of the `conda-forge` website.\n\nGo to the `conda-forge`\n[jaxlib](https://github.com/conda-forge/jaxlib-feedstock#installing-jaxlib) and\n[jax](https://github.com/conda-forge/jax-feedstock#installing-jax) repositories\nfor more details.\n\n\n## JAX nightly installation\n\nNightly releases reflect the state of the main JAX repository at the time they are\nbuilt, and may not pass the full test suite.\n\n- CPU only:\n\n```bash\npip install -U --pre jax -f https://storage.googleapis.com/jax-releases/jax_nightly_releases.html\n```\n\n- Google Cloud TPU:\n\n```bash\npip install -U --pre jax[tpu] -f https://storage.googleapis.com/jax-releases/jax_nightly_releases.html -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n```\n\n- NVIDIA GPU (CUDA 12):\n\n```bash\npip install -U --pre jax[cuda12] -f https://storage.googleapis.com/jax-releases/jax_nightly_releases.html\n```\n\n- NVIDIA GPU (CUDA 12) legacy:\n\nUse the following for historical nightly releases of monolithic CUDA jaxlibs.\nYou most likely do not want this; no further monolithic CUDA jaxlibs will be\nbuilt and those that exist will expire by Sep 2024. Use the \"CUDA 12\" option above.\n\n```bash\npip install -U --pre jaxlib -f https://storage.googleapis.com/jax-releases/jaxlib_nightly_cuda12_releases.html\n```\n\n(building-jax-from-source)=\n## Building JAX from source\n\nRefer to {ref}`building-from-source`.\n\n## Installing older `jaxlib` wheels\n\nDue to storage limitations on the Python package index, the JAX team periodically removes\nolder `jaxlib` wheels from the releases on http://pypi.org/project/jax. These can\nstill be installed directly via the URLs here. For example:\n\n```bash\n# Install jaxlib on CPU via the wheel archive\npip install jax[cpu]==0.3.25 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n\n# Install the jaxlib 0.3.25 CPU wheel directly\npip install jaxlib==0.3.25 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n```\nFor specific older GPU wheels, be sure to use the `jax_cuda_releases.html` URL; for example\n```bash\npip install jaxlib==0.3.25+cuda11.cudnn82 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n```\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/google/jax/main/docs/installation.md"
            },
            {
                "result": {
                    "value": "|            | Linux x86_64 | Linux aarch64 | Mac x86_64   | Mac ARM      | Windows x86_64 | Windows WSL2 x86_64 |\n|------------|--------------|---------------|--------------|--------------|----------------|---------------------|\n| CPU        | yes          | yes           | yes          | yes          | yes            | yes                 |\n| NVIDIA GPU | yes          | yes           | no           | n/a          | no             | experimental        |\n| Google TPU | yes          | n/a           | n/a          | n/a          | n/a            | n/a                 |\n| AMD GPU    | experimental | no            | no           | n/a          | no             | no                  |\n| Apple GPU  | n/a          | no            | experimental | experimental | n/a            | n/a                 |\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Supported platforms",
                    "parent_header": [
                        "JAX: Autograd and XLA",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/google/jax/main/README.md"
            },
            {
                "result": {
                    "value": "| Hardware   | Instructions                                                                                                    |\n|------------|-----------------------------------------------------------------------------------------------------------------|\n| CPU        | `pip install -U jax`                                                                                            |\n| NVIDIA GPU | `pip install -U \"jax[cuda12]\"`                                                                                  |\n| Google TPU | `pip install -U \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html`                 |\n| AMD GPU    | Use [Docker](https://hub.docker.com/r/rocm/jax) or [build from source](https://jax.readthedocs.io/en/latest/developer.html#additional-notes-for-building-a-rocm-jaxlib-for-amd-gpus). |\n| Apple GPU  | Follow [Apple's instructions](https://developer.apple.com/metal/jax/).                                          |\n\nSee [the documentation](https://jax.readthedocs.io/en/latest/installation.html)\nfor information on alternative installation strategies. These include compiling\nfrom source, installing with Docker, using other versions of CUDA, a\ncommunity-supported conda build, and answers to some frequently-asked questions.\n\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Instructions",
                    "parent_header": [
                        "JAX: Autograd and XLA",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/google/jax/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**JAX now runs on Cloud TPUs.** To try out the preview, see the [Cloud TPU\nColabs](https://github.com/google/jax/tree/main/cloud_tpu_colabs). \nFor a deeper dive into JAX:\n- [The Autodiff Cookbook, Part 1: easy and powerful automatic differentiation in JAX](https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html)\n- [Common gotchas and sharp edges](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html)\n- See the [full list of\nnotebooks](https://github.com/google/jax/tree/main/docs/notebooks).\n \n",
                    "original_header": "Quickstart: Colab in the Cloud"
                },
                "confidence": 0.9763444335095857,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google/jax/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "See the [reference docs on automatic\ndifferentiation](https://jax.readthedocs.io/en/latest/jax.html#automatic-differentiation)\nand the [JAX Autodiff\nCookbook](https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html)\nfor more.\n \n",
                    "original_header": "Automatic differentiation with `grad`"
                },
                "confidence": 0.9999965235951893,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google/jax/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "See the [SPMD\nCookbook](https://colab.research.google.com/github/google/jax/blob/main/cloud_tpu_colabs/Pmap_Cookbook.ipynb)\nand the [SPMD MNIST classifier from scratch\nexample](https://github.com/google/jax/blob/main/examples/spmd_mnist_classifier_fromscratch.py)\nfor more.\n \n",
                    "original_header": "SPMD programming with `pmap`"
                },
                "confidence": 0.997774419020755,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google/jax/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For a more thorough survey of current gotchas, with examples and explanations,\nwe highly recommend reading the [Gotchas\nNotebook](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html).\nSome standouts: \n1. JAX transformations only work on [pure functions](https://en.wikipedia.org/wiki/Pure_function), which don't have side-effects and respect [referential transparency](https://en.wikipedia.org/wiki/Referential_transparency) (i.e. object identity testing with `is` isn't preserved). If you use a JAX transformation on an impure Python function, you might see an error like `Exception: Can't lift Traced...`  or `Exception: Different traces at same level`.\n1. [In-place mutating updates of\n   arrays](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#in-place-updates), like `x[i] += y`, aren't supported, but [there are functional alternatives](https://jax.readthedocs.io/en/latest/jax.ops.html). Under a `jit`, those functional alternatives will reuse buffers in-place automatically.\n1. [Random numbers are\n   different](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#random-numbers), but for [good reasons](https://github.com/google/jax/blob/main/docs/jep/263-prng.md).\n1. If you're looking for [convolution\n   operators](https://jax.readthedocs.io/en/latest/notebooks/convolutions.html),\n   they're in the `jax.lax` package.\n1. JAX enforces single-precision (32-bit, e.g. `float32`) values by default, and\n   [to enable\n   double-precision](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#double-64bit-precision)\n   (64-bit, e.g. `float64`) one needs to set the `jax_enable_x64` variable at\n   startup (or set the environment variable `JAX_ENABLE_X64=True`).\n   On TPU, JAX uses 32-bit values by default for everything _except_ internal\n   temporary variables in 'matmul-like' operations, such as `jax.numpy.dot` and `lax.conv`.\n   Those ops have a `precision` parameter which can be used to approximate 32-bit operations\n   via three bfloat16 passes, with a cost of possibly slower runtime.\n   Non-matmul operations on TPU lower to implementations that often emphasize speed over\n   accuracy, so in practice computations on TPU will be less precise than similar\n   computations on other backends.\n1. Some of NumPy's dtype promotion semantics involving a mix of Python scalars\n   and NumPy types aren't preserved, namely `np.add(1, np.array([2],\n   np.float32)).dtype` is `float64` rather than `float32`.\n1. Some transformations, like `jit`, [constrain how you can use Python control\n   flow](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#control-flow).\n   You'll always get loud errors if something goes wrong. You might have to use\n   [`jit`'s `static_argnums`\n   parameter](https://jax.readthedocs.io/en/latest/jax.html#just-in-time-compilation-jit),\n   [structured control flow\n   primitives](https://jax.readthedocs.io/en/latest/jax.lax.html#control-flow-operators)\n   like\n   [`lax.scan`](https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.scan.html#jax.lax.scan),\n   or just use `jit` on smaller subfunctions.\n \n",
                    "original_header": "Current gotchas"
                },
                "confidence": 0.9995893058559719,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/google/jax/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-10-25T21:25:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T09:08:26Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 13401167
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 1098008
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Starlark",
                    "name": "Starlark",
                    "type": "Programming_language",
                    "size": 213229
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 90724
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 17198
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 16497
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "MAXScript",
                    "name": "MAXScript",
                    "type": "Programming_language",
                    "size": 2593
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "367": {
        "filename": "martinballa_PyTAG979-8-3503-2277-4_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "368": {
        "filename": "IDEA-CCNL_Fengshenbang-LM_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\u901a\u7528\u5927\u6a21\u578b\u201c\u59dc\u5b50\u7259\u201d\u7cfb\u5217\uff0c\u5177\u5907\u7ffb\u8bd1\uff0c\u7f16\u7a0b\uff0c\u6587\u672c\u5206\u7c7b\uff0c\u4fe1\u606f\u62bd\u53d6\uff0c\u6458\u8981\uff0c\u6587\u6848\u751f\u6210\uff0c\u5e38\u8bc6\u95ee\u7b54\u548c\u6570\u5b66\u8ba1\u7b97\u7b49\u80fd\u529b\u3002\u76ee\u524d\u59dc\u5b50\u7259\u901a\u7528\u5927\u6a21\u578b(v1/v1.1)\u5df2\u5b8c\u6210\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u3001\u591a\u4efb\u52a1\u6709\u76d1\u7763\u5fae\u8c03\u548c\u4eba\u7c7b\u53cd\u9988\u5b66\u4e60\u4e09\u9636\u6bb5\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002\u59dc\u5b50\u7259\u7cfb\u5217\u6a21\u578b\u5305\u542b\u4ee5\u4e0b\u6a21\u578b\uff1a\n- [Ziya-LLaMA-13B-v1.1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1.1)\n- [Ziya-LLaMA-13B-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1)\n- [Ziya-LLaMA-7B-Reward](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-7B-Reward)\n- [Ziya-LLaMA-13B-Pretrain-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-Pretrain-v1)\n- [Ziya-BLIP2-14B-Visual-v1](https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1)\n \n",
                    "original_header": "\u59dc\u5b50\u7259\u7cfb\u5217"
                },
                "confidence": 0.9054851969672789,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/IDEA-CCNL/Fengshenbang-LM/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "1\u3001\u9996\u5148\u4fee\u6539finetune\u793a\u4f8b\u811a\u672c[finetune_classification.sh](https://github.com/IDEA-CCNL/Fengshenbang-LM/blob/main/fengshen/examples/classification/finetune_classification.sh)\u4e2d\u7684model_type\u548cpretrained_model_path\u53c2\u6570\u3002\u5176\u4ed6\u5982batch_size\u3001data_dir\u7b49\u53c2\u6570\u53ef\u6839\u636e\u81ea\u5df1\u7684\u8bbe\u5907\u4fee\u6539\u3002\n``` sh\nMODEL_TYPE=huggingface-megatron_bert\nPRETRAINED_MODEL_PATH=IDEA-CCNL/Erlangshen-MegatronBert-1.3B\n```\n2\u3001\u7136\u540e\u8fd0\u884c\uff1a\n``` sh\nsh finetune_classification.sh\n```\n \n",
                    "original_header": "\u4f7f\u7528\u793a\u4f8b"
                },
                "confidence": 0.9994295419797925,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/IDEA-CCNL/Fengshenbang-LM/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "### \u6a21\u578b\u4f7f\u7528\n``` python\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\"IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1\").to(\"cuda\")\n\nprompt = '\u98de\u6d41\u76f4\u4e0b\u4e09\u5343\u5c3a\uff0c\u6cb9\u753b'\nimage = pipe(prompt, guidance_scale=7.5).images[0]  \nimage.save(\"\u98de\u6d41.png\")\n```\n \n",
                    "original_header": "\u592a\u4e59\u7cfb\u5217"
                },
                "confidence": 0.9888280804421071,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/IDEA-CCNL/Fengshenbang-LM/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://github.com/IDEA-CCNL/Fengshenbang-LM/blob/main/fengshen/examples/stable_diffusion_chinese/taiyi_handbook.md\n \n",
                    "original_header": "\u4f7f\u7528\u624b\u518c Handbook for Taiyi"
                },
                "confidence": 0.9998508698368468,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/IDEA-CCNL/Fengshenbang-LM/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/finetune_taiyi_stable_diffusion\n \n",
                    "original_header": "\u600e\u6837\u5fae\u8c03(How to finetune)"
                },
                "confidence": 0.9993084688982256,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/IDEA-CCNL/Fengshenbang-LM/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://github.com/IDEA-CCNL/stable-diffusion-webui/blob/master/README.md\n \n",
                    "original_header": "\u914d\u7f6ewebui(Configure webui)"
                },
                "confidence": 0.9999649234964422,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/IDEA-CCNL/Fengshenbang-LM/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/stable_diffusion_dreambooth\n \n",
                    "original_header": "DreamBooth"
                },
                "confidence": 0.9993084688982256,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/IDEA-CCNL/Fengshenbang-LM/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```shell\ngit clone https://github.com/IDEA-CCNL/Fengshenbang-LM.git\ncd Fengshenbang-LM\ngit submodule init\ngit submodule update\n# submodule\u662f\u6211\u4eec\u7528\u6765\u7ba1\u7406\u6570\u636e\u96c6\u7684fs_datasets\uff0c\u901a\u8fc7ssh\u7684\u65b9\u5f0f\u62c9\u53d6\uff0c\u5982\u679c\u7528\u6237\u6ca1\u6709\u5728\u673a\u5668\u4e0a\u914d\u7f6essh-key\u7684\u8bdd\u53ef\u80fd\u4f1a\u62c9\u53d6\u5931\u8d25\u3002\n# \u5982\u679c\u62c9\u53d6\u5931\u8d25\uff0c\u9700\u8981\u5230.gitmodules\u6587\u4ef6\u4e2d\u628assh\u5730\u5740\u6539\u4e3ahttps\u5730\u5740\u5373\u53ef\u3002\npip install --editable .\n```\n \n",
                    "original_header": "\u4f7f\u7528\u81ea\u5df1\u7684\u73af\u5883\u5b89\u88c5"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/IDEA-CCNL/Fengshenbang-LM/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\u6211\u4eec\u63d0\u4f9b\u4e00\u4e2a\u7b80\u5355\u7684\u5305\u542btorch\u3001cuda\u73af\u5883\u7684docker\u6765\u8fd0\u884c\u6211\u4eec\u7684\u6846\u67b6\u3002\n```shell\nsudo docker run --runtime=nvidia --rm -itd --ipc=host --name fengshen fengshenbang/pytorch:1.10-cuda11.1-cudann8-devel\nsudo docker exec -it fengshen bash\ncd Fengshenbang-LM\n# \u66f4\u65b0\u4ee3\u7801 docker\u5185\u7684\u4ee3\u7801\u53ef\u80fd\u4e0d\u662f\u6700\u65b0\u7684\ngit pull\ngit submodule foreach 'git pull origin master' \n# \u5373\u53ef\u5feb\u901f\u7684\u5728docker\u4e2d\u4f7f\u7528\u6211\u4eec\u7684\u6846\u67b6\u5566\n```\n \n",
                    "original_header": "\u4f7f\u7528Docker"
                },
                "confidence": 0.9999999999999716,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/IDEA-CCNL/Fengshenbang-LM/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-10-28T09:48:27Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T16:00:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 2523834
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 243963
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 90132
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 24319
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cuda",
                    "name": "Cuda",
                    "type": "Programming_language",
                    "size": 8035
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 6151
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 279
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "369": {
        "filename": "amihayelboher_CoPE_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-12-15T17:06:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-05-07T08:55:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 418570
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "370": {
        "filename": "Tiiiger_bert_score_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "* Python version >= 3.6\n* PyTorch version >= 1.0.0\n\nInstall from pypi with pip by \n\n```sh\npip install bert-score\n```\nInstall latest unstable version from the master branch on Github by:\n```\npip install git+https://github.com/Tiiiger/bert_score\n```\n\nInstall it from the source by:\n```sh\ngit clone https://github.com/Tiiiger/bert_score\ncd bert_score\npip install .\n```\nand you may test your installation by:\n```\npython -m unittest discover\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "BERTScore"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Tiiiger/bert_score/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- Updated to version 0.3.13\n  - Fix bug with transformers version > 4.17.0 ([#148](https://github.com/Tiiiger/bert_score/pull/148))\n- Updated to version 0.3.12\n  - Having `get_idf_dict` compatible with DDP ([#140](https://github.com/Tiiiger/bert_score/pull/140))\n  - Fix setup bug ([#138](https://github.com/Tiiiger/bert_score/pull/138))\n- Updated to version 0.3.11\n  - Support 6 DeBERTa v3 models\n  - Support 3 ByT5 models\n- Updated to version 0.3.10\n  - Support 8 SimCSE models\n  - Fix the support of scibert (to be compatible with transformers >= 4.0.0)\n  - Add scripts for reproducing some results in our paper (See this [folder](./reproduce))\n  - Support fast tokenizers in huggingface transformers with `--use_fast_tokenizer`. Notably, you will get different scores because of the difference in the tokenizer implementations ([#106](https://github.com/Tiiiger/bert_score/issues/106)). \n  - Fix non-zero recall problem for empty candidate strings ([#107](https://github.com/Tiiiger/bert_score/issues/107)).\n  - Add Turkish BERT Supoort ([#108](https://github.com/Tiiiger/bert_score/issues/108)).\n- Updated to version 0.3.9\n  - Support 3 BigBird models\n  - Fix bugs for mBART and T5\n  - Support 4 mT5 models as requested ([#93](https://github.com/Tiiiger/bert_score/issues/93))\n- Updated to version 0.3.8\n  - Support 53 new pretrained models including BART, mBART, BORT, DeBERTa, T5, BERTweet, MPNet, ConvBERT, SqueezeBERT, SpanBERT, PEGASUS, Longformer, LED, Blendbot, etc. Among them, DeBERTa achives higher correlation with human scores than RoBERTa (our default) on WMT16 dataset. The correlations are presented in this [Google sheet](https://docs.google.com/spreadsheets/d/1RKOVpselB98Nnh_EOC4A2BYn8_201tmPODpNWu4w7xI/edit?usp=sharing).\n  - Please consider using `--model_type microsoft/deberta-xlarge-mnli` or `--model_type microsoft/deberta-large-mnli` (faster) if you want the scores to correlate better with human scores.\n  - Add baseline files for DeBERTa models.\n  - Add example code to generate baseline files (please see the [details](get_rescale_baseline)).\n- Updated to version 0.3.7\n  - Being compatible with Huggingface's transformers version >=4.0.0. Thanks to public contributers ([#84](https://github.com/Tiiiger/bert_score/pull/84), [#85](https://github.com/Tiiiger/bert_score/issues/85), [#86](https://github.com/Tiiiger/bert_score/pull/86)).\n- See [#22](https://github.com/Tiiiger/bert_score/issues/22) if you want to replicate our experiments on the COCO Captioning dataset. \n",
                    "original_header": "News:"
                },
                "confidence": 0.9999999971225861,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Tiiiger/bert_score/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-04-20T15:04:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T15:57:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 382398
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 93092
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1652
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "371": {
        "filename": "zyr17_UniLight_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-04-25T01:59:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-02T06:32:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 170622
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 291
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "372": {
        "filename": "Lichang-Chen_InstructZero_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "- Create env and download all the packages required as follows:\n```\nconda create -n InstructZero\nconda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia\nconda install botorch -c pytorch -c gpytorch -c conda-forge\npip install -r requirements.txt # install other requirements\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models (ICML2024)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Lichang-Chen/InstructZero/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-29T04:35:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T18:47:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 97005
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 615
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "373": {
        "filename": "WilsonWangTHU_neural_graph_evolution_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The repo uses [dm control suite](https://github.com/deepmind/dm_control).\nPlease make sure that you set up the MuJoCo-150 as instructed in the dm control github page.\nNote that we need the specific branch of the @\"merel_2017_humanoid\".\nOtherwise the reward scale and engineering design will be different.\nThe other packages can be installed by running the following commands.\n\n```\npip install -r requirements\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/WilsonWangTHU/neural_graph_evolution/master/README.md"
            },
            {
                "result": {
                    "value": "If you have set up a visdom server, as illustrated in [facebookresearch/visdom](https://github.com/facebookresearch/visdom),\nyou can turn on the reward visualization by, for example if the port is 1234 with IP 192.168.0.1:\n`python evolution_main.py --viz --vis_port 1234 --vis_server 192.168.0.1 ...`\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Setting up the Visdom Server.",
                    "parent_header": [
                        "The hyper-parameters"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/WilsonWangTHU/neural_graph_evolution/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-06-05T21:35:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-04T16:34:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 635574
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 12671
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "374": {
        "filename": "IgnacioVellido_Driver-Assistance-System_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We use the SIADEX HTN planner based on HPDL. To install it, get it [here](https://github.com/IgnacioVellido/VGDL-to-HTN-Parser/tree/master/planners/Siadex), create a directory called ``planner`` under the root directory and compile it in there (a ``planner`` executable file should be generated)\n",
                    "type": "Text_excerpt",
                    "original_header": "Setting the HTN planner",
                    "parent_header": [
                        "Driver Assistance System",
                        ":unlock: Requirements"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/IgnacioVellido/Driver-Assistance-System/main/README.md"
            },
            {
                "result": {
                    "value": "We recommend using Anaconda and setting conda environment [environment.yml](./environment.yml) via the command:\n\n```bash\nconda env create -f environment.yml\n```\n\nNevertheless, if you don't want to use Anaconda the main Python packages are:\n\n- Python 3\n- Numpy\n- Gensim (4.1.2 or superior)\n- Pandas\n- Scikit-learn\n- Matplotlib\n- Streamlit (only for the apps)\n",
                    "type": "Text_excerpt",
                    "original_header": "Setting everything else",
                    "parent_header": [
                        "Driver Assistance System",
                        ":unlock: Requirements"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/IgnacioVellido/Driver-Assistance-System/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-11-25T09:10:16Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-17T05:14:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 78048
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2343
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "375": {
        "filename": "agrimgupta92_sgan_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "All code was developed and tested on Ubuntu 16.04 with Python 3.5 and PyTorch 0.4.\n\nYou can setup a virtual environment to run the code like this:\n\n```bash\npython3 -m venv env               # Create a virtual environment\nsource env/bin/activate           # Activate virtual environment\npip install -r requirements.txt   # Install dependencies\necho $PWD > env/lib/python3.5/site-packages/sgan.pth  # Add current directory to python path\n# Work for a while ...\ndeactivate  # Exit virtual environment\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "Social GAN"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/agrimgupta92/sgan/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can download pretrained models by running the script `bash scripts/download_models.sh`. This will download the following models: \n",
                    "original_header": "Pretrained Models"
                },
                "confidence": 0.9999002367423069,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/agrimgupta92/sgan/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-06-29T04:58:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T15:10:55Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 63437
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1009
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "376": {
        "filename": "mohitKULeuven_HassleWithLocalSearch_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2020-01-21T10:34:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-07-04T12:39:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 132014
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "377": {
        "filename": "neulab_KGxBoard_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* Video demo: https://vimeo.com/735226047\n* Demo website: https://explainaboard.inspiredco.ai/\n* Tutorial for the KGxBoard's API and CLI: https://github.com/neulab/ExplainaBoard/blob/main/docs/task_kg_link_tail_prediction.md \n    * **Note:** before using KGxBoard's API or CLI, make sure you've installed ExplainaBoard first: https://github.com/neulab/ExplainaBoard\n* LibKGE API for KGxBoard: https://github.com/rufex2001/libkge-with-kgxboard-support\n* PyKEEN API for KGxBoard: coming soon\n \n",
                    "original_header": "Resources"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/neulab/KGxBoard/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-07-29T05:26:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-09-08T04:10:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "378": {
        "filename": "tsumers_how-to-talk_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-06-13T23:08:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-12-14T21:15:16Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 1602604
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 645468
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 63438
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 44326
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 9271
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 65
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Procfile",
                    "name": "Procfile",
                    "type": "Programming_language",
                    "size": 29
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "379": {
        "filename": "selBaez_evaluating-conversations-as-ekg_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "In the `src` folder you will find the following: \n",
                    "original_header": "Code overview"
                },
                "confidence": 0.9789206131835643,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/selBaez/evaluating-conversations-as-ekg/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-02-21T21:33:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-09-29T13:18:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 11544964
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 48587
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 11142
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "380": {
        "filename": "dbpedia_ontology-tracker_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\r\n[![Build Status](https://travis-ci.org/dbpedia/ontology-tracker.svg?branch=master)](https://travis-ci.org/dbpedia/ontology-tracker)\r\n\r\n This repository is used as an issue tracker (https://github.com/dbpedia/ontology-tracker/issues) for modification requests in the DBpedia Ontology and also will be updated with new snapshots of the DBpedia ontology (~every 30 minutes if changes occured).\r\n\r\n\r\n \n",
                    "original_header": "DBpedia Ontology Issue tracker"
                },
                "confidence": 0.9949517651947577,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/dbpedia/ontology-tracker/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2015-01-08T08:49:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-07T01:41:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 83117
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 41348
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 22010
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 18357
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 7941
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 6112
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "381": {
        "filename": "AAIR-lab_QACE_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "1. Run the followin command in a terminal\n```\nsudo apt install make g++ python3-venv graphviz gcc-multilib g++-multilib graphviz-dev\nsudo apt install docker.io\n```\n\n> **[Note]** <br>\n> For ARM processors, use `gcc-multilib-i686-linux-gnu` and `g++-multilib-i686-linux-gnu` on place of `gcc-multilib` and `g++-multilib`, respectively.\n\n2. Build PRP\n```\npushd dependencies/prp/src\n./build_all\npopd\n```\n\n3. Setup a virtual environment\n```\npython3 -m venv env\nsource env/bin/activate\n```\n\n4. Install the required python libraries.\n\n```\npip3 install --upgrade pip\npip3 install networkx\npip3 install pydot\npip3 install gym\npip3 install pddlgym\npip3 install pygraphviz\npip3 install argparse\npip3 install tqdm\npip3 install termcolor\npip3 install pygraphviz\npip3 install seaborn\npip3 install graphviz\npip3 install docker\npip3 install urllib3==1.26.0\n```\n\n<br>\n\n> **[Note]** <br>\n> An earlier version of QACE was inernally called Stochastic Agent Interrogation Algorithm (SAIA). These references to `saia` can be found at multiple places, please consider them as `qace`. \n<br>\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Query-based Autonomous Capability Estimation (QACE) Algorithm"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/AAIR-lab/QACE/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-10-15T20:50:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-17T06:55:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "PDDL",
                    "name": "PDDL",
                    "type": "Programming_language",
                    "size": 157733686
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 507136
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "SAS",
                    "name": "SAS",
                    "type": "Programming_language",
                    "size": 389425
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1662
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "382": {
        "filename": "Snagnar_Hieros_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Install pip dependencies:\n```\npip install -r requirements.txt\n```\n\nInstall required tools:\n```\nsudo apt update && sudo apt install -y wget unrar\n```\n\nInstall atari roms:\n```\nbash embodied/scripts/install-atari.sh\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Snagnar/Hieros/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-09-28T09:46:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-14T04:27:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 548825
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2156
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "383": {
        "filename": "lotten_daoopt_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "A recent set of [Boost library](http://www.boost.org) headers is\nrequired to compile the solver (confirmed to work is version 1.53.0),\neither in the system-wide include path or copied/symlinked into\n`./lib/boost` locally. In addition, all solver variants need the Boost\nprogram_options library for linking; the dynamic parallel master also\nneeds the Boost thread and system library.\n \n",
                    "original_header": "Compilation"
                },
                "confidence": 0.9997307932863535,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/lotten/daoopt/uai14/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The easiest and most universal way of compilation is provided through\nthe included CMake files. Create a `build` subfolder and from within\nit run `cmake ..`. Afterwards `make all` starts compilation, while\n`make edit_cache` allows to choose between release and debug compiler\nflags, toggle static linking, and select one of the solver variants\n(see references below); the default choice is the release-optimized,\ndynamically linked, sequential solver. \n* `Worker` -- Purely sequential AOBB solver.\n* `Static` -- Static master mode (also needs worker binaries).\n* `Dynamic` -- Dynamic master mode (also needs worker binaries). \n",
                    "original_header": "CMake"
                },
                "confidence": 0.9999622794931107,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/lotten/daoopt/uai14/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Solutions may not be reported correctly when using the --rotate option. For a\nworkaround, disable tuple generation by definining the NO_ASSIGNMENT flag in\ninclude/DEFINES.h.\n \n",
                    "original_header": "Known issues"
                },
                "confidence": 0.9920536034946135,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/lotten/daoopt/uai14/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2012-02-08T19:00:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2019-05-13T21:06:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 654235
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 470231
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Objective-C",
                    "name": "Objective-C",
                    "type": "Programming_language",
                    "size": 30568
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 181
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "384": {
        "filename": "nasa-impact_hls-foundation-os_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "1. `conda create -n <environment-name> python=3.9`\n2. `conda activate <environment-name>`\n3. Install torch (tested for >=1.7.1 and <=1.11.0) and torchvision (tested for >=0.8.2 and <=0.12). May vary with your system. Please check at: https://pytorch.org/get-started/previous-versions/.\n    1. e.g.: `pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113` \n4. `git clone https://github.com/NASA-IMPACT/hls-foundation-os.git <your-local-path>\\hls-foundation-os`\n5. `git clone https://github.com/open-mmlab/mmsegmentation.git <your-local-path>\\mmsegmentation` \n6. `cd <your-local-path>\\mmsegmentation` \n7. Checkout mmsegmentation version compatible with hls-foundation: `git checkout 186572a3ce64ac9b6b37e66d58c76515000c3280`\n8. modify setup.py so it installs from the cloned mmsegmentation. Change line `mmsegmentation @ git+https://github.com/open-mmlab/mmsegmentation.git@186572a3ce64ac9b6b37e66d58c76515000c3280` to `mmsegmentation @ file:///<your-local-path>/mmsegmentation`\n9. `cd <your-local-path>\\hls-foundation-os`\n10. `pip install -e .`\n11. `pip install -U openmim`\n12. `mim install mmcv-full==1.6.2 -f https://download.openmmlab.com/mmcv/dist/{cuda_version}/{torch_version}/index.html`. Note that pre-built wheels (fast installs without needing to build) only exist for some versions of torch and CUDA. Check compatibilities here: https://mmcv.readthedocs.io/en/v1.6.2/get_started/installation.html\n    1. e.g.: `mim install mmcv-full==1.6.2 -f https://download.openmmlab.com/mmcv/dist/cu115/torch1.11.0/index.html`\n13. `conda install -c conda-forge opencv`\n14. `pip install datasets` \n",
                    "type": "Text_excerpt",
                    "original_header": "Alternate Setup (Windows Users - Tested for Windows 10)",
                    "parent_header": [
                        "Image segmentation by foundation model finetuning",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/nasa-impact/hls-foundation-os/main/README.md"
            },
            {
                "result": {
                    "value": "The flood detection dataset can be downloaded from [Sen1Floods11](https://github.com/cloudtostreet/Sen1Floods11). Splits in the `mmsegmentation` format are available in the `data_splits` folders.\n\n\nThe [NASA HLS fire scars dataset](https://huggingface.co/datasets/nasa-impact/hls_burn_scars) can be downloaded from Hugging Face.\n\nThe [NASA HLS multi-temporal crop classification dataset](https://huggingface.co/datasets/ibm-nasa-geospatial/multi-temporal-crop-classification) can be downloaded from Hugging Face.\n\nUsing git-lfs you can download the data as in the following example: \n``` sh\n# from: https://huggingface.co/datasets/ibm-nasa-geospatial/multi-temporal-crop-classification\n\n# Make sure you have git-lfs installed (https://git-lfs.com)\ngit lfs install\ngit clone https://huggingface.co/datasets/ibm-nasa-geospatial/multi-temporal-crop-classification\n\n# extract files\ncd multi-temporal-crop-classification\ntar -xvf training_chips.tgz && tar -xvf validation_chips.tgz\n```\n\nWithout git-lfs (Credit @robmarkcole):\n```sh\nmkdir data\ncd data\n\nmkdir multi-temporal-crop-classification\ncd multi-temporal-crop-classification\n\n# not this can take some time and appear to hang, be patient\nwget https://huggingface.co/datasets/ibm-nasa-geospatial/multi-temporal-crop-classification/resolve/main/training_chips.tgz?download=true -O training_chips.tgz\ntar -xvzf training_chips.tgz\n\nwget https://huggingface.co/datasets/ibm-nasa-geospatial/multi-temporal-crop-classification/resolve/main/validation_chips.tgz?download=true -O validation_chips.tgz\ntar -xvzf validation_chips.tgz\n\n# delete some mac-os added files\nfind . -name '._*' -delete\n\n# the following are NOT required (TBC)\nhttps://huggingface.co/datasets/ibm-nasa-geospatial/multi-temporal-crop-classification/resolve/main/training_data.txt\nhttps://huggingface.co/datasets/ibm-nasa-geospatial/multi-temporal-crop-classification/resolve/main/validation_data.txt\n\n# instead copy over the files from the splits directory to the location of the images\n\ncd ..\nmkdir hls_burn_scars\ncd hls_burn_scars\nwget https://huggingface.co/datasets/ibm-nasa-geospatial/hls_burn_scars/resolve/main/hls_burn_scars.tar.gz?download=true -O hls_burn_scars.tar.gz\ntar -xvf hls_burn_scars.tar.gz\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Data",
                    "parent_header": [
                        "Image segmentation by foundation model finetuning",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/nasa-impact/hls-foundation-os/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-07-11T15:05:32Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T18:29:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 1828225
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 67431
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "385": {
        "filename": "PJSAC_Trans_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "386": {
        "filename": "christianversloot_machine-learning-articles_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "---\ntitle: \"Easy install of Jupyter Notebook with TensorFlow 2.0 and Docker\"\ndate: \"2020-10-07\"\ncategories:\n  - \"frameworks\"\ntags:\n  - \"docker\"\n  - \"jupyter-notebook\"\n  - \"machine-learning\"\n  - \"tensorflow\"\n---\n\nBeing a data scientist could mean that you have the sexiest job of the 21st Century, according to some business literature. I'd argue that very similar things are true for those who research and engineer machine learning models, as breakthroughs in the areas can directly be captured. If you're familiar with deployment tools, you can even [deploy the model](https://www.machinecurve.com/index.php/2020/03/19/tutorial-how-to-deploy-your-convnet-classifier-with-keras-and-fastapi/) in the field, for example by means of a web service.\n\nIn my experience, success factors of data science and machine learning projects - or any software project in general - include that runtime environments are shared. In the past, this meant that everyone had to install dependencies on their own systems. Then came Python environments, then came Anaconda, but today we will cover Jupyter Notebook. It's widely used in the data science community and therefore deserves a more prominent role on MachineCurve and in any future article I write.\n\nWe'll do a few things in particular. Firstly, we'll take a look at what a Jupyter Notebook is. What can it be used for? How can it help? This is what we will try to answer. Subsequently, we are interested in actually _installing_ such a Notebook onto your system. This could have been problematic, as everyone's host machine works differently (e.g. due to different software installed on the machine, or different operating systems that are in play). Fortunately, with Docker, we can remove many of those problems by abstracting away the host machine. We'll therefore also cover what Docker is, briefly how it works and how to install it to your system.\n\nSubsequently, we're going to install a Jupyter Notebook with Docker. Specifically, we will install a Notebook oriented to TensorFlow projects, although - as we shall see - there are other Notebooks specifically tailored to other use cases (such as Apache Spark).\n\n\\[toc\\]\n\n* * *\n\n## What is a Jupyter Notebook?\n\nNobody installs software without knowing what it is and what it does. If our goal is to use a Jupyer Notebook, we must first understand what it is. Fortunately, the Jupyter website provides clear information as to what you can expect (Project Jupyter, n.d.):\n\n> The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\n\nSounds awesome, doesn't it? :)\n\nIndeed - being widely used within the Data Science Community, a Jupyter Notebook is a web application which can be used for _live code documents_. Those notebooks are essentially digital paper sheets where code can be written. The code can also be executed right there, which makes it an ideal playground for creating a variety of data science and machine learning related code.\n\nAs Python code can be created and executed within a Jupyter Notebook, it is also possible to create and train TensorFlow models from within the web application. What's more, it's even possible to export the Notebook - so that reuse of code is really easy!\n\nHere's what a (part of) a Jupyter Notebook looks like, with some TensorFlow code:\n\n![](images/image-3-1024x356.png)\n\n* * *\n\n## What is Docker?\n\nTime to look at the other component of today's article: Docker. If we take a look at the [Wikipedia page for Docker](https://en.wikipedia.org/wiki/Docker_(software)), we read the following:\n\n> Docker is a set of platform as a service (PaaS) products that use OS-level virtualization to deliver software in packages called containers.\n\nNow, that's quite a technical text, with some interesting words that you may not be familiar with. Let's therefore break things apart into its individual components to understand them better:\n\n- **Platform as a Service (PaaS):** a term used to describe software components that together constitute a platform, i.e. a \"place\" where \"things can run\" - in this case, containers.\n- **OS-level virtualization:** virtualization at the operating system level.\n- **Virtualization:** running an operating system virtually, i.e., within another operating system (such as running a Linux VM on a Windows machine).\n- **OS-level virtualization, again:** virtualization at the operating system level. Now that we understand virtualization, we can understand that it happens _within_ the operating system (virtualization can be applied on hardware as well).\n- **Package-based software called containers:** a design pattern where software is broken up into smaller components, packaged into its own \"virtualized file system\" (such as Linux) and then ran (called a \"container\").\n\nIf you already have some experience with virtualization, it's likely that something is starting to appear here: by means of Docker, you can run software packages in a virtualized way, in their own pseudo-OS, isolated from each other.\n\nIndeed, that is precisely what Docker does - by means of containerization. Not running a _true_ VM, i.e. a real operating system, but running the basics to make e.g. Linux work as the basis for many packages, it allows software developers to 'package' their software and related components together, publish them, for others to run them in an isolated way.\n\nAs a frequent user of Docker myself in my daily work (often, as a container runtime for the Kubernetes orchestration technology), I really love how it works! \ud83d\ude0e\n\nNow that we know what Docker is and what it can be used for, as well understand what Jupyter Notebooks are, we can clearly see that they can be combined together. Using Docker, it becomes possible to run a Jupyter Notebook as well as the dependencies that come installed with one, in an isolated fashion - i.e., as a container. And precisely that is what we're going to do in order to install a Jupyer Notebook on your machine easily!\n\n* * *\n\n## Installing a TensorFlow Notebook with Docker\n\n- Make sure to install Docker first: [click here for installation instructions](https://www.docker.com/products/docker-desktop).\n\nIf Docker was setup successfully on your machine, it's really easy to install a TensorFlow Notebook with Docker. This is because Jupyter has made available so-called [docker-stacks](https://github.com/jupyter/docker-stacks), which are Notebook based Docker images that can be readily installed. There are many, as you can see by means of the link, but those are most prominent:\n\n- **Datascience-notebook:** running data science tasks with a Notebook specifically tailored to data scientists and their package requirements.\n- **TensorFlow-notebook:** training TensorFlow models from your Notebook with `tensorflow` 2.x preinstalled. As we know given the TensorFlow dependencies, this includes the installation of packages such as `numpy` and `scipy`.\n- **Scipy-notebook:** running scientific programming jobs with a Notebook tailored to this usage, specifically focused on `scipy`.\n- **R-notebook:** running mathematical programming with a Notebook filled with R packages.\n- **Pyspark-notebook:** starting Apache Spark jobs from your Notebook with Spark preinstalled.\n\nFor our case, we want to run this command:\n\n```shell\ndocker run -v c:/notebook:/home/jovyan/notebooks -p 8888:8888 jupyter/tensorflow-notebook\n```\n\nIt does the following:\n\n1. It downloads the **jupyter/tensorflow-notebook** Docker image and with `run` creates a container based on this image.\n2. **Port 8888** on your host system maps to **port 8888** within the Docker container, meaning that any communications to http://localhost:8888 will be passed to port 8888 of the container. Fortunately for us, that's where our Notebook runs! (If you have something else running at 8888 locally, you could e.g. move your deployment to port 1234 by writing `-p 1234:8888`.)\n3. We're **mounting** the folder `notebooks` within the container's `/home/jovyan` folder to, in our case `c:/notebook`, because we want to store the Notebooks on our host machine. If we would not do that, all our work would be gone as soon as we kill the Docker container - or if it crashes. Now, all Notebooks are written to `c:/notebook`, and will be loaded into Jupyter the next time your Notebook container starts. Note the following:\n    1. On a Linux or Mac based machine, you can map any folder to `/home/jovyan/notebooks`, e.g. `./hello:/home/jovyan/notebooks`. [This does not work like that on Windows](https://rominirani.com/docker-on-windows-mounting-host-directories-d96f3f056a2c). In Docker for Windows, you will have to make available a folder directly in `c:/`, enable volume mounts in your Docker settings, and mount like we did.\n    2. As you will see when you start Jupyter for the first time, everything is stored in a folder called `notebooks`. This makes sense, because Jupyter itself starts from `/home/jovyan` - and `/home/jovyan/notebooks` simply represents a folder there. If we would mount our volume _directly_ to `/home/jovyan`, however, we would get a permissions error and our Python kernel would not start (see below). That's why we had to mount to a sub folder, so that kernel files generated _within the container_ and Notebooks _stored outside of the container_ are separated!\n\n```shell\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/tornado/web.py\", line 1703, in _execute\n    result = await result\n  File \"/opt/conda/lib/python3.8/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.throw(*exc_info)  # type: ignore\n  File \"/opt/conda/lib/python3.8/site-packages/notebook/services/sessions/handlers.py\", line 69, in post\n    model = yield maybe_future(\n  File \"/opt/conda/lib/python3.8/site-packages/tornado/gen.py\", line 735, in run\n    value = future.result()\n  File \"/opt/conda/lib/python3.8/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.throw(*exc_info)  # type: ignore\n  File \"/opt/conda/lib/python3.8/site-packages/notebook/services/sessions/sessionmanager.py\", line 88, in create_session\n    kernel_id = yield self.start_kernel_for_session(session_id, path, name, type, kernel_name)\n  File \"/opt/conda/lib/python3.8/site-packages/tornado/gen.py\", line 735, in run\n    value = future.result()\n  File \"/opt/conda/lib/python3.8/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.throw(*exc_info)  # type: ignore\n  File \"/opt/conda/lib/python3.8/site-packages/notebook/services/sessions/sessionmanager.py\", line 100, in start_kernel_for_session\n    kernel_id = yield maybe_future(\n  File \"/opt/conda/lib/python3.8/site-packages/tornado/gen.py\", line 735, in run\n    value = future.result()\n  File \"/opt/conda/lib/python3.8/site-packages/notebook/services/kernels/kernelmanager.py\", line 176, in start_kernel\n    kernel_id = await maybe_future(self.pinned_superclass.start_kernel(self, **kwargs))\n  File \"/opt/conda/lib/python3.8/site-packages/jupyter_client/multikernelmanager.py\", line 185, in start_kernel\n    km.start_kernel(**kwargs)\n  File \"/opt/conda/lib/python3.8/site-packages/jupyter_client/manager.py\", line 309, in start_kernel\n    kernel_cmd, kw = self.pre_start_kernel(**kw)\n  File \"/opt/conda/lib/python3.8/site-packages/jupyter_client/manager.py\", line 256, in pre_start_kernel\n    self.write_connection_file()\n  File \"/opt/conda/lib/python3.8/site-packages/jupyter_client/connect.py\", line 468, in write_connection_file\n    self.connection_file, cfg = write_connection_file(self.connection_file,\n  File \"/opt/conda/lib/python3.8/site-packages/jupyter_client/connect.py\", line 138, in write_connection_file\n    with secure_write(fname) as f:\n  File \"/opt/conda/lib/python3.8/contextlib.py\", line 113, in __enter__\n    return next(self.gen)\n  File \"/opt/conda/lib/python3.8/site-packages/jupyter_core/paths.py\", line 445, in secure_write\n    raise RuntimeError(\"Permissions assignment failed for secure file: '{file}'.\"\nRuntimeError: Permissions assignment failed for secure file: '/home/jovyan/.local/share/jupyter/runtime/kernel-38ce2548-e4f9-4a5a-9f28-206ed3225e93.json'. Got '0o655' instead of '0o0600'.\n```\n\n* * *\n\n## Running a Keras model in the Notebook\n\nAfter the Docker container has started, you will see log output in the console (use the `-d` flag if you want to run the container in `daemon` mode, i.e., in the back ground). Log output will look as follows:\n\n```shell\n    To access the notebook, open this file in a browser:\n        file:///home/jovyan/.local/share/jupyter/runtime/nbserver-6-open.html\n    Or copy and paste one of these URLs:\n        http://c456944aff29:8888/?token=cea80acd38c70100d733a2aa185fc7a3048be68ca69c1998\n     or http://127.0.0.1:8888/?token=cea80acd38c70100d733a2aa185fc7a3048be68ca69c1998\n```\n\nYou can now copy the second URL (the first one is a Docker-internal URL) into your web browser and a Notebook environment should start:\n\n![](images/image-2-1024x476.png)\n\nNow click 'New', then 'Python 3', and a new Notebook will be created for you:\n\n![](images/image-4-1024x207.png)\n\nHere, we can add some TensorFlow code, because recall that we ran a Docker container with the TensorFlow dependencies preinstalled, meaning that we can use them immediately. Should you wish to use other resources, you might be able to install them by adding them through `pip` in the container, or preferably, look up the Dockerfile online, copy it and build an image from the copied file including your edits, to ensure that your dependencies won't be gone when you.\n\nWe can now add Keras code for an actual Notebook. However, since we noted before that Notebooks can be easily distributed, it would possibly be preferable to show you the Notebook that I created - [it can be found here](https://github.com/christianversloot/easy-jupyter-notebook/blob/master/example-notebook.ipynb)! :) Note that you can also download it there, and import it into your own Jupyter Notebook environment.\n\nHowever, I've also added the code for a [simple MNIST classifier](https://www.machinecurve.com/index.php/2019/09/17/how-to-create-a-cnn-classifier-with-keras/) in the next section. Here's what our Notebook looks like right now:\n\n![](images/image-5-1024x886.png)\n\n### Keras code that we used\n\n```python\nimport tensorflow\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential, save_model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nimport numpy as np\n\n# Model configuration\nimg_width, img_height = 28, 28\nbatch_size = 250\nno_classes = 10\nvalidation_split = 0.2\nverbosity = 1\nno_epochs = 1\n5\n\n# Load MNIST dataset\n(input_train, target_train), (input_test, target_test) = mnist.load_data()\ninput_shape = (img_width, img_height, 1)\n\n# Reshape data for ConvNet\ninput_train = input_train.reshape(input_train.shape[0], img_width, img_height, 1)\ninput_test = input_test.reshape(input_test.shape[0], img_width, img_height, 1)\ninput_shape = (img_width, img_height, 1)\n\n# Parse numbers as floats\ninput_train = input_train.astype('float32')\ninput_test = input_test.astype('float32')\n\n# Normalize [0, 255] into [0, 1]\ninput_train = input_train / 255\ninput_test = input_test / 255\n\n# Convert target vectors to categorical targets\ntarget_train = tensorflow.keras.utils.to_categorical(target_train, no_classes)\ntarget_test = tensorflow.keras.utils.to_categorical(target_test, no_classes)\n\n# Create the model\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(no_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n              optimizer=tensorflow.keras.optimizers.Adam(),\n              metrics=['accuracy'])\n\n# Fit data to model\nmodel.fit(input_train, target_train,\n          batch_size=batch_size,\n          epochs=no_epochs,\n          verbose=verbosity,\n          validation_split=validation_split)\n\n# Generate generalization metrics for original model\nscore = model.evaluate(input_test, target_test, verbose=0)\nprint(f'CNN - Test loss: {score[0]} / Test accuracy: {score[1]}')\n```\n\n* * *\n\n## Summary\n\nIn this blog, we saw how we can easily install a Jupyter Notebook by means of Docker. Jupyter Notebooks are web application based live code documents where code can be created, run and exchanged with other people. Since Python runs natively within Notebooks, and TensorFlow can be installed, Notebooks have been very prominent in the data science communities.\n\nDocker, on the other hand, is a containerization technology which means that you can package software into containers and then ship them - for other people to run. Combined, we used Docker and Jupyter Notebook to very easily deploy a Notebook on your system. In addition, TensorFlow components came already preinstalled, meaning that you could deploy a TensorFlow model immediately - as we saw by means of a simple Convolutional Neural Network.\n\nI hope that you've learnt something from today's article. If you did, please feel free to leave a comment in the comments section below \ud83d\udcac Please also do the same if you have any other comments, questions or suggestions for improvement. Thank you for reading MachineCurve today and happy engineering! \ud83d\ude0e\n\n\\[kerasbox\\]\n\n* * *\n\n## References\n\n_Jupyter/docker-stacks_. (n.d.). GitHub.\u00a0[https://github.com/jupyter/docker-stacks](https://github.com/jupyter/docker-stacks)\n\n_Project Jupyter_. (n.d.).\u00a0[https://jupyter.org/](https://jupyter.org/)\n\n_Docker_. (n.d.).\u00a0[https://www.docker.com/](https://www.docker.com/)\n\n_Docker (software)_. (2013, July 30). Wikipedia, the free encyclopedia. Retrieved\u00a0October\u00a07, 2020, from\u00a0[https://en.wikipedia.org/wiki/Docker\\_(software)](https://en.wikipedia.org/wiki/Docker_(software))\n",
                    "type": "File_dump"
                },
                "confidence": 1,
                "technique": "file_exploration",
                "source": "https://raw.githubusercontent.com/christianversloot/machine-learning-articles/main/easy-install-of-jupyter-notebook-with-tensorflow-and-docker.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-02-15T18:12:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T04:56:18Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "387": {
        "filename": "probcomp_SolvingBIB-jl_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "388": {
        "filename": "ari-dasci_S-PlanningProblemGeneration_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The main dependencies are: [Python](https://www.python.org/), [Pytorch](https://pytorch.org/) ,[Pytorch Lightning](https://lightning.ai/docs/pytorch/stable/), [CUDA](https://developer.nvidia.com/cuda-toolkit) (only for running on Nvidia GPUs) and the [Fast Downward](https://www.fast-downward.org/) planner. We provide two main installation options. \nThe first one is to manually install all the dependencies (see `Dockerfile` for a complete list) on a Linux machine, and building [FastDownward](https://www.fast-downward.org/) by running `src/nesig/libs/downward/build.py release`.\nThe second (and easiest) option is by creating a [Docker](https://www.docker.com/) image from the `Dockerfile` located in the parent folder of the repo (compatibility between local Nvidia drivers and CUDA in Docker image may need to be checked). We provide detailed instructions for this second option below:\n\n 1. **Clone the repository**: `git clone --depth 1 -b master --recurse-submodules https://github.com/ari-dasci/S-PlanningProblemGeneration.git PlanningProblemGeneration && cd PlanningProblemGeneration `\n 2. **Build the Docker image**: `docker build -t nesig .` (*this may take some time*)\n 3. **Run the container**: `docker run -it --gpus all -p 6006:6006 --mount type=bind,source=/path/to/local/repo,target=/PlanningProblemGeneration nesig`, where `/path/to/local/repo` must be replaced by the absolute path where the repository (*PlanningProblemGeneration*) is located in our local machine. After running this command, we will get a terminal inside the container, from which we can execute the scripts. We use a [bind mount](https://docs.docker.com/storage/bind-mounts/) so that files created by the Docker container (e.g., when generating problems) appear on the host machine (*PlanningProblemGeneration* folder).\n 5. **Test everything works**: an easy way to test the code is to run the tests located in `tests` by running `bash PlanningProblemGeneration/tests/run_all_tests.sh`. Tests also provide an easy way to get familiarized with the code.\n\n**NOTE**: if when running the code you run into an error like `tests/run_all_tests.sh: line 2: $'\\r': command not found` that often means the files contain Windows-style line endings whereas the code expects Linux-style line endings. To solve this error, modify all files in `PlanningProblemGeneration` to contain Linux-style line endings using [dos2unix](https://dos2unix.sourceforge.io/) or clone the repo again with Linux-style line endings.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "NeSIG: A Neuro-Symbolic Method for Learning to Generate Planning Problems"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ari-dasci/S-PlanningProblemGeneration/master/Readme.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-03-24T21:29:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-12T15:40:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "PDDL",
                    "name": "PDDL",
                    "type": "Programming_language",
                    "size": 146505806
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 6255801
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 1876424
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 46521
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 37058
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 29194
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 25802
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Perl",
                    "name": "Perl",
                    "type": "Programming_language",
                    "size": 19755
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Common Lisp",
                    "name": "Common Lisp",
                    "type": "Programming_language",
                    "size": 15865
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 2534
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 1432
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "NewLisp",
                    "name": "NewLisp",
                    "type": "Programming_language",
                    "size": 46
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "389": {
        "filename": "iitkcpslab_rlstl_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Create a python3.7 virtual environment and do the following:   \n\nUnzip the file RLSTL.zip and install the RLSTL package:    \n```\ncd RLSTL/\npip install -e .\n```\n\nInstall the rtamt package   \n```\ncd rtamt/\npip3 install .\n```\n\nAfter installation add the path to the \"RLSTL\" and the \"RLSTL/rtamt\" package   \nto the PYTHONPATH variable in ~/.bashrc file.    \nFor example, if the RLSTL package is ta location /home/PC/RLSTL/, then add the  \nfollowing lines in the ~/.bashrc file:  \nexport PYTHONPATH=/home/PC/RLSTL/:$PYTHONPATH                       \nexport PYTHONPATH=/home/PC/RLSTL/rtamt/:$PYTHONPATH  \n\nAlternatively, instead to adding these lines to ~/.bashrc, you can run these  \ntwo lines in the terminal but it will be valid for a session only.   \n\n\n(In case this variable is not set properly, you might notice error saying  \n\"TypeError: learn() got an unexpected keyword argument 'reward_type').   \n\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "RLSTL"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/iitkcpslab/rlstl/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "RLSTL is a tool to synthesize feedback controllers using Signal Temporal Logic (STL). It is developed using the stable-baselines3 framework (https://github.com/DLR-RM/stable-baselines3) and rtamt online monitoring tool (https://github.com/nickovic/rtamt). \n",
                    "original_header": "RL based synthesis of feedback controller from STL specifications"
                },
                "confidence": 0.9999124887570658,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/iitkcpslab/rlstl/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-11-24T15:51:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-12-04T05:14:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1803340
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 433464
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 249589
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 92969
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 58903
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "MATLAB",
                    "name": "MATLAB",
                    "type": "Programming_language",
                    "size": 50188
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "ANTLR",
                    "name": "ANTLR",
                    "type": "Programming_language",
                    "size": 12931
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1930
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1769
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "390": {
        "filename": "ai4society_Ultra-Metric_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-02-28T21:46:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-13T21:29:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 17822
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 13427
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "391": {
        "filename": "tangjianpku_LINE_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "** Note this repository will no longer be maintained. For node embedding methods, please use our graph embedding system GraphVite: https://github.com/DeepGraphLearning/graphvite \nWe provide both the Windows and LINUX versions. To compile the souce codes, some external packages are required, which are used to generate random numbers for the edge-sampling algorithm in the LINE model. For Windows version, the BOOST package is used and can be downloaded at http://www.boost.org/; for LINUX, the GSL package is used and can be downloaded at http://www.gnu.org/software/gsl/ \nWe provide an example running script for the Youtube data set (available at http://socialnetworks.mpi-sws.mpg.de/data/youtube-links.txt.gz). The script will first run LINE to learn network embeddings, then it will evaluate the learned embeddings on the node classification task. \nTo run the script, users first need to compile the evaluation codes by running make.sh in the folder \"evaluate\". Afterwards, we can run train_youtube.bat or train_youtube.sh to run the whole pipeline. \n",
                    "original_header": "LINE: Large-scale information network embedding"
                },
                "confidence": 0.9793391919853286,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/tangjianpku/LINE/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2015-03-06T03:33:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-10T15:40:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 210054
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 135928
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 34420
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 6164
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2139
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "MATLAB",
                    "name": "MATLAB",
                    "type": "Programming_language",
                    "size": 1820
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 1460
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "392": {
        "filename": "chanind_amr-social-chemistry-reasoner_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "This repo manages dependencies using [Poetry](https://python-poetry.org/). After cloning this repo, run `poetry install` to install dependencies.\n",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "AMR Social Chemistry Reasoner"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/chanind/amr-social-chemistry-reasoner/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The script `amr_reasoner.scripts.evaluate_social_chemistry_rots` can be used to run evaluation. This script can either be used to perform a grid search over parameter values (by pass the `--grid` option), or can be used to evaluate a specific set of hyperparameters. Both of these are illustrated below:\n```bash\n# grid search over possible hyperparameter settings\npoetry run python -m amr_reasoner.scripts.evaluate_social_chemistry_rots \\\n    --grid \\\n    --max-samples 1000\n\n# evaluate a single hyperparameter setting\npoetry run python -m amr_reasoner.scripts.evaluate_social_chemistry_rots \\\n    --min-similarity-threshold 0.9 \\\n    --max-samples 1000\n```\n \n",
                    "original_header": "Evaluation"
                },
                "confidence": 0.9924240466808061,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/chanind/amr-social-chemistry-reasoner/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-03-04T20:38:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-03-14T22:40:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 96805
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "393": {
        "filename": "Question406_LearningToFocus-3_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "394": {
        "filename": "PreferredAI_cornac_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Currently, we are supporting Python 3. There are several ways to install Cornac:\n\n- **From PyPI (recommended):**\n  ```bash\n  pip3 install cornac\n  ```\n\n- **From Anaconda:**\n  ```bash\n  conda install cornac -c conda-forge\n  ```\n\n- **From the GitHub source (for latest updates):**\n  ```bash\n  pip3 install Cython numpy scipy\n  pip3 install git+https://github.com/PreferredAI/cornac.git\n  ```\n\n**Note:** \n\nAdditional dependencies required by models are listed [here](README.md#Models).\n\nSome algorithm implementations use `OpenMP` to support multi-threading. For Mac OS users, in order to run those algorithms efficiently, you might need to install `gcc` from Homebrew to have an OpenMP compiler:\n```bash\nbrew install gcc | brew link gcc\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "Cornac"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/PreferredAI/cornac/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Here, we provide a simple way to serve a Cornac model by launching a standalone web service with [Flask](https://github.com/pallets/flask). It is very handy for testing or creating a demo application. First, we install the dependency:\n```bash\n$ pip3 install Flask\n```\nSupposed that we want to serve the trained BPR model from previous example, we need to save it:\nBASH2*\nAfter that, the model can be deployed easily by running Cornac serving app as follows:\nBASH3*\nHere we go, our model service is now ready. Let's get `top-5` item recommendations for the user `\"63\"`:\nBASH4*\nIf we want to remove seen items during training, we need to provide `TRAIN_SET` which has been saved with the model earlier, when starting the serving app. We can also leverage [WSGI](https://flask.palletsprojects.com/en/3.0.x/deploying/) server for model deployment in production. Please refer to [this](https://cornac.readthedocs.io/en/stable/user/iamadeveloper.html#running-an-api-service) guide for more details.\n \n",
                    "original_header": "Model serving"
                },
                "confidence": 0.9556983945406754,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/PreferredAI/cornac/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "| Year | Model and Paper | Type | Environment | Example |\n| :--: | --------------- | :--: | :---------: | :-----: |\n| 2024 | [Hypergraphs with Attention on Reviews (HypAR)](cornac/models/hypar), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.hypar.recom_hypar), [paper](https://doi.org/10.1007/978-3-031-56027-9_14)| Hybrid / Sentiment / Explainable | [requirements](cornac/models/hypar/requirements_cu116.txt), CPU / GPU | [quick-start](https://github.com/PreferredAI/HypAR)\n| 2022 | [Disentangled Multimodal Representation Learning for Recommendation (DMRL)](cornac/models/dmrl), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.dmrl.recom_dmrl), [paper](https://arxiv.org/pdf/2203.05406.pdf) | Content-Based / Text & Image | [requirements](cornac/models/dmrl/requirements.txt), CPU / GPU | [quick-start](examples/dmrl_example.py)\n| 2021 | [Bilateral Variational Autoencoder for Collaborative Filtering (BiVAECF)](cornac/models/bivaecf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.bivaecf.recom_bivaecf), [paper](https://dl.acm.org/doi/pdf/10.1145/3437963.3441759) | Collaborative Filtering / Content-Based | [requirements](cornac/models/bivaecf/requirements.txt), CPU / GPU | [quick-start](https://github.com/PreferredAI/bi-vae), [deep-dive](https://github.com/recommenders-team/recommenders/blob/main/examples/02_model_collaborative_filtering/cornac_bivae_deep_dive.ipynb)\n|      | [Causal Inference for Visual Debiasing in Visually-Aware Recommendation (CausalRec)](cornac/models/causalrec), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.causalrec.recom_causalrec), [paper](https://arxiv.org/abs/2107.02390) | Content-Based / Image | [requirements](cornac/models/causalrec/requirements.txt), CPU / GPU | [quick-start](examples/causalrec_clothing.py)\n|      | [Explainable Recommendation with Comparative Constraints on Product Aspects (ComparER)](cornac/models/comparer), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.comparer.recom_comparer_sub), [paper](https://dl.acm.org/doi/pdf/10.1145/3437963.3441754) | Explainable | CPU | [quick-start](https://github.com/PreferredAI/ComparER)\n| 2020 | [Adversarial Multimedia Recommendation (AMR)](cornac/models/amr), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.amr.recom_amr), [paper](https://ieeexplore.ieee.org/document/8618394) | Content-Based / Image | [requirements](cornac/models/amr/requirements.txt), CPU / GPU | [quick-start](examples/amr_clothing.py)\n|      | [Hybrid Deep Representation Learning of Ratings and Reviews (HRDR)](cornac/models/hrdr), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.hrdr.recom_hrdr), [paper](https://www.sciencedirect.com/science/article/abs/pii/S0925231219313207) | Content-Based / Text | [requirements](cornac/models/hrdr/requirements.txt), CPU / GPU | [quick-start](examples/hrdr_example.py)\n|      | [LightGCN: Simplifying and Powering Graph Convolution Network](cornac/models/lightgcn), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.lightgcn.recom_lightgcn), [paper](https://arxiv.org/pdf/2002.02126.pdf) | Collaborative Filtering | [requirements](cornac/models/lightgcn/requirements.txt), CPU / GPU | [quick-start](examples/lightgcn_example.py)\n|      | [Predicting Temporal Sets with Deep Neural Networks (DNNTSP)](cornac/models/dnntsp), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.dnntsp.recom_dnntsp), [paper](https://arxiv.org/pdf/2006.11483.pdf) | Next-Basket | [requirements](cornac/models/dnntsp/requirements.txt), CPU / GPU | [quick-start](examples/dnntsp_tafeng.py)\n|      | [Recency Aware Collaborative Filtering (UPCF)](cornac/models/upcf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.upcf.recom_upcf), [paper](https://dl.acm.org/doi/abs/10.1145/3340631.3394850) | Next-Basket | [requirements](cornac/models/upcf/requirements.txt), CPU | [quick-start](examples/upcf_tafeng.py)\n|      | [Temporal-Item-Frequency-based User-KNN (TIFUKNN)](cornac/models/tifuknn), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.tifuknn.recom_tifuknn), [paper](https://arxiv.org/pdf/2006.00556.pdf) | Next-Basket | CPU | [quick-start](examples/tifuknn_tafeng.py)\n|      | [Variational Autoencoder for Top-N Recommendations (RecVAE)](cornac/models/recvae), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.recvae.recom_recvae), [paper](https://doi.org/10.1145/3336191.3371831) | Collaborative Filtering | [requirements](cornac/models/recvae/requirements.txt), CPU / GPU | [quick-start](examples/recvae_example.py)\n| 2019 | [Correlation-Sensitive Next-Basket Recommendation (Beacon)](cornac/models/beacon), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#correlation-sensitive-next-basket-recommendation-beacon), [paper](https://www.ijcai.org/proceedings/2019/0389.pdf) | Next-Basket | [requirements](cornac/models/beacon/requirements.txt), CPU / GPU | [quick-start](examples/beacon_tafeng.py)\n|      | [Embarrassingly Shallow Autoencoders for Sparse Data (EASE\u1d3f)](cornac/models/ease), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.ease.recom_ease), [paper](https://arxiv.org/pdf/1905.03375.pdf) | Collaborative Filtering | CPU | [quick-start](examples/ease_movielens.py)\n|      | [Neural Graph Collaborative Filtering (NGCF)](cornac/models/ngcf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.ngcf.recom_ngcf), [paper](https://arxiv.org/pdf/1905.08108.pdf) | Collaborative Filtering | [requirements](cornac/models/ngcf/requirements.txt), CPU / GPU | [quick-start](examples/ngcf_example.py)\n| 2018 | [Collaborative Context Poisson Factorization (C2PF)](cornac/models/c2pf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.c2pf.recom_c2pf), [paper](https://www.ijcai.org/proceedings/2018/0370.pdf) | Content-Based / Graph | CPU | [quick-start](examples/c2pf_example.py)\n|      | [Graph Convolutional Matrix Completion (GCMC)](cornac/models/gcmc), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.gcmc.recom_gcmc), [paper](https://www.kdd.org/kdd2018/files/deep-learning-day/DLDay18_paper_32.pdf) | Collaborative Filtering | [requirements](cornac/models/gcmc/requirements.txt), CPU / GPU | [quick-start](examples/gcmc_example.py)\n|      | [Multi-Task Explainable Recommendation (MTER)](cornac/models/mter), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.mter.recom_mter), [paper](https://arxiv.org/pdf/1806.03568.pdf) | Explainable | CPU | [quick-start](examples/mter_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/07_explanations.ipynb)\n|      | [Neural Attention Rating Regression with Review-level Explanations (NARRE)](cornac/models/narre), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.narre.recom_narre), [paper](http://www.thuir.cn/group/~YQLiu/publications/WWW2018_CC.pdf) | Explainable / Content-Based | [requirements](cornac/models/narre/requirements.txt), CPU / GPU | [quick-start](examples/narre_example.py)\n|      | [Probabilistic Collaborative Representation Learning (PCRL)](cornac/models/pcrl), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.pcrl.recom_pcrl), [paper](http://www.hadylauw.com/publications/uai18.pdf) | Content-Based / Graph | [requirements](cornac/models/pcrl/requirements.txt), CPU / GPU | [quick-start](examples/pcrl_example.py)\n|      | [Variational Autoencoder for Collaborative Filtering (VAECF)](cornac/models/vaecf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.vaecf.recom_vaecf), [paper](https://arxiv.org/pdf/1802.05814.pdf) | Collaborative Filtering | [requirements](cornac/models/vaecf/requirements.txt), CPU / GPU | [quick-start](examples/vaecf_citeulike.py), [param-search](tutorials/param_search_vaecf.ipynb), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/09_deep_learning.ipynb)\n| 2017 | [Collaborative Variational Autoencoder (CVAE)](cornac/models/cvae), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.cvae.recom_cvae), [paper](http://eelxpeng.github.io/assets/paper/Collaborative_Variational_Autoencoder.pdf) | Content-Based / Text | [requirements](cornac/models/cvae/requirements.txt), CPU / GPU | [quick-start](examples/cvae_example.py)\n|      | [Conditional Variational Autoencoder for Collaborative Filtering (CVAECF)](cornac/models/cvaecf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.cvaecf.recom_cvaecf), [paper](https://dl.acm.org/doi/10.1145/3132847.3132972) | Content-Based / Text | [requirements](cornac/models/cvaecf/requirements.txt), CPU / GPU | [quick-start](examples/cvaecf_filmtrust.py)\n|      | [Generalized Matrix Factorization (GMF)](cornac/models/ncf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.ncf.recom_gmf), [paper](https://arxiv.org/pdf/1708.05031.pdf) | Collaborative Filtering | [requirements](cornac/models/ncf/requirements.txt), CPU / GPU | [quick-start](examples/ncf_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/09_deep_learning.ipynb)\n|      | [Indexable Bayesian Personalized Ranking (IBPR)](cornac/models/ibpr), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.ibpr.recom_ibpr), [paper](http://www.hadylauw.com/publications/cikm17a.pdf) | Collaborative Filtering | [requirements](cornac/models/ibpr/requirements.txt), CPU / GPU | [quick-start](examples/ibpr_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/08_retrieval.ipynb)\n|      | [Matrix Co-Factorization (MCF)](cornac/models/mcf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.mcf.recom_mcf), [paper](https://dsail.kaist.ac.kr/files/WWW17.pdf) | Content-Based / Graph | CPU | [quick-start](examples/mcf_office.py), [cross-modality](https://github.com/lgabs/cornac/blob/luan/describe-gpu-supported-models-readme/tutorials/text_to_graph.ipynb)\n|      | [Multi-Layer Perceptron (MLP)](cornac/models/ncf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.ncf.recom_mlp), [paper](https://arxiv.org/pdf/1708.05031.pdf) | Collaborative Filtering | [requirements](cornac/models/ncf/requirements.txt), CPU / GPU | [quick-start](examples/ncf_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/09_deep_learning.ipynb)\n|      | [Neural Matrix Factorization (NeuMF) / Neural Collaborative Filtering (NCF)](cornac/models/ncf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.ncf.recom_neumf), [paper](https://arxiv.org/pdf/1708.05031.pdf) | Collaborative Filtering | [requirements](cornac/models/ncf/requirements.txt), CPU / GPU | [quick-start](examples/ncf_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/09_deep_learning.ipynb)\n|      | [Online Indexable Bayesian Personalized Ranking (Online IBPR)](cornac/models/online_ibpr), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.online_ibpr.recom_online_ibpr), [paper](http://www.hadylauw.com/publications/cikm17a.pdf) | Collaborative Filtering | [requirements](cornac/models/online_ibpr/requirements.txt), CPU / GPU | [quick-start](examples/ibpr_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/08_retrieval.ipynb)\n|      | [Visual Matrix Factorization (VMF)](cornac/models/vmf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.vmf.recom_vmf), [paper](https://dsail.kaist.ac.kr/files/WWW17.pdf) | Content-Based / Image | [requirements](cornac/models/vmf/requirements.txt), CPU / GPU | [quick-start](examples/vmf_clothing.py)\n| 2016 | [Collaborative Deep Ranking (CDR)](cornac/models/cdr), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.cdr.recom_cdr), [paper](http://inpluslab.com/chenliang/homepagefiles/paper/hao-pakdd2016.pdf) | Content-Based / Text | [requirements](cornac/models/cdr/requirements.txt), CPU / GPU | [quick-start](examples/cdr_example.py)\n|      | [Collaborative Ordinal Embedding (COE)](cornac/models/coe), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.coe.recom_coe), [paper](http://www.hadylauw.com/publications/sdm16.pdf) | Collaborative Filtering | [requirements](cornac/models/coe/requirements.txt), CPU / GPU |\n|      | [Convolutional Matrix Factorization (ConvMF)](cornac/models/conv_mf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.conv_mf.recom_convmf), [paper](http://uclab.khu.ac.kr/resources/publication/C_351.pdf) | Content-Based / Text | [requirements](cornac/models/conv_mf/requirements.txt), CPU / GPU | [quick-start](examples/conv_mf_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/09_deep_learning.ipynb)\n|      | [Learning to Rank Features for Recommendation over Multiple Categories (LRPPM)](cornac/models/lrppm), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#learn-to-rank-user-preferences-based-on-phrase-level-sentiment-analysis-across-multiple-categories-lrppm), [paper](https://www.yongfeng.me/attach/sigir16-chen.pdf) | Explainable | CPU | [quick-start](examples/lrppm_example.py)\n|      | [Session-based Recommendations With Recurrent Neural Networks (GRU4Rec)](cornac/models/gru4rec), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.gru4rec.recom_gru4rec), [paper](https://arxiv.org/pdf/1511.06939.pdf) | Next-Item | [requirements](cornac/models/gru4rec/requirements.txt), CPU / GPU | [quick-start](examples/gru4rec_yoochoose.py)\n|      | [Spherical K-means (SKM)](cornac/models/skm), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.skm.recom_skmeans), [paper](https://www.sciencedirect.com/science/article/pii/S092523121501509X) | Collaborative Filtering | CPU | [quick-start](examples/skm_movielens.py)\n|      | [Visual Bayesian Personalized Ranking (VBPR)](cornac/models/vbpr), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.vbpr.recom_vbpr), [paper](https://arxiv.org/pdf/1510.01784.pdf) | Content-Based / Image | [requirements](cornac/models/vbpr/requirements.txt), CPU / GPU | [quick-start](examples/vbpr_tradesy.py), [cross-modality](tutorials/vbpr_text.ipynb), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/05_multimodality.ipynb)\n| 2015 | [Collaborative Deep Learning (CDL)](cornac/models/cdl), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.cdl.recom_cdl), [paper](https://arxiv.org/pdf/1409.2944.pdf) | Content-Based / Text | [requirements](cornac/models/cdl/requirements.txt), CPU / GPU | [quick-start](examples/cdl_example.py), [deep-dive](https://github.com/lgabs/cornac/blob/luan/describe-gpu-supported-models-readme/tutorials/working_with_auxiliary_data.md)\n|      | [Hierarchical Poisson Factorization (HPF)](cornac/models/hpf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.hpf.recom_hpf), [paper](http://jakehofman.com/inprint/poisson_recs.pdf) | Collaborative Filtering | CPU | [quick-start](examples/hpf_movielens.py)\n|      | [TriRank: Review-aware Explainable Recommendation by Modeling Aspects](cornac/models/trirank), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.trirank.recom_trirank), [paper](https://wing.comp.nus.edu.sg/wp-content/uploads/Publications/PDF/TriRank-%20Review-aware%20Explainable%20Recommendation%20by%20Modeling%20Aspects.pdf) | Explainable | CPU | [quick-start](examples/trirank_example.py)\n| 2014 | [Explicit Factor Model (EFM)](cornac/models/efm), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.efm.recom_efm), [paper](https://www.yongfeng.me/attach/efm-zhang.pdf) | Explainable | CPU | [quick-start](examples/efm_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/07_explanations.ipynb)\n|      | [Social Bayesian Personalized Ranking (SBPR)](cornac/models/sbpr), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#social-bayesian-personalized-ranking-sbpr), [paper](https://cseweb.ucsd.edu/~jmcauley/pdfs/cikm14.pdf) | Content-Based / Social | CPU | [quick-start](examples/sbpr_epinions.py)\n| 2013 | [Hidden Factors and Hidden Topics (HFT)](cornac/models/hft), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.hft.recom_hft), [paper](https://cs.stanford.edu/people/jure/pubs/reviews-recsys13.pdf) | Content-Based / Text | CPU | [quick-start](examples/hft_example.py)\n| 2012 | [Weighted Bayesian Personalized Ranking (WBPR)](cornac/models/bpr), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#weighted-bayesian-personalized-ranking-wbpr), [paper](http://proceedings.mlr.press/v18/gantner12a/gantner12a.pdf) | Collaborative Filtering | CPU | [quick-start](examples/bpr_netflix.py)\n| 2011 | [Collaborative Topic Regression (CTR)](cornac/models/ctr), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.ctr.recom_ctr), [paper](http://www.cs.columbia.edu/~blei/papers/WangBlei2011.pdf) | Content-Based / Text | CPU | [quick-start](examples/ctr_example_citeulike.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/05_multimodality.ipynb)\n| Earlier | [Baseline Only](cornac/models/baseline_only), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#baseline-only), [paper](http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf) | Baseline | CPU | [quick-start](examples/svd_example.py)\n|      | [Bayesian Personalized Ranking (BPR)](cornac/models/bpr), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#bayesian-personalized-ranking-bpr) [paper](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf) | Collaborative Filtering | CPU | [quick-start](examples/bpr_netflix.py), [deep-dive](https://github.com/recommenders-team/recommenders/blob/main/examples/02_model_collaborative_filtering/cornac_bpr_deep_dive.ipynb)\n|      | [Factorization Machines (FM)](cornac/models/fm), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#factorization-machines-fm), [paper](https://www.csie.ntu.edu.tw/~b97053/paper/Factorization%20Machines%20with%20libFM.pdf) | Collaborative Filtering / Content-Based | Linux, CPU | [quick-start](examples/fm_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/06_contextual_awareness.ipynb)\n|      | [Global Average (GlobalAvg)](cornac/models/global_avg), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.global_avg.recom_global_avg), [paper](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf) | Baseline | CPU | [quick-start](examples/biased_mf.py)\n|      | [Global Personalized Top Frequent (GPTop)](cornac/models/gp_top), [paper](https://dl.acm.org/doi/pdf/10.1145/3587153) | Next-Basket | CPU | [quick-start](examples/gp_top_tafeng.py)\n|      | [Item K-Nearest-Neighbors (ItemKNN)](cornac/models/knn), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#item-k-nearest-neighbors-itemknn), [paper](https://dl.acm.org/doi/pdf/10.1145/371920.372071) | Neighborhood-Based | CPU | [quick-start](examples/knn_movielens.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/02_neighborhood.ipynb)\n|      | [Matrix Factorization (MF)](cornac/models/mf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.mf.recom_mf), [paper](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf) | Collaborative Filtering | CPU / GPU | [quick-start](examples/biased_mf.py), [pre-split-data](examples/given_data.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/03_matrix_factorization.ipynb)\n|      | [Maximum Margin Matrix Factorization (MMMF)](cornac/models/mmmf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.mmmf.recom_mmmf), [paper](https://link.springer.com/content/pdf/10.1007/s10994-008-5073-7.pdf) | Collaborative Filtering | CPU | [quick-start](examples/mmmf_exp.py)\n|      | [Most Popular (MostPop)](cornac/models/most_pop), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.most_pop.recom_most_pop), [paper](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf) | Baseline | CPU | [quick-start](examples/bpr_netflix.py)\n|      | [Non-negative Matrix Factorization (NMF)](cornac/models/nmf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.nmf.recom_nmf), [paper](http://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf) | Collaborative Filtering | CPU | [quick-start](examples/nmf_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/03_matrix_factorization.ipynb)\n|      | [Probabilistic Matrix Factorization (PMF)](cornac/models/pmf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.pmf.recom_pmf), [paper](https://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf) | Collaborative Filtering | CPU | [quick-start](examples/pmf_ratio.py)\n|      | [Session Popular (SPop)](cornac/models/spop), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.spop.recom_spop), [paper](https://arxiv.org/pdf/1511.06939.pdf) | Next-Item / Baseline | CPU | [quick-start](examples/spop_yoochoose.py)\n|      | [Singular Value Decomposition (SVD)](cornac/models/svd), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.svd.recom_svd), [paper](https://people.engr.tamu.edu/huangrh/Spring16/papers_course/matrix_factorization.pdf) | Collaborative Filtering | CPU | [quick-start](examples/svd_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/03_matrix_factorization.ipynb)\n|      | [Social Recommendation using PMF (SoRec)](cornac/models/sorec), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.sorec.recom_sorec), [paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.304.2464&rep=rep1&type=pdf) | Content-Based / Social | CPU | [quick-start](examples/sorec_filmtrust.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/05_multimodality.ipynb)\n|      | [User K-Nearest-Neighbors (UserKNN)](cornac/models/knn), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#user-k-nearest-neighbors-userknn), [paper](https://arxiv.org/pdf/1301.7363.pdf) | Neighborhood-Based | CPU | [quick-start](examples/knn_movielens.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/02_neighborhood.ipynb)\n|      | [Weighted Matrix Factorization (WMF)](cornac/models/wmf), [docs](https://cornac.readthedocs.io/en/stable/api_ref/models.html#module-cornac.models.wmf.recom_wmf), [paper](http://yifanhu.net/PUB/cf.pdf) | Collaborative Filtering | [requirements](cornac/models/wmf/requirements.txt), CPU / GPU | [quick-start](examples/wmf_example.py), [deep-dive](https://github.com/PreferredAI/tutorials/blob/master/recommender-systems/04_implicit_feedback.ipynb) \n",
                    "original_header": "Models"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/PreferredAI/cornac/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-07-17T06:31:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-15T13:05:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1346129
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cython",
                    "name": "Cython",
                    "type": "Programming_language",
                    "size": 269972
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 226189
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 40444
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 5411
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 981
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "395": {
        "filename": "raki123_counterfactuals_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "For developement clone via \n```\ngit clone git@github.com:raki123/counterfactuals.git\n```\n\nWe require Python >= 3.6. \n\nAll required modules are listed in `requirements.txt` and can be obtained by running\n```\npip install -r requirements.txt\n```\n\nTo use `WhatIf` as usual but have changes to the code available run\n```\npip install -e .\n```\nin the root directory of this repository.\n",
                    "type": "Text_excerpt",
                    "original_header": "Development setup",
                    "parent_header": [
                        "WhatIf"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/raki123/counterfactuals/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For usage on Linux you may install this software as a pip package via\n```\npip install counterfactuals\n```\nExamples for command line usage are available below. \n",
                    "original_header": "WhatIf"
                },
                "confidence": 0.9999999999995453,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/raki123/counterfactuals/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-12-07T16:41:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-31T07:02:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 56582
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 55
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "396": {
        "filename": "weijingxuan_COCO-MMR_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**2023-07-10:** COCO-MMR version 1.0 completed. \n**2023-09-16:** COCO-MMR version 1.1 officially released.\n \n",
                    "original_header": "5. Version History"
                },
                "confidence": 0.9806437964598844,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/weijingxuan/COCO-MMR/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-09-16T07:29:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-18T15:55:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 18391
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "397": {
        "filename": "NagisaZj_CUP_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "* Install dependencies: \n  ```\n  git init\n  git add .\n  git commit -m init\n  pip install -r requirements/dev.txt\n  cd ./src\n  git clone git@github.com:NagisaZj/metaworld-cup.git\n  git clone git@github.com:NagisaZj/mtenv.git\n  cd ./src/mtenv\n  pip install -e .\n  cd ../metaworld-cup\n  pip install -e .\n  ```",
                    "type": "Text_excerpt",
                    "original_header": "Setup",
                    "parent_header": [
                        "CUP: Critic-Guided Policy Reuse"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/NagisaZj/CUP/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-10-05T02:01:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-11T12:14:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 565507
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 3147
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 764
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 638
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "398": {
        "filename": "ZJULearning_TransAt_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "+ valid.txt: validation file, same format as train.txt \n+ test.txt: test file, same format as train.txt. \n",
                    "original_header": "Benchmark datasets"
                },
                "confidence": 0.9883268837917589,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ZJULearning/TransAt/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-07-02T01:36:55Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-04-18T11:23:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 165504
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1308
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "399": {
        "filename": "Dtradke_Teams_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "400": {
        "filename": "anlopez94_opf_gnn_ppo_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-09-30T11:58:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-04T14:02:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 84837
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "401": {
        "filename": "gyunamister_ProPPa_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Please make sure to install the binaries of [Graphviz](https://graphviz.org/) and [Python 3.8.8](https://www.python.org/downloads/release/python-383/) before you proceed. In the following, shell scripts are developed for the zsh, so if you use a different shell, then you need to modify the scripts accordingly.\n\nIn the first shell:\n\n```bash\ngit clone https://github.com/gyunamister/ProPPa.git\ncd src/backend/db\ndocker-compose up\n```\n\nIn the second shell:\n\n```bash\nexport PROPPA_PATH=<path_to_your_project_root> # the directory where src/ is located\ncd src/backend\n./run_celery.sh\n```\n\nAlternatives to Windows:\n\n```bash\npip install eventlet  \nset REDIS_LOCALHOST_OR_DOCKER=localhost\nset RABBIT_LOCALHOST_OR_DOCKER=localhost\nset RABBITMQ_USER=dtween\nset RABBITMQ_PASSWORD=dtween191!\ncd src/backend/tasks\ncelery -A tasks worker --loglevel=INFO -P eventlet\n```\n\nIn the third shell:\n\n```bash\nexport PROPPA_PATH=<path_to_your_project_root> # the directory where src/ is located\ncd src/backend\n./run_opera.sh\n```\n\nThe default username is admin, and the default password is test123 for logging into the system available at 127.0.0.1/8050.\n",
                    "type": "Text_excerpt",
                    "original_header": "Manual",
                    "parent_header": [
                        "Deployment"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/gyunamister/ProPPa/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "For automatic and platform-independent deployment, simply execute the following commands:\n```shell script\ngit clone https://github.com/gyunamister/ProPPa.git\ncd src/\ndocker-compose up\n```\nAfter installations, the web service is available at *127.0.0.1/8050*. \nThe default username is *admin*, and the default password is *test123* for logging into the system.\nIf you would like the Dash web service to run in debug mode, then change the value of the environment variable **DEBUG_MODE** in the [env file](src/.env) to **true**. \n",
                    "original_header": "Automatic"
                },
                "confidence": 0.9999999998437374,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/gyunamister/ProPPa/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-06-15T07:28:04Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-06-15T07:28:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 404926
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 2189
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 2088
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 381
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "402": {
        "filename": "dikonov_Universal-Dictionary-of-Concepts_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**Other UNL dictionaries:**\n- The UNL Development Center (UNDC) dictionary: http://www.undl.org/unlexp/\n- UNLArium UNLdic http://www.unlweb.net/unlarium/ \n",
                    "original_header": "Related links:"
                },
                "confidence": 0.999005718391245,
                "technique": "supervised_classification",
                "source": "https://gitlab.com/dikonov/Universal-Dictionary-of-Concepts/-/blob/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Our resource is hosted at Gitlab and mirrored at GitHub.  \n- https://gitlab.com/dikonov/Universal-Dictionary-of-Concepts (Main repository)\n- https://github.com/dikonov/Universal-Dictionary-of-Concepts (Mirror)\n \n",
                    "original_header": "Git repositories"
                },
                "confidence": 0.9616573654034424,
                "technique": "supervised_classification",
                "source": "https://gitlab.com/dikonov/Universal-Dictionary-of-Concepts/-/blob/master/README.md"
            }
        ],
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "403": {
        "filename": "ADMAntwerp_XAIstories_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To use the code for SHAPstory generation, refer to the provided Jupyter Notebook: [`SHAPstories_Example.ipynb`](SHAPstories_Example.ipynb). \n",
                    "original_header": "Narrative Generation"
                },
                "confidence": 0.9841325108640823,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/ADMAntwerp/XAIstories/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-09-20T11:23:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-29T11:59:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 17988
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 7620
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "404": {
        "filename": "COLAB2_midca_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "MIDCA Version 1.4: User manual and tutorial for the Metacognitive Integrated Dual-Cycle Architecture (https://tinyurl.com/midcadoc) \n0. (Recommended, but optional) Use a virtualenv before installing MIDCA: \n   ```\n   cd midca/\n   python3 -m venv .env\n   source .env/bin/activate\n   ``` \n   Make sure to `source .env/bin/activate` whenever you open a new terminal to run MIDCA. If you are running MIDCA from PyCharm it should automatically detect the environment and use that version of python. \n\n1. To install MIDCA, run the setup.py file:  \n    ```\n    python setup.py install\n    ```\n    \n    If you will be making changes to MIDCA's code, use the `develop` option, like the following: \n     ```\n    python setup.py develop\n    ``` \n    ```\n    cd midca/\n    python examples/cogsci_demo.py\n    ``` \n5. For an overview of MIDCA and more details about how it works, see the github wiki\n   (https://github.com/COLAB2/midca/wiki) and/or docs folder. \n",
                    "original_header": "MIDCA: The Metacognitive Integrated Dual-Cycle Architecture."
                },
                "confidence": 0.9983305639025039,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/COLAB2/midca/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-10-13T19:53:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-08T01:55:16Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1350497
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 3791
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "405": {
        "filename": "delas_OnlineSoftConformance_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2018-12-04T19:33:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-01-23T10:10:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 106190
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1353
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "406": {
        "filename": "radum2275_merlin_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The source code is organized along the following directory structure and \nrequires a standard GNU build using the GNU Autotools toolchain. \n",
                    "original_header": "Source Code"
                },
                "confidence": 0.9972557469287324,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/radum2275/merlin/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The simplest way to compile the solver is to run `make` in the root folder. The \n`Makefile` distributed with this version compiles the solver in `debug` mode\n(i.e., `-g` option) on a MacOS platform. For `Ubuntu`, please discard the `-stdlib=libc++`\noption in line 2 of the `Makefile`.\n \n",
                    "original_header": "Build"
                },
                "confidence": 0.9960834444080265,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/radum2275/merlin/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "    { \n        \"algorithm\" : \"lbp\",  \n        \"iterations\" : 860,  \n        \"task\" : \"MAR\",  \n        \"value\" : -2.551383,  \n        \"status\" : \"true\",  \n        \"solution\" : [ \n            { \n                \"variable\" : 0,  \n                \"states\" : 2,  \n                \"marginal\" : [0.960694, 0.039306] \n            }, \n            { \n                \"variable\" : 1,  \n                \"states\" : 2,  \n                \"marginal\" : [0.912524, 0.087476] \n            }\n        ]\n    } \n    { \n        \"algorithm\" : \"wmb\",  \n        \"ibound\" : 2,  \n        \"iterations\" : 10,  \n        \"task\" : \"MMAP\",  \n        \"value\" : -12.801573,  \n        \"status\" : \"true\",  \n        \"solution\" : [ \n            { \n                \"variable\" : 0, \n                \"value\" : 0\n            }, \n            { \n                \"variable\" : 1, \n                \"value\" : 0\n            }\n        ] \n    }\n    \n    \n",
                    "original_header": "JSON Output File Format"
                },
                "confidence": 0.9650969148871342,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/radum2275/merlin/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2016-03-04T11:41:52Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-25T19:46:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 501621
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 1227
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 810
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "407": {
        "filename": "PolycraftWorld_PAL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "1. If you haven't already, pull this branch of the repository to your work directory:\n    `git clone -b release_2.0 --single-branch https://github.com/StephenGss/pal.git`\n1. For a fresh install:\n    * navigate to polycraft/pal/setup/ and execute `./setup_linux_headless.sh` (may need sudo permissions).\n    * We have also provided our current setup scripts in that folder (they include a few additional packages enabling us to upload tournament results to SQL) for your reference.\n2. For a pre-existing environment, review the apt-get commands in _setup_linux_shortened.sh_ and execute as-needed.\n3. pip install all requirements. We recommend using a package manager like conda\n   * `conda create --name pal_manager python=3.8 # or use your favorite venv`\n   * `cd polycraft/pal/ && python -m pip install -r requirements.txt`\n4. unzip and move to a known location the zipped tournament JSONs. We recommend testing the setup with a VIRGIN No Novelty variant\n",
                    "type": "Text_excerpt",
                    "original_header": "1. Ubuntu",
                    "parent_header": [
                        "Installation:"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/PolycraftWorld/PAL/master/README.md"
            },
            {
                "result": {
                    "value": "* The last command, `./gradlew runclient` may fail with the following as part of the error message:\n\t`Could not determine java version from '#.#.#'.`\n    * Solution: Run `sudo update-alternatives --config java`\n\t* Choose the option with jdk-8\n* The last command, `./gradlew runclient` may fail with the following as part of the error message:\n\t`Process 'command '/usr/lib/jvm/java-8-openjdk-amd64/bin/java'' finished with non-zero exit value 1`\n\t* Check the stack trace for mention of `Can't connect to X11 window server using 'localhost:0.0' as the value of the DISPLAY variable.`\n\t* Agents that will use SENSE_SCREEN must have systems with video cards or have the xvfb package installed. Please see \n\t* Other agents may be able to run on these systems, but solutions to this issue are based on your local configuration.\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Possible issues",
                    "parent_header": [
                        "Installation:",
                        "1. Ubuntu"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/PolycraftWorld/PAL/master/README.md"
            },
            {
                "result": {
                    "value": "* Key dependency: Java JDK 8\n\t* https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html\n\t* Or as appropriate with Oracle\n\t* You may have to sign in and create an account.\n* Get Git: https://git-scm.com/downloads\n\t* Download and install with all defaults\n* Clone repo (if repo is not already cloned): \n\t* Navigate to target folder for installing Polycraft AI Lab\n\t* Run command prompt/PowerShell\n\t* git clone https://github.com/StephenGss/PAL.git\n* Pull updates (if repo is already cloned):\n",
                    "type": "Text_excerpt",
                    "original_header": "2. Windows",
                    "parent_header": [
                        "Installation:"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/PolycraftWorld/PAL/master/README.md"
            },
            {
                "result": {
                    "value": "Below is an exhaustive list of variables defined in config.py and their associated CLI flag to override their values (where applicable).\n\nCritical Parameters requiring edits before runtime are:\n* AGENT_COMMAND/AGENT_COMMAND_UNIX\n* PAL_COMMAND/PAL_COMMAND_UNIX\n* AGENT_DIRECTORY\n* GAMES_FOLDER\n    * Note: please use one of the pre-created tournaments (after unzipping them). \n    The script reads through this folder in a random order and looks for a specific naming pattern for each game JSON to sort them appropriately and \n    will raise a ValueError if the pattern is not found.\n* GAME_COUNT \n\n| Parameter  | CLI flag | Comments |\n|-----------|--------------------------|--------------|\n|MAX_STEP_COST      | N/A (see file)           | Maximum step cost before a game is ended - set to 1,000,000 |\n|PAL_COMMAND        | N/A (see file)          | Windows command to execute the polycraft client               |\n|PAL_COMMAND_UNIX   | N/A (see file)        | Linux command to run polycraft. |\n|MAX_TIME           | `-i <time>` | maximum time in seconds for a given game (default: 300)|\n|TOURNAMENT_ID      | `-t <name>` | name of the tournament |\n|AGENT_DIRECTORY    | `-d <../agent/>` | work directory where AGENT_COMMAND_UNIX gets executed |\n|AGENT_COMMAND_UNIX | `-x <bash cmd>` | command necessary to launch the Agent AI |\n|AGENT_COMMAND      | `-x <windows cmd>` | -x modifies both parameters (OS-agnostic) |\n|AGENT_ID           | `-a <agent_name>` | name of agent |\n|GAME_COUNT         | `-c <count>`        | number of games to be played. If count > number of games available in the games folder, all games are played.\n|GAMES_FOLDER       | `-g <games/>` | location of folder containing tournament JSONs. |\n\n__NOTE__: the PAL_COMMAND_UNIX must be adjusted away from default to run on a computer with a graphics card & display attached. Please \nsee the related comment in the config.py file, as the appropriate UNIX command (`./gradlew runclient`).\n",
                    "type": "Text_excerpt",
                    "original_header": "Setting Config Variables",
                    "parent_header": [
                        "Launching &amp; Running:"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/PolycraftWorld/PAL/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* New Environment variable PAL_FPS to set game speed frames per second. This can increase your agent's actions per second and greatly decrease training time. By default, this is set to 20 and the maximum is 1000. However, depending on the machine, you may not get the expected frames per second. The frames per second will also depend on what commands you are using. Some commands take 1 frame to perform and others take 2. \n",
                    "original_header": "Release 1.3"
                },
                "confidence": 0.9965766696633187,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/PolycraftWorld/PAL/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* config.py (new file) now contains key configurations necessary to launch tournaments. These configurations can be edited through command line arguments, enabling other scripts to \"git pull\" & execute this code without having to make edits to any files.\n* Game JSONs are now read from a directory containing a \"Tournament\" of game JSONs. \n    * JSON zips of 10, 100, & 1000 game tournaments __will be provided separately__. Usage instructions will be attached.\n    * JSONs must adhere to a strict naming convention of _\\*\\_Gxxxx\\_*.json_ where XX indicates the game number. \n    * Tournaments are played in game order from least to greatest\n* Log Files are created for all STDOUT/STDERR messages across three threads. They are saved in PolycraftAIGym/Logs/:\n    * PAL_log contains all of the output from the PAL (Polycraft) thread\n    * Agent_log contains all printed messages from the AI Agent\n    * Debug_log contains messages generated by the LaunchTournament.py script (main thread)\n* New setup folder includes UNIX commands for installing all system dependencies & an updated requirements.txt correctly includes all necessary packages to run this script\n \n",
                    "original_header": "Release 1.1"
                },
                "confidence": 0.9999999421662568,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/PolycraftWorld/PAL/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The Polycraft World AI API consists of 28 total different API commands at Release 1.5.0 on 5.4.2020. These commands are broken down into SYSTEM commands, DEV commands, and GAME commands. The GAME commands are further divided into MOVE commands, SENSE commands, INTERACT commands. \n",
                    "original_header": "Polycraft Bot API"
                },
                "confidence": 0.999122597355172,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/PolycraftWorld/PAL/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* **START**  \n\t* no args ever used | called once to start tournaments\n* **RESET** domain ../available_tests/pogo_nonov.json\n\t* the base pogo experiment\n* **RESET** domain ../available_tests/hg_nonov.json\n\t* the base hunter-gatherer experiment\n* The following function on the cloud virtual machines for the test harness:\n\t* **RESET** -d ../dry-run/hunger-gatherer/tournament_1/trial_1/hg_1.1.json\n\t* **RESET** -d ../dry-run/hunger-gatherer/tournament_1/trial_1000/hg_1.1000.json\n\t* **RESET** -d ../dry-run/hunger-gatherer/tournament_100/trial_1/hg_100.1.json\n\t* **RESET** -d ../dry-run/hunger-gatherer/tournament_100/trial_1000/hg_100.1000.json\n\t* **RESET** -d ../dry-run/pogo-creation/tournament_1/trial_1000/pogo_1.1.json\n\t* **RESET** -d ../dry-run/pogo-creation/tournament_1/trial_1000/pogo_1.1000.json\n\t* **RESET** -d ../dry-run/pogo-creation/tournament_100/trial_1000/pogo_100.1.json\n\t* **RESET** -d ../dry-run/pogo-creation/tournament_100/trial_1000/pogo_100.1000.json\n\t\t* -d (domain) path to .json novelty transform \n\t\t* called 1,000 times per tournament to start a new trial\n\t\t* different tournaments will run using cloned TA2 agents on different cloud machines\n\t\t* novelty will be pre-set in the .jsons and not generated at run-time\n \n",
                    "original_header": "SYSTEM commands: (2 total)"
                },
                "confidence": 0.9999753763081224,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/PolycraftWorld/PAL/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-01-19T22:04:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-04-22T05:24:21Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 216045
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Rich Text Format",
                    "name": "Rich Text Format",
                    "type": "Programming_language",
                    "size": 71908
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 8694
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 582
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 211
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "408": {
        "filename": "yangji9181_AutoPath_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "AutoPath is implemented with TensorFlow and Python2. Please make sure you have the newest version of both of them. If not sure, simply run\n```\npip2 install --upgrade pip\npip2 install --upgrade tensorflow\npip2 install tqdm\n```\n \n",
                    "original_header": "Deployment"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/yangji9181/AutoPath/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-04-04T19:28:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-03-16T08:18:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 24581
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "409": {
        "filename": "VT-NLP_open_domain_entity_state_tracking_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "torch version: 1.4.0+cu100 \n",
                    "original_header": "package version"
                },
                "confidence": 0.958251453255429,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/VT-NLP/open_domain_entity_state_tracking/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**3.3-Evaluation**\uff1a please get into 6_test_our_model, and run:\n```\npython 1_change_file.py\npython 2_simple_eval.py\n```\n \n<img src=\"https://github.com/VT-NLP/open_domain_entity_state_tracking/blob/main/with_reward.png\" width=\"300\"/>\nNote: the BLEU is the BLEU-2, ROUGE is the ROUGE-L.\n \n",
                    "original_header": "3-KIEST w/o ESC"
                },
                "confidence": 0.9632168067865003,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/VT-NLP/open_domain_entity_state_tracking/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "get into the 3_reward_clasification and run:\n```\nCUDA_VISIBLE_DEVICES=0 python train.py\n```\n \n",
                    "original_header": "4-Classification Reward:"
                },
                "confidence": 0.940594963655024,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/VT-NLP/open_domain_entity_state_tracking/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<img src=\"https://github.com/VT-NLP/open_domain_entity_state_tracking/blob/main/final.png\" width=\"300\"/>\nNote: the BLEU is the BLEU-2, ROUGE is the ROUGE-L.\n \n",
                    "original_header": "5-KIEST:"
                },
                "confidence": 0.9956343149329743,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/VT-NLP/open_domain_entity_state_tracking/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-02-01T14:14:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-09-08T21:56:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 487818
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 5306
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "410": {
        "filename": "MetricsDI_DIMetrics_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "~~~ shell",
                    "type": "Text_excerpt",
                    "original_header": "Install",
                    "parent_header": [
                        "DI-Metrics: Metrics for Hierarchical Document Information Extraction Evaluation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/MetricsDI/DIMetrics/main/README.md"
            },
            {
                "result": {
                    "value": "export CUDA_HOME=/usr/local/cuda-X.X python setup.py install\n~~~\n\nYou will also need to install gcc compiler if not already installed:\n`conda install gcc_linux-64`\n",
                    "type": "Text_excerpt",
                    "original_header": "pip install -e ."
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/MetricsDI/DIMetrics/main/README.md"
            },
            {
                "result": {
                    "value": "Currently implemented metrics can be found in `dime`. All code is in Python 3.\n\n* Levenshtine Distance\n* Longest Common Substring Distance\n* Intersection over Union (Convex Hull, Grouped)\n* Intersection over Union (by constituent bounding box) (credit: DocBank)\n* Hierarchical Edit Distance\n* Tree Edit Distance (for Tables) (credit: IBM)\n* Hungarian Algorithm. We frame class-to-line item grouping as a credit assignment problem. We use bi-partite graph matching and Hungarian algorithm for some evaluation approaches with nested fields using Hungarian Algorithm.\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Currently implemented metrics",
                    "parent_header": [
                        "pip install -e ."
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/MetricsDI/DIMetrics/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-04-06T16:34:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-31T18:16:18Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 4251703
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 144239
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Cuda",
                    "name": "Cuda",
                    "type": "Programming_language",
                    "size": 3156
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 787
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 763
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 209
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "411": {
        "filename": "GuillermoPuebla_rrl_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-02-19T15:25:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-03-25T13:31:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 207012
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "412": {
        "filename": "alejandrodemiquel_ARC_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2020-04-22T04:33:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2020-04-22T04:34:54Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 16627
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 6422
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 3880
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "413": {
        "filename": "Lion-ZS_ER_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To preprocess the datasets, run the following commands.\n```shell script\ncd code\npython3 process_datasets.py\n```\n \n",
                    "original_header": "1. Preprocess the Datasets"
                },
                "confidence": 0.9998795352839059,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Lion-ZS/ER/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-12-08T13:13:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-06-08T03:36:06Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "414": {
        "filename": "xiangyu-sun-789_NTS-NOTEARS_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-09-09T13:00:41Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-08T08:38:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 57233
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "415": {
        "filename": "HKU-Smart-Mobility-Lab_Transpotation_Simulator_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "1. Download the code\n\n  `git clone git@github.com:HKU-Smart-Mobility-Lab/Transportation_Simulator.git`\n\n2. Pull the docker image\n\n  `docker pull jingyunliu663/simulator`\n\n- after running the code, you can use `docker images` to check whether the image is available\n- the docker image comes with the conda environment `new_simulator` and the mongoDB service running in background within the container\n\n3. Run the docker image & get a docker container\n```bash\ndocker run -d -e CRYPTOGRAPHY_OPENSSL_NO_LEGACY=1 -v /path/to/the/Transportation_Simulator:/simulator/scripts --name simulator jingyunliu663/simulator\n```\n- Arguments:\n  - `-d`: detach, run in background\n  - `-v path/to/your/local/file/system:/path/to/your/target/directory/inside/container`: This will mount the local directory into the container. Any changes made to the files in this directory within the container will also be reflected on the local host system, and vice versa.\n  - `--name`: name the container as *simulator*\n  - the last argument is the image name (after all, container is a running instance of an image)\n\n- you can use `docker ps` to check the running containers\n\n4. Enter the interactive shell of the conatiner `simulator`\n```bash\ndocker exec -it simultor /bin/bash\n```\n\n- After enter the interactive shell , you will be in the working directory `/simulator`, you can navigate yourself to  `/simulator/scripts` directory (the directory you choose to mount to) to run the main function\n- You have to activate the conda environment: `conda activate new_simulator` \n\n",
                    "type": "Text_excerpt",
                    "original_header": "Install"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/HKU-Smart-Mobility-Lab/Transpotation_Simulator/main/readme.md"
            },
            {
                "result": {
                    "value": "There are three files in 'input' directory. You can use the driver data and order data provided by us. Also, you can run `python handle_raw_data.py`  to generate orders' information, run `python driver_generation.py`  to generate drviers' information.  \n\nIn [config.py](https://github.com/HKU-Smart-Mobility-Lab/Transpotation_Simulator/blob/main/simulator/config.py), you can set the parameters of the simulator.\n\n```python\n't_initial' # start time of the simulation (s)\n't_end'  # end time of the simulation (s)\n'delta_t' # interval of the simulation (s) \n'vehicle_speed' # speed of vehicle (km / h)\n'repo_speed'  # speed of reposition\n'order_sample_ratio' # ratio of order sampling\n'order_generation_mode'  # the mode of order generation\n'driver_sample_ratio' : 1, # ratio of driver sampling\n'maximum_wait_time_mean' : 300, # mean value of maximum waiting time\n'maximum_wait_time_std' : 0, # variance of maximum waiting time\n\"maximum_pickup_time_passenger_can_tolerate_mean\":float('inf'),  # s\n\"maximum_pickup_time_passenger_can_tolerate_std\"\n\"maximum_price_passenger_can_tolerate_mean\"\n\"maximum_price_passenger_can_tolerate_std\"\n'maximal_pickup_distance'  # km\n'request_interval': 5,  #\n'cruise_flag' :False, # \n'delivery_mode':'rg',\n'pickup_mode':'rg',\n'max_idle_time' : 1,\n'cruise_mode': 'random',\n'reposition_flag': False,\n'eligible_time_for_reposition' : 10, # s\n'reposition_mode': '',\n'track_recording_flag' : True,\n'driver_far_matching_cancel_prob_file' : 'driver_far_matching_cancel_prob',\n'input_file_path':'input/dataset.csv',\n'request_file_name' : 'input/order', #'toy_requests',\n'driver_file_name' : 'input/driver_info',\n'road_network_file_name' : 'road_network_information.pickle',\n'dispatch_method': 'LD', #LD: lagarange decomposition method designed by Peibo Duan\n# 'method': 'instant_reward_no_subway',\n'simulator_mode' : 'toy_mode',\n'experiment_mode' : 'train',\n'driver_num':500,\n'side':4, # grid side length\n'price_per_km':5,  # \uffe5 / km\n'road_information_mode':'load',\n'north_lat': 40.8845,\n'south_lat': 40.6968,\n'east_lng': -74.0831,\n'west_lng': -73.8414,\n'rl_mode': 'reposition',  # reposition and matching\n'method': 'sarsa_no_subway',  #  'sarsa_no_subway' / 'pickup_distance' / 'instant_reward_no_subway'   \n'reposition_method' #2C_global_aware',  # A2C, A2C_global_aware, random_cruise, stay  \n\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Data preparing",
                    "parent_header": [
                        "File Structure"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/HKU-Smart-Mobility-Lab/Transpotation_Simulator/main/readme.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```\n- simulator\n-- input\n  -- graph.graphml\n  -- order.pickle\n  -- driver_info.pickle\n-- output\n  -- some output files\n-- test\n  -- test scripts\n-- utils\n  -- driver_generation.py\n  -- find_closest_point.py\n  -- handle_raw_data.py\n-- dispatch_alg.py\n-- simulator_pattern.py\n-- simulator_env.py\n-- A2C.py\n-- sarsa.py\n-- main.py\n-- config.py\n-- LICENSE.md\n-- api_doc.md\n- readme.md\n```\n \n",
                    "original_header": "File Structure"
                },
                "confidence": 0.9999096811395657,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/HKU-Smart-Mobility-Lab/Transpotation_Simulator/main/readme.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-11-30T09:30:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-02T06:03:19Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 226508
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 26729
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "416": {
        "filename": "HibaArnaout_usefulnegations_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "1) turing_award_winners.tsv; source: [https://www.wikidata.org](https://www.wikidata.org),\n2) usa_presidents.tsv; source: [https://www.wikidata.org](https://www.wikidata.org),\n3) india_hotels.tsv; source: [https://www.booking.com](https://www.booking.com).\n \n",
                    "original_header": "Sources"
                },
                "confidence": 0.9614840437101231,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/HibaArnaout/usefulnegations/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-07-08T16:05:11Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-04-12T08:11:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 5244
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "417": {
        "filename": "TPTPWorld_NonClassicalLogic_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-04-08T13:44:16Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-05T15:01:27Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "OpenEdge ABL",
                    "name": "OpenEdge ABL",
                    "type": "Programming_language",
                    "size": 37453
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Lex",
                    "name": "Lex",
                    "type": "Programming_language",
                    "size": 10321
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 8190
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 7362
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 4900
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "418": {
        "filename": "abisee_cnn-dailymail_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Run\n```\npython make_datafiles.py /path/to/cnn/stories /path/to/dailymail/stories\n```\nreplacing `/path/to/cnn/stories` with the path to where you saved the `cnn/stories` directory that you downloaded; similarly for `dailymail/stories`. \nThis script will do several things:\n* The directories `cnn_stories_tokenized` and `dm_stories_tokenized` will be created and filled with tokenized versions of `cnn/stories` and `dailymail/stories`. This may take some time. ***Note**: you may see several `Untokenizable:` warnings from Stanford Tokenizer. These seem to be related to Unicode characters in the data; so far it seems OK to ignore them.*\n* For each of the url lists `all_train.txt`, `all_val.txt` and `all_test.txt`, the corresponding tokenized stories are read from file, lowercased and written to serialized binary files `train.bin`, `val.bin` and `test.bin`. These will be placed in the newly-created `finished_files` directory. This may take some time.\n* Additionally, a `vocab` file is created from the training data. This is also placed in `finished_files`.\n* Lastly, `train.bin`, `val.bin` and `test.bin` will be split into chunks of 1000 examples per chunk. These chunked files will be saved in `finished_files/chunked` as e.g. `train_000.bin`, `train_001.bin`, ..., `train_287.bin`. This should take a few seconds. You can use either the single files or the chunked files as input to the Tensorflow code (see considerations [here](https://github.com/abisee/cnn-dailymail/issues/3)).\n \n",
                    "original_header": "3. Process into .bin and vocab files"
                },
                "confidence": 0.999970067259871,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/abisee/cnn-dailymail/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**Python 3 version**: This code is in Python 2. If you want a Python 3 version, see . \n"
                },
                "confidence": 0.9999803518150564,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/abisee/cnn-dailymail/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-04-30T08:58:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-11T02:34:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 10055
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "419": {
        "filename": "ml-research_SLASH_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Arseny Skryagin, Wolfgang Stammer, Daniel Ochs, Devendra Singh Dhami , Kristian Kersting  \n \n<p align=\"center\">\n  <img src=\"./imgs/slash_icon.png\">\n</p>\n\n[![MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n",
                    "type": "Text_excerpt",
                    "original_header": "Scalable Neural-Probabilistic Answer Set Programming"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ml-research/SLASH/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-22T09:16:07Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-23T07:01:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 547553
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 494214
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 9591
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1603
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "420": {
        "filename": "xplanlab_xroute_env_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "To interact with the xroute environment, you need to download the simulator first:\n\n| Operating System | Download Link |\n| --- | --- |\n| Ubuntu 22.04 | [Download](https://drive.google.com/file/d/1-Zxd0HiOHclNtwCON5wOM78eCzsPrOBB/view?usp=sharing) |\n\nThen, put the simulator in the `third_party/openroad` folder.\n\nYou may also need to execute the following command to install some libraries to ensure that OpenRoad can start up properly.\n\n```bash\ncd third_party/openroad\nchmod +x DependencyInstaller.sh\nsource ./DependencyInstaller.sh\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "XRoute Environment",
                        "Quickstart"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/xplanlab/xroute_env/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can choose to launch the simulator in following modes:\n \n",
                    "original_header": "Launch Mode"
                },
                "confidence": 0.9664042760430686,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/xplanlab/xroute_env/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "In this mode, the simulator should launch first, then the agent can control the simulator to train the model.\n```bash\ncd examples && python3 launch_training.py\n\ncd baseline/DQN && python3 train_DQN.py cpu\n# cd baseline/PPO && python3 train_PPO.py cpu\n```\n \nAfter executing the command above, the simulator will listen to the port 6667 to wait for environment reset command, and then interact with the agent via port 5556.\n \n",
                    "original_header": "Training Mode"
                },
                "confidence": 0.9989202594827278,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/xplanlab/xroute_env/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "In this mode, the agent should launch first, then the simulator can connect to the agent to get the action.\n```bash\ncd baseline/DQN && python3 test_DQN.py cpu 5556\n# cd baseline/PPO && python3 test_PPO.py cpu 5556\n\ncd examples && python3 launch_evaluation.py 5556\n```\n \n",
                    "original_header": "Evaluation Mode"
                },
                "confidence": 0.9999999927476608,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/xplanlab/xroute_env/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-16T06:20:52Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-31T09:19:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 92867
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 7803
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Tcl",
                    "name": "Tcl",
                    "type": "Programming_language",
                    "size": 2582
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 1200
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 386
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "421": {
        "filename": "Bjarten_early-stopping-pytorch_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2018-12-29T20:15:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-13T14:28:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 88001
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 2109
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "422": {
        "filename": "lwgkzl_MedDG_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "https://drive.google.com/drive/folders/109WnXlNhmqttxYwb4EEscYGcA_-eq8Eg?usp=sharing\n \n",
                    "original_header": "Dataset"
                },
                "confidence": 0.9931259754213461,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/lwgkzl/MedDG/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-09-27T14:49:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-16T03:27:09Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 83388
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "423": {
        "filename": "pablovin_ChefsHatGYM_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We also provide a list of existing plugins and extensions for this library:\n \n",
                    "original_header": "ChefsHatGym V2"
                },
                "confidence": 0.9752208370662415,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/pablovin/ChefsHatGYM/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can use our pip installation:\n```python\n   pip install chefshatgym\n\n```\nRefer to our full [documentation](https://chefshatgym.readthedocs.io/en/latest/) for a complete usage and development guide.\n \n \n",
                    "original_header": "Instalation"
                },
                "confidence": 0.9999998322400784,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/pablovin/ChefsHatGYM/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "All the examples in this repository are distributed under a Non-Comercial license. If you use this environment, you have to agree with the following itens: \n",
                    "original_header": "Legacy Plugins and Extensions"
                },
                "confidence": 0.9965857559927951,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/pablovin/ChefsHatGYM/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Get more information here: https://www.chefshatcup.poli.br/home\n \n",
                    "original_header": "Chef`s Hat Cup: Revenge of the Agent!"
                },
                "confidence": 0.9749306333712916,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/pablovin/ChefsHatGYM/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Get more information here: https://www.whisperproject.eu/chefshat#competition\n \n",
                    "original_header": "The First Chef's Hat Cup is online!"
                },
                "confidence": 0.9150878477604346,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/pablovin/ChefsHatGYM/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-02-29T16:43:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T08:52:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 231393
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "424": {
        "filename": "xbrlej_FiPOMDP_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "See the [Experiment reproducibility guide].\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation (regarding experiments)",
                    "parent_header": [
                        "FiPOMDP - Fuel in Partially Observable Markov Decision Processes"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/xbrlej/FiPOMDP/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "[FiMDPEnv]: https://github.com/FiMDP/FiMDPEnv\n[FiMDP]: https://github.com/FiMDP/FiMDP\n[FiMDP README]: https://github.com/xbrlej/FiPOMDP/blob/master/FiMDP-README.md\n[Experiment reproducibility guide]: ./REPROD-GUIDE.md\n \n",
                    "original_header": "Experiments for AAAI 2023"
                },
                "confidence": 0.9999999999994316,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/xbrlej/FiPOMDP/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-10-08T17:25:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-24T21:32:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 7729007
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 941248
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 4159
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "425": {
        "filename": "yunyikristy_DualMind_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "```\nconda create -n dualmind python=3.7 -y\nconda activate dualmind\n```\n\nInstall other requirements for this repository:\n\n```\nconda install pytorch=1.10.0 torchvision=0.11.1 -c pytorch -y\npip install -r requirements.txt\npip install git+https://github.com/openai/CLIP.git\n```\n\n(Optional) Install habitat data generation and evaluation environment.\n\nInstall [habitat-lab](https://github.com/facebookresearch/habitat-lab)\nand [habitat-sim](https://github.com/facebookresearch/habitat-sim):\n\n- conda install habitat-sim\n   ```\n   conda install habitat-sim=0.2.2 withbullet headless -c conda-forge -c aihabitat\n   ```\n- pip install habitat-lab=0.2.2\n   ```\n   git clone --branch v0.2.2 https://github.com/facebookresearch/habitat-lab.git\n   cd habitat-lab\n   pip install -e .\n  ```\n- You can download the datasets used in this work from the\n  following [website](https://github.com/facebookresearch/habitat-lab/blob/main/DATASETS.md).\n\n(Optional) Install metaworld data generation and evaluation environment.\n\n```\ngit clone https://github.com/rlworkgroup/metaworld.git\ncd metaworld\npip install -e .\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Setting up:",
                    "parent_header": [
                        "DualMind: Is Imitation All You Need? Generalized Decision-Making with Dual-Phase Training"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/yunyikristy/DualMind/main/README.md"
            },
            {
                "result": {
                    "value": "- Habitat data generation\n   ```\n   python data_generate/habitat_data.py\n   ```\n- Metaworld data generation\n   ```\n   python data_generate/metaworld_data.py\n   ```\n",
                    "type": "Text_excerpt",
                    "original_header": "Data generation",
                    "parent_header": [
                        "DualMind: Is Imitation All You Need? Generalized Decision-Making with Dual-Phase Training",
                        "Dataset Preparation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/yunyikristy/DualMind/main/README.md"
            },
            {
                "result": {
                    "value": "For simplicity and uniformity, all our datasets are structured in the following way:\n\n```\n\n/path/to/data/\n\u251c\u2500\u2500 gibson/\n\u2502   \u251c\u2500\u2500 scene1/\n\u2502   \u2502   \u251c\u2500\u2500 scene1_1.zip\n\u2502   \u2502   \u2514\u2500\u2500 scene1_2.zip\n\u2502   \u2514\u2500\u2500 scene2/\n\u2502       \u251c\u2500\u2500 scene2_1.zip\n\u2502       \u2514\u2500\u2500 scene2_2.zip\n\u251c\u2500\u2500 mp3d/\n\u2502   \u251c\u2500\u2500 scene1/\n\u2502   \u2502   \u251c\u2500\u2500 scene1_1.zip\n\u2502   \u2502   \u2514\u2500\u2500 scene1_2.zip\n\u2502   \u2514\u2500\u2500 scene2/\n\u2502       \u251c\u2500\u2500 scene2_1.zip\n\u2502       \u2514\u2500\u2500 scene2_2.zip\n\u251c\u2500\u2500 train_habitat.json\n\u2514\u2500\u2500 train_metaworld.json\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Dataset structure",
                    "parent_header": [
                        "DualMind: Is Imitation All You Need? Generalized Decision-Making with Dual-Phase Training",
                        "Dataset Preparation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/yunyikristy/DualMind/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-07-15T21:46:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-15T05:06:52Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 303920
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "426": {
        "filename": "alonjacovi_XAI-Scholar_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "The code used to interface with SemanticScholar uses the unofficial [semanticscholar](https://github.com/danielnsilva/semanticscholar) python library. Install with `pip install semanticscholar`. The plots and graphs use [Seaborn](https://seaborn.pydata.org/) and [GraphOnline](http://graphonline.ru/en/).\n \n",
                    "original_header": "Sources"
                },
                "confidence": 0.999974997462787,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/alonjacovi/XAI-Scholar/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-12-25T14:22:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-07T17:50:15Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 393017
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "427": {
        "filename": "ChuXiaokai_baidu_ultr_dataset_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Suppose your have downloaded [the Web Search Session Data](https://drive.google.com/drive/folders/1Q3bzSgiGh1D5iunRky6mb89LpxfAO73J?usp=sharing) (training data) and [annotation_data_0522.txt](https://drive.google.com/file/d/1hdWRRSMrCnQxilYfjTx8RhW3XTgiSd9Q/view?usp=sharing) (test data) on Google drive.\n\nMoreover, we provide the resource for those who cannot access google drive. [training data](https://searchscience.baidu.com/dataset_ultr_train.html) [test data](https://searchscience.baidu.com/baidu_ultr/labeled_dataset/test_data.txt) [unigram dict](https://searchscience.baidu.com/baidu_ultr/labeled_dataset/unigram_dict_0510_tokens.txt).\n\n\nFirst, move all the zip file into dir './data/train_data/', e.g.,\n> ```mv yourpath/*.gz ./data/train_data/```\n\nSecond, move the file **part-00000.gz** into './data/click_data/', we will treat it as one of the validation set.\n> ```mv ./data/train_data/part-00000.gz ./data/click_data/part-00000.gz``` \n\nFinally, split the annotated data [annotation_data_0522.txt](https://drive.google.com/file/d/1hdWRRSMrCnQxilYfjTx8RhW3XTgiSd9Q/view?usp=sharing) into test and validation set. Move them into dir './data/annotate_data/'\n> ```mv test_data.txt ./data/annotate_data/```\n> ```mv val_data.txt ./data/annotate_data/```\n",
                    "type": "Text_excerpt",
                    "original_header": "0. Prepare the corpus",
                    "parent_header": [
                        "A Large Scale Search Dataset from Baidu Search Engine",
                        "Quick Start"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/ChuXiaokai/baidu_ultr_dataset/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-06-08T02:21:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-03T10:58:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 154908
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "428": {
        "filename": "DeepGraphLearning_KnowledgeGraph-2014_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "429": {
        "filename": "UlisseMini_procgen-tools_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Required dependencies should be installed using `pip install -r requirements.txt`.   \nData dependencies (cached episode data, etc.) will be downloaded\nautomatically when needed. \n \n",
                    "original_header": "procgen-tools"
                },
                "confidence": 0.9987834425364259,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/UlisseMini/procgen-tools/main/README.ipynb"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\nThen, modify the cheese position, update the environment, and render again: \n",
                    "original_header": "Maze State Parsing, Editing and Updating"
                },
                "confidence": 0.9408410072417424,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/UlisseMini/procgen-tools/main/README.ipynb"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-01-12T22:27:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-16T14:22:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 50953356
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 459429
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1454
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 922
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "430": {
        "filename": "spechub_Hets_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Hets is a parsing, static analysis and proof management tool incorporating various provers and different specification languages, thus providing a tool for heterogeneous specifications. Logic translations are first-class citizens.\n",
                    "type": "Text_excerpt",
                    "original_header": "Hets (The heterogeneous tool set)"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "* general-purpose logics: [Propositional](http://en.wikipedia.org/wiki/Propositional_calculus), [QBF](http://en.wikipedia.org/wiki/QBF), [TPTP](http://www.tptp.org/)/SoftFOL, [CASL](http://www.informatik.uni-bremen.de/cofi/index.php/CASL) (FOL), [HasCASL](http://www.informatik.uni-bremen.de/agbkb/forschung/formal_methods/CoFI/HasCASL/) (HOL)\n* logical frameworks: [Isabelle](http://www.cl.cam.ac.uk/research/hvg/Isabelle/), [LF](http://en.wikipedia.org/wiki/LF_%28logical_framework%29), DFOL\n* modeling languages: [Meta-Object Facility (MOF)](https://en.wikipedia.org/wiki/Meta-Object_Facility), [Query/View/Transformation (QVT)](https://en.wikipedia.org/wiki/QVT)\n* ontologies and constraint languages: [OWL](http://www.w3.org/TR/owl2-overview/), [CommonLogic](https://en.wikipedia.org/wiki/Common_Logic), [RelScheme](http://en.wikipedia.org/wiki/Database_schema), ConstraintCASL\n* reactive systems: CspCASL, [CoCASL](http://www.informatik.uni-bremen.de/agbkb/forschung/formal_methods/CoFI/CoCASL/), ModalCASL, [Maude](http://maude.cs.uiuc.edu/)\n* programming languages: [Haskell](http://www.haskell.org/), [VSE](https://link.springer.com/chapter/10.1007/3-540-60973-3_92)\n* logics of specific tools: Reduce, DMU ([CATIA](http://en.wikipedia.org/wiki/CATIA))\n",
                    "type": "Text_excerpt",
                    "original_header": "Supported languages",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "* [minisat](http://minisat.se/) and [zChaff](http://www.princeton.edu/~chaff/zchaff.html), which are SAT solvers,\n* [SPASS](http://www.spass-prover.org/), [Vampire](http://en.wikipedia.org/wiki/Vampire_%28theorem_prover%29), [Darwin](http://combination.cs.uiowa.edu/Darwin/), [Hyper](https://link.springer.com/chapter/10.1007/978-3-540-73595-3_37) and MathServe, which are automatic first-order theorem provers,\n* [Pellet](https://github.com/stardog-union/pellet) and [Fact++](http://owl.man.ac.uk/factplusplus/), description logic tableau provers,\n* [Leo-II](http://page.mi.fu-berlin.de/cbenzmueller/leo/) and [Satallax](http://www.ps.uni-saarland.de/~cebrown/satallax/), automated higher-order provers,\n* [Isabelle](http://www.cl.cam.ac.uk/Research/HVG/Isabelle/), an interactive higher-order theorem prover,\n* [CSPCASL-prover](http://dx.doi.org/10.1016/j.entcs.2009.08.018), an Isabelle-based prover for CspCASL,\n* [VSE](https://link.springer.com/chapter/10.1007/3-540-60973-3_92), an interactive prover for dynamic logic.\n\nThe structuring constructs of the heterogeneous specification language are those of the [OMG](http://www.omg.org)-standardised [Distributed Ontology, Model and Specification Language (DOL)](http://dol-omg.org), extending those of [CASL](http://www.informatik.uni-bremen.de/cofi/index.php/CASL). However, Hets can also read other structuring constructs, like those of Haskell, Maude or OWL. All these are mapped to so-called development graphs and processed with a proof calculus for heterogeneous development graphs that allows to decompose global proof obligations into local ones (during this, Hets also needs to compute [colimits](http://en.wikipedia.org/wiki/Limit_%28category_theory%29#Colimits_2) of theories over the involved logics).\n\nHets is based on a graph of logics and logic translations. The overall architecture is depicted below. Adding new logics and logic translations to Hets can be done with moderate effort by adding some Haskell code to the Hets source. With the [Latin](https://link.springer.com/chapter/10.1007/978-3-642-22673-1_24) project, this becomes much easier: logics (and in the near future also logic translations) can be declaratively specified in LF.\n\n![Architecture of the heterogeneous tool set Hets](https://github.com/spechub/attachment/raw/a0f26aadac374988f7bee3e191e95ca30e7be511/hets2010.png)\n",
                    "type": "Text_excerpt",
                    "original_header": "The following provers have been connected to Hets:",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "You can try out Hets using the [Web-based interface](http://rest.hets.eu/)\nor install it easily in a [docker container](https://github.com/spechub/Hets/wiki/How-to-use-the-Hets-Docker-Container).\n",
                    "type": "Text_excerpt",
                    "original_header": "Using Hets",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "```\nsudo dpkg --add-architecture i386\t\t\t# not needed for hets-server\nsudo apt-add-repository ppa:hets/hets\nsudo apt-get install hets-desktop\n```",
                    "type": "Text_excerpt",
                    "original_header": "The basic system",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Using Hets",
                        "Installing Hets under Ubuntu"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "```\nsudo dpkg --add-architecture i386\t\t\t# not needed for hets-server\nsudo apt-add-repository -S \"deb [trusted=yes] http://pkg.cs.ovgu.de/LNF/linux/ubuntu 22.04/\"\nsudo apt-get install hets-desktop\n```\n\n\n* for using Hets as a server providing a RESTful interface, use hets-server. This is a smaller version without GUI dependencies. Note that also hets-desktop can be used as as server.\n",
                    "type": "Text_excerpt",
                    "original_header": "The basic system (Ubuntu jammy 22.04)",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Using Hets",
                        "Installing Hets under Ubuntu"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "For Hets development additionally type in\n```\nsudo apt-add-repository -s \"deb http://ppa.launchpad.net/hets/hets/ubuntu bionic main\"\nsudo apt-get update\nsudo apt-get build-dep hets-desktop\n```\nReplace 'bionic' with the Ubuntu version that you use.\nThe Hets sources should be obtained from the git repository (see the end of this page).\n",
                    "type": "Text_excerpt",
                    "original_header": "Hets development",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Using Hets",
                        "Installing Hets under Ubuntu"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "We provide the AUR-packages [`hets-desktop-bin`](https://aur.archlinux.org/packages/hets-desktop-bin/) and [`hets-server-bin`](https://aur.archlinux.org/packages/hets-server-bin/) to install 64 bit binaries of Hets/Hets-server.\nIf you would like to compile Hets yourself, you can install one of the AUR-packages [`hets-desktop`](https://aur.archlinux.org/packages/hets-desktop/) and [`hets-server`](https://aur.archlinux.org/packages/hets-server/).\n",
                    "type": "Text_excerpt",
                    "original_header": "Installing Hets under Archlinux",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Using Hets"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "* Please use a [docker container](https://github.com/spechub/Hets/wiki/How-to-use-the-Hets-Docker-Container).\n",
                    "type": "Text_excerpt",
                    "original_header": "Installing Hets under macOS and Windows",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Using Hets"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "Download the [Hets libraries](https://github.com/spechub/Hets-lib) and set $HETS_LIB to the folder containing these.\n",
                    "type": "Text_excerpt",
                    "original_header": "Hets libraries",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Using Hets"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "Hets is called with\n```\nhets filename\n```\nor\n```\nhets -g filename\n```\nFor entering the command line mode, just call\n```\nhets -I\n```\nFor a short description of the options, call\n```\nhets --help\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Quickstart",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Using Hets"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "See [RESTful Interface](https://github.com/spechub/Hets/wiki/RESTful-Interface)\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Restful Interface",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Using Hets"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "To support writing CASL specifications we have an [emacs mode](http://www.informatik.uni-bremen.de/agbkb/forschung/formal_methods/CoFI/hets/emacs_mode)\n",
                    "type": "Text_excerpt",
                    "original_header": "Emacs Mode for CASL specifications",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Using Hets"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "With the option \"-o pp.tex\" hets can produce nice LaTeX output from your specifictions that can be embedded in your publications using the [hetcasl.sty](http://www.informatik.uni-bremen.de/agbkb/forschung/formal_methods/CoFI/hets/hetcasl.sty) style file.\n",
                    "type": "Text_excerpt",
                    "original_header": "Including specifications in LaTeX documents",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Using Hets"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "A good starting point is the code documentation for [Hets - the Heterogeneous Tool Set](http://hets.eu/docs/).\n\nSince Hets is rather large and complex we recommend following the interactive session in [Debugging and Testing Hets](https://github.com/spechub/Hets/wiki/Debugging-and-Testing-Hets) to get familiar with the central datastructures of Hets.\n\nThe formal background and the general structure of Hets is described in chapter 7 of [Heterogeneous specification and the heterogeneous tool set](http://iks.cs.ovgu.de/~till/papers/habil.pdf).\n",
                    "type": "Text_excerpt",
                    "original_header": "Development",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "Hets is written in [Haskell](http://www.haskell.org), and is compiled using [GHC](http://www.haskell.org/ghc) using a couple of language extensions. Among the Haskell [books and tutorials](http://www.haskell.org/haskellwiki/Books_and_tutorials) we recommend [Real World Haskell](http://book.realworldhaskell.org/).\nThe [language definition](http://www.haskell.org/onlinereport) covers the Haskell98 standard which we are supposed to stick to in most cases. Make sure that you are familiar with at least the most common [library functions of the Prelude](http://www.haskell.org/onlinereport/prelude-index.html).\nFor searching or looking up any [library functions](http://www.haskell.org/ghc/docs/latest/html/libraries) you may also try [Hoogle](http://www.haskell.org/hoogle).\n\nAlso look into [programming guidelines](http://www.haskell.org/haskellwiki/Programming_guidelines) and [things to avoid in Haskell](http://www.haskell.org/haskellwiki/Things_to_avoid).\n",
                    "type": "Text_excerpt",
                    "original_header": "Haskell",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Development"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            },
            {
                "result": {
                    "value": "* Get the git repository and its submodules\n    ```\n    git clone https://github.com/spechub/Hets.git\n    cd Hets\n    git submodule update --init --recursive\n    ```\n* [Install Stack](https://docs.haskellstack.org/en/stable/install_and_upgrade) (use the generic Linux option if you are on Ubuntu).\n* Install build- and GUI-dependencies\n  * Ensure a JDK is installed (version >= 1.7)\n  * Automatically install dependencies with\n  ```\n  ./install_dependencies.sh\n  ```\n  * Manual install\n    * Ubuntu:\n      ```\n      sudo apt install libglib2.0-dev libcairo2-dev libpango1.0-dev libgtk2.0-dev libglade2-dev libncurses-dev\n      sudo apt install postgresql postgresql-server-dev-9.5\n      sudo apt install ant\n      ```\n    * macOS:\n      ```\n      brew cask install xquartz\n      brew install binutils glib libglade cairo gtk fontconfig freetype gettext spechub/hets/udrawgraph\n      brew install ant\n      ```\n* If you work with OWL ontologies, build OWL tools before running hets. Warnings produced by stack (like \"You are not the owner of '/.stack-work/'. Aborting to protect file permissions\")\n  can be ignored as the script doesn't use ghc or stack in general.\n  ```\n  sudo make install-owl-tools\n  ```\n* Setup Stack for Hets (this needs to be done only once after every time the stack.yaml has changed):\n  ```\n  stack setup\n  make restack\n  ```\n  When you invoke `make` for the first time, this will give you warnings about not having found a compiler (\"No compiler found, expected minor version match with ghc-...\").\n  Don't let this discourage you - it's normal.\n  Running `make stack` will take care of it and install the compiler.\n  Running `make restack` does the same thing, as `make stack`, but needs to be run every time the dependencies (`stack.yaml`) change.\n* Build Hets with one of the following:\n  ```\n    make\n    make hets\n    make hets_server\n    make docs\n  ```\n  This uses Stack to build the Hets[-Server] binary (or, in the last case, the Hets code documentation, using haddock).\n  During this process, the specified version of GHC is installed in the user directory, all dependencies are built and finally, the Hets[-Server] binary is compiled.\n* If you want to clean the extra-dependencies of Stack that are put into the Hets working directory, run\n  ```\n  make clean_stack\n  ```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Build Hets using Stack",
                    "parent_header": [
                        "Hets (The heterogeneous tool set)",
                        "Development"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/spechub/Hets/master/README"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2014-06-04T17:20:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-24T18:13:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Haskell",
                    "name": "Haskell",
                    "type": "Programming_language",
                    "size": 9031729
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 1865631
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 139182
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 133179
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Standard ML",
                    "name": "Standard ML",
                    "type": "Programming_language",
                    "size": 130552
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Emacs Lisp",
                    "name": "Emacs Lisp",
                    "type": "Programming_language",
                    "size": 88991
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 68210
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 57442
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 51809
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Perl",
                    "name": "Perl",
                    "type": "Programming_language",
                    "size": 20323
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "OCaml",
                    "name": "OCaml",
                    "type": "Programming_language",
                    "size": 18058
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 14394
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "OpenEdge ABL",
                    "name": "OpenEdge ABL",
                    "type": "Programming_language",
                    "size": 14150
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Yacc",
                    "name": "Yacc",
                    "type": "Programming_language",
                    "size": 13262
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Isabelle",
                    "name": "Isabelle",
                    "type": "Programming_language",
                    "size": 11118
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 10196
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Logos",
                    "name": "Logos",
                    "type": "Programming_language",
                    "size": 10027
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 9962
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 2815
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 1403
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Mathematica",
                    "name": "Mathematica",
                    "type": "Programming_language",
                    "size": 922
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "PHP",
                    "name": "PHP",
                    "type": "Programming_language",
                    "size": 656
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Hack",
                    "name": "Hack",
                    "type": "Programming_language",
                    "size": 588
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "AMPL",
                    "name": "AMPL",
                    "type": "Programming_language",
                    "size": 109
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "431": {
        "filename": "skewondr_FoLiBi_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```\n### pip install accelerate einops yacs iopath\n\n### execute baselines \nCUDA_VISIBLE_DEVICES=0 python main.py --seed 12405 --model_name sakt --data_name algebra05 --de_type none_0 --gpu_num 0 --server_num 0 --describe baselines\n\n### execute rc \nCUDA_VISIBLE_DEVICES=0 python main.py --seed 12405 --model_name sakt --data_name algebra05 --de_type relative_0 --gpu_num 0 --server_num 0 --describe rc\n\n### execute mono\nCUDA_VISIBLE_DEVICES=0 python main.py --seed 12405 --model_name sakt --data_name algebra05 --de_type monotonic_0 --gpu_num 0 --server_num 0 --describe mono\n\n### execute alibi\nCUDA_VISIBLE_DEVICES=0 python main.py --seed 12405 --model_name sakt --data_name algebra05 --de_type alibi1_0 --gpu_num 0 --server_num 0 --describe alibi\n```\n \n",
                    "original_header": "Forgetting-aware Linear Bias for Attentive Knowledge Tracing"
                },
                "confidence": 0.9999999876157234,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/skewondr/FoLiBi/folibi/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-08-07T12:08:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-05T06:53:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 181440
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 734
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "432": {
        "filename": "InkiInki_DKMIL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "We use two datasets in our paper for demonstration: \n1) [Benchmark dataset](https://www.kaggle.com/inkiyinji) \n2) [Image dataset](dataset/bag_generator2D.py).\n",
                    "type": "Text_excerpt",
                    "original_header": "Data Preparation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/InkiInki/DKMIL/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-12-12T12:20:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-15T02:13:17Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 112871
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "433": {
        "filename": "YChen1993_ELECRec_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We provide the trained models on Yelp, Beauty, Sports_and_Games, and Toys_and_Games datasets in `./src/output` folder. You can directly evaluate the trained models on test set by running:\n```\npython main.py --data_name <Data_name> --model_idx 0 --do_eval\n```\n \n",
                    "original_header": "Evaluate Model"
                },
                "confidence": 0.9174564702514456,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/YChen1993/ELECRec/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To train ELECRec on a specific dataset, change to the `src` folder and run following command: \n```\nbash scripts/run_<data_name>.sh\n```\n \n",
                    "original_header": "Train Model"
                },
                "confidence": 0.9998875621424722,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/YChen1993/ELECRec/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-04-07T17:58:16Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-01T13:57:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 60273
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 819
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "434": {
        "filename": "speckdavid_symk_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We recommend using the following configuration which uses bidirectional search.\n```console\n./fast-downward.py domain.pddl problem.pddl --search \"sym_bd()\"\n```\n \nOther configurations are forward or backward search: `--search \"sym_fw()\"` or `--search \"sym_bw()\"`. \nIf you are interested in more options, you can run `./fast-downward.py --search -- --help sym_bd` to view the help for `sym_bd`.\n \n",
                    "original_header": "Single Optimal Solution"
                },
                "confidence": 0.9546430859989371,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/speckdavid/symk/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We recommend using the following configuration which uses bidirectional search and \nreports the best **k** plans. Note that you can also specify `num_plans=infinity` if you want to find all possible plans.\n```console\n./fast-downward.py domain.pddl problem.pddl --search \"symk_bd(plan_selection=top_k(num_plans=**k**,dump_plans=false))\"\n```\n \nNote that with `./fast-downward.py --plan-file sas_plan dom...` you can specify the path and name of the generated plan files (here: `sas_plan`), and by setting the `dump_plans` argument to `true`, all plans found will also be dumped to the console. \nIf you are interested in more options, you can run `./fast-downward.py --search -- --help symk_bd` to view the help for `symk_bd`.\n \n",
                    "original_header": "Top-k Configurations"
                },
                "confidence": 0.9819116117314909,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/speckdavid/symk/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "It is possible to run SymK also with forward or backward search instead of bidirectional search, e.g., with `--search \"symk_fw(...)\"` or `--search \"symk_bw(...)\"`. Depending on the domain, one of these configurations may be faster than bidirectional search (`\"--search symk_bd(...)\"`).\n \n",
                    "original_header": "Other Configurations"
                },
                "confidence": 0.9967629533940557,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/speckdavid/symk/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "We recommend to use the following configurations which use bidirectional search.\n \n",
                    "original_header": "Unordered Plan Selector"
                },
                "confidence": 0.9949730275901028,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/speckdavid/symk/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Two simple examples of plan selectors are the [top_k_selector](src/search/symbolic/plan_selection/top_k_selector.cc) and\nthe [top_k_even_selector](src/search/symbolic/plan_selection/top_k_even_selector.cc).\nFor this purpose it is possible to write your own plan selector.\nThe most important function is *add_plan*, in which you can specify whether a newly generated plan shall be accepted or rejected.\nTo create your own plan selector, you can copy the *.cc* and *.h* files of one of these two selectors and adjust them accordingly. Also add the new file name to [DownwardFiles.cmake](src/search/DownwardFiles.cmake), similar to the other selection files.\nFinally, if you want to find a plan with your *awesome_selector* selector (the name of the selector you specified for the plugin in the *.cc* file), you can use the following command. \n```console\n./fast-downward.py domain.pddl problem.pddl --search \"symk_bd(plan_selection=awesome_selector(num_plans=1))\"\n```\n \nNote, that you can also search for the best **k** plans using your selector.\n \n",
                    "original_header": "New Plan Selector"
                },
                "confidence": 0.9961558982171357,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/speckdavid/symk/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-10-31T11:59:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-15T08:33:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 23073664
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 3207717
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 454636
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 382999
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 271764
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 218974
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "PDDL",
                    "name": "PDDL",
                    "type": "Programming_language",
                    "size": 210664
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 51188
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Roff",
                    "name": "Roff",
                    "type": "Programming_language",
                    "size": 14291
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "M4",
                    "name": "M4",
                    "type": "Programming_language",
                    "size": 7120
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Smarty",
                    "name": "Smarty",
                    "type": "Programming_language",
                    "size": 5156
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "435": {
        "filename": "marcotcr_lime_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "The lime package is on [PyPI](https://pypi.python.org/pypi/lime). Simply run:\n\n```sh\npip install lime\n```\n\nOr clone the repository and run:\n\n```sh\npip install .\n```\n\nWe dropped python2 support in `0.2.0`, `0.1.1.37` was the last version before that.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "lime"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/marcotcr/lime/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<a href=\"https://www.youtube.com/watch?v=hUnRCxnydCc\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/marcotcr/lime/master/doc/images/video_screenshot.png\" width=\"450\" alt=\"KDD promo video\"/></a> \n",
                    "original_header": "lime"
                },
                "confidence": 0.9998234333851458,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/marcotcr/lime/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<img src=\"https://raw.githubusercontent.com/marcotcr/lime/master/doc/images/images.png\" width=200 />\n \n",
                    "original_header": "Images (explaining prediction of 'Cat' in pros and cons)"
                },
                "confidence": 0.9761829072360136,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/marcotcr/lime/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<img src=\"https://raw.githubusercontent.com/marcotcr/lime/master/doc/images/lime.png\" width=300px />\n \n",
                    "original_header": "What are explanations?"
                },
                "confidence": 0.9955312059939544,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/marcotcr/lime/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2016-03-15T22:18:10Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T07:37:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 1249591
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 168304
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 469
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 462
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 387
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "436": {
        "filename": "irshadbhat_csnli_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Requirements\n^^^^^^^^^^^^ \n    pip install -r requirements.txt\n    python build_viterbi.py build_ext --inplace\n    \nDownload models from `csnli-models`_. \n.. _`csnli-models`: https://bitbucket.org/irshadbhat/csnli-models/src \n",
                    "original_header": "CSNLI"
                },
                "confidence": 0.9817850078653949,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/irshadbhat/csnli/master/README.rst"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-08-28T11:38:22Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-03-09T16:37:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 290669
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "437": {
        "filename": "mitmedialab_viznet_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2019-04-03T00:03:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-14T01:30:14Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 1219245
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 104625
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 80559
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 1736
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 540
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 440
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "438": {
        "filename": "BrainCog-X_Brain-Cog_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "1. You can install braincog by running:\n\n    > `pip install braincog`\n\n2. Also, install from github by running:\n\n    > `pip install git+https://github.com/braincog-X/Brain-Cog.git`\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Install Online",
                    "parent_header": [
                        "BrainCog",
                        "Install"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/BrainCog-X/Brain-Cog/main/README.md"
            },
            {
                "result": {
                    "value": "1.  If you are a developer, it is recommanded to download or clone\n    braincog from github.\n\n    > `git clone https://github.com/braincog-X/Brain-Cog.git`\n\n2.  Enter the folder of braincog\n\n    > `cd Brain-Cog`\n\n3.  Install braincog locally\n\n    > `pip install -e .`\n \n",
                    "type": "Text_excerpt",
                    "original_header": "Install locally",
                    "parent_header": [
                        "BrainCog",
                        "Install"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/BrainCog-X/Brain-Cog/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n<img src=\"https://raw.githubusercontent.com/Brain-Cog-Lab/Brain-Cog/main/figures/mirror-test.gif\" alt=\"mt\" width=\"55%\" />\n<img src=\"https://raw.githubusercontent.com/Brain-Cog-Lab/Brain-Cog/main/figures/joy.gif\" alt=\"mt\" width=\"55%\" />\n \n",
                    "original_header": "Brain-Inspired AI"
                },
                "confidence": 0.9999992663158386,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/BrainCog-X/Brain-Cog/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n<img src=\"https://raw.githubusercontent.com/Brain-Cog-Lab/Brain-Cog/main/figures/braincog-mouse-brain-model-10s.gif\" alt=\"bmbm10s\" width=\"55%\" /> \n<img src=\"https://raw.githubusercontent.com/Brain-Cog-Lab/Brain-Cog/main/figures/braincog-macaque-10s.gif\" alt=\"bm10s\" width=\"55%\" />\n<img src=\"https://raw.githubusercontent.com/Brain-Cog-Lab/Brain-Cog/main/figures/braincog-humanbrain-10s.gif\" alt=\"bh10s\" width=\"55%\" /> \n",
                    "original_header": "Brain Simulation"
                },
                "confidence": 0.9999999768215846,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/BrainCog-X/Brain-Cog/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-10-29T09:48:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T08:05:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 537361
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "439": {
        "filename": "finnickniu_LDAM_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-09-15T01:25:39Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-12-02T03:33:00Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 97568
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "440": {
        "filename": "isee4xai_iSeeOnto_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-10-05T13:53:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-12T08:16:44Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 5
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "441": {
        "filename": "hsu-aut_lion_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<p align=\"center\">\n    <img height=\"150px\" src=\"https://github.com/hsu-aut/lion/blob/documentation/images/images/LiOn-Logo.png?raw=true\">\n</p>\n<h1 align=\"center\">LiOn</h1>\n<h2 align=\"center\">A Lightweight Industrial Ontology Support Tool</h2>\n<br> \n# Setup \n## Requirements\nIn order to run LiOnS, you must have Node.js installed. Download it from https://nodejs.org/en/download/ and install it as per the instructions. \n"
                },
                "confidence": 0.9693805675571534,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/hsu-aut/lion/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "1. Clone or download the repository in the directory of your choice.\n2. Start your own instance of [GraphDB](https://www.ontotext.com/products/graphdb/). Open your browser and go to `http://localhost:7200`. Go to `\"Setup\" -> \"Repositories\" -> \"Create new repository\"`. Create a new repository called `testdb`. You can change this later on.\n3. Optional: Start your own ECLASS database (deprecated, we recommend adding your own certificate to be able to access ECLASS's web service). If you really want to setup your own DB, see [this info](https://github.com/hsu-aut/lion#setup-custom-eclass-database).\n4. Open a terminal in both `backend` and `frontend` folder. Of course you can open a terminal in you IDE (e.g. VS Code) so that you have the code and the terminal in one place.\n5. In both terminal, execute `npm install` to install all npm dependencies\n6. As soon as `npm install` finished, execute `npm run start:dev` in both shells to start both backend and frontend in develoment mode. \n7. Both backend and frontend should now be starting. They both run in an interactive mode, i.e., as soon as you save changes, they will recompile / restart.\n8. Open your browser at `localhost:4200` if it isn't opened automatically. \n",
                    "original_header": "Running LiOnS in development mode"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/hsu-aut/lion/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n## Running a release version\n:construction: Documentation coming soon :construction: \n## Setup ECLASS \n### Setup ECLASS Webservice \n### Setup CLASS MySQL database \n"
                },
                "confidence": 0.9716127301506587,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/hsu-aut/lion/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Install [MySQL](https://dev.mysql.com/downloads/installer/). MySQL Server is the minimum, but additionally installing MySQL Workbench will make the setup easier. \nSet up a database called `eclass`. Create the tables `eclass_pr` for properties and `eclass_un` for units of measures from the `.csv` files you just downloaded. The SQL data base configuration should be as follows:\n```\n    \"host\": \"127.0.0.1\",\n    \"user\": \"root\",\n    \"password\": \"root\",\n    \"database\": \"eclass\"\n```\n \n",
                    "original_header": "Setup CLASS MySQL database"
                },
                "confidence": 0.9962793785891499,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/hsu-aut/lion/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2019-03-28T09:05:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-10T01:27:02Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "TypeScript",
                    "name": "TypeScript",
                    "type": "Programming_language",
                    "size": 603600
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 202115
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "SCSS",
                    "name": "SCSS",
                    "type": "Programming_language",
                    "size": 25146
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 15026
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "442": {
        "filename": "kingoflolz_mesh-transformer-jax_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-03-13T23:31:13Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T03:56:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 176361
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 97381
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 3121
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 664
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "443": {
        "filename": "AAIR-lab_DAAISy_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "FF:\n   \n - Please install flex and bison for FF to compile.\n\n - On newer versions of gcc (tested on gcc 10.2.0) please make the following changes:\n    - main.c:150 : Comment out the gbracket_count definition\n       ```\n       int gbracket_count; --> /* int gbracket_count; */\n       ```\n     - relax.c:111 : Define lcurrent_goals as static\n       ```\n       State lcurrent_goals; --> static State lcurrent_goals;\n       ```\n     - search.c:110 : Define lcurrent_goals as static\n       ```\n       State lcurrent_goals; --> static State lcurrent_goals;\n       ```\n    \n\n<br />\n\nPlease note that this is research code and not yet ready for public delivery,\nhence most parts are not documented.\n\nIn case of any queries, please contact [verma.pulkit@asu.edu](mailto:verma.pulkit@asu.edu),\nor [rmnayyar@asu.edu](mailto:rmnayyar@asu.edu).\n\n<br />\n",
                    "type": "Text_excerpt",
                    "original_header": "Common Installation Issues",
                    "parent_header": [
                        "Differential Assessment of AI System (DAAISy)"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/AAIR-lab/DAAISy/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```\n|-- dependencies/\n|   |-- fama/\n|   |-- FD/\n|   |-- FF/\n|   |-- madagascar/\n|   |-- VAL/\n|-- domains/\n|   |-- domain_name/\n|   |   |-- domains/\n|   |   |-- instances/\n|   |   |-- observations/\n|-- random_states/\n|-- results/\n|-- src/\n|   |-- agent.py\n|   |-- config.py\n|   |-- generate_random_states.py\n|   |-- model_drift/\n|   |-- interrogation/\n|   |-- lattice/\n|   |-- query/\n|   |-- utils/\n|-- README.md\n|-- config.py\n|-- learn_model.py\n|-- generate_random_init_domains.py\n``` \n- dependencies/: This directory includes the external software used to run the code. This includes fama, FF, FD, madagascar, and  VAL. \n  - fama: https://github.com/sjimenezgithub/strips-learning/\n  - FF: https://fai.cs.uni-saarland.de/hoffmann/ff/FF-v2.3.tgz\n  - FD: https://github.com/aibasel/downward\n  - madagascar: https://users.aalto.fi/~rintanj1/jussi/software.html\n  - VAL: https://github.com/KCL-Planning/VAL \n",
                    "original_header": "Directory Structure"
                },
                "confidence": 0.997864172465101,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/AAIR-lab/DAAISy/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-03-17T20:55:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-04-01T00:02:16Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 571553
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 601
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "444": {
        "filename": "richoux_Taunt_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2021-11-16T01:26:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-05-23T09:34:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "445": {
        "filename": "RUCKBReasoning_FC-KBQA_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "446": {
        "filename": "Hangwei12358_cross-person-HAR_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Three datasets (UCIHAR, Opportunity, and UniMiB SHAR) are utilized in the experiments. The pre-processed outcome can be downloaded from [HERE](https://drive.google.com/drive/folders/1S4oGTs8ChD8ezmxOrnqcboWVWHvT7CdH?usp=sharing). Please save datasets under folder `./data`. The `data_preprocess_[dataset-name].py` can conduct data-preprocessing automatically. \n\n",
                    "type": "Text_excerpt",
                    "original_header": "Datasets Preparation",
                    "parent_header": [
                        "cross-person-HAR"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Hangwei12358/cross-person-HAR/main/README.md"
            },
            {
                "result": {
                    "value": "Create an environment named `gile` in Anaconda and install necessary packages. \n```shell script\nconda create --name gile python=3.6\nconda activate gile\nconda install -c pytorch pytorch=1.3\nconda install -c conda-forge matplotlib\nconda install -c conda-forge scikit-learn\nconda install -c conda-forge tqdm\nconda install -c pytorch torchvision\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Environment Setup",
                    "parent_header": [
                        "cross-person-HAR"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/Hangwei12358/cross-person-HAR/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-12-09T05:14:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-19T01:56:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 101840
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "447": {
        "filename": "microsoft_mttl_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n \n",
                    "original_header": "Trademarks"
                },
                "confidence": 0.9988852287322683,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/microsoft/mttl/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-07-11T16:36:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-20T11:32:15Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 964600
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 10434
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 336
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "448": {
        "filename": "Vicinity111_DCE-RD_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-08-08T06:20:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-06T08:26:42Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 53094
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "449": {
        "filename": "AIG-ist-tugraz_ExamMultiConf_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-09-17T17:15:03Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-09-17T18:10:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 63386
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "450": {
        "filename": "Ludeme_Ludii_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Ludii is a general game system being developed as part of the [ERC-funded Digital Ludeme Project (DLP)](http://ludeme.eu/). This repository hosts the publicly available source code for Ludii. A precompiled build (Ludii.JAR) can be downloaded from [Ludii's downloads page](https://ludii.games/download.php).\n \n",
                    "original_header": "The Ludii General Game System"
                },
                "confidence": 0.9202641013427078,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/Ludeme/Ludii/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2021-05-03T12:54:50Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T07:59:05Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 15285976
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 36508
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "PostScript",
                    "name": "PostScript",
                    "type": "Programming_language",
                    "size": 28912
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "GLSL",
                    "name": "GLSL",
                    "type": "Programming_language",
                    "size": 7540
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "451": {
        "filename": "leela-zero_leela-zero_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "If you are on Windows, download an official release from [here](https://github.com/leela-zero/leela-zero/releases) and head to the [Usage](#usage-for-playing-or-analyzing-games)\nsection of this README. \nIf you are on macOS, Leela Zero is available through [Homebrew](https://homebrew.sh), the de facto standard\npackage manager. You can install it with:\n```\nbrew install leela-zero\n``` \nIf you are on Unix, you have to compile the program yourself. Follow\nthe compilation instructions below and then read the [Usage](#usage-for-playing-or-analyzing-games) section.\n \n",
                    "original_header": "I just want to play with Leela Zero right now"
                },
                "confidence": 0.9800257223948189,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/leela-zero/leela-zero/next/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "    dump_supervised sgffile.sgf train.txt \n",
                    "original_header": "Supervised learning"
                },
                "confidence": 0.9464863067772983,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/leela-zero/leela-zero/next/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- [ ] Further optimize Winograd transformations.\n- [ ] Improve GPU batching in the search.\n- [ ] Root filtering for handicap play.\n- More backends:\n- [ ] MKL-DNN based backend.\n- [ ] CUDA specific version using cuDNN or cuBLAS.\n- [ ] AMD specific version using MIOpen/ROCm.\n \n",
                    "original_header": "Todo"
                },
                "confidence": 0.9999919528806119,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/leela-zero/leela-zero/next/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* Status page of the distributed effort:\nhttps://zero.sjeng.org\n* GUI and study tool for Leela Zero:\nhttps://github.com/featurecat/lizzie\n* Watch Leela Zero's training games live in a GUI:\nhttps://github.com/barrybecker4/LeelaWatcher\n* Original Alpha Go (Lee Sedol) paper:\nhttps://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf\n* Alpha Go Zero paper:\nhttps://deepmind.com/documents/119/agz_unformatted_nature.pdf\n* Alpha Zero (Go, Chess, Shogi) paper:\nhttps://arxiv.org/pdf/1712.01815.pdf\n* AlphaGo Zero Explained In One Diagram:\nhttps://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0\n* Stockfish chess engine ported to Leela Zero framework:\nhttps://github.com/LeelaChessZero/lczero\n* Leela Chess Zero (chess optimized client)\nhttps://github.com/LeelaChessZero/lc0\n \n",
                    "original_header": "Related links"
                },
                "confidence": 0.9999999999998863,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/leela-zero/leela-zero/next/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2017-10-24T18:19:43Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-21T12:00:57Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 1044791
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 108286
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 74719
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 62758
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 2020
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 1956
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "QMake",
                    "name": "QMake",
                    "type": "Programming_language",
                    "size": 1076
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "452": {
        "filename": "marslanm_multimodality-representation-learning_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**Vqa:\u00a0Visual question answering.**[2015 ICCV] \n",
                    "original_header": "Classification"
                },
                "confidence": 0.9568005720053764,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/marslanm/multimodality-representation-learning/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "**Analyzing Compositionality of Visual Question Answering.**[2019 NIPS] \n**OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge.**[2019 CVPR] \n",
                    "original_header": "Generation"
                },
                "confidence": 0.9223048119645451,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/marslanm/multimodality-representation-learning/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Vqa:\u00a0Visual question answering.**[2015 ICCV] \n",
                    "original_header": "Multimodal-Datasets"
                },
                "confidence": 0.9568005720053764,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/marslanm/multimodality-representation-learning/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-03-13T15:25:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-06T09:21:55Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "453": {
        "filename": "peschue_ai4eu-sudoku_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "A Tutorial video about this \"Sudoku Hello World\" can be found here:\nhttps://www.youtube.com/watch?v=gM-HRMNOi4w\n \n",
                    "original_header": "AI4EU Sudoku Hello World"
                },
                "confidence": 0.9129014801534725,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/peschue/ai4eu-sudoku/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-11-02T15:49:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2021-12-01T14:08:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 27212
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 3600
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 2814
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CSS",
                    "name": "CSS",
                    "type": "Programming_language",
                    "size": 1211
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 1146
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 474
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "454": {
        "filename": "Inspector-GameTesting_Inspector-GameTesting_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-02-24T06:23:40Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2022-03-26T03:25:15Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "455": {
        "filename": "xybFight_NAR4TSP_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n### How to Run\n```shell\n# 1. Training\npython -u train.py\n\n# 2. Testing\npython -u val.py\n```\n \n"
                },
                "confidence": 0.9918921622878571,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/xybFight/NAR4TSP/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "  * https://github.com/xbresson/TSP_Transformer \n",
                    "original_header": "Acknowledgments"
                },
                "confidence": 0.998083881578065,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/xybFight/NAR4TSP/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-06-09T08:34:14Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-05T09:36:38Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 29405
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "456": {
        "filename": "semanticsystems_swemls-toolkit_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Prerequisite: \n* Java 11 and Maven 3 installation \nBuild your maven project:  \n* open the project in an IDE (e.g., IntelliJ or Eclipse)\n* build the application using the following command: `mvn clean install`\n* run the application with the following command:  `java -jar target/swemls-toolkit-0.1.0-jar-with-dependencies.jar` \n",
                    "original_header": "Instructions"
                },
                "confidence": 0.9823772608524199,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/semanticsystems/swemls-toolkit/main/readme.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-12-16T12:56:06Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-09-01T08:23:20Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 7391
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "457": {
        "filename": "jw3il_PommerLearn_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Of course, you can also build and run the image manually. Have a closer look at the scripts from the previous section for details.\n\nAdditional notes:\n* You can limit the gpu access of a container like `--gpus device=4`. However, PommerLearn has a `--gpu` argument that can be used instead.\n* **Warning**: If you use rootless docker, the container will probably run out of memory. \n    Adding `--ipc=host` or `--shm-size=32g` to the `docker run` command helps.\n    This is also done by default in `docker/run.sh`.\n",
                    "type": "Text_excerpt",
                    "original_header": "Manual Docker Build",
                    "parent_header": [
                        "PommerLearn: Learning-based MCTS in the Pommerman Environment",
                        "Docker"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/jw3il/PommerLearn/master/README.md"
            },
            {
                "result": {
                    "value": "For the python side:\n\n* `python 3.7` and `pip`\n\n    It is recommend to use virtual environments. This guide will use [Anaconda](https://www.anaconda.com/). Create an environment named `pommer` with\n\n    ```\n    $ conda create -n pommer python=3.7\n    ```\n\nFor the C++ side:\n\n* Essential build tools: `gcc`, `make`, `cmake`\n\n    ```\n    $ sudo apt install build-essential cmake\n    ```\n\n* The dependencies [z5](https://github.com/constantinpape/z5), [xtensor](https://github.com/xtensor-stack/xtensor), [boost](boost.org) and [json by nlohmann](https://github.com/nlohmann/json/) can directly be installed with conda in the pommer environment:\n\n    ```\n    (pommer) $ conda install -c conda-forge z5py xtensor boost nlohmann_json blosc\n    ```\n\n* [Blaze](https://bitbucket.org/blaze-lib/blaze/src/master/) needs to be installed manually. Note that it can be unpacked anywhere, it does not have to be `/usr/local`. For further information, you can refer to the [installation guide](https://bitbucket.org/blaze-lib/blaze/wiki/Configuration%20and%20Installation#!manual-installation-on-linuxmacos) or the Dockerfiles in this repository.\n\n    ```\n    cmake -DCMAKE_INSTALL_PREFIX=/usr/local/\n    sudo make install\n    export BLAZE_PATH=/usr/local/include/\n    ```\n* Manual installation of **TensorRT** (not Torch-TensorRT), including CUDA and cuDNN. Please refer to the installation guide by NVIDIA https://developer.nvidia.com/tensorrt-getting-started.\n",
                    "type": "Text_excerpt",
                    "original_header": "Manual Installation of Dependencies",
                    "parent_header": [
                        "PommerLearn: Learning-based MCTS in the Pommerman Environment",
                        "Development"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/jw3il/PommerLearn/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Available backends:\n- TensorRT (**NVIDIA GPU required**): Tested with TensorRT 8.0.1 and PyTorch 1.9.0.\n \n",
                    "original_header": "Docker"
                },
                "confidence": 0.9998630767725101,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/jw3il/PommerLearn/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "1. Build the image\n    ```\n    $ bash docker/build.sh\n    ```\n    This automatically caches the dependencies. If you run it again, only the code is rebuilt. If you want to rebuild the whole image, just call `bash docker/build.sh --no-cache`. \n1. Specify where you want to store the data generated by the experiments as environment variable `$POMMER_DATA_DIR`. You can `export POMMER_DATA_DIR=/some/dir` or just add `POMMER_DATA_DIR=/some/dir` as a prefix to the command in the following step. \n3. Create a container and run the training loop (replace `--help` with the arguments of your choice)\n    ```\n    $ bash docker/run.sh --help\n    ```\n    * Note that `--dir` and `--exec` are already specified correctly by `docker/run.sh`.\n    * All GPUs are visible in the container and gpu 0 is used by default. You can specify the gpu to be used like `--gpu 4`.\n \n",
                    "original_header": "Build Scripts"
                },
                "confidence": 0.9999881745161923,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/jw3il/PommerLearn/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "    ```\n    $POMMER_EXEC --mode=ffa_sl --max-games=-1 --chunk-size=1000 --chunk-count=1000 --log --file-prefix=./1M_simple\n    ```\n    where `$POMMER_EXEC` can be your `PommerLearn` executable or `MODE=exec bash docker/run.sh` \n4. You can now perform search experiments with both models. Use `POMMER_1VS1=false MODE=exec bash run.sh` for the single-player search and `POMMER_1VS1=true MODE=exec bash run.sh`git  for the two-player search.\n5. To reproduce our results, you can generate 5 sl and dummy models labeled with the respective suffix `-0` to `-4`. Navigate into the docker directory and run the search experiments with \n    ```\n    ./docker $ bash search_experiments.sh\n    ``` \n",
                    "original_header": "Search Approaches"
                },
                "confidence": 0.9687823423948044,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/jw3il/PommerLearn/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Navigate into the docker directory and run the rl experiments with\n```\n./docker $ bash rl_experiments.sh\n```\n \n",
                    "original_header": "Reinforcement Learning"
                },
                "confidence": 0.9823250045008977,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/jw3il/PommerLearn/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "This repository depends on submodules. Clone it and initialize all submodules with\n```\n$ git clone git@gitlab.com:jweil/PommerLearn.git && \\\n$ cd PommerLearn && \\\n$ git submodule update --init\n```\n \n",
                    "original_header": "Clone Repository"
                },
                "confidence": 1.0,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/jw3il/PommerLearn/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "1. The current version requires you to set the env variables \n    * `CONDA_ENV_PATH`: path of your conda environment (e.g. `~/conda/envs/pommer`)\n    * `BLAZE_PATH`: blaze installation path (e.g. `/usr/local/include`)\n    * `CUDA_PATH`: cuda installation path (e.g. `/usr/local/cuda`)\n    * `TENSORRT_PATH` (when using the CrazyAra TensorRT backend, e.g. `/usr/src/tensorrt`)\n    * [`Torch_DIR`] (when using the CrazyAra Torch backend, currently untested) \n2. Build the C++ environment with the provided `CMakeLists.txt`. To use TensorRT >= 8 (recommended), you have to specify `-DUSE_TENSORRT8=ON`.\n```\n/PommerLearn/build $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_TENSORRT8=ON -DCMAKE_CXX_COMPILER=\"$(which g++)\" ..\n/PommerLearn/build $ make VERBOSE=1 all -j8\n```\n \n",
                    "original_header": "Build Instructions"
                },
                "confidence": 0.9989953125505323,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/jw3il/PommerLearn/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "Prerequisites and Building\n* Make sure that you've pulled all submodules recursively\n* In older versions of TensorRT, you have to manually comment out `using namespace sample;` in `deps/CrazyAra/engine/src/nn/tensorrtapi.cpp`\n* We experienced issues with `std::filesystem` being undefined when using GCC 7.5.0. We recommend to update to more recent versions, e.g. GCC 11.2.0. \nRunning\n* For runtime issues like `libstdc++.so.6: version 'GLIBCXX_3.4.30' not found`, try loading your system libraries with `export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/x86_64-linux-gnu/`. \n  On some systems, ctypes somehow uses a different libstdc++ from the conda environment instead of the correct lib path. \n  As a last resort, you can back up the original library `mv /conda-lib-path/libstdc++.so.6 /conda-lib-path/libstdc++.so.6.old` and then create a symbolic link `ln -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /conda-lib-path/libstdc++.so.6`.\n* If you encounter errors like `ModuleNotFoundError: No module named 'training'`, set your `PYTHONPATH` to the `pommerlearn` directory. For example, `export PYTHONPATH=/PommerLearn/pommerlearn`.\n* When loading `tensorboard` runs, you can get errors like `Error: tonic::transport::Error(Transport, hyper::Error(Accept, Os { code: 24, kind: Other, message: \"Too many open files\" }))`. The argument `--load_fast=false` might help.\n \n",
                    "original_header": "Troubleshooting"
                },
                "confidence": 0.9999999364787056,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/jw3il/PommerLearn/master/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You can install the plotting utility for [gprof](https://ftp.gnu.org/old-gnu/Manuals/gprof-2.9.1/html_mono/gprof.html): https://github.com/jrfonseca/gprof2dot \nActivate the CMake option `USE_PROFILING` in `CMakeLists.txt` and rebuild.\nRun the executable and generate the plot:\n```bash\n./PommerLearn --mode ffa_mcts --max_games 10\ngprof PommerLearn | gprof2dot | dot -Tpng -o profile.png\n```\n \n",
                    "original_header": "Performance Profiling"
                },
                "confidence": 0.971653848079755,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/jw3il/PommerLearn/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-02-23T10:22:27Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-09T12:03:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 212400
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 140199
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 11118
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 5943
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 3058
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 820
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "458": {
        "filename": "maxwellreuter_chatgpt-refusals_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "To run the code, you will need to install the appropriate dependencies using [`pip`](https://packaging.python.org/en/latest/tutorials/installing-packages/#installing-from-pypi), [Conda](https://docs.conda.io/en/latest/), or similar.\n \n",
                    "original_header": "I'm Afraid I Can't Do That - Predicting Prompt Refusal in Black-Box Generative Language Models"
                },
                "confidence": 0.9999935427000974,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/maxwellreuter/chatgpt-refusals/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-05-26T15:09:01Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-24T12:57:12Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 9353
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "459": {
        "filename": "pbellot_graphyp_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-04-14T07:48:23Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-06-19T22:31:28Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 7145222
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "460": {
        "filename": "owlcs_pizza-ontology_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2016-11-29T23:21:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-08T02:24:56Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Web Ontology Language",
                    "name": "Web Ontology Language",
                    "type": "Programming_language",
                    "size": 163301
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "461": {
        "filename": "AndreaTocchetti_ACMReviewPaperPolimiDelft_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-10-13T08:12:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-01-16T12:28:35Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "TeX",
                    "name": "TeX",
                    "type": "Programming_language",
                    "size": 29799491
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 39725
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 3298
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "462": {
        "filename": "SUSTechGameAI_MFEDRL_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "* Python 3.9.6\n* JPype 1.3.0\n* pygame 2.0.1\n* dtw 1.4.0\n* scipy 1.7.2\n* torch 1.9.0+cu111\n* numpy 1.20.3\n* gym 0.21.0 \n",
                    "original_header": "Environments that have been tested"
                },
                "confidence": 0.9978247720223525,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/SUSTechGameAI/MFEDRL/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-07-26T03:53:34Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-30T09:34:25Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 171858
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 3370
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 2104
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "463": {
        "filename": "sm-ai-team_simplemind_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Run the following instructions in a Bash shell.\n\nFirst, establish the directory to be used for hosting your dev code:\n```bash\n# Replace this path to wherever you plan to hold your development directories\nexport dev_dir=\"/your/path/to/dev/dir\"\n\n# If you haven't made this directory yet, make it\nmkdir $dev_dir\n```\n\nInstalling SimpleMind within your development directory:\n```bash\n# Change to your dev directory\ncd $dev_dir\n\n# Clone the repository\ngit clone https://gitlab.com/sm-ai-team/simplemind.git\n\n### if that doesn't work, try this:\n# git clone https://gitlab.com/sm-ai-team/simplemind.git\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Installing SM",
                    "parent_header": [
                        "SimpleMind adds thinking to deep neural networks",
                        "Getting started"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://gitlab.com/sm-ai-team/simplemind/-/blob/develop/README.md"
            },
            {
                "result": {
                    "value": "A Docker image with the prerequisites can be built -- please see [this](docker/README.md). Note that if you use the Docker image, the `core` can be called via `/core` within the Docker image (rather than `./core` in the below examples). \n\n```bash\ncd $dev_dir/simplemind\ndocker build -t sm:everything -f docker/Dockerfile_everything --no-cache  .\n\n### IMPORTANT: if building in an M1 Mac (and possibly a pre-M1 Mac), add `--platform linux/amd64` in the docker build command\n\n### i.e.\n# docker build -t sm:everything -f docker/Dockerfile_everything --platform linux/amd64 --no-cache  .\n\n# Test the SM-Core\ncd $dev_dir/simplemind\ndocker run --ipc=host -v $PWD:/workdir  -it sm:everything bash\n/core run /sm/core_src/test-files/ping-pong.yaml\n\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "[RECOMMENDED] Installing dependencies with a Docker:",
                    "parent_header": [
                        "SimpleMind adds thinking to deep neural networks",
                        "Getting started",
                        "Installing SM dependencies"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://gitlab.com/sm-ai-team/simplemind/-/blob/develop/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "```bash\ncd $dev_dir\ndocker run --ipc=host -v $PWD:/workdir -w /workdir -it sm:everything bash\n\ncd simplemind/simplemind/agent/scratch\n/core generate sm-flex-agent --name my-awesome-agent\n\n### The agent name should use \"-\" rather than \"_\"\n### This will generate a .py file in the scratch directory\n\n```\n \n",
                    "original_header": "Creating flex agent code"
                },
                "confidence": 0.9992568676033767,
                "technique": "supervised_classification",
                "source": "https://gitlab.com/sm-ai-team/simplemind/-/blob/develop/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "When updating existing code, two tests should be performed before making a merge request.\n1) The CXR example in the `simplemind` repo.\n* Follow the [instructions](#running-a-basic-example) above to run the example\n* Ensure that the output images are consistent with those shown in the [example explanation](#explaining-the-example)\n2) The UCLA Knowledge Graph in the `simplemind-applications` repo.\n* Pull the latest repo updates in the `develop` branch\n* Follow the instructions for *Running the ucla_think_kg.yaml*\n* Ensure that the outputs are consistent with the images shown \n",
                    "original_header": "Code repo practices"
                },
                "confidence": 0.9516961887074697,
                "technique": "supervised_classification",
                "source": "https://gitlab.com/sm-ai-team/simplemind/-/blob/develop/README.md"
            }
        ],
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "464": {
        "filename": "bwapi_bwapi_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "You may experience issues when working with BWAPI. Here are some steps you may want to follow in order to resolve them.\n1. Check the log files found in `Starcraft/Errors/`.\n2. Ask in the IRC channel if anyone has experienced your issue before.\n3. Check the Issue Tracker to see if your issue has already been reported.\n4. Submit an issue to the Issue Tracker. Some pieces of information to consider submitting are\n  * Log files\n  * Screenshots\n  * Version or revision number\n  * Operating System\n  * **Steps to reproduce the problem** \n",
                    "original_header": "Issues {#issues}"
                },
                "confidence": 0.9999996844462586,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/bwapi/bwapi/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2014-01-19T16:43:45Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-16T04:47:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 3067074
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Inno Setup",
                    "name": "Inno Setup",
                    "type": "Programming_language",
                    "size": 534085
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C#",
                    "name": "C#",
                    "type": "Programming_language",
                    "size": 135355
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 31105
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 15766
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "SWIG",
                    "name": "SWIG",
                    "type": "Programming_language",
                    "size": 10814
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 1916
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "VBScript",
                    "name": "VBScript",
                    "type": "Programming_language",
                    "size": 1779
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "465": {
        "filename": "stellargraph_stellargraph_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Data for StellarGraph can be prepared using common libraries like Pandas and scikit-learn.\n\n``` python\nimport pandas as pd\nfrom sklearn import model_selection\n\ndef load_my_data():\n    # your own code to load data into Pandas DataFrames, e.g. from CSV files or a database\n    ...\n\nnodes, edges, targets = load_my_data()\n\n# Use scikit-learn to compute training and test sets\ntrain_targets, test_targets = model_selection.train_test_split(targets, train_size=0.5)\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Data preparation",
                    "parent_header": [
                        "StellarGraph Machine Learning Library",
                        "Example: GCN"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/stellargraph/stellargraph/develop/README.md"
            },
            {
                "result": {
                    "value": "StellarGraph is a Python 3 library and we recommend using Python version `3.6`. The required Python version\ncan be downloaded and installed from [python.org](https://python.org/). Alternatively, use the Anaconda Python\nenvironment, available from [anaconda.com](https://www.anaconda.com/products/individual#Downloads).\n\nThe StellarGraph library can be installed from PyPI, from Anaconda Cloud, or directly from GitHub, as described below.\n",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "StellarGraph Machine Learning Library"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/stellargraph/stellargraph/develop/README.md"
            },
            {
                "result": {
                    "value": "To install StellarGraph library from [PyPI](https://pypi.org) using `pip`, execute the following command:\n```\npip install stellargraph\n```\n\n[Some of the examples][demos] require installing additional dependencies as well as `stellargraph`. To install these dependencies as well as StellarGraph using `pip` execute the following command:\n```\npip install stellargraph[demos]\n```\n\nThe community detection demos require `python-igraph` which is only available on some platforms. To install this in addition to the other demo requirements:\n```\npip install stellargraph[demos,igraph]\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Install StellarGraph using PyPI:",
                    "parent_header": [
                        "StellarGraph Machine Learning Library",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/stellargraph/stellargraph/develop/README.md"
            },
            {
                "result": {
                    "value": "The StellarGraph library is available an [Anaconda Cloud](https://anaconda.org/stellargraph/stellargraph) and can be installed in [Anaconda Python](https://anaconda.com) using the command line `conda` tool, execute the following command:\n```\nconda install -c stellargraph stellargraph\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Install StellarGraph in Anaconda Python:",
                    "parent_header": [
                        "StellarGraph Machine Learning Library",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/stellargraph/stellargraph/develop/README.md"
            },
            {
                "result": {
                    "value": "First, clone the StellarGraph repository using `git`:\n```\ngit clone https://github.com/stellargraph/stellargraph.git\n```\n\nThen, `cd` to the StellarGraph folder, and install the library by executing the following commands:\n```\ncd stellargraph\npip install .\n```\n\nSome of the examples in the `demos` directory require installing additional dependencies as well as `stellargraph`. To install these dependencies as well as StellarGraph using `pip` execute the following command:\n```\npip install .[demos]\n```\n\n",
                    "type": "Text_excerpt",
                    "original_header": "Install StellarGraph from GitHub source:",
                    "parent_header": [
                        "StellarGraph Machine Learning Library",
                        "Installation"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/stellargraph/stellargraph/develop/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2018-04-13T07:35:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T13:59:18Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1740018
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 18236
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Dockerfile",
                    "name": "Dockerfile",
                    "type": "Programming_language",
                    "size": 3274
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "466": {
        "filename": "edgetrier_AI-Reasoner_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-05-27T22:11:08Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-11-26T21:40:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 295477
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "467": {
        "filename": "boschresearch_KGE-Welding_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "468": {
        "filename": "drugs4covid_EBOCA-Resources_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2022-06-08T07:40:52Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-06-09T12:16:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 352
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "469": {
        "filename": "idsia_credici_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "Add the following code in the  pom.xml of your project:\n\n```\n    <repositories>\n        <repository>\n            <id>cremaRepo</id>\n            <url>https://raw.github.com/idsia/crema/mvn-repo/</url>\n        </repository>\n    </repositories>\n\n    <dependencies>\n        <dependency>\n            <groupId>ch.idsia</groupId>\n            <artifactId>credici</artifactId>\n            <version>0.1.4</version>\n            <scope>compile</scope>\n        </dependency>\n    </dependencies>\n```",
                    "type": "Text_excerpt",
                    "original_header": "Installation"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/idsia/credici/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-06-12T14:48:46Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-02T14:18:51Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Java",
                    "name": "Java",
                    "type": "Programming_language",
                    "size": 249288
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "470": {
        "filename": "obsproject_obs-studio_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": ".. image:: https://github.com/obsproject/obs-studio/actions/workflows/push.yaml/badge.svg?branch=master\n   :alt: OBS Studio Build Status - GitHub Actions\n   :target: https://github.com/obsproject/obs-studio/actions/workflows/push.yaml?query=branch%3Amaster \n.. image:: https://badges.crowdin.net/obs-studio/localized.svg\n   :alt: OBS Studio Translation Project Progress\n   :target: https://crowdin.com/project/obs-studio \n.. image:: https://img.shields.io/discord/348973006581923840.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2\n   :alt: OBS Studio Discord Server\n   :target: https://obsproject.com/discord\n \n",
                    "original_header": "OBS Studio <a href=\"https://obsproject.com\">https://obsproject.com</a>"
                },
                "confidence": 0.999680165500007,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/obsproject/obs-studio/master/README.rst"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "- Website: https://obsproject.com \n- Help/Documentation/Guides: https://github.com/obsproject/obs-studio/wiki \n- Forums: https://obsproject.com/forum/ \n- Build Instructions: https://github.com/obsproject/obs-studio/wiki/Install-Instructions \n- Developer/API Documentation: https://obsproject.com/docs \n- Donating/backing/sponsoring: https://obsproject.com/contribute \n- Bug Tracker: https://github.com/obsproject/obs-studio/issues\n \n",
                    "original_header": "Quick Links"
                },
                "confidence": 0.9958467993372827,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/obsproject/obs-studio/master/README.rst"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "`PVS-Studio <https://pvs-studio.com/pvs-studio/?utm_source=website&utm_medium=github&utm_campaign=open_source>`_ - static analyzer for C, C++, C#, and Java code.\n \n",
                    "original_header": "SAST Tools"
                },
                "confidence": 0.9999994492742796,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/obsproject/obs-studio/master/README.rst"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2013-10-01T02:40:31Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-22T09:12:58Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 6785914
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "C++",
                    "name": "C++",
                    "type": "Programming_language",
                    "size": 4300853
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "CMake",
                    "name": "CMake",
                    "type": "Programming_language",
                    "size": 756237
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Objective-C",
                    "name": "Objective-C",
                    "type": "Programming_language",
                    "size": 274871
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Objective-C++",
                    "name": "Objective-C++",
                    "type": "Programming_language",
                    "size": 198887
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "M",
                    "name": "M",
                    "type": "Programming_language",
                    "size": 27681
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Swift",
                    "name": "Swift",
                    "type": "Programming_language",
                    "size": 19545
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Lua",
                    "name": "Lua",
                    "type": "Programming_language",
                    "size": 15045
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 9593
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 7238
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "SWIG",
                    "name": "SWIG",
                    "type": "Programming_language",
                    "size": 7055
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Batchfile",
                    "name": "Batchfile",
                    "type": "Programming_language",
                    "size": 3177
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "AppleScript",
                    "name": "AppleScript",
                    "type": "Programming_language",
                    "size": 2406
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "471": {
        "filename": "solimul_yal-lin_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "./configure.sh\nmake\n \n",
                    "original_header": "Build Commands"
                },
                "confidence": 0.9832350282143723,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/solimul/yal-lin/master/README"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-03-22T21:50:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-03-30T23:28:29Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "C",
                    "name": "C",
                    "type": "Programming_language",
                    "size": 159868
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 1799
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "472": {
        "filename": "LHRLAB_NQE_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "* *Linux(SSH) + Python3.7.13 + Pytorch1.8.1 + Cuda10.2*\n\n```\npip install torch==1.8.1+cu102 torchvision==0.9.1+cu102 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Default implementation environment",
                    "parent_header": [
                        "NQE",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/LHRLAB/NQE/main/README.md"
            },
            {
                "result": {
                    "value": "Install dependencies:\n```\npip install -r requirements.txt\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Install Dependencies",
                    "parent_header": [
                        "NQE",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/LHRLAB/NQE/main/README.md"
            },
            {
                "result": {
                    "value": "We tested the effectiveness of our model on two datasets, including the WD50K-QE dataset and the WD50K-NFOL dataset.\n\n* WD50K-QE dataset is a dataset created with the multi-hop reasoning method StarQE. It covering multi-hop reasoning with conjunction logic operation. We call it \"wd50k_qe\" in the code. You can download and upzip the WD50K-QE dataset file from [TeraBox](https://terabox.com/s/1jiIHls_9FSoY--ULOMpcOg) or [Baidu Netdisk](https://pan.baidu.com/s/1IIFaPfXQIKKdWbX1HX6heA?pwd=26mp).\n\n```\nunzip wd50k_qe.zip -d data/\n```\n\n* WD50K-NFOL is a hyper-relational dataset we created covering logical operations including conjunction, disjunction and negation as well as combined operations. We call it \"wd50k_nfol\" in the code. You can download and upzip the WD50K-NFOL dataset file from [TeraBox](https://terabox.com/s/1qX58BMsVvTOZujndCFl9jg) or [Baidu Netdisk](https://pan.baidu.com/s/1D8ATQIEuwlZIa3LJJRjRPg?pwd=72ag). \n\n```\nunzip wd50k_nfol.zip -d data/\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Configure the Dataset",
                    "parent_header": [
                        "NQE",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/LHRLAB/NQE/main/README.md"
            },
            {
                "result": {
                    "value": "Then, we should generate the groundtruth of the chosen dataset for evaluation. If you don't change the dataset, please skip this step, because the zip files above have already got the groundtruth in \"gt\\\" file by following operation.\n\n* For WD50K-QE dataset:\n```\npython src/generate_groundtruth.py --dataset wd50k_qe\n```\n* For WD50K-NFOL dataset:\n```\npython src/generate_groundtruth.py --dataset wd50k_nfol\n```\n",
                    "type": "Text_excerpt",
                    "original_header": "Generate the Groundtruth",
                    "parent_header": [
                        "NQE",
                        "Setup"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/LHRLAB/NQE/main/README.md"
            },
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "After training, you can only run prediction using \"src/map_iter_qe.py\" by with argument \"do_learn\" False and argument \"do_predict\" True. In this case, you need to select the ckpts file you want to use and configure the \"prediction_ckpt\" argument as you want. \n",
                    "original_header": "Evaluation"
                },
                "confidence": 0.9999939491307858,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/LHRLAB/NQE/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-11-21T03:41:20Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-26T01:29:48Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 151699
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "473": {
        "filename": "pivithuruthejanamarasinghe_AI-Copilot-Data_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-09-13T07:22:18Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-25T03:45:33Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "474": {
        "filename": "pipihaiziguai_T3OMVP_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "- Clone this repo:\n```bash\ngit clone https://github.com/its-ant-bupt/T3OMVP.git\ncd T3OMVP\n```",
                    "type": "Text_excerpt",
                    "original_header": "Installation",
                    "parent_header": [
                        "T3OMVP",
                        "Getting Started"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/pipihaiziguai/T3OMVP/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2022-02-23T06:36:59Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-06-25T19:56:14Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 100830
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "475": {
        "filename": "hhdo_DaeMon_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "<img src=\"https://github.com/hhdo/DaeMon/blob/main/img/DaeMon.png\" alt=\"DaeMon_Architecture\" width=\"800\" class=\"center\">\n \n",
                    "original_header": "Adaptive Path-Memory Network for Temporal Knowledge Graph Reasoning"
                },
                "confidence": 0.9806699749603923,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/hhdo/DaeMon/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2023-01-20T17:08:37Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-07-19T07:37:24Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 48487
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "476": {
        "filename": "meta-logic_lltp_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2017-03-23T11:54:14Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-05-15T09:54:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "OpenEdge ABL",
                    "name": "OpenEdge ABL",
                    "type": "Programming_language",
                    "size": 1005693952
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "OCaml",
                    "name": "OCaml",
                    "type": "Programming_language",
                    "size": 16094
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 7849
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 5847
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Makefile",
                    "name": "Makefile",
                    "type": "Programming_language",
                    "size": 374
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "477": {
        "filename": "balabit_Mouse-Dynamics-Challenge_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "value": "This repository contains the **[Balabit Mouse Dynamics Challenge][balabit]** data set which includes timing and positioning information of mouse pointers. It can be used for evaluating the performance of behavioral biometric algorithms based on mouse dynamics for user authentication/identification purposes.  \nWe make the data set accessible to researchers and experts in the fields of IT security and data science with the hope of contributing to research and providing a benchmark data set.  \nThe data set was first made public during a data science competition on [datapallet.io][datapallet]. The files and descriptions in this repository originate from the challenge itself.  \n\n[balabit]: https://medium.com/balabit-unsupervised/releasing-the-balabit-mouse-dynamics-challenge-data-set-a15a016fba6c\n[datapallet]: https://datapallet.io\n",
                    "type": "Text_excerpt",
                    "original_header": "BALABIT MOUSE CHALLENGE DATA SET"
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/balabit/Mouse-Dynamics-Challenge/master/README.md"
            },
            {
                "result": {
                    "value": "The goal of the challenge was to protect a set of users from the unauthorized usage of their accounts by learning the characteristics of how they use their mouses.  \n\nDuring their work, these users usually log in to remote servers with their remote desktop client. A network monitoring device is set between the client and the remote computer that inspects all traffic as described by the RDP protocol. This includes the mouse interactions of the user that is transmitted from the client to the server during the remote session.  \n\nOnce in a while, a user account is stolen and is being used illegally, i.e., by a person that is not the legit owner of the account.  \n\nHow can you detect such misuses?  \nFortunately, you have access to the data that was recorded by the network monitoring device. Also, it is supposed that the way a person moves their mouse is specific to them and can be used as a kind of behavioral biometric identifier.  \nIf you could in fact identify the typical patterns of each user, you would be able to easily notice a stolen account by seeing that the mouse movement data going from the account to the remote server is not characteristic of the owner of said account.  \n\nYou have to build a model that can fulfil this task.  \n",
                    "type": "Text_excerpt",
                    "original_header": "The Challenge",
                    "parent_header": [
                        "BALABIT MOUSE CHALLENGE DATA SET"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/balabit/Mouse-Dynamics-Challenge/master/README.md"
            },
            {
                "result": {
                    "value": "The 'training_files' folder contains 10 folders, one for every user account in the system. In each of these folders, you are given the data of a few remote sessions that are known to be carried out by the legal owners of the respective user accounts.  \n\nThe 'test_files' folder contains also 10 folders. Each folder represents a user account, and comprises the data of several shorter sessions. Each of these test sessions was recorded as the session of the respective user account; however, the true identity of the user in a test session is unknown.  \n\nThe fields of each session file is to be translated as follows:  \n- *record timestamp*: elapsed time (in sec) since the start of the session as recorded by the netork monitoring device  \n- *client timestamp*: elapsed time (in sec) since the start of the session as recorded by the RDP client  \n- *button*: the current condition of the mouse buttons  \n- *state*: additional information about the current state of the mouse  \n- *x*: the x coordinate of the cursor on the screen  \n- *y*: the y coordinate of the cursor on the screen  \n",
                    "type": "Text_excerpt",
                    "original_header": "Session Files",
                    "parent_header": [
                        "BALABIT MOUSE CHALLENGE DATA SET"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/balabit/Mouse-Dynamics-Challenge/master/README.md"
            },
            {
                "result": {
                    "value": "In the challenge, for each test session file the task was to provide an anomaly score between 0 and 1 that tells how unlikely it is that the remote session was carried out by the respective user account. Submissions were judged on the area under the ROC curve. The AUC was calculated in a global manner (all predictions together).  \n\nThe 'public_labels.csv' file contains the labels of the *public part* of the test data (i.e., those that contributed to the public leaderboard score). Each row describes whether a certain test session capture a legal or an illegal session.  \n",
                    "type": "Text_excerpt",
                    "original_header": "Labels",
                    "parent_header": [
                        "BALABIT MOUSE CHALLENGE DATA SET"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/balabit/Mouse-Dynamics-Challenge/master/README.md"
            },
            {
                "result": {
                    "value": "Although this data set is offered as benchmark data for detecting illegal account usages, during its creation no such misuses were carried out. All recorded data reflect work executed during authenticated remote sessions that have not been hijacked. The attacks are imitated. For each user, in order to simulate illegal usage of his/her account, data from other users are artificially mixed into the test data of said user. Since all users engage in the same kind of unspecified administative tasks, the data from the artificial attackers do not reflect malicious activities.  \n",
                    "type": "Text_excerpt",
                    "original_header": "Attack Model",
                    "parent_header": [
                        "BALABIT MOUSE CHALLENGE DATA SET"
                    ]
                },
                "confidence": 1,
                "technique": "header_analysis",
                "source": "https://raw.githubusercontent.com/balabit/Mouse-Dynamics-Challenge/master/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2016-08-01T14:42:36Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-04-13T16:23:30Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    },
    "478": {
        "filename": "microsoft_responsible-ai-toolbox_2024-08-22.json",
        "installation_instructions": [
            {
                "result": {
                    "type": "Text_excerpt",
                    "value": "\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/microsoft/responsible-ai-widgets/main/img/responsible-ai-toolbox.png\" alt=\"ResponsibleAIToolboxOverview\" width=\"750\"/> \n\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/microsoft/responsible-ai-widgets/main/img/responsible-ai-dashboard.png\" alt=\"ResponsibleAIDashboard\" width=\"750\"/> \nThis repository contains the Jupyter notebooks with examples to showcase how to use this widget. Get started [here](https://github.com/microsoft/responsible-ai-toolbox/blob/main/notebooks/responsibleaidashboard/tabular/getting-started.ipynb). \n\n### Installation \nUse the following pip command to install the Responsible AI Toolbox. \nIf running in jupyter, please make sure to restart the jupyter kernel after installing.\n```\npip install raiwidgets\n```\n \nIf a pipeline script is provided, the explanation function assumes that the running pipeline script returns a prediction. The repository also supports models trained via **PyTorch**, **TensorFlow**, and **Keras** deep learning frameworks. \n",
                    "original_header": "Responsible AI Toolbox"
                },
                "confidence": 0.9732817862470727,
                "technique": "supervised_classification",
                "source": "https://raw.githubusercontent.com/microsoft/responsible-ai-toolbox/main/README.md"
            }
        ],
        "date_created": [
            {
                "result": {
                    "value": "2020-07-06T20:46:53Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2024-08-19T09:24:55Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": [
            {
                "result": {
                    "value": "TypeScript",
                    "name": "TypeScript",
                    "type": "Programming_language",
                    "size": 9061112
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Python",
                    "name": "Python",
                    "type": "Programming_language",
                    "size": 1562044
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Jupyter Notebook",
                    "name": "Jupyter Notebook",
                    "type": "Programming_language",
                    "size": 327441
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "JavaScript",
                    "name": "JavaScript",
                    "type": "Programming_language",
                    "size": 30522
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "HTML",
                    "name": "HTML",
                    "type": "Programming_language",
                    "size": 740
                },
                "confidence": 1,
                "technique": "GitHub_API"
            },
            {
                "result": {
                    "value": "Shell",
                    "name": "Shell",
                    "type": "Programming_language",
                    "size": 242
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ]
    },
    "479": {
        "filename": "oogle_tuning_playbook_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": "No date_created found.",
        "date_updated": "No date_updated found.",
        "programming_languages": "No programming languages found."
    },
    "480": {
        "filename": "n-brindise_pointwiseExpl-example_2024-08-22.json",
        "installation_instructions": "No installation instructions found.",
        "date_created": [
            {
                "result": {
                    "value": "2023-03-31T09:10:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "date_updated": [
            {
                "result": {
                    "value": "2023-03-31T09:10:47Z",
                    "type": "Date"
                },
                "confidence": 1,
                "technique": "GitHub_API"
            }
        ],
        "programming_languages": "No programming languages found."
    }
}